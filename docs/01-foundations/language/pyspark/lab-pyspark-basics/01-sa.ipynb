{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import collections\n",
    "from operator import add\n",
    "from pyspark.sql import (Row, SparkSession)\n",
    "from pyspark.sql.functions import (\n",
    "    avg,\n",
    "    col,\n",
    "    round as rnd,\n",
    "    asc,\n",
    "    desc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDD : immutable distributed collection of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[816, 823, 678, 238, 491]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1000))\n",
    "rdd.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('world', 6), ('hello', 6)]\n"
     ]
    }
   ],
   "source": [
    "test_file = \"data/raw/word.txt\"\n",
    "text_file = sc.textFile(test_file)\n",
    "counts = text_file.flatMap(lambda line : line.split(\" \")) \\\n",
    "                .map(lambda word : (word, 1)) \\\n",
    "                .reduceByKey(lambda a, b: a + b)\n",
    "print(counts.collect())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90: 2\n",
      "70: 1\n",
      "80: 1\n",
      "100: 1\n"
     ]
    }
   ],
   "source": [
    "test_file = \"data/raw/grade.txt\"\n",
    "text_file = sc.textFile(test_file)\n",
    "grade = text_file.map(lambda line: line.split(\" \")[1])\n",
    "\n",
    "# Return the count of each unique value in this RDD as a dictionary of (value, count) pairs.\n",
    "grade_count = grade.countByValue()\n",
    "    \n",
    "for grade, count in sorted(grade_count.items(), key= lambda item: item[1], reverse=True):\n",
    "    print(f\"{grade}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 2), ('b', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating Key / Value RDD\n",
    "# reduceByKey(): Merge the values for each key using an associative and commutative reduce function.\n",
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "sorted(rdd.reduceByKey(add).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 2), ('b', 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupByKey(): Group the values for each key in the RDD into a single sequence. Hash-partitions the resulting RDD with numPartitions partitions.\n",
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "sorted(rdd.groupByKey().mapValues(len).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [1, 1]), ('b', [1])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rdd.groupByKey().mapValues(list).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1', 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sortByKey(): Sorts this RDD, which is assumed to consist of (key, value) pairs.\n",
    "tmp = [('a', 1), ('b', 2), ('1', 3), ('d', 4), ('2', 5)]\n",
    "sc.parallelize(tmp).sortByKey().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[52] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keys(), values(): Create a RDD of keys or just values\n",
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])\n",
    "rdd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', (1, 2)), ('a', (1, 3))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join, rightOuterJoin, leftOuterJoin, cogroup, subtractByKey\n",
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
    "y = sc.parallelize([(\"a\", 2), (\"a\", 3)])\n",
    "sorted(x.join(y).collect())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency is the key for performance!!!\n",
    "\n",
    "if you only need values, use mapValues() or flatMapValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auckland: 49.856\n",
      "NA: 12.4682\n",
      "Johannesburg: 42.1772\n",
      "Marseille: 39.3908\n",
      "Odesa: 14.8838\n",
      "Tottori: 34.2518\n",
      "Warsaw: 6.8\n",
      "BrasÃ­lia: 62.9744\n",
      "Canoas: 50.009\n",
      "Cape Town: 49.9946\n",
      "Hamilton: 44.564\n",
      "Kherson: 7.0952\n",
      "Kiev: 2.85619999999999\n",
      "Lvov: 7.1726\n",
      "Paris: 25.0232\n",
      "Stockholm: 13.3988\n",
      "Tokyo: 29.156\n",
      "Uppsala: 6.0494\n",
      "Wroclaw: 9.167\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "# Return a new RDD containing only the elements that satisfy a predicate.\n",
    "test_file = \"data/raw/temperature.csv\"\n",
    "\n",
    "def get_data(line, header):\n",
    "    if line != header:\n",
    "        col = line.split(',')\n",
    "        city = col[6].strip(\"\\\"\")\n",
    "        avg_temp_fahr = col[4]\n",
    "        yield (city, avg_temp_fahr)\n",
    "    \n",
    "lines = sc.textFile(test_file)\n",
    "\n",
    "# get header string\n",
    "header = lines.first()\n",
    "\n",
    "parsed_line = lines.flatMap(lambda line: get_data(line, header))\n",
    "\n",
    "# filter NA values\n",
    "filtered_line = parsed_line.filter(lambda x: \"NA\" not in x[1])\n",
    "\n",
    "# finding min temperature\n",
    "min_temp = filtered_line.reduceByKey(lambda x, y: min(float(x), float(y)))\n",
    "final_list = min_temp.collect();\n",
    "for city, temperature in final_list:\n",
    "    print(f\"{city}: {temperature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10000, 4.0), (40000, 7.0), (5000, 7.0), (4000, 2.0), (9000, 4.0), (8000, 9.0)]\n"
     ]
    }
   ],
   "source": [
    "test_file = \"data/raw/house_price.csv\"\n",
    "\n",
    "def parse_line(line: str):\n",
    "    city, price, count = line.split(',')\n",
    "    return (int(price), int(count))\n",
    "\n",
    "lines = sc.textFile(test_file)\n",
    "price_count = lines.map(parse_line)\n",
    "# [(10000, 3), (10000, 5), (40000, 7), (5000, 7), (4000, 2), (9000, 4), (5000, 7), (4000, 2), (8000, 9)]\n",
    "\n",
    "sum_of_count = price_count.mapValues(lambda count: (count, 1))\\\n",
    "                .reduceByKey(lambda a, b: (int(a[0]) + int(b[0]), int(a[1]) + int(b[1]))) \n",
    "\n",
    "# ('10000', (3, 1)), ('10000', (5, 1)) ...\n",
    "# [('10000', (8, 2)), ('4000', (4, 2)), ('9000', ('4', 1)), ('8000', ('9', 1)), ('40000', ('7', 1)), ('5000', (14, 2))]\n",
    "\n",
    "avg_by_count = sum_of_count.mapValues(lambda total_count: int(total_count[0]) / total_count[1])\n",
    "results = avg_by_count.collect()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['joe', 'sarah', 'tom'], ['hyundai']]\n"
     ]
    }
   ],
   "source": [
    "# map vs. flatMap\n",
    "\n",
    "# map transformation applies a function to each row in a DataFrame/Dataset and returns the new transformed Dataset.\n",
    "# 1 => 1\n",
    "# flatMap transformation flattens the DataFrame/Dataset after applying the function on every element and returns a new transformed Dataset. The returned Dataset will return more rows than the current DataFrame. It is also referred to as a one-to-many transformation function\n",
    "# 1 => Many\n",
    "# One of the use cases of flatMap() is to flatten column which contains arrays, list, or any nested collection\n",
    "\n",
    "rdd = sc.parallelize([(\"name\", \"joe,sarah,tom\"), (\"car\", \"hyundai\")])\n",
    "result = rdd.map(lambda x: x[1].split(\",\"))\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joe', 'sarah', 'tom', 'hyundai']\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([(\"name\", \"joe,sarah,tom\"), (\"car\", \"hyundai\")])\n",
    "result = rdd.flatMap(lambda x: x[1].split(\",\"))\n",
    "print(result.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+------------+\n",
      "|              name|             country|               email|compensation|\n",
      "+------------------+--------------------+--------------------+------------+\n",
      "|  Willian Cummings|             Senegal|    areus@test.canon|       77369|\n",
      "|      Clarita Gill|             Ecuador| tomaslau@test.games|       86986|\n",
      "| Walter Washington|          Kazakhstan|mbilderbach@examp...|       91072|\n",
      "|       Lexie Banks|                Mali|unterdreht@test.date|       97933|\n",
      "|        Luise Hunt|               Kenya|adellecharles@tes...|       96175|\n",
      "|     Sebrina Walsh|         Puerto Rico|andrewcohen@examp...|       99276|\n",
      "|      Josiah Lyons|              Malawi|nandini_m@test.ry...|       91768|\n",
      "|      Temeka Grant|              Israel|terryxlife@test.g...|       71642|\n",
      "|  Narcisa Saunders|Palestinian Terri...|raquelwilson@exam...|       77287|\n",
      "|      Lisbeth Lane|          Azerbaijan|coreyweb@test.coffee|       82473|\n",
      "|       Evan Lawson|               Tonga|claudioguglieri@e...|       84796|\n",
      "|Gearldine Mcdaniel|            Slovenia|xtopherpaul@examp...|       96005|\n",
      "|   Kristel Jenkins|        Cook Islands|randomlies@exampl...|       79421|\n",
      "|   Douglass Porter|            Cambodia|ludwiczakpawel@ex...|       79263|\n",
      "|      Ahmed Warren|              Israel|brajeshwar@exampl...|       90636|\n",
      "|       Norah Reyes|   Brunei Darussalam|   soffes@example.mt|       80723|\n",
      "|      Emerita Ward|       Guinea-Bissau|nandini_m@example...|       88913|\n",
      "|   Hassan Mcdaniel|            Kiribati|  soffes@example.day|       93460|\n",
      "|   Joannie Bradley|             Bolivia|ehsandiary@test.o...|       96565|\n",
      "|     Gaylene Ellis|Palestinian Terri...|timmillwood@examp...|       95569|\n",
      "+------------------+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def parse_line(line: str):\n",
    "    fields = line.split('|') # |\n",
    "    return Row(\n",
    "        name=str(fields[0]),\n",
    "        country=str(fields[1]),\n",
    "        email=str(fields[2]),\n",
    "        compensation=int(fields[3]))\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
    "lines = spark.sparkContext.textFile(\"data/raw/income.txt\")\n",
    "income_data = lines.map(parse_line)\n",
    "\n",
    "# Creates a DataFrame from an RDD, a list or a pandas.DataFrame.\n",
    "# SparkSession.createDataFrame(data, schema=None, samplingRatio=None, verifySchema=True)[source]\n",
    "schema_income = spark.createDataFrame(data=income_data).cache()\n",
    "\n",
    "# Creates or replaces a local temporary view with this DataFrame.\n",
    "schema_income.createOrReplaceTempView(\"income\")\n",
    "\n",
    "# returns the dataframe\n",
    "medium_income_df = spark.sql(\n",
    "    \"SELECT * FROM income WHERE compensation >= 70000 AND compensation <= 100000\")\n",
    "medium_income_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"sql_import_csv\").getOrCreate()\n",
    "csv_file_path = \"data/raw/age.csv\"\n",
    "\n",
    "# header option: either csv has header or not (default: header = false)\n",
    "# inferSchema: either all columns are str or not\n",
    "\n",
    "data = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(csv_file_path)\n",
    "\n",
    "# show schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+\n",
      "|             name|age|\n",
      "+-----------------+---+\n",
      "|    Neville Hardy| 56|\n",
      "|      Dacia Cohen| 74|\n",
      "|    Kathey Daniel| 10|\n",
      "|     Mallie Welch| 12|\n",
      "|     Katia Bryant| 14|\n",
      "|Laurice Robertson| 53|\n",
      "|     Minh Barrett| 27|\n",
      "|   Latashia Perez| 52|\n",
      "|      Elvina Ross| 68|\n",
      "|  Augustus Snyder| 20|\n",
      "|        Elois Cox| 65|\n",
      "|    Jolanda Dixon| 14|\n",
      "|      Rutha Young| 10|\n",
      "| Waltraud Holland| 10|\n",
      "|   Colton Flowers| 77|\n",
      "|     Meri Hawkins| 43|\n",
      "|     Theola Mason| 71|\n",
      "|  Antonia Pearson| 25|\n",
      "|   Delicia Murray| 41|\n",
      "|    Cicely Harvey| 37|\n",
      "+-----------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show column name with data\n",
    "data.select(\"name\", \"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+--------------------+\n",
      "|             name|age|             country|\n",
      "+-----------------+---+--------------------+\n",
      "|    Neville Hardy| 56|                Niue|\n",
      "|      Dacia Cohen| 74|Falkland Islands ...|\n",
      "|Laurice Robertson| 53|        Saudi Arabia|\n",
      "|     Minh Barrett| 27|French Southern T...|\n",
      "|   Latashia Perez| 52|             Finland|\n",
      "|      Elvina Ross| 68|         New Zealand|\n",
      "|        Elois Cox| 65|            Paraguay|\n",
      "|   Colton Flowers| 77|Saint Vincent and...|\n",
      "|     Meri Hawkins| 43|             Jamaica|\n",
      "|     Theola Mason| 71|              Gambia|\n",
      "|  Antonia Pearson| 25|             Namibia|\n",
      "|   Delicia Murray| 41|         El Salvador|\n",
      "|    Cicely Harvey| 37|              Belize|\n",
      "|    Berry Russell| 49|       New Caledonia|\n",
      "|   Lauryn Hubbard| 80|           Mauritius|\n",
      "|    Judson Willis| 34|              Sweden|\n",
      "|     Junita Meyer| 49|             Moldova|\n",
      "|        Apryl Fox| 48|            Maldives|\n",
      "|   Dorsey Wheeler| 56|Sao Tome and Prin...|\n",
      "|       Jae Duncan| 47|              Norway|\n",
      "+-----------------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter the data for age of 20 above\n",
    "data.filter(data.age > 20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|age|count|\n",
      "+---+-----+\n",
      "| 31|   16|\n",
      "| 65|   16|\n",
      "| 53|   14|\n",
      "| 78|   16|\n",
      "| 34|   15|\n",
      "| 28|   11|\n",
      "| 76|   14|\n",
      "| 27|   10|\n",
      "| 26|   15|\n",
      "| 44|   14|\n",
      "| 12|   15|\n",
      "| 22|   17|\n",
      "| 47|   17|\n",
      "| 52|   16|\n",
      "| 13|   14|\n",
      "| 16|   18|\n",
      "| 20|   12|\n",
      "| 40|   22|\n",
      "| 57|    9|\n",
      "| 54|   17|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group by age and aggregates for count\n",
    "data.groupBy(\"age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---+----------+\n",
      "|             name|age|(age - 10)|\n",
      "+-----------------+---+----------+\n",
      "|    Neville Hardy| 56|        46|\n",
      "|      Dacia Cohen| 74|        64|\n",
      "|    Kathey Daniel| 10|         0|\n",
      "|     Mallie Welch| 12|         2|\n",
      "|     Katia Bryant| 14|         4|\n",
      "|Laurice Robertson| 53|        43|\n",
      "|     Minh Barrett| 27|        17|\n",
      "|   Latashia Perez| 52|        42|\n",
      "|      Elvina Ross| 68|        58|\n",
      "|  Augustus Snyder| 20|        10|\n",
      "|        Elois Cox| 65|        55|\n",
      "|    Jolanda Dixon| 14|         4|\n",
      "|      Rutha Young| 10|         0|\n",
      "| Waltraud Holland| 10|         0|\n",
      "|   Colton Flowers| 77|        67|\n",
      "|     Meri Hawkins| 43|        33|\n",
      "|     Theola Mason| 71|        61|\n",
      "|  Antonia Pearson| 25|        15|\n",
      "|   Delicia Murray| 41|        31|\n",
      "|    Cicely Harvey| 37|        27|\n",
      "+-----------------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# custom arithmetic\n",
    "data.select(data.name, data.age, data.age - 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----+\n",
      "|             name|age1|\n",
      "+-----------------+----+\n",
      "|    Neville Hardy|  56|\n",
      "|      Dacia Cohen|  74|\n",
      "|    Kathey Daniel|  10|\n",
      "|     Mallie Welch|  12|\n",
      "|     Katia Bryant|  14|\n",
      "|Laurice Robertson|  53|\n",
      "|     Minh Barrett|  27|\n",
      "|   Latashia Perez|  52|\n",
      "|      Elvina Ross|  68|\n",
      "|  Augustus Snyder|  20|\n",
      "|        Elois Cox|  65|\n",
      "|    Jolanda Dixon|  14|\n",
      "|      Rutha Young|  10|\n",
      "| Waltraud Holland|  10|\n",
      "|   Colton Flowers|  77|\n",
      "|     Meri Hawkins|  43|\n",
      "|     Theola Mason|  71|\n",
      "|  Antonia Pearson|  25|\n",
      "|   Delicia Murray|  41|\n",
      "|    Cicely Harvey|  37|\n",
      "+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# column alias\n",
    "data.select(data.name, col(\"age\").alias(\"age1\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             country|          avg(age)|\n",
      "+--------------------+------------------+\n",
      "|                Chad|             36.25|\n",
      "|            Paraguay| 47.77777777777778|\n",
      "|            Anguilla|              72.0|\n",
      "|               Macao|              72.0|\n",
      "|Heard Island and ...|              30.0|\n",
      "|             Senegal|              53.0|\n",
      "|              Sweden|45.333333333333336|\n",
      "|             Tokelau|34.166666666666664|\n",
      "|French Southern T...|50.666666666666664|\n",
      "|            Kiribati|48.666666666666664|\n",
      "|   Republic of Korea|58.166666666666664|\n",
      "|              Guyana|              39.0|\n",
      "|             Eritrea|             39.75|\n",
      "|              Jersey|              58.8|\n",
      "|         Philippines|48.333333333333336|\n",
      "|            Djibouti|              38.6|\n",
      "|               Tonga|              49.0|\n",
      "|      Norfolk Island|35.333333333333336|\n",
      "|            Malaysia|60.666666666666664|\n",
      "|           Singapore|              40.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# average\n",
    "data.select(data.name, data.age, data.country).groupBy(\"country\").avg(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             country|          avg(age)|\n",
      "+--------------------+------------------+\n",
      "|             Tunisia|              10.0|\n",
      "|                Iran|              14.0|\n",
      "|           Greenland|              14.5|\n",
      "|                Cuba|              15.0|\n",
      "|              Zambia|              16.0|\n",
      "|          Costa Rica|              17.0|\n",
      "|          Guadeloupe|              21.0|\n",
      "|             Ireland|              21.0|\n",
      "|            Suriname|23.333333333333332|\n",
      "|    Saint Barthelemy|              24.0|\n",
      "|              Taiwan|24.666666666666668|\n",
      "|             Namibia|              25.0|\n",
      "|             Moldova|             25.75|\n",
      "|       Faroe Islands|              26.0|\n",
      "|      Western Sahara|26.666666666666668|\n",
      "|Bouvet Island (Bo...|26.666666666666668|\n",
      "|Saint Kitts and N...|              27.0|\n",
      "|             Vietnam|             27.25|\n",
      "|   Equatorial Guinea|              27.5|\n",
      "|           Gibraltar|27.666666666666668|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# average & Sort\n",
    "data.select(data.name, data.age, data.country).groupBy(\"country\").avg(\"age\").sort(\"avg(age)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|             country|avg_age|\n",
      "+--------------------+-------+\n",
      "|                Chad|  36.25|\n",
      "|            Paraguay|  47.78|\n",
      "|            Anguilla|   72.0|\n",
      "|               Macao|   72.0|\n",
      "|Heard Island and ...|   30.0|\n",
      "|             Senegal|   53.0|\n",
      "|              Sweden|  45.33|\n",
      "|             Tokelau|  34.17|\n",
      "|French Southern T...|  50.67|\n",
      "|            Kiribati|  48.67|\n",
      "|   Republic of Korea|  58.17|\n",
      "|              Guyana|   39.0|\n",
      "|             Eritrea|  39.75|\n",
      "|              Jersey|   58.8|\n",
      "|         Philippines|  48.33|\n",
      "|            Djibouti|   38.6|\n",
      "|               Tonga|   49.0|\n",
      "|      Norfolk Island|  35.33|\n",
      "|            Malaysia|  60.67|\n",
      "|           Singapore|   40.0|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# average & round\n",
    "data.select(data.name, data.age, data.country).groupBy(\"country\").agg(rnd(avg(\"age\"), 2).alias(\"avg_age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343191058819caea96d5cde1bd3b1a75b4807623ce2cda0e1c8499e39ac847e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
