---
AWSTemplateFormatVersion: '2010-09-09'
Parameters:
  ProjectPrefix:
    Type: String
    Default: athenasns
  ProjectSuffix:
    Type: String
    Default: wys
  StringLength:
    Type: String
    Default: 10
  LogBucket:
    Type: String
    Default: wys-de
Resources:
  # Create a Lambda function that generate a random string
  LambdaForStringGeneration:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Join [ "-", [!Ref ProjectPrefix, "LambdaForStringGeneration", !Ref ProjectSuffix ] ]
      Handler: "index.lambda_handler"
      Role: !GetAtt [ LambdaGenerateStringRole, Arn ]
      Code:
        ZipFile:
          !Sub
          - |-
            import random
            import string
            import http.client
            from urllib.parse import urlparse
            import json
            import uuid

            def send_response(request, response, status=None, reason=None):
                if status is not None:
                    response['Status'] = status

                if reason is not None:
                    response['Reason'] = reason

                if 'ResponseURL' in request and request['ResponseURL']:
                    print(request['ResponseURL'])
                    url = urlparse(request['ResponseURL'])
                    body = json.dumps(response)
                    https = http.client.HTTPSConnection(url.hostname)
                    https.request('PUT', url.path+'?'+url.query, body)

                return response

            def lambda_handler(event, context):
                response = {
                    'StackId': event['StackId'],
                    'RequestId': event['RequestId'],
                    'LogicalResourceId': event['LogicalResourceId'],
                    'Status': 'SUCCESS'
                }

                if 'PhysicalResourceId' in event:
                    response['PhysicalResourceId'] = event['PhysicalResourceId']
                else:
                    response['PhysicalResourceId'] = str(uuid.uuid4())

                if event['RequestType'] == 'Delete':
                    return send_response(event, response)

                random_string = ''.join(random.choice(string.ascii_lowercase + string.digits) for _ in range(${stringLength}))

                response['Data'] = {'RandomString': random_string}
                response['Reason'] = 'Successful'
                return send_response(event, response)
          - { stringLength: !Ref StringLength}

      Runtime: "python3.7"
      Timeout: "600"
  LambdaGenerateStringRole:
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName: !Join [ "-", [!Ref ProjectPrefix, "LambdaGenerateStringRole", !Ref ProjectSuffix ] ]
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - 'sts:AssumeRole'
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
  ###
  # Create an AWS Glue database
  GlueDatabase:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref AWS::AccountId
      DatabaseInput:
        Name: !Join [ "-", [!Ref ProjectPrefix, "gluedatabase", !Ref ProjectSuffix ] ]
  ###
  # Create an AWS Athena workGroup
  AthenaWorkGroup:
    Type: AWS::Athena::WorkGroup
    Properties:
      Name: !Join [ "-", [!Ref ProjectPrefix, "AthenaWorkGroup", !Ref ProjectSuffix ] ]
      State: ENABLED
      WorkGroupConfiguration:
        EnforceWorkGroupConfiguration: false
        PublishCloudWatchMetricsEnabled: false
        RequesterPaysEnabled: true
        ResultConfiguration:
          OutputLocation: !Join [ "", ["s3://", !Ref LogBucket, "/", !Ref ProjectPrefix, "/", !Ref ProjectSuffix, "/result" ] ]
  ###
  # Create an AWS Glue crawler
  GlueCrawler:
    DependsOn: GlueDatabase
    Type: AWS::Glue::Crawler
    Properties:
      DatabaseName: !Join [ "-", [!Ref ProjectPrefix, "GlueDatabase", !Ref ProjectSuffix ] ]
      Name: !Join [ "-", [!Ref ProjectPrefix, "GlueCrawler", !Ref ProjectSuffix ] ]
      Role: !GetAtt [ GlueCrawlerExecutionRole, Arn ]
      SchemaChangePolicy:
        UpdateBehavior: "UPDATE_IN_DATABASE"
        DeleteBehavior: "LOG"
      Targets:
        S3Targets:
          - Path: !Join [ "", [ !Ref LogBucket, "/", !Ref ProjectPrefix, "/", !Ref ProjectSuffix,  "/log" ] ]
  GlueCrawlerExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Join [ "-", [!Ref ProjectPrefix, "GlueCrawlerExecutionRole", !Ref ProjectSuffix ] ]
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: glue.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: GlueCrawlerExecutionPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - glue:*
                  - s3:GetObject
                  - s3:PutObject
                  - s3:ListBucket
                  - s3:GetBucketLocation
                  - s3:GetBucketAcl
                Resource: "*"
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: !Sub "arn:${AWS::Partition}:logs:*:*:/aws-glue/*"
  ###
  # Create a Lambda function to populate log file
  LambdaForDataGeneration:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Join [ "-", [!Ref ProjectPrefix, "LambdaForDataGeneration", !Ref ProjectSuffix ] ]
      Handler: "index.lambda_handler"
      Role: !GetAtt [ LambaForDataGenerationExecutionRole, Arn ]
      Code:
        ZipFile:
          !Sub
          - |-
            import boto3
            import random
            import csv
            import json

            YEAR_RANGE_BEGIN = 0
            YEAR_RANGE_END = 19
            MAKE_RANGE_BEGIN = 0
            MAKE_RANGE_END = 25
            NUM_DATASETS = 20
            BASE_YEAR = 2000
            BASE_MAKE = 65
            year = [BASE_YEAR + i for i in range(NUM_DATASETS)]
            make = [BASE_MAKE + i for i in range(26)]

            def lambda_handler(event, context):
              s3 = boto3.resource('s3')
              columns = [['year', 'grade']]
              datasets = [[year[random.randint(YEAR_RANGE_BEGIN, YEAR_RANGE_END)], chr(make[random.randint(MAKE_RANGE_BEGIN, MAKE_RANGE_END)])] for i in range(NUM_DATASETS)]
              csv_data = columns + datasets

              bucket_name = '${bucket}'
              bucket = s3.Bucket(bucket_name)

              with open('/tmp/log.csv', 'w') as writeFile:
                  writer = csv.writer(writeFile)
                  writer.writerows(csv_data)

              bucket.upload_file('/tmp/log.csv', '${logpth}/log.csv')

              return {
                  'statusCode': 200,
                  'body': json.dumps({
                      'log': '${logpth}/log.csv',
                  })
              }
          - {
              bucket: !Ref LogBucket,
              logpth: !Join [ "/", [!Ref ProjectPrefix, !Ref ProjectSuffix, "log" ] ]
            }

      Runtime: "python3.7"
      Timeout: "600"
  LambaForDataGenerationExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Join [ "-", [!Ref ProjectPrefix, "LambaForDataGenerationExecutionRole", !Ref ProjectSuffix ] ]
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: LambaForDataGenerationExecutionPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - "s3:PutObject"
                Resource: !Join ["/", [!Join [ "", ["arn:aws:s3:::", !Ref LogBucket ] ], "*"]]
  ###
  # Creates a lambda function that invokes crawler
  LambdaForInvokingCrawler:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Join [ "-", [!Ref ProjectPrefix, "LambdaForInvokingCrawler", !Ref ProjectSuffix ] ]
      Handler: "index.lambda_handler"
      Role: !GetAtt [ LambaForCrawlerInvocationExecutionRole, Arn ]
      Code:
        ZipFile:
          !Sub
          - |-
            import json
            import boto3
            import time

            MAX_RETRY = 20
            def lambda_handler(event, context):
              client = boto3.client('glue')
              response = client.start_crawler(
                  Name='${crawler}'
              )
              retry_count = 1
              while retry_count < MAX_RETRY:
                  time.sleep(30)
                  crawler_status = client.get_crawler(
                      Name='${crawler}'
                  )
                  crawler_run_status = crawler_status['Crawler']['State']
                  if crawler_run_status == 'READY':
                      break
                  retry_count += 1
              return {
                  'statusCode': 200,
                  'body': json.dumps('Crawler completes')
              }
          - { crawler: !Join [ "-", [!Ref ProjectPrefix, "GlueCrawler", !Ref ProjectSuffix ] ]}

      Runtime: "python3.7"
      Timeout: "600"
  LambaForCrawlerInvocationExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Join [ "-", [!Ref ProjectPrefix, "LambaForCrawlerInvocationExecutionRole", !Ref ProjectSuffix ] ]
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: LambaForCrawlerInvocationExecutionPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - glue:StartCrawler
                  - glue:GetCrawler
                Resource: "*"
  ###
  # Create a SNS topic
  SNSTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Join [ "-", [!Ref ProjectPrefix, "SNSTopic", !Ref ProjectSuffix ] ]
  ###
  # Create a Step Functions state machine
  AthenaStateMachine:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      RoleArn: !GetAtt [ AthenaWorkflowExecutionRole, Arn ]
      StateMachineName: !Join [ "-", [!Ref ProjectPrefix, "AthenaStateMachine", !Ref ProjectSuffix ] ]
      DefinitionString:
        !Sub
        - |-
          {
            "StartAt": "Generate example log",
            "States": {
              "Generate example log": {
                "Resource": "${dataGenerationLambda}",
                "Type": "Task",
                "Next": "Run Glue crawler"
              },
              "Run Glue crawler": {
                "Resource": "${crawlerLambda}",
                "Type": "Task",
                "Next": "Start an Athena query"
              },
              "Start an Athena query": {
                "Resource": "arn:${AWS::Partition}:states:::athena:startQueryExecution.sync",
                "Parameters": {
                  "QueryString": "SELECT * FROM \"${database}\".\"log\" limit 1",
                  "WorkGroup": "${workgroup}"
                },
                "Type": "Task",
                "Next": "Get query results"
              },
              "Get query results": {
                "Resource": "arn:${AWS::Partition}:states:::athena:getQueryResults",
                "Parameters": {
                  "QueryExecutionId.$": "$.QueryExecution.QueryExecutionId"
                },
                "Type": "Task",
                "Next": "Send query results"
              },
              "Send query results": {
                "Resource": "arn:${AWS::Partition}:states:::sns:publish",
                "Parameters": {
                  "TopicArn": "${snsTopicArn}",
                  "Message": {
                    "Input.$": "$.ResultSet.Rows"
                  }
                },
                "Type": "Task",
                "End": true
              }
            }
          }
        - {snsTopicArn: !Ref SNSTopic, database: !Ref GlueDatabase, dataGenerationLambda: !GetAtt [ LambdaForDataGeneration, Arn ], crawlerLambda: !GetAtt [ LambdaForInvokingCrawler, Arn ], workgroup: !Ref AthenaWorkGroup}
  AthenaWorkflowExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Join [ "-", [!Ref ProjectPrefix, "AthenaWorkflowExecutionRole", !Ref ProjectSuffix ] ]
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: states.amazonaws.com
            Action: "sts:AssumeRole"
      Path: "/"
      Policies:
        - PolicyName: AthenaPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - lambda:InvokeFunction
                Resource:
                  - !GetAtt [ LambdaForDataGeneration, Arn ]
                  - !GetAtt [ LambdaForInvokingCrawler, Arn ]
              - Effect: Allow
                Action:
                  - sns:Publish
                Resource:
                  - !Ref SNSTopic
              - Effect: Allow
                Action:
                  - athena:getQueryResults
                  - athena:startQueryExecution
                  - athena:stopQueryExecution
                  - athena:getQueryExecution
                  - athena:getDataCatalog
                Resource:
                  - !Sub "arn:${AWS::Partition}:athena:${AWS::Region}:${AWS::AccountId}:workgroup/${AthenaWorkGroup}"
                  - !Sub "arn:${AWS::Partition}:athena:${AWS::Region}:${AWS::AccountId}:datacatalog/*"
              - Effect: Allow
                Action:
                  - s3:GetBucketLocation
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:ListBucketMultipartUploads
                  - s3:ListMultipartUploadParts
                  - s3:AbortMultipartUpload
                  - s3:CreateBucket
                  - s3:PutObject
                Resource: !Sub "arn:${AWS::Partition}:s3:::*"
              - Effect: Allow
                Action:
                  - glue:CreateDatabase
                  - glue:GetDatabase
                  - glue:GetDatabases
                  - glue:UpdateDatabase
                  - glue:DeleteDatabase
                  - glue:CreateTable
                  - glue:UpdateTable
                  - glue:GetTable
                  - glue:GetTables
                  - glue:DeleteTable
                  - glue:BatchDeleteTable
                  - glue:BatchCreatePartition
                  - glue:CreatePartition
                  - glue:UpdatePartition
                  - glue:GetPartition
                  - glue:GetPartitions
                  - glue:BatchGetPartition
                  - glue:DeletePartition
                  - glue:BatchDeletePartition
                Resource:
                  - !Sub "arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:database/*"
                  - !Sub "arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:table/*"
                  - !Sub "arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:catalog"
Outputs:
  StateMachineArn:
    Value: !Ref AthenaStateMachine
  ExecutionInput:
    Description: Sample input to StartExecution.
    Value:
      >
      {}