{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "import re\n",
    "from snowflake.snowpark.session import Session\n",
    "import boto3\n",
    "from lat_lon_parser import parse\n",
    "import csv\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secret(secret_name, region_name=\"us-east-1\"):\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name)\n",
    "    get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    get_secret_value_response = json.loads(get_secret_value_response['SecretString'])\n",
    "    return get_secret_value_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = get_secret(\"wysde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": creds[\"SNOWFLAKE_ACCOUNT\"],\n",
    "    \"user\": creds[\"SNOWFLAKE_USERNAME\"],\n",
    "    \"password\": creds[\"SNOWFLAKE_PASSWORD\"],\n",
    "    \"warehouse\": creds[\"SNOWFLAKE_WAREHOUSE\"],\n",
    "    \"role\": creds[\"SNOWFLAKE_ROLE\"],\n",
    "    \"database\": \"sparsh\",\n",
    "    \"schema\": \"public\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_PATH = \"./data/inegi\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanEmpty(row):\n",
    "    for i,v in enumerate(row):\n",
    "        if not v or v == '*':\n",
    "            row[i] = 'NULL'\n",
    "        elif v == 'N/D':\n",
    "            row[i] = 0\n",
    "        else:\n",
    "            if str(v):\n",
    "                row[i] = str(v)\n",
    "            else:\n",
    "                if v.isnumeric():\n",
    "                    row[i] = int(v)\n",
    "                    print(row[i])\n",
    "                if float(v):\n",
    "                    row[i] = float(v)\n",
    "                    print(row[i])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openCSV(filename:str):\n",
    "    newInegi = []\n",
    "    with open(filename, newline='', encoding='utf8') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for row in reader:\n",
    "            if not row[0].isnumeric():\n",
    "                continue\n",
    "            #mun = 0 (totales de entidad) or loc = 0 (totales de entidad) \n",
    "            if int(row[4]) == 0 or int(row[4]) == 9998 or int(row[4]) == 9999:\n",
    "                continue\n",
    "            else:\n",
    "                newRow = [row[0],\n",
    "                row[2], \n",
    "                row[3], \n",
    "                row[4], \n",
    "                row[5], \n",
    "                'NULL' if not row[6] else parse(row[6]), \n",
    "                'NULL' if not row[7] else parse(row[7]), \n",
    "                row[8],\n",
    "                row[9],\n",
    "                row[10], \n",
    "                row[11], \n",
    "                row[130], \n",
    "                row[185], \n",
    "                row[186], \n",
    "                row[187], \n",
    "                row[214], \n",
    "                row[215], \n",
    "                row[237], \n",
    "                row[238],\n",
    "                row[182]\n",
    "                ]\n",
    "                newInegi.append(cleanEmpty(newRow))\n",
    "    return newInegi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearCSV(data):\n",
    "    csv.register_dialect('pipe', delimiter='|')\n",
    "    with open(os.path.join(BASE_DATA_PATH, 'csv/inegi.csv'), 'w', encoding='utf8', newline='') as f:\n",
    "        writer = csv.writer(f,dialect=\"pipe\")\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "    f.close()\n",
    "    print(\"CSV creado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateDatatypeJson(dato, tipo,i, key,row):    \n",
    "    try:\n",
    "        if tipo == 'int':\n",
    "            if dato == 'NULL':\n",
    "                return 0\n",
    "            else:\n",
    "                return int(dato)\n",
    "        if tipo == 'float':\n",
    "            if dato == 'NULL':\n",
    "                return 0.0\n",
    "            else:\n",
    "                return float(dato)\n",
    "        if tipo == 'str':\n",
    "            if dato == 'NULL':\n",
    "                return 'NULL'\n",
    "            else:\n",
    "                return str(dato)\n",
    "        else:\n",
    "            return 'NULL'\n",
    "    except ValueError as e:\n",
    "        if key == 'ALTITUD':\n",
    "            return 0.0\n",
    "        else:\n",
    "            return str('******')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leerData4Json(archivo:str):\n",
    "    datos = []\n",
    "    tempDic = {}\n",
    "    #Schema de tipos datos\n",
    "    schema = ['int', 'int', 'str' ,'int','str','float','float','int','int','int','int','int','int','int','int','int','int','int','int','int']\n",
    "    keys = ['ENTIDAD','MUN','NOM_MUN','LOC','NOM_LOC','LONGITUD','LATITUD','ALTITUD','POBTOT','POBFEM','POBMAS','PCON_DISC','GRAPROES','GRAPROES_F','GRAPROES_M','PSINDER','PDER_SS','VIVTOT','TVIVHAB','VPH_INTER']\n",
    "    with open(archivo, newline='', encoding='utf8') as file:\n",
    "        reader = csv.reader(file, delimiter='|', quotechar=',')\n",
    "        for i,row in enumerate(reader):\n",
    "            for idx in range((len(row))):\n",
    "                tempDic[keys[idx]] = validateDatatypeJson(row[idx],schema[idx], i, keys[idx],row)\n",
    "            datos.append(tempDic)   \n",
    "            tempDic = {}\n",
    "    return datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crearJson(json_filename:str, csv_data):\n",
    "    with open(json_filename,'w', encoding='utf-8') as jsonfile:\n",
    "        for row in csv_data:\n",
    "            jsonfile.write(json.dumps(row) + '\\n')\n",
    "    jsonfile.close()\n",
    "    print(\"JSON \" + json_filename + \" creado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressFile(filename):\n",
    "    with open(filename, 'rb') as f_in:\n",
    "        with gzip.open(filename + '.gz', 'wb') as f_out:\n",
    "            f_out.writelines(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullJson(csv_data):\n",
    "    jsonArray = []\n",
    "    filename = 'inegi.json'\n",
    "    for row in csv_data:\n",
    "        jsonArray.append(row)\n",
    "    crearJson(filename, jsonArray)\n",
    "    compressFile(filename)\n",
    "    print(\"JSON Completo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitJson(csv_data, parts:int):\n",
    "    jsondir = ''\n",
    "    extractDir = os.path.join(BASE_DATA_PATH, 'json')\n",
    "    if not os.path.exists(extractDir):\n",
    "        os.mkdir(extractDir)\n",
    "        jsondir = extractDir + '/'\n",
    "    else:\n",
    "        jsondir = extractDir + '/'\n",
    "\n",
    "    idx = 1\n",
    "    idx_filename = 1\n",
    "    jsonArray = []\n",
    "    tregs = len(csv_data)\n",
    "    rlimits = []\n",
    "    dranges = []\n",
    "    print(\"total registros: \" + str(tregs))\n",
    "    limit = round(tregs // parts) \n",
    "    print('limite: ' + str(limit))\n",
    "    diff = tregs - limit*parts\n",
    "    print('diferencia: ' + str(diff))\n",
    "    for i in range(0,parts+1):\n",
    "        rlimits.append(i*limit)\n",
    "    \n",
    "    s = 1\n",
    "    a = 0\n",
    "\n",
    "    for i in rlimits:\n",
    "        if s < len(rlimits): \n",
    "            temprange = range(rlimits[a],rlimits[s])\n",
    "            dranges.append(temprange)\n",
    "            #json\n",
    "            filename = jsondir + 'inegi'+ str(idx_filename) + '.json'\n",
    "            crearJson(filename, csv_data[temprange.start:temprange.stop])\n",
    "            compressFile(filename)\n",
    "            idx_filename = idx_filename + 1\n",
    "            a = s\n",
    "            s += 1\n",
    "        elif s == len(rlimits) and diff > 0:\n",
    "            #json\n",
    "            filename = jsondir + 'inegi'+ str(idx_filename) + '.json'\n",
    "            crearJson(filename, csv_data[-diff:])\n",
    "            compressFile(filename)\n",
    "            idx_filename = idx_filename + 1\n",
    "    \n",
    "    print(\"JSON particionado!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalHabitantesCSV(filename:str):\n",
    "    total = 0\n",
    "    with open(filename, newline='',encoding='utf8') as file:\n",
    "        reader = csv.reader(file, delimiter='|')\n",
    "        for row in reader:\n",
    "            if row[8].isnumeric():\n",
    "                total = total + int(row[8])\n",
    "    file.close()\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalHabitantesJson(filename):\n",
    "    total = 0\n",
    "    with open(filename, 'r', newline='') as file:\n",
    "        for row in file:\n",
    "            datos = json.loads(row)\n",
    "            #print(datos['POBTOT'])\n",
    "            total = total + datos['POBTOT']\n",
    "    file.close()\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_download = 'https://www.inegi.org.mx/contenidos/programas/ccpv/2020/datosabiertos/iter/iter_00_cpv2020_csv.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inegiDownloadFile(url:str) -> bool:\n",
    "    try:\n",
    "        zipfilename = url.split('/')[-1]\n",
    "        os.makedirs(BASE_DATA_PATH)\n",
    "        data_path = os.path.join(BASE_DATA_PATH, zipfilename)\n",
    "        if not os.path.isfile(data_path):\n",
    "            r = requests.get(url,allow_redirects=True)\n",
    "            if r.status_code == 200:\n",
    "                open(data_path, 'wb').write(r.content)\n",
    "                return True    \n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False        \n",
    "    except requests.RequestException as err:\n",
    "        print(err)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if inegiDownloadFile(url_download):\n",
    "    print('Descargado')\n",
    "else:\n",
    "    print('Ya descargado')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzipDatos(zipfilename:str):\n",
    "    if os.path.isfile(zipfilename):\n",
    "        print('Archivo en directorio...OK')\n",
    "        extractDir = os.path.join(BASE_DATA_PATH, 'csv')\n",
    "        if not os.path.exists(extractDir):\n",
    "            os.mkdir(extractDir)\n",
    "        with zipfile.ZipFile(zipfilename, 'r') as zipa:\n",
    "            zipa.extractall(extractDir)\n",
    "        print('Unzipped')\n",
    "    else:\n",
    "        print('Archivo debe ser descargado antes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo en directorio...OK\n",
      "Unzipped\n"
     ]
    }
   ],
   "source": [
    "unzipDatos(os.path.join(BASE_DATA_PATH, 'iter_00_cpv2020_csv.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscarArchivo(filename:str):\n",
    "    dirname = os.path.join(BASE_DATA_PATH, \"csv/iter_00_cpv2020/conjunto_de_datos/\")\n",
    "    for ruta in os.listdir(dirname):\n",
    "        if os.path.isfile(os.path.join(dirname, filename)):\n",
    "            return os.path.join(dirname,ruta)\n",
    "        else:\n",
    "            print('Sin archivo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV creado!\n"
     ]
    }
   ],
   "source": [
    "rutaCSV = buscarArchivo('conjunto_de_datos_iter_00CSV20.csv')\n",
    "newInegi = openCSV(rutaCSV)\n",
    "crearCSV(newInegi)\n",
    "newInegi.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total registros: 189432\n",
      "limite: 27061\n",
      "diferencia: 5\n",
      "JSON ./data/inegi/json/inegi1.json creado!\n",
      "JSON ./data/inegi/json/inegi2.json creado!\n",
      "JSON ./data/inegi/json/inegi3.json creado!\n",
      "JSON ./data/inegi/json/inegi4.json creado!\n",
      "JSON ./data/inegi/json/inegi5.json creado!\n",
      "JSON ./data/inegi/json/inegi6.json creado!\n",
      "JSON ./data/inegi/json/inegi7.json creado!\n",
      "JSON ./data/inegi/json/inegi8.json creado!\n",
      "JSON particionado!\n"
     ]
    }
   ],
   "source": [
    "leerCSV = leerData4Json(os.path.join(BASE_DATA_PATH, 'csv/inegi.csv'))\n",
    "splitJson(leerCSV, 7)\n",
    "leerCSV.clear()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado\n",
      "[Row(CURRENT_WAREHOUSE()='COMPUTE_WH', CURRENT_DATABASE()='SPARSH', CURRENT_ROLE()='ACCOUNTADMIN')]\n"
     ]
    }
   ],
   "source": [
    "sesion = Session.builder.configs(connection_parameters).create()\n",
    "if sesion != None:\n",
    "    print(\"Conectado\")\n",
    "    print(sesion.sql(\"select current_warehouse(), current_database(), current_role()\").collect()) \n",
    "else:\n",
    "    print(\"Error de conexión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sesion.use_role(connection_parameters['role'])\n",
    "sesion.sql(\"grant all privileges on database \"+connection_parameters['database']+ \" to role \"+connection_parameters['role'] +\";\").collect()\n",
    "sesion.use_database(connection_parameters['database'])\n",
    "sesion.use_schema(connection_parameters['schema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#warehouse\n",
    "sesion.sql(\"grant usage on warehouse \"+connection_parameters['warehouse']+\" to role \"+connection_parameters['role'] +\";\").collect()\n",
    "sesion.use_warehouse(connection_parameters['warehouse'])\n",
    "\n",
    "#Schema\n",
    "sesion.sql(\"grant all privileges on schema \"+connection_parameters['schema']+\" to role \"+connection_parameters['role'] +\";\").collect()\n",
    "sesion.sql(\"grant create stage on schema \" +connection_parameters['schema']+\" to role \"+connection_parameters['role'] +\";\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully. 0 objects affected.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sesion.sql(\"create or replace table inegi_raw (v VARIANT);\").collect()\n",
    "sesion.sql(\"grant select on all tables in schema \"+connection_parameters['schema']+\" to role \"+connection_parameters['role'] +\";\").collect()\n",
    "sesion.sql(\"grant select on all views in schema \"+connection_parameters['schema']+\" to role \"+connection_parameters['role'] +\";\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingesta_setup() -> dict:\n",
    "    env = {\n",
    "        'account' : connection_parameters['account'],\n",
    "        'snowstage' : 'inegi'\n",
    "    }\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area INEGI successfully created.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = ingesta_setup()\n",
    "sesion.sql('CREATE STAGE IF NOT EXISTS '+ env['snowstage']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solo_archivos(ruta) -> list:\n",
    "    ingesta_files = []\n",
    "    for file in os.listdir(ruta):\n",
    "        # search given pattern in the line \n",
    "        if re.search(\"\\.json.gz$\", file):\n",
    "            ingesta_files.append(os.path.join(ruta,file))\n",
    "    return ingesta_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/inegi/json/inegi3.json.gz',\n",
       " './data/inegi/json/inegi2.json.gz',\n",
       " './data/inegi/json/inegi1.json.gz',\n",
       " './data/inegi/json/inegi8.json.gz',\n",
       " './data/inegi/json/inegi4.json.gz',\n",
       " './data/inegi/json/inegi5.json.gz',\n",
       " './data/inegi/json/inegi7.json.gz',\n",
       " './data/inegi/json/inegi6.json.gz']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archivos_dir = os.path.join(BASE_DATA_PATH, 'json')\n",
    "archivos = solo_archivos(archivos_dir)\n",
    "archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPLOADED\n",
      "UPLOADED\n",
      "UPLOADED\n",
      "UPLOADED\n",
      "UPLOADED\n",
      "UPLOADED\n",
      "UPLOADED\n",
      "UPLOADED\n",
      "UPLOADED\n"
     ]
    }
   ],
   "source": [
    "for file in archivos:\n",
    "    put_result = sesion.file.put('file://' + file , '@' + env['snowstage'])\n",
    "    print(put_result[0].status)\n",
    "    \n",
    "file = os.path.join(os.getcwd(),'src/entidad.py') \n",
    "put_result = sesion.file.put('file://' + file , '@' + env['snowstage'], auto_compress= False, overwrite=True)\n",
    "print(put_result[0].status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando...\n",
      "Transformación Completado\n"
     ]
    }
   ],
   "source": [
    "print(\"Transformando...\")\n",
    "sesion.sql(\"create or replace file format json type = json;\").collect()\n",
    "sesion.sql(\"copy into inegi_raw from @\" + env['snowstage'] + \" file_format = json pattern = '.*inegi[1-8].json.gz';\").collect()\n",
    "print(\"Transformación Completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesión terminada\n"
     ]
    }
   ],
   "source": [
    "sesion.close()\n",
    "print(\"Sesión terminada\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import udf\n",
    "from snowflake.snowpark.types import StringType\n",
    "from snowflake.snowpark.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado\n",
      "[Row(CURRENT_WAREHOUSE()='COMPUTE_WH', CURRENT_DATABASE()='SPARSH', CURRENT_ROLE()='ACCOUNTADMIN')]\n"
     ]
    }
   ],
   "source": [
    "sesion = Session.builder.configs(connection_parameters).create()\n",
    "if sesion != None:\n",
    "    print(\"Conectado\")\n",
    "    print(sesion.sql(\"select current_warehouse(), current_database(), current_role()\").collect()) \n",
    "else:\n",
    "    print(\"Error de conexión\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='View INEGI_DATA successfully created.')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"create or replace  view INEGI_DATA as select \" + \\\n",
    " \"v:ENTIDAD::int as entidad,\" + \\\n",
    " \"v:MUN::int as municipio,\" + \\\n",
    " \"v:NOM_MUN::string as nom_municipio,\" + \\\n",
    " \"v:LOC::string as localidad,\" + \\\n",
    " \"v:NOM_LOC::string as nom_localidad,\" + \\\n",
    " \"v:LONGITUD::float as longitud,\" + \\\n",
    " \"v:LATITUD::float as latitud,\" + \\\n",
    " \"v:ALTITUD::int as altitud,\" + \\\n",
    " \"v:POBTOT::int as pob_total,\" + \\\n",
    " \"v:POBFEM::int as pob_fem,\" + \\\n",
    " \"v:POBMAS::int as pob_masc,\" + \\\n",
    " \"v:PCON_DISC::int as pob_discapacidad,\" + \\\n",
    " \"v:GRAPROES::int as pob_escolaridad,\" + \\\n",
    " \"v:GRAPROES_F::int as pob_esco_fem,\" + \\\n",
    " \"v:GRAPROES_M::int as pob_esco_masc,\" + \\\n",
    " \"v:PSINDER::int as pob_sssalud,\" + \\\n",
    " \"v:PDER_SS::int as pob_cssalud,\" + \\\n",
    " \"v:VIVTOT::int as total_vivienda,\" + \\\n",
    " \"v:TVIVHAB::int total_habitada,\" + \\\n",
    " \"v:VPH_INTER::int as hab_internet \" + \\\n",
    " \"from INEGI_RAW;\"\n",
    "sesion.sql(query).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF declaration\n",
    "entidad_udf = sesion.udf.register_from_file(file_path='@inegi/entidad.py',func_name='nom_entidad',return_type=StringType(),input_types=[IntegerType()],is_permanent=True, name=\"nom_entidad\",stage_location=\"@inegi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='View INEGI_MAPA successfully created.')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vista con totales por entidad aplicando UDF para convertir número de entidad x nombre entidad\n",
    "viewquery = \"create or replace view INEGI_MAPA as \" + \\\n",
    "\"with poblacion_lat as ( select latitud,longitud, nom_entidad(entidad) as nom_entidad,\" + \\\n",
    "\"ROW_NUMBER() OVER(PARTITION BY nom_entidad ORDER BY nom_entidad DESC) AS row_number from INEGI_DATA),\" + \\\n",
    "\"poblacion_t as (select sum(pob_total) as poblacion_total,nom_entidad(entidad) as nom_entidad from \" + \\\n",
    "\"INEGI_DATA group by entidad order by poblacion_total desc)\" + \\\n",
    "\" select pl.nom_entidad,pt.poblacion_total, pl.latitud, pl.longitud\" + \\\n",
    "\" from poblacion_lat pl left join poblacion_t pt on pl.nom_entidad = pt.nom_entidad\" + \\\n",
    "\" where row_number = 1;\"\n",
    "sesion.sql(viewquery).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------\n",
      "|\"NOM_ENTIDAD\"         |\"POBLACION_TOTAL\"  |\"LATITUD\"           |\"LONGITUD\"           |\n",
      "---------------------------------------------------------------------------------------\n",
      "|OAXACA                |4132148            |18.095924166666663  |-96.58116027777776   |\n",
      "|PUEBLA                |6583278            |19.995293333333333  |-97.84910722222222   |\n",
      "|SAN LUIS POTOSI       |2822255            |22.238184166666667  |-99.21526083333332   |\n",
      "|TLAXCALA              |1342977            |19.539680833333335  |-98.08591972222222   |\n",
      "|COAHUILA DE ZARAGOZA  |3146771            |27.844765           |-103.72405305555556  |\n",
      "|TAMAULIPAS            |3527735            |23.775704444444443  |-98.41690472222224   |\n",
      "|NAYARIT               |1235456            |20.78537194444445   |-105.46803611111112  |\n",
      "|HIDALGO               |3082841            |20.29848944444445   |-99.41953666666669   |\n",
      "|BAJA CALIFORNIA SUR   |798447             |26.29847388888889   |-111.53780972222222  |\n",
      "|DURANGO               |1832650            |24.25024277777778   |-105.80358527777776  |\n",
      "---------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Validar la vista solo con totales por entidad\n",
    "df_entidad = sesion.table(\"INEGI_MAPA\")\n",
    "df_entidad.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sesion.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-snow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:16:26) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56a1ac3adb378e653a21dff9ebdc18cce0787fb994608cdea40d0604c77313fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
