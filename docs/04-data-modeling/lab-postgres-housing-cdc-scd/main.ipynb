{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 01_01_2023.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/01_01_2023.csv\n",
    "prop_id;house_type;has_furniture;surface;price;\n",
    "1;Apartment;True;15;490;\n",
    "2;Apartment;False;18;450;\n",
    "3;House;False;50;650;\n",
    "4;Apartment;True;20;540;\n",
    "5;House;True;55;750;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 02_01_2023.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/02_01_2023.csv\n",
    "prop_id;house_type;has_furniture;surface;price;\n",
    "1;Apartment;True;15;490;\n",
    "4;Apartment;True;20;550;\n",
    "5;House;True;55;750;\n",
    "6;Apartment;True;22;500;\n",
    "7;Apartment;True;24;580;\n",
    "8;House;True;52;650;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing today.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile data/today.csv\n",
    "prop_id;house_type;has_furniture;surface;price;\n",
    "4;Apartment;True;20;540;\n",
    "6;Apartment;True;22;500;\n",
    "8;House;True;52;640;\n",
    "9;Apartment;True;30;600;\n",
    "10;Apartment;False;35;620;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "SQLAlchemy==1.4.39\n",
    "pandas==1.3.5\n",
    "psycopg2-binary==2.9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime, timedelta\n",
    "import uuid\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secret(secret_name, region_name=\"us-east-1\"):\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name)\n",
    "    get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    get_secret_value_response = json.loads(get_secret_value_response['SecretString'])\n",
    "    return get_secret_value_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = get_secret(\"wysde\")\n",
    "USERNAME = creds[\"RDS_POSTGRES_USERNAME\"]\n",
    "PASSWORD = creds[\"RDS_POSTGRES_PASSWORD\"]\n",
    "HOST = creds[\"RDS_POSTGRES_HOST\"]\n",
    "DATABASE = 'sparsh'\n",
    "\n",
    "conn_str = 'postgresql://{0}:{1}@{2}/{3}'.format(USERNAME, PASSWORD, HOST, DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.displaycon=False\n",
    "%config SqlMagic.feedback=False\n",
    "%config SqlMagic.displaylimit=5\n",
    "%reload_ext sql\n",
    "%sql {conn_str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(conn_str)\n",
    "Session = sessionmaker(engine)\n",
    "session = Session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After collecting data from the website, we'll load the new data to the data warehouse. Suppose we already have some data in the warehouse, we won't need the same data again. Otherwise, the statistics won't be correct. Here is what we need to implement:\n",
    "\n",
    "-   Add new data to the warehouse\n",
    "-   For data that has been changed on the website (for example, the price drops), we'll mark them as expired and add the new version to the warehouse.\n",
    "-   If the offer is no longer available on the website, we mark it as \"expired\" in the warehouse.\n",
    "\n",
    "To determine whether a property is \"new\", we can use the technique described [here](https://www.sspaeti.com/blog/data-engineering-project-in-twenty-minutes). We'll add a new field called `fingerprint` that will be used to differentiate properties. We already have the \"prop_id\" field, which is a unique identifier, in the data source. Since we also want to track the price, we will add that information to the `fingerprint`. As a result, the fingerprint is created by joining `prop_id` and `price`. We can have many rows for the same property in the database, as long as the price is different.\n",
    "\n",
    "We create a table called `housing_staging` for pre-aggregation data and `housing_model` for aggregated data. In the staging table, we use `valid_from` and `expired` fields to track the offer. We will see how these fields are used in the BackFill and Recompute Data part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_db():\n",
    "    create_table_housing_staging_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS housing_staging (\n",
    "        id varchar PRIMARY KEY,\n",
    "        prop_id int8,\n",
    "        house_type varchar,\n",
    "        has_furniture boolean,\n",
    "        price float,\n",
    "        surface float,\n",
    "        fingerprint varchar,\n",
    "        valid_from timestamp DEFAULT CURRENT_TIMESTAMP,\n",
    "        expired timestamp DEFAULT NULL\n",
    "        );\n",
    "    \"\"\"\n",
    "    session.execute(text(create_table_housing_staging_sql))\n",
    "\n",
    "    create_table_housing_model_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS housing_model(\n",
    "        date timestamp,\n",
    "        house_type varchar,\n",
    "        has_furniture boolean,\n",
    "        nb_props int,\n",
    "        avg_price float,\n",
    "        avg_price_per_m2 float\n",
    "    );\n",
    "    \"\"\"\n",
    "    session.execute(text(create_table_housing_model_sql))\n",
    "\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_db()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose you loaded the data collected to a table tmp_housing. Thanks to the field fingerprint , we can identify offers that have been changed or removed from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file: str) -> None:\n",
    "    extracted_data = pd.read_csv(csv_file, sep=\";\")\n",
    "\n",
    "    extracted_data[\"fingerprint\"] = extracted_data[\"prop_id\"].astype(\n",
    "        str\n",
    "    ) + extracted_data[\"price\"].astype(str)\n",
    "    extracted_data[\"id\"] = [uuid.uuid4() for _ in range(len(extracted_data.index))]\n",
    "\n",
    "    session.execute(text(\"DROP TABLE IF EXISTS tmp_housing\"))\n",
    "    session.commit()\n",
    "\n",
    "    extracted_data.to_sql(\"tmp_housing\", engine)\n",
    "\n",
    "    expired: datetime = datetime.today()\n",
    "    expired = expired - timedelta(days=1)\n",
    "    expired = expired.replace(hour=23, minute=59, second=59)\n",
    "    expired = expired.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    update_updated_n_deleted_props_sql = f\"\"\"UPDATE housing_staging\n",
    "            SET expired = '{expired}' \n",
    "            WHERE id IN (SELECT h.id \n",
    "                FROM housing_staging h\n",
    "                LEFT JOIN tmp_housing t\n",
    "                ON h.prop_id = t.prop_id\n",
    "                AND h.expired IS NULL\n",
    "                WHERE t.prop_id IS NULL\n",
    "                OR h.fingerprint != t.fingerprint\n",
    "            )\n",
    "            \"\"\"\n",
    "    session.execute(text(update_updated_n_deleted_props_sql))\n",
    "\n",
    "    valid_from: datetime = datetime.today()\n",
    "    valid_from = valid_from.replace(hour=0, minute=0, second=0)\n",
    "    valid_from = valid_from.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_new_or_updated_props_sql = f\"\"\"\n",
    "        INSERT INTO housing_staging (\n",
    "            id, prop_id,\n",
    "            house_type, has_furniture,\n",
    "            price, surface,\n",
    "            fingerprint, valid_from\n",
    "        ) (SELECT t.id, t.prop_id,\n",
    "        t.house_type, t.has_furniture,\n",
    "        t.price, t.surface,\n",
    "        t.fingerprint, '{valid_from}'\n",
    "        FROM tmp_housing t\n",
    "        LEFT JOIN housing_staging h\n",
    "        ON t.prop_id = h.prop_id\n",
    "        AND h.expired IS NULL\n",
    "        WHERE h.prop_id IS NULL\n",
    "        OR h.fingerprint != t.fingerprint)\n",
    "        \"\"\"\n",
    "    session.execute(text(insert_new_or_updated_props_sql))\n",
    "\n",
    "    session.execute(text(\"DROP TABLE tmp_housing\"))\n",
    "    session.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this function for today.csv file. In the housing_staging table, you’ll have these rows (the value of valid_from column will be different):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data('data/today.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>house_type</th>\n",
       "      <th>has_furniture</th>\n",
       "      <th>price</th>\n",
       "      <th>surface</th>\n",
       "      <th>fingerprint</th>\n",
       "      <th>valid_from</th>\n",
       "      <th>expired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97952e76-5127-4398-b792-b56e6ed7f518</td>\n",
       "      <td>4</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>True</td>\n",
       "      <td>540.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4540</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3c006ad9-8d0b-44cd-a70d-707dd5a8d690</td>\n",
       "      <td>6</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>True</td>\n",
       "      <td>500.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6500</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0620d450-6935-4bf1-a23f-e7cbd4c5fd65</td>\n",
       "      <td>8</td>\n",
       "      <td>House</td>\n",
       "      <td>True</td>\n",
       "      <td>640.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8640</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37d404aa-7c70-4dce-9575-954473aca082</td>\n",
       "      <td>9</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>True</td>\n",
       "      <td>600.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a7b5c9f9-0ee8-4b2a-87aa-7168b38c02a3</td>\n",
       "      <td>10</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>False</td>\n",
       "      <td>620.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10620</td>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  prop_id house_type  has_furniture  \\\n",
       "0  97952e76-5127-4398-b792-b56e6ed7f518        4  Apartment           True   \n",
       "1  3c006ad9-8d0b-44cd-a70d-707dd5a8d690        6  Apartment           True   \n",
       "2  0620d450-6935-4bf1-a23f-e7cbd4c5fd65        8      House           True   \n",
       "3  37d404aa-7c70-4dce-9575-954473aca082        9  Apartment           True   \n",
       "4  a7b5c9f9-0ee8-4b2a-87aa-7168b38c02a3       10  Apartment          False   \n",
       "\n",
       "   price  surface fingerprint valid_from expired  \n",
       "0  540.0     20.0        4540 2023-02-22    None  \n",
       "1  500.0     22.0        6500 2023-02-22    None  \n",
       "2  640.0     52.0        8640 2023-02-22    None  \n",
       "3  600.0     30.0        9600 2023-02-22    None  \n",
       "4  620.0     35.0       10620 2023-02-22    None  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM housing_staging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will answer three following questions:\n",
    "\n",
    "- How many offers are currently available?\n",
    "- The average price.\n",
    "- The average cost per m2.\n",
    "\n",
    "We can compute these 3 KPIs from the housing_staging table. The idea is to filter out expired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data() -> None:\n",
    "    date: datetime = datetime.today()\n",
    "    date = date.replace(hour=0, minute=0, second=0)\n",
    "    date = date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    transform_data_sql = f\"\"\"\n",
    "            INSERT INTO housing_model (\n",
    "                date, house_type, has_furniture,\n",
    "                nb_props, avg_price, avg_price_per_m2\n",
    "            ) (SELECT '{date}', house_type, has_furniture,\n",
    "                COUNT(prop_id) nb_props, AVG(price) avg_price,\n",
    "                AVG(price/surface) avg_price_per_m2\n",
    "                FROM housing_staging\n",
    "                WHERE expired IS NULL\n",
    "                GROUP BY house_type, has_furniture\n",
    "            )\n",
    "    \"\"\"\n",
    "\n",
    "    session.execute(text(transform_data_sql))\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what we get from the housing_model table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>house_type</th>\n",
       "      <th>has_furniture</th>\n",
       "      <th>nb_props</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>avg_price_per_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>17.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>546.666667</td>\n",
       "      <td>23.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-22</td>\n",
       "      <td>House</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>12.307692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date house_type  has_furniture  nb_props   avg_price  avg_price_per_m2\n",
       "0 2023-02-22  Apartment          False         1  620.000000         17.714286\n",
       "1 2023-02-22  Apartment           True         3  546.666667         23.242424\n",
       "2 2023-02-22      House           True         1  640.000000         12.307692"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM housing_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backfill and Recompute Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we need to backfill and recompute data for a day in the past. For instance, when you discover corrupted data in the warehouse and decide to reload the staging data and recalculate the KPI. Another example is that our pipeline failed to load data to the warehouse due to an error.\n",
    "\n",
    "The tricky part is when we reload data for a day, the data of later dates will be affected. To illustrate that, consider this scenario:\n",
    "\n",
    "We have the following rows in the housing_staging table:\n",
    "\n",
    "```\n",
    "| prop_id | valid_from          | expired |\n",
    "|---------|---------------------|---------|\n",
    "| 4       | 2023-02-18 00:00:00 | NULL    |\n",
    "| 6       | 2023-02-18 00:00:00 | NULL    |\n",
    "| 8       | 2023-02-18 00:00:00 | NULL    |\n",
    "| 9       | 2023-02-18 00:00:00 | NULL    |\n",
    "| 10      | 2023-02-18 00:00:00 | NULL    |\n",
    "```\n",
    "\n",
    "Now if we want to load data in the file 02_01_2023.csv, we should have this result:\n",
    "\n",
    "```\n",
    "| prop_id | valid_from          | expired             |\n",
    "|---------|---------------------|---------------------|\n",
    "|       1 | 2023-01-02 00:00:00 | 2023-02-17 23:59:59 |\n",
    "|       4 | 2023-01-02 00:00:00 | 2023-02-17 23:59:59 |\n",
    "|       4 | 2023-02-18 00:00:00 |                     |\n",
    "|       5 | 2023-01-02 00:00:00 | 2023-02-17 23:59:59 |\n",
    "|       6 | 2023-01-02 00:00:00 |                     |\n",
    "|       7 | 2023-01-02 00:00:00 | 2023-02-17 23:59:59 |\n",
    "|       8 | 2023-01-02 00:00:00 | 2023-02-17 23:59:59 |\n",
    "|       8 | 2023-02-18 00:00:00 |                     |\n",
    "|       9 | 2023-02-18 00:00:00 |                     |\n",
    "|      10 | 2023-02-18 00:00:00 |                     |\n",
    "```\n",
    "\n",
    "The following modifications are made:\n",
    "\n",
    "- Property with id 1,5 and 7 are added. It is valid from 02 January 2023 to the end of 17 February 2023. Because it was in 02_01_2023.csv but not today.csv\n",
    "- A new line for properties 4 and 8 is added. Because the price of this property changes between 02_01_2023.csvand today.csv\n",
    "- For property 6, the value of valid_from is modified from 2023–02–18 00:00:00 to 2023–01–02 00:00:00 . Because this property appears in 2 files and its price is unchanged, we should take the more ancient timestamp.\n",
    "Property 9 and 10 data remain unchanged.\n",
    "\n",
    "Given this complexity, we have 2 options:\n",
    "\n",
    "- We remove data from the date we want to reload. Then reload data from that date. This is easier to do but can take longer time to finish if you have a lot of data.\n",
    "- We load only data for the date and update data for later days.\n",
    "\n",
    "In this lab, we take the first option. To load data in 02_01_2023.csv , we first need to remove data from that date. Then rerun the load function for 02_01_2023.csv and today.csv.\n",
    "\n",
    "In the previous section, we only run the ingestion and transformation steps for the current date. We need to modify those functions by including a new parameter for_date. Then, we set the value of valid_from and expired field according to for_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file: str, for_date: Optional[datetime] = None) -> None:\n",
    "    extracted_data = pd.read_csv(csv_file, sep=\";\")\n",
    "\n",
    "    extracted_data[\"fingerprint\"] = extracted_data[\"prop_id\"].astype(\n",
    "        str\n",
    "    ) + extracted_data[\"price\"].astype(str)\n",
    "    extracted_data[\"id\"] = [uuid.uuid4()\n",
    "                            for _ in range(len(extracted_data.index))]\n",
    "\n",
    "    session.execute(text(\"DROP TABLE IF EXISTS tmp_housing\"))\n",
    "    session.commit()\n",
    "\n",
    "    extracted_data.to_sql(\"tmp_housing\", engine)\n",
    "\n",
    "    expired: datetime = datetime.today()\n",
    "    if for_date is not None:\n",
    "        expired = for_date\n",
    "    expired = expired - timedelta(days=1)\n",
    "    expired = expired.replace(hour=23, minute=59, second=59)\n",
    "    expired = expired.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    update_updated_n_deleted_props_sql = f\"\"\"UPDATE housing_staging\n",
    "            SET expired = '{expired}' \n",
    "            WHERE id IN (SELECT h.id \n",
    "                FROM housing_staging h\n",
    "                LEFT JOIN tmp_housing t\n",
    "                ON h.prop_id = t.prop_id\n",
    "                AND h.expired IS NULL\n",
    "                WHERE t.prop_id IS NULL\n",
    "                OR h.fingerprint != t.fingerprint\n",
    "            )\n",
    "            \"\"\"\n",
    "    session.execute(text(update_updated_n_deleted_props_sql))\n",
    "\n",
    "    valid_from: datetime = datetime.today()\n",
    "    if for_date is not None:\n",
    "        valid_from = for_date\n",
    "    valid_from = valid_from.replace(hour=0, minute=0, second=0)\n",
    "    valid_from = valid_from.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    insert_new_or_updated_props_sql = f\"\"\"\n",
    "        INSERT INTO housing_staging (\n",
    "            id, prop_id,\n",
    "            house_type, has_furniture,\n",
    "            price, surface,\n",
    "            fingerprint, valid_from\n",
    "        ) (SELECT t.id, t.prop_id,\n",
    "            t.house_type, t.has_furniture,\n",
    "            t.price, t.surface,\n",
    "            t.fingerprint, '{valid_from}'\n",
    "            FROM tmp_housing t\n",
    "            LEFT JOIN housing_staging h\n",
    "            AND h.expired IS NULL\n",
    "            ON t.prop_id = h.prop_id\n",
    "            WHERE h.prop_id IS NULL\n",
    "            OR t.fingerprint != h.fingerprint\n",
    "        )\n",
    "        \"\"\"\n",
    "    session.execute(text(insert_new_or_updated_props_sql))\n",
    "\n",
    "    session.execute(text(\"DROP TABLE tmp_housing\"))\n",
    "    session.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the transformation step, we will need to adjust the condition. In the previous version, we take the rows where the expired field is NULL because we were running for the current day.\n",
    "\n",
    "If we recompute data in the housing_model table for day D given the following days’ data has been loaded in the housing_staging table, we will only take rows that are valid until day D and are expired from the end of day D or are still active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(for_date: Optional[datetime] = None):\n",
    "\n",
    "    date: datetime = datetime.today()\n",
    "    if for_date is not None:\n",
    "    date = for_date\n",
    "    date = date.replace(hour=0, minute=0, second=0)\n",
    "    date = date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    transform_data_sql = f\"\"\"\n",
    "            INSERT INTO housing_model(\n",
    "                date, house_type, has_furniture, nb_props,\n",
    "                avg_price, avg_price_per_m2\n",
    "            ) (SELECT '{date}', house_type, has_furniture,\n",
    "                COUNT(prop_id) nb_props, AVG(price) avg_price,\n",
    "                AVG(price/surface) avg_price_per_m2\n",
    "                FROM housing_staging\n",
    "                WHERE valid_from <= '{date}'\n",
    "                AND (expired IS NULL OR expired > '{date}')\n",
    "                GROUP BY house_type, has_furniture\n",
    "            ) \n",
    "            \"\"\"\n",
    "            \n",
    "    session.execute(text(transform_data_sql))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that’s it, you have the data ingestion and transformation necessary to analyze housing price data over time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we applied change data capture and slowly changing dimension type 2 modelization to build a model for housing price analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343191058819caea96d5cde1bd3b1a75b4807623ce2cda0e1c8499e39ac847e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
