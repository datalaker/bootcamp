{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca01fb86",
   "metadata": {},
   "source": [
    "# Topic Modeling on Twitter Data with LDA using PySparkML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b7a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install nb_black==1.0.7 nltk==3.6.6 altair==4.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b3e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbc2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "from typing import List\n",
    "\n",
    "import boto3\n",
    "import nltk\n",
    "import sagemaker_pyspark\n",
    "from pandas import Series as pd_Series\n",
    "from pyspark import SparkConf, keyword_only\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import (\n",
    "    CountVectorizer,\n",
    "    CountVectorizerModel,\n",
    "    IDF,\n",
    "    RegexTokenizer,\n",
    "    StopWordsRemover,\n",
    "    Tokenizer,\n",
    "    VectorAssembler,\n",
    ")\n",
    "from pyspark.sql import Column, SparkSession, functions as F, types as T\n",
    "from pyspark.sql.dataframe import DataFrame as pdf\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae95e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for display purposes only\n",
    "from pandas import DataFrame as pd_DataFrame, option_context as pd_option_context\n",
    "\n",
    "# only used to verify that data containing ML model predictions, which was exported to S3, can\n",
    "# be re-loaded (into a Dask or Pandas DataFrame)\n",
    "import dask.dataframe as dd\n",
    "from pandas import read_parquet as pd_read_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ac127",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.model_interpretation\n",
    "from src.model_interpretation import interpret_model as mih, import_export_models as iem\n",
    "\n",
    "%aimport src.nlp\n",
    "from src.nlp import clean_text as ch\n",
    "\n",
    "%aimport src.s3\n",
    "from src.s3 import bucket_contents as s3h\n",
    "\n",
    "%aimport src.visualization\n",
    "from src.visualization import visualize as vh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9f92a",
   "metadata": {},
   "source": [
    "## About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d328b0f",
   "metadata": {},
   "source": [
    "In this notebook, PySpark ML will be used to perform topic modeling on the streamed tweets data stored in the CSV files (prepared using `3_combine_raw_data.ipynb`) in an S3 bucket.\n",
    "\n",
    "**Notes**\n",
    "1. This is an initial attempt at unsupervised learning with this data. The objective is to build up a minimum reliable end-to-end workflow here consisting of **both**\n",
    "   - complete data processing\n",
    "     - with an emphasis on processing text data\n",
    "   - unsupervised ML\n",
    "     - with manual hyper-parameter adjustments\n",
    "\n",
    "   each of which can be iteratively improved in the future.\n",
    "2. As the requirement for this project is to use big-data tools only, we will restrict ourselves to using\n",
    "   - PySpark for manipulating the data in a PySpark `DataFrame`\n",
    "     - even though the dataset used here does fit in memory and could be analysed using in-memory tools\n",
    "   - PySpark ML for implementing topic modeling (unsupervised machine learning)\n",
    "3. An AWS SageMaker notebook hosted on a T3 XLarge instance ([specifications](https://aws.amazon.com/ec2/instance-types/)) was used for running this notebook.\n",
    "4. To ensure repeatability in\n",
    "   - applying NLP on the tweet text\n",
    "     - the previous (most recently) trained vectorizer model will be loaded from a sub-folder in the same S3 bucket containing the CSV files\n",
    "       - here, this was done after reasonable choices for the `minDF` and `maxDF` hyper-parameters of the vectorizer model were found (from tuning these two hyper-parameters manually) and only the topic modeling algorithm (LDA) was left to be optimized\n",
    "     - a newly defined vectorizer model will be trained and saved (with a timestamp in the suffix of its filename) to a sub-folder in the same S3 bucket\n",
    "   - applying LDA [randomness in LDA is due to the probabilistic aspect of this algorithm ([1](https://stackoverflow.com/a/60661226/4057186))]\n",
    "     - the `seed` hyper-parameter in the PySparkML `LDA` object will be set to a fixed value\n",
    "       - this is used to save the state of a random function, so it yields the same random numbers on multiple calls\n",
    "     - the LDA hyper-parameter for the maximum number of iterations (`maxIter`, [link](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.LDA.html#pyspark.ml.clustering.LDA.maxIter)) will need to be increased sufficiently (from its default value of 20) such that the learned topics do converge\n",
    "       - a best effort was made to optimize this choice manually\n",
    "\n",
    "**Requirements**\n",
    "1. This notebook must be run on an AWS SageMaker instance.\n",
    "2. Required Python libraries can be installed by un-commenting the first cell of this notebook.\n",
    "3. Two environment variables\n",
    "   - `AWS_S3_BUCKET_NAME`\n",
    "      - the name of the S3 bucket containing the hourly CSVs of streamed Twitter data\n",
    "   - `AWS_REGION`\n",
    "\n",
    "   must be accessible to this SageMaker instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7c95d",
   "metadata": {},
   "source": [
    "The Python package requirements to run this notebook are different to those listed in the `requirements.txt` file (used by notebook `3_combine_raw_data.ipynb`) for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!pip3 freeze | grep -E 'boto3|s3fs|black==|jupyter-server|sagemaker|sagemaker_pyspark|pandas|pyspark|dask|nltk|altair|plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6c78b",
   "metadata": {},
   "source": [
    "## User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1605dda",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# S3\n",
    "path_to_folder = \"/datasets/twitter/kinesis-demo/\"\n",
    "\n",
    "# Data Loading (from hourly CSV files)\n",
    "num_files_to_use = 25\n",
    "# number of rows (streamed tweets) to load into PySpark DataFrame\n",
    "nrows = 800_000\n",
    "\n",
    "# Data processing\n",
    "all_cols_to_process = [\n",
    "    \"document\",  # 'document' is optional\n",
    "    \"created_at\",\n",
    "    \"user_joined\",\n",
    "    \"in_reply_to_screen_name\",\n",
    "    \"source_text\",\n",
    "    \"place_country\",\n",
    "    \"user_followers\",\n",
    "    \"user_friends\",\n",
    "    \"user_listed\",\n",
    "    \"user_favourites\",\n",
    "    \"user_statuses\",\n",
    "    \"user_protected\",\n",
    "    \"user_verified\",\n",
    "    \"user_location\",\n",
    "    \"reviewText\",\n",
    "]\n",
    "\n",
    "# Vectorizer\n",
    "count_vectorizer_filename = \"count_vec_model\"\n",
    "save_count_vectorizer = False\n",
    "s3_models_subfolder = \"models\"  # note: change this from 'predictions' to 'models'\n",
    "\n",
    "# LDA\n",
    "# # this should be tuned iteratively (discussed later)\n",
    "num_topics = 4\n",
    "\n",
    "# Model Evaluation (for reading tweets predicted to belong to the same topic)\n",
    "num_top_terms_per_topic = 15\n",
    "num_top_docs_to_read = 8\n",
    "\n",
    "# Output file (containing data with predicted topic)\n",
    "output_file_name = \"processed_with_predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket_name = os.getenv(\"AWS_S3_BUCKET_NAME\")\n",
    "aws_region = os.getenv(\"AWS_REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_cols = [f\"topic_{i}\" for i in range(num_topics)]\n",
    "cols_to_show_when_reading = (\n",
    "    [\"document\", \"reviewText\"] + topic_cols + [\"dominant_prob\", \"dominant_topic\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4fbb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pyspark_df(df: pdf, nrows: int = 5) -> pd_DataFrame:\n",
    "    \"\"\"Display the first n rows of a PySpark DataFrame as a Pandas DataFrame.\"\"\"\n",
    "    return df.limit(nrows).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3030a",
   "metadata": {},
   "source": [
    "Download NLTK stopwords, if not previously done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not os.path.isdir(\n",
    "    os.path.join(os.path.expanduser(\"~\"), \"nltk_data\", \"corpora\", \"stopwords\")\n",
    "):\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "all_stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3867b717",
   "metadata": {},
   "source": [
    "Append custom stopwords to the list of stopwords provied by the NLTK library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_stop_words = [\n",
    "    # specific to crypto mining\n",
    "    \"crypto\",\n",
    "    \"token\",\n",
    "    \"koistarter\",\n",
    "    \"daostarter\",\n",
    "    \"decentralized\",\n",
    "    \"services\",\n",
    "    \"pancakeswap\",\n",
    "    \"eraxnft\",\n",
    "    \"browsing\",\n",
    "    \"kommunitas\",\n",
    "    \"hosting\",\n",
    "    \"internet\",\n",
    "    \"exipofficial\",\n",
    "    \"servers\",\n",
    "    \"wallet\",\n",
    "    \"liquidity\",\n",
    "    \"rewards\",\n",
    "    \"floki\",\n",
    "    \"10000000000000linkstelegram\",\n",
    "    \"dogecoin\",\n",
    "    \"czbinance\",\n",
    "    \"watch\",\n",
    "    \"binance\",\n",
    "    \"dogelonmars\",\n",
    "    \"cryptocurrency\",\n",
    "    \"hbomax\",\n",
    "    \"money\",\n",
    "    \"danheld\",\n",
    "    \"dogelon\",\n",
    "    \"bitcoin\",\n",
    "    \"nftart\",\n",
    "    \"bvbtc\",\n",
    "    # inappropriate\n",
    "    \"fuckkk\",\n",
    "    \"fucking\",\n",
    "    # general words that won't be useful to analysis here (subjective choices)\n",
    "    \"provides\",\n",
    "    \"crazy\",\n",
    "    \"marketing\",\n",
    "    \"locked\",\n",
    "    \"happy\",\n",
    "    \"first\",\n",
    "    \"would\",\n",
    "    \"always\",\n",
    "    \"still\",\n",
    "    \"could\",\n",
    "    \"right\",\n",
    "    \"thank\",\n",
    "    \"project\",\n",
    "    \"great\",\n",
    "    \"really\",\n",
    "    \"think\",\n",
    "    \"check\",\n",
    "    \"supply\",\n",
    "    \"going\",\n",
    "    \"completed\",\n",
    "    \"still\",\n",
    "    \"people\",\n",
    "    \"years\",\n",
    "    \"matter\",\n",
    "    \"never\",\n",
    "    \"always\",\n",
    "    \"things\",\n",
    "    \"amazing\",\n",
    "    \"around\",\n",
    "    \"better\",\n",
    "    \"another\",\n",
    "    \"please\",\n",
    "    \"looking\",\n",
    "    \"today\",\n",
    "    \"since\",\n",
    "    \"thing\",\n",
    "    \"every\",\n",
    "    \"something\",\n",
    "    \"future\",\n",
    "    \"thanks\",\n",
    "    \"youre\",\n",
    "    \"don't\",\n",
    "    \"don't\",\n",
    "    \"someone\",\n",
    "    \"ready\",\n",
    "    \"taken\",\n",
    "    \"using\",\n",
    "    \"enough\",\n",
    "    \"maybe\",\n",
    "    \"believe\",\n",
    "    \"making\",\n",
    "    \"stuff\",\n",
    "    \"might\",\n",
    "    \"point\",\n",
    "    \"makes\",\n",
    "    \"family\",\n",
    "    \"everyone\",\n",
    "    \"thats\",\n",
    "    \"actually\",\n",
    "    \"everything\",\n",
    "    \"little\",\n",
    "    \"change\",\n",
    "    \"without\",\n",
    "    \"gonna\",\n",
    "    \"already\",\n",
    "    \"getting\",\n",
    "    \"theres\",\n",
    "    \"looks\",\n",
    "    \"can't\",\n",
    "    \"didn't\",\n",
    "    \"called\",\n",
    "    \"found\",\n",
    "    \"nothing\",\n",
    "    \"though\",\n",
    "    \"literally\",\n",
    "    \"bring\",\n",
    "    # not words\n",
    "    \"aaaaaaaaaa\",\n",
    "    \"aaaaaand\",\n",
    "    \"aaaaand\",\n",
    "    \"aaaahhhh\",\n",
    "    \"aaaand\",\n",
    "    \"aaaaaa\",\n",
    "    \"aaahh\",\n",
    "    \"aaare\",\n",
    "]\n",
    "# Manually add to stop words\n",
    "for manual_stop_word in manual_stop_words:\n",
    "    all_stopwords.add(manual_stop_word)\n",
    "all_stopwords = list(all_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0bd32c",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. This custom list was iteratively built up by training the topic model algorithm, inspecting the top words in each learned topic and removing any occurrences of commonly occurring words that were (subjectively) determined to not add value to the topic. Such words should not contribute the highest weight to a topic and so should be removed from the text vocabulary that is used here.\n",
    "2. Sine we're trying to learn topics related to tweets about *space* news, tweets about crypto currency (which are likely being picked up due to their connection to the company SpaceX) are not useful and should be removed from the vocabulary. An alternative approach would be to keep those words in and choose a number of topics that (if possible) confines tweets about crypto-current to a single topic. This alternate approach was not used here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a95d1ca",
   "metadata": {},
   "source": [
    "## PySpark Setup (on AWS SageMaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conf = (SparkConf()\n",
    "        .set(\"spark.driver.extraClassPath\", \":\".join(sagemaker_pyspark.classpath_jars())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d9c5e",
   "metadata": {},
   "source": [
    "Start a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8465faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(conf=conf)\n",
    "    .appName(\"schema_test\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ef736",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508499c",
   "metadata": {},
   "source": [
    "### Get List of S3 CSV Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106a598",
   "metadata": {},
   "source": [
    "Get a list of all the CSV files containing the tweets data (files with a prefix `tweets_*.csv`), and not the metadata (prefix `tweets_metadata_*.csv`), from `csvs/` folder in the S3 bucket path at `<bucket-name>/datasets/twitter/kinesis-demo/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "existing_csv_files_list = s3h.get_existing_csv_files_list(\n",
    "    s3_bucket_name, path_to_folder[1:] + \"csvs/tweets_\"\n",
    ")\n",
    "files_csvs_list = [f for f in existing_csv_files_list if \"metadata\" not in f]\n",
    "files_csvs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a098eb",
   "metadata": {},
   "source": [
    "### Load all CSV Files into Single PySpark `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5643313",
   "metadata": {},
   "source": [
    "Read all CSV files from the `csvs/` in the S3 bucket path at `<bucket-name>/datasets/twitter/kinesis-demo/` into a PySpark `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbc1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType(\n",
    "    [\n",
    "        T.StructField(\"id\", T.StringType()),\n",
    "        T.StructField(\"contributors\", T.StringType()),\n",
    "        T.StructField(\"created_at\", T.StringType()),\n",
    "        T.StructField(\"source\", T.StringType()),\n",
    "        T.StructField(\"in_reply_to_screen_name\", T.StringType()),\n",
    "        T.StructField(\"source_text\", T.StringType()),\n",
    "        T.StructField(\"place_id\", T.StringType()),\n",
    "        T.StructField(\"place_url\", T.StringType()),\n",
    "        T.StructField(\"place_place_type\", T.StringType()),\n",
    "        T.StructField(\"place_country_code\", T.StringType()),\n",
    "        T.StructField(\"place_country\", T.StringType()),\n",
    "        T.StructField(\"user_name\", T.StringType()),\n",
    "        T.StructField(\"user_screen_name\", T.StringType()),\n",
    "        T.StructField(\"user_followers\", T.IntegerType()),\n",
    "        T.StructField(\"user_friends\", T.IntegerType()),\n",
    "        T.StructField(\"user_listed\", T.IntegerType()),\n",
    "        T.StructField(\"user_favourites\", T.IntegerType()),\n",
    "        T.StructField(\"user_statuses\", T.IntegerType()),\n",
    "        T.StructField(\"user_protected\", T.BooleanType()),\n",
    "        T.StructField(\"user_verified\", T.BooleanType()),\n",
    "        T.StructField(\"user_joined\", T.StringType()),\n",
    "        T.StructField(\"user_location\", T.StringType()),\n",
    "        T.StructField(\"retweeted_tweet\", T.StringType()),\n",
    "        T.StructField(\"text\", T.StringType()),\n",
    "        T.StructField(\"file_name\", T.StringType()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189d8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = spark.read.csv(\n",
    "    [f's3a://{s3_bucket_name}' + f\"/{f}\" for f in files_csvs_list],\n",
    "    header=True,\n",
    "    schema=schema,\n",
    "    # inferSchema=True\n",
    ").withColumnRenamed(\"text\", \"reviewText\")\n",
    "df = df.limit(nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca22ca",
   "metadata": {},
   "source": [
    "(Optional) Add a row number (row counter) column to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50656c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "w = Window().orderBy(F.lit('A'))\n",
    "df = df.withColumn(\"document\", F.row_number().over(w))\n",
    "with pd_option_context(\"display.max_columns\", 50):\n",
    "    display(show_pyspark_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6e6f38",
   "metadata": {},
   "source": [
    "Get the number of rows (retrieved tweets) in the data, number of pyspark `DataFrame` partitions and the number of workers on the host (single-node) cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06908bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\n",
    "    f\"Raw data contains {df.count():,} rows and {len(df.columns):,} columns \"\n",
    "    f\"in {df.rdd.getNumPartitions()} partitions, on a host with \"\n",
    "    f\"{len(os.sched_getaffinity(0))} CPUs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11395f13",
   "metadata": {},
   "source": [
    "Show the first 4 rows from the PySpark `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with pd_option_context(\"display.max_columns\", 100):\n",
    "    display(show_pyspark_df(df, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f216b2",
   "metadata": {},
   "source": [
    "Get a `DataFrame` version of the Spark Schema (`df.printSchema()`) for the PySpark `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a01534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtypes_pyspark = pd_DataFrame.from_records(\n",
    "    [\n",
    "        {\"name\": field.name, \"dtype\": field.dataType, \"nullable\": field.nullable}\n",
    "        for field in df.schema.fields\n",
    "    ]\n",
    ").set_index(\"name\")\n",
    "df_dtypes_pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2c3b5",
   "metadata": {},
   "source": [
    "Cache the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28357308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773f638",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085b8f2",
   "metadata": {},
   "source": [
    "For processing the data, text and non-text columns will be treated separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37768878",
   "metadata": {},
   "source": [
    "### Processing Non-Text Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6c59a",
   "metadata": {},
   "source": [
    "We'll define a PySparkML pipeline ([v2.4.0](https://spark.apache.org/docs/2.4.0/ml-pipeline.html#pipeline), [latest version](https://spark.apache.org/docs/latest/ml-pipeline.html), [API for latest version](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Pipeline.html)) to process all useful non-text columns from the data.\n",
    "\n",
    "This pipeline will accept a list of all useful columns and return a DataFrame with the same input columns and the processed versions, a suffix will be added to the column name to\n",
    "- indicate that it is has been processed\n",
    "- keep it separate from the raw data\n",
    "\n",
    "As an example, the column `created_at` will be converted from a string into a datetime datatype, and the converted version of this column will be returned as `created_at_dt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33aa069",
   "metadata": {},
   "source": [
    "The following processing steps will be applied\n",
    "- drop rows with duplicated tweets (retweets) since the text of the tweet (which will be used in NLP) is repeated\n",
    "  - for analysing text data with topic modeling, we don't need multiple observations (rows) with the same text (re-tweets)\n",
    "    - such rows are only useful when exploring the data after the text-based analysis has been completed\n",
    "      - if a topic is learned for a specific tweet, then that same topic applies to all re-tweets\n",
    "    - so, for NLP analysis, the duplicated rows (re-tweets) in the text column can be dropped\n",
    "  - based on how data was collected using `twitter_s3.py`, an example of a retweet is\n",
    "    - (row 10) `retweeted_tweet = 'no'` and text column = `'text here'`\n",
    "    - (row 91) `retweeted_tweet = 'yes'` and text column = `'text here'`\n",
    "    - (row 201) `retweeted_tweet = 'yes'` and text column = `'text here'`\n",
    "\n",
    "    where we only need the first tweet (row 10) and so we can drop all rows corresponding to retweets\n",
    "- convert the following columns from the `string` datatype to `datetime`s\n",
    "  - `created_at` (date and time when the tweet was posted)\n",
    "  - `user_joined` (date and time when user joined Twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b0afc",
   "metadata": {},
   "source": [
    "Apply the non-text processing pipeline to process all the useful non-text columns from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Remove retweets\n",
    "df = df.filter(df.retweeted_tweet != 'yes')\n",
    "\n",
    "# Select the columns to be processed, including the text column\n",
    "df_processed = df.select(all_cols_to_process)\n",
    "\n",
    "# Drop rows with a missing value in the text column\n",
    "df_processed = df_processed.na.drop(subset=[\"reviewText\"])\n",
    "\n",
    "# Apply datetime formatting for the two datetime columns\n",
    "for c in [\"created_at\", \"user_joined\"]:\n",
    "    df_processed = df_processed.withColumn(\n",
    "        f\"{c}_dt\",\n",
    "        F.to_timestamp(F.col(c), \"yyyy-MM-dd HH:mm:ss\"),\n",
    "    )\n",
    "\n",
    "print(f\"Number of rows in processed data = {df_processed.count():,}\")\n",
    "with pd_option_context(\"display.max_colwidth\", 1_000):\n",
    "    display(show_pyspark_df(df_processed, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81a10c",
   "metadata": {},
   "source": [
    "The non-text data processing is now ready and we can proceed to preparing the text data column for quantitative analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bd323",
   "metadata": {},
   "source": [
    "### Processing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a013",
   "metadata": {},
   "source": [
    "We'll now process the text data column. All the processed data columns from the previous section, including the text column, will be retained. However, here, we will only be processing the text column from this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a833c",
   "metadata": {},
   "source": [
    "#### Cleaning Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1b3f7",
   "metadata": {},
   "source": [
    "Since we are looking to build up a useful text vocabulary on which to perform NLP tasks, we'll first perform the following text cleaning steps\n",
    "- replace multiple whitespaces with a single whitespace from the text of the tweet\n",
    "- remove leading and trailing whitespace from the text of the tweet\n",
    "- drop rows where the tweet is missing or contains an empty string (if any)\n",
    "- change text to lowercase\n",
    "- remove numbers\n",
    "- remove punctuation\n",
    "\n",
    "The steps will help with [tokenization](https://neptune.ai/blog/tokenization-in-nlp) during the NLP data preparation step (done in the next sub-section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Replace multiple whitespaces with a single whitespace\n",
    "df_processed = df_processed.select(\n",
    "    all_cols_to_process\n",
    "    + [\"created_at_dt\", \"user_joined_dt\"]\n",
    "    + [\n",
    "        ch.replace_multiple_spaces(F.col(\"reviewText\")).alias(\n",
    "            \"reviewText_processed\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Remove leading and trailing spaces\n",
    "df_processed = df_processed.select(\n",
    "    all_cols_to_process\n",
    "    + [\n",
    "        ch.remove_lead_trail_spaces(F.col(\"reviewText_processed\")).alias(\n",
    "            \"reviewText_processed\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Change text to lowercase\n",
    "df_processed = df_processed.select(\n",
    "    all_cols_to_process\n",
    "    + [F.lower(F.col(\"reviewText_processed\")).alias(\"reviewText_processed\")]\n",
    ")\n",
    "\n",
    "# Remove special characters\n",
    "df_processed = df_processed.withColumn(\n",
    "    'reviewText_processed', F.regexp_replace('reviewText_processed', r\"[^a-zA-z]\", \" \")\n",
    ")\n",
    "\n",
    "# Remove numbers\n",
    "df_processed = df_processed.select(\n",
    "    all_cols_to_process\n",
    "    + [\n",
    "        F.regexp_replace(F.col(\"reviewText_processed\"), \"\\d+\", \"\").alias(\n",
    "            \"reviewText_processed\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Remove punctuation\n",
    "df_processed = df_processed.select(\n",
    "    all_cols_to_process\n",
    "    + [ch.remove_punctuation(F.col(\"reviewText_processed\")).alias(\"reviewText_processed\")]\n",
    ")\n",
    "\n",
    "# Drop rows where the tweet text is a blank string\n",
    "df_processed_no_blanks = df_processed.filter(df_processed[\"reviewText\"] != '')\n",
    "\n",
    "# Get words from the raw text (used as crude filter for tweets based on their length,\n",
    "# to remove short tweets)\n",
    "df_processed_no_blanks = df_processed_no_blanks.withColumn(\n",
    "    \"reviewText_trimmed\", F.trim(F.col(\"reviewText\"))\n",
    ").withColumn(\"words\", F.split(\"reviewText_trimmed\", \"\\s+\"))\n",
    "\n",
    "print(f\"Number of rows in processed data = {df_processed_no_blanks.count():,}\")\n",
    "show_pyspark_df(df_processed_no_blanks, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca00b6",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. In the Twitter streaming script `twitter_s3.py`, hashtags and usernames were removed from the text of the tweet and stored in a separate variable in the raw data. For this version of the analysis, we will not use hashtags and usernames but these can be combined with the tweet text in future iterations of this analysis.\n",
    "2. The last processing step above was to get a crude count of the number of words in each tweet. This was done in order to filter out short tweets, in order to help the effectiveness of the LDA algorithm (more is discussed next)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc948ba2",
   "metadata": {},
   "source": [
    "As mentioned earlier, LDA can be sub-optimal for topic modeling with short texts. We will now apply the following filter to the data to remove short tweets\n",
    "- for the purposes of this analysis, we will only keep raw tweets that have a minimum of 25 words\n",
    "  - as more tweets are streamed and the size of the processed data (shown immediately above) increases, we can increase this minimum number of words to a larger number than 25\n",
    "  - more is discussed about this length and about LDA for short texts at the end of this notebook\n",
    "  - earlier, we split the raw tweets into words; we will use this `words` column to filter out short tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed79524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_no_blanks = df_processed_no_blanks.filter(F.size(\"words\") > 25)\n",
    "print(\n",
    "    \"Number of rows in processed data, after filtering out tweets based on \"\n",
    "    f\"length of text = {df_processed_no_blanks.count():,}\"\n",
    ")\n",
    "show_pyspark_df(df_processed_no_blanks, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47361c",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. This significant reduces the size of the dataset passed to LDA, but it removes tweets that will be challenging to use with LDA.\n",
    "2. It is better to apply this filter here, before data is passed to the NLP pipeline, since those are expensive computing tasks that won't benefit from having these shorter texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c78b72",
   "metadata": {},
   "source": [
    "#### NLP on Cleaned Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0859bb65",
   "metadata": {},
   "source": [
    "Now, we'll apply an NLP pipeline to extract features from the cleaned text data. This pipeline will consist of the following three steps\n",
    "- tokenization\n",
    "  - here we will restrict the minimum token length that we will accept using the `minTokenLength` key word\n",
    "    - this is a hyperparameter of the NLP pipeline that can be tuned during future versions of this analysis\n",
    "- removal of stop words\n",
    "  - these are frequently occurring words that won't offer any useful information\n",
    "- vectorization\n",
    "  - this is the process of associating words or phrases from a text vocabulary to a real-valued vector\n",
    "  - there are several approaches to vectorization, but we will restrict ourselves to TFIDF vectorization ([1](https://openclassrooms.com/en/courses/6532301-introduction-to-natural-language-processing/7067116-apply-the-tf-idf-vectorization-approach), [2](https://monkeylearn.com/blog/what-is-tf-idf/))\n",
    "    - in PySpark this can be done using a combination of a `CountVectorizer` ([link](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.CountVectorizer.html)) and `IDF` ([link](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.IDF.html)) classes from the `pyspark.ml` module\n",
    "      - `CountVectorizer` has three particularly useful hyperparameters `minDF`, `maxDF` and `vocabSize` that could be extensively tuned in future versions of this analysis\n",
    "    - disadvantage of the TFIDF technique\n",
    "      - If a text corpus consists of 10 documents, then the vector created has a length of 10; if there are 10,000 documents, then the vector is of length 10,000. This means that the size and words in the vocabulary depend completely on the text corpus. The same words in two different vocabularies will produce different vector representations depending on the corpus being analysed. An alternative to this form of vectorization includes using word embeddings such as `Word2Vec` ([1](https://stackoverflow.com/questions/62749877/word2vec-in-short-text-clustering#comment110985077_62749877)), which was not used in this iteration of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = RegexTokenizer(\n",
    "    minTokenLength=5,\n",
    "    inputCol=\"reviewText_processed\",\n",
    "    outputCol=\"tokens\",\n",
    "    toLowercase=True,\n",
    "    pattern=\"\\\\s+\",  # default (meaning: https://stackoverflow.com/a/13750765/4057186)\n",
    "    # pattern=\"\\\\W\",  # other options to try to keep words: '[\\\\W_]+' or \"\\\\W\"\n",
    ")\n",
    "\n",
    "# Removal of Stop Words\n",
    "remover = StopWordsRemover(\n",
    "    inputCol=\"tokens\", outputCol=\"tokens_no_stopwords\", stopWords=all_stopwords\n",
    ")\n",
    "\n",
    "# TFIDF Vectorization\n",
    "count_vec_params = dict(\n",
    "    inputCol=\"tokens_no_stopwords\",\n",
    "    outputCol=\"rawFeatures\",\n",
    "    # vocabSize: default = 262144\n",
    "    vocabSize=262144,\n",
    "    # minDF: if float, ignores terms with document freq less than minDF (default = 1.0)\n",
    "    minDF=5,\n",
    "    # maxDF: if float, ignores tokens with document freq > maxDF (default = 9223372036854775807)\n",
    "    maxDF=0.75,\n",
    ")\n",
    "if save_count_vectorizer:\n",
    "    # Create new count vectorizer model\n",
    "    count_vectorizer = CountVectorizer(**count_vec_params)\n",
    "    print(f\"Defined new CountVectorizer object\")\n",
    "else:\n",
    "    # Get all paths (excluding prefix with protocol and bucket name) to previously saved\n",
    "    # count vectorizer models (sorted in ascending order by timestamp suffix in their filenames)\n",
    "    vectorizer_fpaths = iem.get_all_saved_vectorizer_models_from_s3(\n",
    "        s3_bucket_name,\n",
    "        aws_region,\n",
    "        f\"{path_to_folder[1:]}{s3_models_subfolder}/\",\n",
    "        \"count_vec\",\n",
    "    )\n",
    "    # Get full filepath to latest count vectorizer model\n",
    "    count_vectorizer_filepath = f\"s3a://{s3_bucket_name}/{vectorizer_fpaths[-1][:-1]}\"\n",
    "    # Load latest count vectorizer model from folder in S3 bucket\n",
    "    count_vectorizer = CountVectorizerModel.load(count_vectorizer_filepath)\n",
    "    print(\n",
    "        f\"Loaded CountVectorizer from folder {vectorizer_fpaths[-1][:-1]} in S3 bucket\"\n",
    "    )\n",
    "idf = IDF(minDocFreq=0, inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "tfidf_vectorizer = Pipeline(stages=[count_vectorizer, idf])\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"1gram_idf\"], outputCol=\"features\")\n",
    "\n",
    "# Combined text processing pipeline\n",
    "pipe = Pipeline(stages=[tokenizer, remover, tfidf_vectorizer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe93faa",
   "metadata": {},
   "source": [
    "Apply the text processing pipeline to process the text column from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d86edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe_trained = pipe.fit(df_processed_no_blanks)\n",
    "df_text_processed_no_blanks = pipe_trained.transform(df_processed_no_blanks)\n",
    "print(f\"Number of rows in processed data = {df_text_processed_no_blanks.count():,}\")\n",
    "show_pyspark_df(df_text_processed_no_blanks, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6897f6b",
   "metadata": {},
   "source": [
    "Save the trained `CountVectorizer` to a folder in S3 bucket (if specified in **User Inputs** section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcfb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if save_count_vectorizer:\n",
    "    # Assemble S3 filepath with timestamp in filename\n",
    "    timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    count_vectorizer_filepath = (\n",
    "        f\"s3a://{s3_bucket_name}{path_to_folder}{s3_models_subfolder}/{count_vectorizer_filename}_{timestr}\"\n",
    "    )\n",
    "    # Save the trained CountVectorizer in the relevant stage from the PySpark NLP pipeline\n",
    "    pipe_trained.stages[-1].stages[0].save(count_vectorizer_filepath)\n",
    "    print(f\"Saved newly trained CountVectorizer to path {count_vectorizer_filepath} in S3 bucket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced85e2",
   "metadata": {},
   "source": [
    "We'll now drop duplicates based on the processed text (before stopwords were removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5da9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_text_processed = df_text_processed_no_blanks.dropDuplicates(\n",
    "    subset=[\"reviewText_processed\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50481c3",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. All the texts are now in lowercase and have been processed so it is now possible to identify duplicates among tweets that could have previously differed from eachother only in whitespace or the case of the text that makes up the tweet (making it difficult or impossible to identify duplicated tweets), and then drop such duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a018c",
   "metadata": {},
   "source": [
    "Check if cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_processed.storageLevel.useMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e7cba",
   "metadata": {},
   "source": [
    "Cache the processed data, which will be queried and then used for LDA modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_processed_cached = df_text_processed.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c645b",
   "metadata": {},
   "source": [
    "#### Dropping Irrelevant Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d8f47",
   "metadata": {},
   "source": [
    "Although duplicated and re-tweets have been dropped, some tweets might be leftover that differ from others by a few characters or words. We'll refer to these as *leftover duplicates*. We'll now get a random sample of the processed data to visually inspect and identify any such leftover duplicated or inappropriate / irrelevant tweets that can be manually dropped for the analysis to be performed here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8119f60f",
   "metadata": {},
   "source": [
    "Get the number of rows in the processed data as a Python variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_rows_proc = df_text_processed_cached.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\n",
    "    \"Number of rows in processed data, after filtering tweets by length and\"\n",
    "    f\" removing duplicates = {n_rows_proc:,}\"\n",
    ")\n",
    "show_pyspark_df(df_text_processed_cached, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f36f8ef",
   "metadata": {},
   "source": [
    "Get a random sample of the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_sample = df_text_processed_cached.sample(withReplacement=False, fraction=50 / n_rows_proc).toPandas()\n",
    "with pd_option_context(\"display.max_rows\", 200):\n",
    "    with pd_option_context(\"display.max_colwidth\", 1_000):\n",
    "        display(df_sample[[\"document\", \"reviewText\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980ea28",
   "metadata": {},
   "source": [
    "## Topic Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e06c90",
   "metadata": {},
   "source": [
    "We'll now perform the quantitative analysis, which will be limited to unsupervised ML using the Latent Dirichlet Allocation (LDA) algorithm. It is implemented in PySpark ML and that implementation will be used here. Limitations of this choice are discussed in the **Conclusions and Future Work** section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0bbb1a",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956dc75",
   "metadata": {},
   "source": [
    "We'll define a dictionary of LDA hyper-parameters to be used to train the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab642d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_params_dict = dict(\n",
    "    featuresCol=\"features\",  # features or tokens_no_stopwords\n",
    "    optimizer=\"em\",  # 'online' or 'em'\n",
    "    maxIter=85,\n",
    "    k=num_topics,\n",
    "    seed=88,\n",
    ")\n",
    "lda = LDA(**lda_params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a16e33",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. Hyper-parameter tuning of the `maxIter` and `k` (number of topics) hyper-parameters was done by manually changing its values in this hyper-parameter dictionary and inspecting a chart of the top words (by weight) per topic (will be discussed shortly) and adjusting hyper-parameter values until coherent terms appeared in a given topic. With better data processing to remove leftover duplicated tweets (identified in the last sub-section of **Data Processing** above), these choices would be further tuned by reading the top documents per topic. All hyper-parameters in the NLP step were kept fixed while this manual tuning of the `maxIter` hyper-parameter was performed.\n",
    "2. The same approach was used for brief hyper-parameter tuning of the `minDF` and `maxDF` hyper-parameters of the TFIDF Vectorization step from the NLP sub-section earlier. During this brief tuning process, the `maxIter` value in the LDA algorithm was kept fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500fcc4",
   "metadata": {},
   "source": [
    "Train the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Starting time = {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}...\", end=\"\")\n",
    "model = lda.fit(df_text_processed_cached)\n",
    "print(f\"Done at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d0b64",
   "metadata": {},
   "source": [
    "## ML Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f859a02",
   "metadata": {},
   "source": [
    "### Terms per Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f611cd",
   "metadata": {},
   "source": [
    "Get the size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce7d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vocabSize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8691b12b",
   "metadata": {},
   "source": [
    "Get vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4d3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vocabList = pipe_trained.stages[-1].stages[0].vocabulary\n",
    "vocabList[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a39cda",
   "metadata": {},
   "source": [
    "Get topic-terms matrix with the top `n` term (token) weights for each topic ([1](https://spark.apache.org/docs/1.6.1/api/java/org/apache/spark/mllib/clustering/LDAModel.html#describeTopics()), [2](https://spark.apache.org/docs/latest/ml-clustering.html#latent-dirichlet-allocation-lda), [3](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.mllib.clustering.LDAModel.html#pyspark.mllib.clustering.LDAModel.describeTopics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9be5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topic_terms = model.describeTopics(maxTermsPerTopic=num_top_terms_per_topic)\n",
    "show_pyspark_df(df_topic_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166ada6",
   "metadata": {},
   "source": [
    "In order to interpret the LDA model's topics, the term names are of use to us and not the indices. Term names come from the vocabulary of the `CountVectorizer` ([1](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.CountVectorizer.html#pyspark.ml.feature.CountVectorizer.binary)) pre-processing step, which then allows us to convert the `termIndices` column to `termNames` that can be interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a7318",
   "metadata": {},
   "source": [
    "We will now get the term names for each topic using the vocabulary we retrieved above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dff = df_topic_terms.toPandas().apply(\n",
    "    lambda s: s.apply(pd_Series).stack().reset_index(drop=True, level=1)\n",
    ").reset_index(drop=True)\n",
    "# Map term indices to vocabulary terms, in order to get the term (token)\n",
    "# corresponding to each term index\n",
    "dff[\"termNames\"] = dff[\"termIndices\"].map(vocabList.__getitem__)\n",
    "dff['topic'] = dff['topic'].map('topic_{}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f88bfc",
   "metadata": {},
   "source": [
    "Plot the top `n` terms for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vh.altair_plot_grid_by_column(\n",
    "    dff,\n",
    "    xvar=\"termWeights\",\n",
    "    yvar=\"termNames\",\n",
    "    col2grid=\"topic\",\n",
    "    space_between_plots=10,\n",
    "    row_size=1,\n",
    "    fig_size=(150, 200),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ae699",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. This was the chart used to manually tune hyper-parameters, as mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7a83d",
   "metadata": {},
   "source": [
    "We'll now export this small `DataFrame` with the weights of the tterms for each topic to a CSV file in the `predictions/` sub-folder in the same S3 bucket containing the sub-folder with the hourly CSV files that were loaded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Starting time = {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}...\", end=\"\")\n",
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "full_file_path = (\n",
    "    f\"s3://{s3_bucket_name}{path_to_folder}\"\n",
    "    f\"{s3_models_subfolder}/term_weights_{timestr}.csv\"\n",
    ")\n",
    "dff.to_csv(full_file_path)\n",
    "print(f\"done at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67b86c",
   "metadata": {},
   "source": [
    "### Topics per Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52010ad4",
   "metadata": {},
   "source": [
    "Get the topics per document.i.e. make predictions with the trained LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topics_matrix = model.transform(df_text_processed_cached)\n",
    "with pd_option_context('display.max_colwidth', 1_000):\n",
    "    display(\n",
    "        show_pyspark_df(\n",
    "            df_topics_matrix.select(\n",
    "                [\"document\", \"created_at\", \"user_joined\", \"reviewText\", \"topicDistribution\"]\n",
    "            ),\n",
    "            3,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6593fd",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The LDA model's predictions for topics is a vector of probabilities (that add up to 1.0) for each topic, per row (document) in the data. This vector is shown in the `topicDistribution` column above and is referred to as the distribution of topics across for each document ([1](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.LDA.html#pyspark.ml.clustering.LDA.topicDistributionCol), [2](https://stackoverflow.com/questions/33072449/extract-document-topic-matrix-from-pyspark-lda-model), [3](https://stackoverflow.com/questions/49740675/how-to-get-the-topic-probability-for-each-document-for-topic-modeling-using-lda), [4](https://www.mathworks.com/help/textanalytics/ref/ldamodel.html#d123e21088)). LDA's predictions don't give a single discrete topic but, instead, return this vector and the user must decide how to interpret the values in each vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99656952",
   "metadata": {},
   "source": [
    "Check if cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics_matrix.storageLevel.useMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0f156",
   "metadata": {},
   "source": [
    "Cache the LDA model's predictions since it will be used to explode the vectors of topic distribution into separate columns and then query those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_topics_matrix_cached = df_topics_matrix.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267dfc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# IGNORE\n",
    "# df_topics_matrix_pandas = df_topics_matrix_cached.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771d04a",
   "metadata": {},
   "source": [
    "We'll now extract the vector of topic probabilities into separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd27092",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ith = F.udf(mih.ith_, T.DoubleType())\n",
    "df_processed_topics_matrix = df_topics_matrix_cached.select(\n",
    "    df_topics_matrix_cached.columns\n",
    "    + [\n",
    "        ith(\"topicDistribution\", F.lit(i)).alias(\"topic_\" + str(i))\n",
    "        for i in range(num_topics)\n",
    "    ]\n",
    ")\n",
    "show_pyspark_df(df_processed_topics_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc9a98d",
   "metadata": {},
   "source": [
    "Finally, we'll extract a new column (`dominant_topic`) with the topic with the highest probability predicted by the LDA model (`dominant_prob`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_processed_topics_matrix = mih.get_max_val_name(\n",
    "    df_processed_topics_matrix, topic_cols, [\"dominant_prob\", \"dominant_topic\"]\n",
    ")\n",
    "show_pyspark_df(df_processed_topics_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a106d73",
   "metadata": {},
   "source": [
    "Check if cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8193045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_topics_matrix.storageLevel.useMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa217e1",
   "metadata": {},
   "source": [
    "Cache the data with these two new columns added, since it will be used in multiple queries (next) to print out the raw tweets (texts) for reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9070d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_processed_topics_matrix_cached = df_processed_topics_matrix.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f871d8",
   "metadata": {},
   "source": [
    "A random sample of the documents (tweets) predicted with the highest probability to belong to each topic are printed out below for reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26808d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "visual_sep = '=' * 25\n",
    "for q, topic_col in enumerate([f\"topic_{n}\" for n in range(num_topics)]):\n",
    "    # Get top 50 documents based on predicted probability, within a single topic\n",
    "    df_single_topic = df_processed_topics_matrix_cached.select(\n",
    "        cols_to_show_when_reading\n",
    "    ).filter(\n",
    "        f\"dominant_topic == '{topic_col}'\"\n",
    "    ).orderBy(topic_col, ascending=[False]).limit(50)\n",
    "    # Get a random sample of the top 50 documents (tweets)\n",
    "    n_rows_proc = df_single_topic.count()\n",
    "    df_single_topic = df_single_topic.sample(\n",
    "        withReplacement=False,\n",
    "        fraction=num_top_docs_to_read / n_rows_proc,\n",
    "    )\n",
    "    # Convert sample to pandas (this will be a small DataFrame of < 10 rows)\n",
    "    df_single_topic_pandas = df_single_topic.toPandas()\n",
    "\n",
    "    # Create string of top n terms and term weights\n",
    "    term_weights_names_str = \", \".join(\n",
    "        [\n",
    "            f\"{row['termNames']} = {row['termWeights']:.4f}\"\n",
    "            for _, row in (\n",
    "                dff.query(f\"topic == '{topic_col}'\").iloc[:, -2:].iterrows()\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    if q > 0:\n",
    "        print(\"\\n\")\n",
    "    print(f\"{visual_sep} topic = {topic_col} {visual_sep}\\n{term_weights_names_str}\\n\")\n",
    "    # Print random sample of the text of the tweet from the n documents with the highest\n",
    "    # predicted probability of belonging to a given topic\n",
    "    # - this involves iterating over the rows of the small pandas DataFrame created above\n",
    "    for idx, row in df_single_topic_pandas.iterrows():\n",
    "        topic_probs_str = \", \".join(\n",
    "            [\n",
    "                f\"{topic_name_str} = {topic_prob_value:.3f}\"\n",
    "                for topic_name_str, topic_prob_value in row[topic_cols]\n",
    "                .sort_values(ascending=False)\n",
    "                .iteritems()\n",
    "            ]\n",
    "        )\n",
    "        print(f\"document = {row['document']}: {topic_probs_str}\\n{row['reviewText'].strip()}\")\n",
    "        if idx < len(df_single_topic_pandas) - 1:\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f846877",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. These should allow for fine-tuning the choices of topic names determined by inspecting the top terms in each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ea949",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. When 10-12 topics were chosen, a number of different topics contained tweets about the same subject. This is an indicator that the number of topics must be reduced. When 5-7 topics were picked, the overlap reduced sufficiently that it seemed like there was some distinction between the topics. **From the runs of this notebook with varying `num_topics` (number of topics passed to the LDA algorithm), the optimal choice for the number of topics in the streamed twitter data was determined to be 4, based on the best combination of (a) reading the content of the tweets with the highest predicted probability of belonging to a topic and (b) interpreting the top terms (by weight) per topic.**\n",
    "2. It is possible that there are two choices for the optimal number of topics\n",
    "   - choosing a smaller number that reveals the high-level topics (this appears to be the case here)\n",
    "   - choosing a larger number that reveals the low-level topics, possibly sub-topics within each of the high-level topics\n",
    "     - from the preliminary tuning of `num_topics` done here, using this approach, it was not possible to extract meaningful topics that were also able to capture the same subject (in the text of the tweets) as the subject suggested by the top terms (by weight) in each topic\n",
    "3. It is clear that further pre-processing is required to filter out the *leftover duplicated tweets*. Without doing this, it can be difficult to use the output printed above to fine-tune / verify the name of the topic found using the top words in each topic, since multiple (duplicated) versions of the same tweet appear in the random sample of the top `n` tweets (documents) within each topic. We want these printed tweets to be unique since such text will help to verify the name assigned to the topics. Futher filtering to remove these duplicates (by extending the list `unwanted_partial_strings_list` used to filter tweets in `3_combined_data.ipynb`) does appear necessary before reading tweets will be useful for naming topics and picking an appropriate number of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9bb9d0",
   "metadata": {},
   "source": [
    "### Naming the Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa3a23",
   "metadata": {},
   "source": [
    "Based on the top terms per topic and reading the tweets predicted (with a high probability) to belong to a given topic, the following are the names assigned to the topics\n",
    "- topic 3\n",
    "  - All about Satellites and Telescopes for Space Exploration\n",
    "    - Space Mission updates\n",
    "    - space research competition\n",
    "    - space explorer comic book\n",
    "- topic 2\n",
    "  - Activities related to Space Research\n",
    "    - People and companies associated with advancing research in the space sector\n",
    "    - shuttle launch tests\n",
    "    - opening of space research facility\n",
    "- topic 1\n",
    "  - [Astrology](https://undsci.berkeley.edu/article/astrology_checklist) predictions\n",
    "    > Astrology uses a set of rules about the relative positions and movements of heavenly bodies to generate predictions and explanations for events on Earth and human personality traits.\n",
    "- topic 0\n",
    "  - Astronomy\n",
    "    - satellite images of the Earth and Moon\n",
    "    - people involved in astronomy research\n",
    "    - satellite centers associated with facilities also appear here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f499cf3",
   "metadata": {},
   "source": [
    "Use a Python dictionary to replace placeholder values in the `dominant_topic` column of the cached `DataFrame` above with the names assigned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4644bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"topic_3\": \"Satellites and Telescopes\",\n",
    "    \"topic_2\": \"Activities related to Space Research\",\n",
    "    \"topic_1\": \"Astrology\",\n",
    "    \"topic_0\": \"Astronomy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3dca8e",
   "metadata": {},
   "source": [
    "Show the number of missing values in the mapped `dominant_topic` that would result when applying this mapping (there should be no missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e246857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_topics_matrix_cached.withColumn(\n",
    "    \"dominant_topic_named\", F.col(\"dominant_topic\")\n",
    ").replace(to_replace=mapping, subset=[\"dominant_topic_named\"]).where(\n",
    "    F.col(\"reviewText\").isNull()\n",
    ").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12293645",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. There are no missing values after applying the mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9d9fe",
   "metadata": {},
   "source": [
    "Apply the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524622c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_processed_topics_matrix_cached = df_processed_topics_matrix_cached.withColumn(\n",
    "    \"dominant_topic_named\",\n",
    "    F.col(\"dominant_topic\")\n",
    ").replace(\n",
    "    to_replace=mapping,\n",
    "    subset=['dominant_topic_named']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e12e8",
   "metadata": {},
   "source": [
    "We'll also re-generate the above plot with the new topic names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vh.altair_plot_grid_by_column(\n",
    "    dff.replace({\"topic\": mapping}),\n",
    "    xvar=\"termWeights\",\n",
    "    yvar=\"termNames\",\n",
    "    col2grid=\"topic\",\n",
    "    space_between_plots=10,\n",
    "    row_size=1,\n",
    "    fig_size=(150, 200),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cf2c1",
   "metadata": {},
   "source": [
    "## Merge with Processed Data and Export to S3 `predictions/` sub-folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b947b9a2",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f873ec86",
   "metadata": {},
   "source": [
    "The processed data is shown below (this was before duplicates in the `reviewText_processed` column were dropped and after tweets were filtered by their length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899df7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "show_pyspark_df(df_text_processed_no_blanks.select(all_cols_to_process), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38261661",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The predicted topics are only valid for the tweets (texts) that are sufficiently long. For this reason, we can only merge with the processed data that was prepared by removing the short tweets and cannot merge with the raw data since there would be a lot of tweets without a predicted topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53471218",
   "metadata": {},
   "source": [
    "We'll now `LEFT JOIN` this with the filtered data that was used for LDA analysis, so that we can get the topic assigned to all duplicates of a particular tweet. The join will be performed on the processed version of the tweet text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea1381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_processed_with_topics = df_text_processed_no_blanks.select(all_cols_to_process + [\"reviewText_processed\"]).alias(\"left\").join(\n",
    "    df_processed_topics_matrix_cached.select([\"reviewText\", \"reviewText_processed\", \"dominant_topic_named\", \"dominant_prob\"]).alias(\"right\"),\n",
    "    on=[\"reviewText_processed\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "show_pyspark_df(df_processed_with_topics, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5c3ea",
   "metadata": {},
   "source": [
    "Since the raw version of the tweet text columns were not involved in the `JOIN` but are present on both the LHS and RHS, they will both appear in the merged data. Find all rows where these two columns do not agree with each other after the `JOIN` was performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with pd_option_context(\"display.max_colwidth\", 5000):\n",
    "    display(\n",
    "        show_pyspark_df(\n",
    "            df_processed_with_topics\n",
    "            .withColumn(\"d\", F.col(\"left.reviewText\") == F.col(\"right.reviewText\"))\n",
    "            .where(F.col(\"d\") == False)\n",
    "            .select(\n",
    "                [\n",
    "                    F.col(\"left.reviewText\").alias(\"reviewText_left\"),\n",
    "                    F.col(\"right.reviewText\").alias(\"reviewText_right\"),\n",
    "                ]\n",
    "            ),\n",
    "            100\n",
    "        ).sample(10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6910b1c1",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. Above is a random sample of 10 rows where these two columns do not agree with eachother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4a077",
   "metadata": {},
   "source": [
    "**Observeations**\n",
    "1. Above is a comparison of the `reviewText` columns on either side of the `LEFT JOIN` that do not match eachother. It is not very clear why most of these rows do not match. The column on the left comes from the processed data and the column on the right from the processed and de-duplicated data that was passed through the NLP pipeline and LDA. Since there doen't appear to be clearly visible differences in most of these rows, we'll\n",
    "   - use the left version in EDA (next section)\n",
    "   - keep both versions\n",
    "   - rename the columns by adding the `_left` and `_right` suffix respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbfcd2",
   "metadata": {},
   "source": [
    "Rename `reviewText` columns by appending a suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "col_renaming_dict = {'left.reviewText': 'reviewText_left', 'right.reviewText': 'reviewText_right'}\n",
    "for k, v in col_renaming_dict.items():\n",
    "    df_processed_with_topics = df_processed_with_topics.withColumn(v, F.col(k)).drop(F.col(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327e836",
   "metadata": {},
   "source": [
    "Check if cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_with_topics.storageLevel.useMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0893551f",
   "metadata": {},
   "source": [
    "Cache the merged data, which will be used to count missing values next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ebebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_processed_with_topics_cached = df_processed_with_topics.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d89c50",
   "metadata": {},
   "source": [
    "Show the number of rows in the processed data (LHS of the `LEFT JOIN`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4362953",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_text_processed_no_blanks.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83552ead",
   "metadata": {},
   "source": [
    "Show the number of rows in the merged data (RHS of the `LEFT JOIN`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14739702",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_processed_with_topics_cached.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59205b",
   "metadata": {},
   "source": [
    "Verify that there are no missing values in the merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a0b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# count missing values in the tweet text of the processed data (LHS of the LEFT JOIN)\n",
    "df_text_processed_no_blanks.where(F.col(\"reviewText\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# count missing values in the tweet text of the merged data\n",
    "df_processed_with_topics_cached.where(F.col(\"reviewText_left\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed8b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# count missing values in the tweet text of the merged data\n",
    "df_processed_with_topics_cached.where(F.col(\"reviewText_right\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86db818",
   "metadata": {},
   "source": [
    "Count the number of rows with a missing value in the predicted topic name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72518af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_processed_with_topics_cached.where(F.col(\"dominant_topic_named\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e584149",
   "metadata": {},
   "source": [
    "### Export to `predictions/` sub-folder in S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a53928",
   "metadata": {},
   "source": [
    "Show the number of PySpark `DataFrame` partitions in the merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b30190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_with_topics_cached.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d358fa1",
   "metadata": {},
   "source": [
    "We'll now export this merged data to the `predictions/` sub-folder in the same S3 bucket containing the sub-folder with the hourly CSV files that were loaded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9997f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Starting time = {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}...\", end=\"\")\n",
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "full_file_path = (\n",
    "    f\"s3a://{s3_bucket_name}{path_to_folder}predictions/\"\n",
    "    f\"{output_file_name}_{timestr}.parquet.gzip\"\n",
    ")\n",
    "(\n",
    "    df_processed_with_topics_cached\n",
    "    .write.mode(\"overwrite\")\n",
    "    .option('compression', 'gzip')\n",
    "    .option(\"header\", \"true\")\n",
    "    .parquet(full_file_path)\n",
    ")\n",
    "print(f\"Done at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df38207f",
   "metadata": {},
   "source": [
    "### (Optional) Read Exported Data from the `predictions/` sub-folder in S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c4237",
   "metadata": {},
   "source": [
    "Get path to pre-existing Parquet file saved in the `predictions/` sub-folder in S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c463a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parquet_files_list = s3h.get_existing_csv_files_list(\n",
    "    s3_bucket_name, path_to_folder[1:] + f\"predictions/{output_file_name}_\"\n",
    ")\n",
    "main_parquet_files_list = [f.rstrip(\"/_SUCCESS\") for f in parquet_files_list if \"_SUCCESS\" in f]\n",
    "print(main_parquet_files_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff30569",
   "metadata": {},
   "source": [
    "Assemble dictionary with full filepath to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac62021",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_file_paths_dict = {\n",
    "    \"pyspark\": f\"s3a://{s3_bucket_name}/{main_parquet_files_list[0]}\",\n",
    "    \"pandas\": f\"s3://{s3_bucket_name}/{main_parquet_files_list[0]}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889817f",
   "metadata": {},
   "source": [
    "#### PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc0ef0",
   "metadata": {},
   "source": [
    "Check that we can read the exported data back with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ab8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded = spark.read.parquet(full_file_paths_dict[\"pyspark\"])\n",
    "show_pyspark_df(df_reloaded, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7152e",
   "metadata": {},
   "source": [
    "Check if cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reloaded.storageLevel.useMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8119f",
   "metadata": {},
   "source": [
    "Cache the reloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached = df_reloaded.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db6af4",
   "metadata": {},
   "source": [
    "Show (a `DataFrame` version of) the Spark Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtypes_pyspark = pd_DataFrame.from_records(\n",
    "    [\n",
    "        {\"name\": field.name, \"dtype\": field.dataType, \"nullable\": field.nullable}\n",
    "        for field in df_reloaded.schema.fields\n",
    "    ]\n",
    ").set_index(\"name\")\n",
    "df_dtypes_pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc95199",
   "metadata": {},
   "source": [
    "Show the number of rows in the re-loaded PySpark `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c9e585",
   "metadata": {},
   "source": [
    "Show the number of PySpark `DataFrame` partitions in the reloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fdedf",
   "metadata": {},
   "source": [
    "#### `dask.DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e682987",
   "metadata": {},
   "source": [
    "Check that we can read the exported data back with Dask `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4295d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf = dd.read_parquet(full_file_paths_dict[\"pandas\"], engine=\"auto\")\n",
    "ddf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ffe0d",
   "metadata": {},
   "source": [
    "Show the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5292b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.dtypes.rename(\"dtype\").rename_axis(\"name\").to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec003f",
   "metadata": {},
   "source": [
    "Show the number of rows in the re-loaded `dask.DataFrame` (DDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7415776",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len(ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d43eac",
   "metadata": {},
   "source": [
    "Show the number of `dask.DataFrame` partitions in the reloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7066d",
   "metadata": {},
   "source": [
    "Get length of each partition in the re-loaded DDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01441d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf_partition_sizes = (\n",
    "    ddf.map_partitions(len)\n",
    "    .compute()\n",
    "    .rename(\"num_rows_in_partition\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"partition_index\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c41ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd_option_context(\"display.max_rows\", 200):\n",
    "    display(ddf_partition_sizes.sample(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e348e1",
   "metadata": {},
   "source": [
    "#### `pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64933541",
   "metadata": {},
   "source": [
    "Check that we can read this back with Pandas (this will only be possible if the data is small enough to fit into memory; if not, then `dask` or `pyspark` are required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed970125",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_pandas = pd_read_parquet(full_file_paths_dict[\"pandas\"], engine=\"auto\")\n",
    "df_reloaded_pandas.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab509a3",
   "metadata": {},
   "source": [
    "Show the datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f68d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reloaded_pandas.dtypes.rename(\"dtype\").rename_axis(\"name\").to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0647070e",
   "metadata": {},
   "source": [
    "Show the number of rows in the re-loaded `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_reloaded_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bf6b5",
   "metadata": {},
   "source": [
    "## EDA of Data with Assigned Topic Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1815951",
   "metadata": {},
   "source": [
    "This section will include a brief exploration of the data with the predicted topic names using the data reloaded into the `PySpark` `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168111c",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435643e",
   "metadata": {},
   "source": [
    "Drop rows with a missing topic name in the `dominant_topic_named` column (see discussion about this in the **Merge with Processed Data and Export to S3** section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ad50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Pandas\n",
    "# import pandas as pd\n",
    "# df_reloaded_pandas = df_reloaded_pandas.dropna(subset=[\"dominant_topic_named\"])\n",
    "\n",
    "# PySpark\n",
    "df_reloaded_cached = df_reloaded_cached.dropna(subset=[\"dominant_topic_named\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f97a8",
   "metadata": {},
   "source": [
    "Convert timestamp columns to `datetime` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Pandas\n",
    "# df_reloaded_pandas[\"created_at_hour\"] = pd.to_datetime(\n",
    "#     df_reloaded_pandas[\"created_at\"]\n",
    "# ).dt.hour\n",
    "# df_reloaded_pandas[\"created_at_weekday\"] = pd.to_datetime(\n",
    "#     df_reloaded_pandas[\"created_at\"]\n",
    "# ).dt.day_name()\n",
    "# df_reloaded_pandas['created_at_dt'] = pd.to_datetime(df_reloaded_pandas['created_at']).dt.date\n",
    "\n",
    "# PySpark\n",
    "df_reloaded_cached = df_reloaded_cached.withColumn(\n",
    "    \"created_at_dt\", F.date_format(df_reloaded_cached.created_at, \"yyyy-MM-dd HH:mm:ss\")\n",
    ")\n",
    "df_reloaded_cached = df_reloaded_cached.withColumn(\n",
    "    \"created_at_hour\", F.hour(\"created_at_dt\")\n",
    ").withColumn(\"created_at_weekday\", F.date_format(\"created_at_dt\", \"E\"))\n",
    "df_reloaded_cached = df_reloaded_cached.withColumn(\"created_at_date\", F.to_date(\"created_at_dt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b5fb6",
   "metadata": {},
   "source": [
    "### Business Questions about the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48eac4",
   "metadata": {},
   "source": [
    "**1. Get the 10 most common Twitter user screen names who received a reply to any of their tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Pandas\n",
    "# df_reloaded_pandas[\"in_reply_to_screen_name\"].value_counts().nlargest(10).to_frame()\n",
    "\n",
    "# PySpark\n",
    "df_most_replied_to_user_toPandas = (\n",
    "    df_reloaded_cached.groupBy([\"in_reply_to_screen_name\"])\n",
    "    .count()\n",
    "    .orderBy([\"count\"], ascending=False)\n",
    "    .toPandas()\n",
    ")\n",
    "df_most_replied_to_user_toPandas.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d2fb9a",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. The majority of the tweets were not posted as a reply to another user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4079af3",
   "metadata": {},
   "source": [
    "**2. What are the 20 Twitter clients that were most frequently used to post a tweet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Pandas\n",
    "# df_reloaded_pandas[\"source_text\"].value_counts().nlargest(10).to_frame()\n",
    "\n",
    "# PySpark\n",
    "df_top_clients_toPandas = (\n",
    "    df_reloaded_cached.groupBy([\"source_text\"])\n",
    "    .count()\n",
    "    .orderBy([\"count\"], ascending=False)\n",
    "    .toPandas()\n",
    ")\n",
    "df_top_clients_toPandas.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37df0cb",
   "metadata": {},
   "source": [
    "**3. For the top 7 most frequently used Twitter clients, show an appropriate chart of the frequency (number of tweets) for each of the named topics in this dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32bb1d",
   "metadata": {},
   "source": [
    "Get a list with the top twenty most frequently used Twitter clients (using result of above question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec20f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_wanted = df_top_clients_toPandas[\"source_text\"].tolist()[:7]\n",
    "sources_wanted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d05322",
   "metadata": {},
   "source": [
    "Count the number of tweets posted from each of these top 20 clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b501ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Pandas\n",
    "# df_reloaded_pandas[df_reloaded_pandas[\"source_text\"].isin(sources_wanted)].groupby(\n",
    "#     [\"source_text\", \"dominant_topic_named\"], as_index=False\n",
    "# ).size()\n",
    "\n",
    "# PySpark\n",
    "df_sources_grouped = df_reloaded_cached.filter(F.col(\"source_text\").isin(sources_wanted)).groupBy(\n",
    "    [\"source_text\", \"dominant_topic_named\"]\n",
    ").count().orderBy([\"source_text\", \"dominant_topic_named\"], ascending=[True, True])\n",
    "show_pyspark_df(df_sources_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3874be5",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Twitter for iPhone seems to be the preferred platform for users posting tweets about Astrology. The absolute number of tweets, within this topic, is the highest for the twitter app on the iPhone. On all other platforms, the fewest tweets posted fall under the Astrology topic. However, on the iPhone app, Astrology is among the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c84d4",
   "metadata": {},
   "source": [
    "Pivot the clientwise grouped data keeping client along the rows and topics along the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a7d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distinct_column_vals = [\n",
    "    v.asDict()[\"dominant_topic_named\"]\n",
    "    for v in df_reloaded_cached.select(\"dominant_topic_named\").distinct().collect()\n",
    "]\n",
    "df_sources_pivotted_toPandas = df_sources_grouped.groupBy(\"source_text\").pivot(\n",
    "    \"dominant_topic_named\", distinct_column_vals\n",
    ").sum(\"count\").withColumnRenamed(\n",
    "    \"Activities related to Space Research\", \"Space Research\"\n",
    ").withColumnRenamed(\n",
    "    \"Satellites and Telescopes\", \"Satellites / Telescopes\"\n",
    ").toPandas().set_index(\"source_text\")\n",
    "df_sources_pivotted_toPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e2de4",
   "metadata": {},
   "source": [
    "Re-shape data into format suitable for PlotLy `go.Heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annot = df_sources_pivotted_toPandas.copy()\n",
    "for col in df_annot:\n",
    "    df_annot[col] = df_annot[col].map(\"{:,}\".format)\n",
    "data_dict = vh.convert_df_to_format_for_plotly_heatmap(\n",
    "    df_sources_pivotted_toPandas, df_annot, True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43606a9",
   "metadata": {},
   "source": [
    "Plot the heatmap from the reshaped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vh.plot_plotly_heatmap(\n",
    "    data_dict=data_dict,\n",
    "    annotation_text=data_dict[\"annotation_text\"],\n",
    "    margin_dict=dict(l=30, r=0, b=0, t=0, pad=0),\n",
    "    fig_width=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52119e8",
   "metadata": {},
   "source": [
    "**4. Show descriptive statistics (min, mean, median and max) about the number of users followers, by topic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de21d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Pandas\n",
    "# df_reloaded_pandas.groupby([\"dominant_topic_named\"], as_index=False)[\n",
    "#     \"user_followers\"\n",
    "# ].agg([\"min\", \"mean\", \"median\", \"max\"])\n",
    "\n",
    "# PySpark\n",
    "df_stats_by_topic_toPandas = df_reloaded_cached.groupby([\"dominant_topic_named\"]).agg(\n",
    "    F.min(F.col('user_followers')).alias('user_followers_min'),\n",
    "    F.avg(F.col('user_followers')).alias('user_followers_mean'),\n",
    "    # F.percentile_approx(\"user_followers\", 0.5).alias(\"user_followers_median\"),  # pyspark>=3.1.0\n",
    "    F.expr('percentile(user_followers, array(0.5))')[0].alias('50%'),  # pyspark==2.4.0\n",
    "    F.max(F.col('user_followers')).alias('user_followers_max'),\n",
    ").toPandas()\n",
    "df_stats_by_topic_toPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90160b29",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Users who tweeted about Astrology have the fewest followers on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631bf84c",
   "metadata": {},
   "source": [
    "**5. Show a heatmap of the number of tweets by hour of the day and day of the week, for the most popular topic during every combination of hour and weekday on which Twitter data was streamed. Create a chart from this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Pandas\n",
    "# df_reloaded_pandas.groupby(\n",
    "#     [\"created_at_weekday\", \"created_at_hour\", \"dominant_topic_named\"], as_index=False\n",
    "# )[\"document\"].count().sort_values(\"document\", ascending=False).groupby(\n",
    "#     [\"created_at_weekday\", \"created_at_hour\"]\n",
    "# ).first().reset_index()\n",
    "\n",
    "# PySpark\n",
    "df_reloaded_cached_dt_agg = df_reloaded_cached.groupBy(\n",
    "    [\"created_at_date\", \"created_at_weekday\", \"created_at_hour\", \"dominant_topic_named\"]\n",
    ").count().orderBy([\"count\"], ascending=False)\n",
    "w = Window.partitionBy(\n",
    "    [\"created_at_date\", \"created_at_weekday\", \"created_at_hour\"]\n",
    ").orderBy(F.desc(\"count\"))\n",
    "df_most_tweeted_topics = df_reloaded_cached_dt_agg.withColumn(\n",
    "    \"row_number\", F.row_number().over(w)\n",
    ").where(\"row_number = 1\").drop(\"row_number\")\n",
    "df_most_tweeted_topics_toPandas = df_most_tweeted_topics.toPandas()\n",
    "df_most_tweeted_topics_toPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828bf90",
   "metadata": {},
   "source": [
    "Convert the `create_at_date` column to a string, which Altair can serialize to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc4ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most_tweeted_topics_toPandas[date_col_name] = pd.to_datetime(\n",
    "    df_most_tweeted_topics_toPandas[date_col_name]\n",
    ").dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91576c4f",
   "metadata": {},
   "source": [
    "Plot the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chart = vh.plot_altair_heatmap(\n",
    "    data=df_most_tweeted_topics_toPandas,\n",
    "    legend=alt.Legend(\n",
    "        title=\"Average Number of Tweets\",\n",
    "        orient=\"none\",\n",
    "        legendX=250,\n",
    "        titleAnchor=\"start\",\n",
    "        direction=\"vertical\",\n",
    "    ),\n",
    "    tooltip=[\n",
    "        alt.Tooltip(\"created_at_hour:O\", title=\"Hour\"),\n",
    "        alt.Tooltip(\"created_at_weekday:N\", title=\"Weekday\"),\n",
    "        alt.Tooltip(\"created_at_date:N\", title=\"Date\"),\n",
    "        alt.Tooltip(\"dominant_topic_named:N\", title=\"Topic\"),\n",
    "        alt.Tooltip(f\"mean(count):Q\", title=\"Avg. Number of Tweets\", format=\",\"),\n",
    "    ],\n",
    "    agg=\"mean\",\n",
    "    xvar=\"created_at_weekday\",\n",
    "    yvar=\"created_at_hour\",\n",
    "    color_by_col=\"count\",\n",
    "    ptitle=\"Tweets During the Day\",\n",
    "    sort_x=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"],\n",
    "    sort_y=list(range(0, 23 + 1)),\n",
    "    marker_linewidth=1,\n",
    "    cmap=\"yelloworangered\",\n",
    "    scale=\"log\",\n",
    "    show_x_labels=True,\n",
    "    show_y_labels=True,\n",
    "    fig_size=(240, 750),\n",
    ").configure_view(strokeWidth=0).configure_axis(\n",
    "    domain=False, labelFontSize=14, titleFontSize=16\n",
    ").configure_title(\n",
    "    anchor=\"middle\", fontSize=16\n",
    ").configure_legend(labelFontSize=14)\n",
    "display(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a773b5",
   "metadata": {},
   "source": [
    "**6. Did any verified or protected Twitter users posted tweets?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc239fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.where(F.col(\"user_protected\") == True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b6886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.where(F.col(\"user_verified\") == True).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324bb0f1",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. There were no tweets by protected users.\n",
    "2. There were approximately 4,000 tweets by verified users, out of a total of approximately 240,000 tweets with a topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c67837",
   "metadata": {},
   "source": [
    "**7. In how many tweets is the user's location available? In how many is it missing?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835dffa4",
   "metadata": {},
   "source": [
    "Count for non-missing and missing values in the `place_country` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c4603",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.where(~F.col(\"place_country\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.where(F.col(\"place_country\").isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c1b65",
   "metadata": {},
   "source": [
    "Count for non-missing and missing values in the `user_location` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.where(F.col(\"user_location\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab28be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.where(F.col(\"user_location\") == \"None\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached.where(~(F.col(\"user_location\") == \"None\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f6c48",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "1. Out of 240,000 tweets\n",
    "   - approximately 1,000 tweets are not missing a value in the `place_country` column\n",
    "   - approximately 154,000 tweets are not missing a value in the `user_location` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ad0ab",
   "metadata": {},
   "source": [
    "**8. What are the 50 user locations from which tweets were posted?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ffd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Pandas\n",
    "# df_reloaded_pandas[\"user_location\"].value_counts().nlargest(10).to_frame()\n",
    "\n",
    "# PySpark\n",
    "df_top_locations_toPandas = (\n",
    "    df_reloaded_cached\n",
    "    .where(~(F.col(\"user_location\").isin([\"Earth\", \"Planet Earth\", \"she/her\", \"None\"])))\n",
    "    .groupBy([\"user_location\"])\n",
    "    .count()\n",
    "    .orderBy([\"count\"], ascending=False)\n",
    "    .toPandas()\n",
    ")\n",
    "print(f\"Tweets were posted from {df_top_locations_toPandas['user_location'].nunique():,} unique locations\")\n",
    "df_top_locations_toPandas.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0fbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_50_user_locations = df_top_locations_toPandas[\"user_location\"].head(50).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32416de",
   "metadata": {},
   "source": [
    "**9. Find the name of the country containing the top 50 user locations from question 8.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d7b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_reloaded_cached_with_country = df_reloaded_cached.withColumn(\n",
    "    \"country\",\n",
    "    F.when(\n",
    "        df_reloaded_cached.user_location.like(\"% CA\")\n",
    "        | df_reloaded_cached.user_location.like(\"% DC\")\n",
    "        | df_reloaded_cached.user_location.like(\"% NY\")\n",
    "        | df_reloaded_cached.user_location.like(\"% WA\")\n",
    "        | df_reloaded_cached.user_location.like(\"% TX\")\n",
    "        | df_reloaded_cached.user_location.like(\"% IL\")\n",
    "        | df_reloaded_cached.user_location.like(\"% FL\")\n",
    "        | df_reloaded_cached.user_location.like(\"% MD\")\n",
    "        | df_reloaded_cached.user_location.like(\"% PA\")\n",
    "        | df_reloaded_cached.user_location.like(\"%, OR\")\n",
    "        | df_reloaded_cached.user_location.like(\"% MA\")\n",
    "        | df_reloaded_cached.user_location.like(\"% AZ\")\n",
    "        | df_reloaded_cached.user_location.like(\"% TX\")\n",
    "        | df_reloaded_cached.user_location.like(\"% GA\")\n",
    "        | df_reloaded_cached.user_location.like(\"% USA\")\n",
    "        | (df_reloaded_cached.user_location == \"United States\")\n",
    "        | (df_reloaded_cached.user_location.like(\"Los Angeles%\"))\n",
    "        | (df_reloaded_cached.user_location == \"USA\")\n",
    "        | (df_reloaded_cached.user_location.like(\"Texas\"))\n",
    "        | (df_reloaded_cached.user_location == \"Los Angeles\"),\n",
    "        \"USA\",\n",
    "    )\n",
    "    .when(\n",
    "        (df_reloaded_cached.user_location == \"United Kingdom\")\n",
    "        | df_reloaded_cached.user_location.like(\"% United Kingdom\")\n",
    "        | df_reloaded_cached.user_location.like(\"% England\")\n",
    "        | (df_reloaded_cached.user_location == \"London\")\n",
    "        | (df_reloaded_cached.user_location == \"UK\"),\n",
    "        \"UK\",\n",
    "    )\n",
    "    .when(\n",
    "        df_reloaded_cached.user_location.like(\"% India\")\n",
    "        | (df_reloaded_cached.user_location == \"India\"),\n",
    "        \"India\",\n",
    "    )\n",
    "    .when(\n",
    "        df_reloaded_cached.user_location == \"Australia\",\n",
    "        \"Australia\",\n",
    "    )\n",
    "    .when(\n",
    "        (df_reloaded_cached.user_location == \"Canada\")\n",
    "        | df_reloaded_cached.user_location.like(\"% Ontario\"),\n",
    "        \"Canada\",\n",
    "    )\n",
    "    .when(\n",
    "        (df_reloaded_cached.user_location == \"Republic of the Philippines\")\n",
    "        | (df_reloaded_cached.user_location == \"Philippines\"),\n",
    "        \"Philippines\",\n",
    "    )\n",
    "    .when(\n",
    "        df_reloaded_cached.user_location == \"Indonesia\",\n",
    "        \"Indonesia\",\n",
    "    )\n",
    "    .when(\n",
    "        df_reloaded_cached.user_location == \"None\",\n",
    "        \"None\",\n",
    "    )\n",
    "     .when(\n",
    "        (df_reloaded_cached.user_location == \"France\")\n",
    "        | (df_reloaded_cached.user_location.like(\"% France\")),\n",
    "        \"France\",\n",
    "    )\n",
    "    .when(\n",
    "        (df_reloaded_cached.user_location == \"Germany\")\n",
    "        | (df_reloaded_cached.user_location == \"Deutschland\"),\n",
    "        \"Germany\",\n",
    "    )\n",
    "    .when(\n",
    "        (df_reloaded_cached.user_location.like(\"% Kenya\")),\n",
    "        \"Kenya\",\n",
    "    )\n",
    "    .when(\n",
    "        df_reloaded_cached.user_location.like(\"%xico%\"),\n",
    "        \"Mexico\",\n",
    "    )\n",
    "    .otherwise(\"Other\"),\n",
    ")\n",
    "show_pyspark_df(df_reloaded_cached_with_country, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393635dc",
   "metadata": {},
   "source": [
    "Verify `Other` is not present in the derived country name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42884954",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "assert (\n",
    "    df_reloaded_cached_with_country\n",
    "    .filter(F.col(\"user_location\").isin(top_50_user_locations))\n",
    "    .filter(F.col(\"country\") == \"Other\")\n",
    "    .select([\"user_location\", \"country\"])\n",
    "    .count()\n",
    ") == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb1b58",
   "metadata": {},
   "source": [
    "**10. Count the number of tweets by country, for those tweets originating from any of the top 50 locations (by number of tweets) found in question 8.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027717d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_top_50_countries_toPandas = (\n",
    "    df_reloaded_cached_with_country\n",
    "    .filter(F.col(\"user_location\").isin(top_50_user_locations))\n",
    "    .groupBy([\"country\"])\n",
    "    .count()\n",
    "    .orderBy([\"count\"], ascending=False)\n",
    "    .toPandas()\n",
    ")\n",
    "df_top_50_countries_toPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72034dd",
   "metadata": {},
   "source": [
    "**11. For each of the countries containing the top 50 user locations (by number of tweets posted) from question 8., count the number of tweets by topic. Create a chart from this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ba862",
   "metadata": {},
   "source": [
    "For the top 50 user locations, count the number of tweets by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_top_50_countries_grouped = (\n",
    "    df_reloaded_cached_with_country\n",
    "    .filter(F.col(\"user_location\").isin(top_50_user_locations))\n",
    "    .groupBy([\"country\", \"dominant_topic_named\"])\n",
    "    .count()\n",
    "    .orderBy([\"country\", \"count\"], ascending=[True, False])\n",
    ")\n",
    "show_pyspark_df(df_top_50_countries_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87574353",
   "metadata": {},
   "source": [
    "Pivot the countrywise grouped data keeping country along the rows and topics along the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66264c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_countries_pivotted_toPandas = df_top_50_countries_grouped.groupBy(\"country\").pivot(\n",
    "    \"dominant_topic_named\", distinct_column_vals\n",
    ").sum(\"count\").withColumnRenamed(\n",
    "    \"Activities related to Space Research\", \"Space Research\"\n",
    ").withColumnRenamed(\n",
    "    \"Satellites and Telescopes\", \"Satellites / Telescopes\"\n",
    ").toPandas().set_index(\"country\")\n",
    "df_countries_pivotted_toPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93e0b6",
   "metadata": {},
   "source": [
    "Re-shape data into format suitable for PlotLy `go.Heatmap()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_annot = df_countries_pivotted_toPandas.copy()\n",
    "for col in df_annot:\n",
    "    df_annot[col] = df_annot[col].map(\"{:,}\".format)\n",
    "data_dict = vh.convert_df_to_format_for_plotly_heatmap(\n",
    "    df_countries_pivotted_toPandas, df_annot, True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16680fab",
   "metadata": {},
   "source": [
    "Plot the heatmap from the reshaped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vh.plot_plotly_heatmap(\n",
    "    data_dict=data_dict,\n",
    "    annotation_text=data_dict[\"annotation_text\"],\n",
    "    margin_dict=dict(l=30, r=0, b=0, t=0, pad=0),\n",
    "    fig_width=900,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7e059",
   "metadata": {},
   "source": [
    "## Conclusions and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa48d64b",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "In this preliminary attempt to learn the topics from twitter data, the LDA algorithm has at least suggested topics that can be named based on the top `n` terms within each topic. Manual hyper-parameter tuning has been performed to help with this and the number of topics was also determined by inspecting the top `n` words by weight for each topic. This is a preliminary attempt at topic modeling with PySpark ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4315dd",
   "metadata": {},
   "source": [
    "### Difficulties and Recommendations for Future Work\n",
    "#### ML Modeling\n",
    "Using LDA for topic modeling with shorter texts can be challenging ([1](https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-e7ff75290f8)). The Latent part of LDA refers to the hidden nature of the topics in the documents (tweet texts) ([1](https://towardsdatascience.com/short-text-topic-modeling-70e50a57c883), [2](https://www.analyticsvidhya.com/blog/2021/06/part-2-topic-modeling-and-latent-dirichlet-allocation-lda-using-gensim-and-sklearn/)). LDA assumes each document is made up of a distribution of topics and each topic itself is comprised of a distribution of words. With these documents and words, LDA will learn the hidden link (layer) between them ([1](https://towardsdatascience.com/short-text-topic-modelling-lda-vs-gsdmm-20f1db742e14)).i.e. learn the topics. With short texts, there is generally room for only one topic in the text so there can be a larger error in the learned topic probabilities ([3](https://stackoverflow.com/a/29789165)).\n",
    "\n",
    "Both the length of the text used and the number of text documents in the data influence the efficiency of LDA ([1](https://dl.acm.org/doi/10.5555/3044805.3044828)). For streaming twitter data, the number of documents (tweets) is not such a big problem since we can simply collect more tweets for analysis. However, these tweets need to be long enough to improve the efficiency of using LDA for topic modeling. The overall domain in which the documents fall will have some influence on these two variables.\n",
    "\n",
    "Recommendations for the minimum number of words required by LDA (in a single document) range from 50-200 to a few thousand ([1](https://towardsdatascience.com/short-text-topic-modeling-70e50a57c883), [2](https://towardsdatascience.com/lda-topic-modeling-with-tweets-deff37c0e131), [3](https://www.researchgate.net/post/What_would_be_considered_the_minimum_length_of_document_minimum_number_of_words_for_training_an_LDA_SLDA_topic_model), [4](https://link.springer.com/article/10.1007/s11135-020-00976-w), [5](https://www.frontiersin.org/articles/10.3389/frai.2020.00042/full)). These are approximations and not hard claims. For the current analysis (tweets related to *space*) even the lower end of this range requires filtering out a lot of tweets and significantly reducing the size of the dataset from one that would require a big-data ML tool (as would be the case with our raw streamed tweets data) such as Spark ML to others that do not have this requirement. This opens up the possibility of using other algorithms that are more equipped to handle shorter texts, such as Gibbs Sampling algorithm for the Dirichlet Multinomial Mixture model (GSDMM) ([1](https://www.semanticscholar.org/paper/A-dirichlet-multinomial-mixture-model-based-for-Yin-Wang/d03ca28403da15e75bc3e90c21eab44031257e80?p2df)), which is [implemented in Python](https://github.com/rwalk/gsdmm) with example uses available ([1](https://stackoverflow.com/a/62331941/4057186), [2](https://towardsdatascience.com/short-text-topic-modelling-lda-vs-gsdmm-20f1db742e14), [3](https://gist.github.com/rrpelgrim/ef88b94f32dff78af4ef3253c93b6436)). Future work should either explore use of this technique for this dataset or assess more references comparing LDA to other unsupervised ML techniques for short texts.\n",
    "\n",
    "#### Text Data Processing\n",
    "In the current work, the topics were named using the top words per topic. Removing the *leftover duplicated* tweets from twitter data will help re-affirm or reject these names. As we saw earlier, such duplicates can come in the form of tweets that differ in as little as one word. From reading the documents within each topic, we can see that the further processing is needed to remove such tweets before LDA. So, the top `n` (unique) documents printed for reading contain several of these *leftover duplicates* which makes it difficult to decide if a topic is appropriately named or if it should even exist by reading the documents (tweets) in that topic. Regardless of the ML algorithm used, iteratively removing such *leftover duplicates* will help in\n",
    "- validating the names of the topics by reading the top (unique) tweets within each topic (without unnecessary duplication)\n",
    "- fine-tune the number of topics to be learned\n",
    "- reduce ML model training time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351d602",
   "metadata": {},
   "source": [
    "## Summary of Assumptions and Limitations\n",
    "### Assumptions\n",
    "1. Re-tweets (identical text in tweet) are not useful to the topic modeling algorithm (LDA). Only a single version of each tweet is sufficient.\n",
    "2. Regarding short tweets, tweets with more than 25 words in their text can be used with LDA.\n",
    "\n",
    "### Limitations\n",
    "1. After processing to replace a double whitespace by a single one, changing to lowercase and trimming the text, the majority of duplicated tweets (which are not retweets) can be removed. Some duplicates, which differ from the original tweet by a single word, remain and (per assumption 1. above) future work should focus on trying to remove these.\n",
    "2. Preliminary hyper-parameter tuning was performed for TFIDF vectorization and LDA."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
