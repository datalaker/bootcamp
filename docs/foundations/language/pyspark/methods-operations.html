<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-foundations/language/pyspark/methods-operations">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Methods, Operations and Functions | Recohut Data Bootcamp</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.recohut.com/docs/foundations/language/pyspark/methods-operations"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="data science, data engineering, data analytics"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Methods, Operations and Functions | Recohut Data Bootcamp"><meta data-rh="true" name="description" content="PySpark provides a variety of methods to work with data, some of the most commonly used are:"><meta data-rh="true" property="og:description" content="PySpark provides a variety of methods to work with data, some of the most commonly used are:"><link data-rh="true" rel="icon" href="/img/branding/favicon-black.svg"><link data-rh="true" rel="canonical" href="https://www.recohut.com/docs/foundations/language/pyspark/methods-operations"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/foundations/language/pyspark/methods-operations" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/foundations/language/pyspark/methods-operations" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut Data Bootcamp RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Data Bootcamp Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B4S1B1ZDTT"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-B4S1B1ZDTT",{})</script><link rel="stylesheet" href="/assets/css/styles.47c7b9d5.css">
<link rel="preload" href="/assets/js/runtime~main.251db5a0.js" as="script">
<link rel="preload" href="/assets/js/main.1462881d.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Bootcamp</b></a><a class="navbar__item navbar__link" href="/docs/introduction">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sparsh-ai/recohut" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/basics/de-basics">Getting Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/cloud/cloud-basics">Cloud Computing</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/foundations/language/sql/sql-basics">Programming</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/foundations/language/sql/sql-basics">SQL</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/foundations/language/python/introduction-to-python">Python</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/foundations/language/pyspark/install">PySpark</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/install">Installing Spark</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/dataframe">PySpark DataFrame</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/foundations/language/pyspark/methods-operations">Methods, Operations and Functions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/partitioning">Partitioning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/lazy-processing">Lazy Processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/caching">Caching</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/udf">UDFs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/broadcasting">Broadcasting</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/cheat-sheet">cheat-sheet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/execution-plan">Spark Execution Plan</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/pyspark-vs-pandas">PySpark vs Pandas</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/lab-pyspark-basics">Lab: Pyspark Basics</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/processing/databricks/lab-databricks-pyspark-s3">Lab: Connect AWS to PySpark and build an ETL pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/lab-spark-optimizations-2">Lab: Spark Optimizations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/lab-spark-optimizations">Lab: Spark Optimizations for Analytics Workloads</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/lab-uber-analysis">Lab: Uber Data Analysis in Pyspark</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/lab-understand-spark-query-execution">Lab: Understanding Spark Query Execution</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/lab-bcg">Lab: BCG Case Study</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/processing/databricks/lab-databricks-scala-postgres-s3">Lab: S3 Postgres Scala</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/foundations/language/pyspark/lab-calculating-partitions">Calculating Spark Partitions</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/foundations/language/scala/lab-scala-getting-started">Spark Scala</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/storage/serialization">Data Storage</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/processing/databricks">Data Processing</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/data-modeling/sql-data-modeling">Data Modeling</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/extraction/api">Data Extraction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/orchestration/airflow">Data Pipelines</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/visualization/flask">Data Visualization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/devops">DevOps</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/mathematics">Mathematics</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/basics/origin">Data Science</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/casestudies/99group">Extras</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Programming</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">PySpark</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Methods, Operations and Functions</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Methods, Operations and Functions</h1><p>PySpark provides a variety of methods to work with data, some of the most commonly used are:</p><ul><li><code>.show()</code>: Displays the first 20 rows of a DataFrame</li><li><code>.count()</code>: Counts the number of rows in a DataFrame</li><li><code>.describe()</code>: Computes basic statistics of a DataFrame</li><li><code>.head()</code>: Returns the first n rows of a DataFrame</li><li><code>.select()</code>: Selects specific columns from a DataFrame</li><li><code>.filter()</code>: Filters the rows of a DataFrame based on a condition</li><li><code>.groupBy()</code>: Groups the rows of a DataFrame by a specific column</li><li><code>.orderBy()</code>: Sorts the rows of a DataFrame by one or more columns</li></ul><p>PySpark also provides a variety of operations for transforming and processing data, such as:</p><ul><li><code>.map()</code>: Applies a function to each element of an RDD or DataFrame</li><li><code>.reduce()</code>: Combines the elements of an RDD or DataFrame using a specified function</li><li><code>.flatMap()</code>: Applies a function to each element of an RDD or DataFrame, and flattens the results</li><li><code>.filter()</code>: Filters the elements of an RDD or DataFrame based on a condition</li><li><code>.distinct()</code>: Returns a new RDD or DataFrame with distinct elements</li><li><code>.union()</code>: Returns a new RDD or DataFrame with elements from both the source RDD or DataFrame and another RDD or DataFrame</li></ul><p>PySpark provides a variety of built-in functions for data manipulation, such as:</p><ul><li><code>count()</code>: Counts the number of rows in a DataFrame</li><li><code>sum()</code>: Sums the values of a specific column</li><li><code>avg()</code>: Computes the average of the values of a specific column</li><li><code>min()</code>: Returns the minimum value of a specific column</li><li><code>max()</code>: Returns the maximum value of a specific column</li><li><code>concat()</code>: Concatenates two or more columns into a single column</li><li><code>split()</code>: Splits a string column into multiple columns</li><li><code>substring()</code>: Returns a substring of a string column</li></ul><p>These functions can be used in combination with the PySpark SQL module to perform a variety of data manipulation tasks.</p><p>Here is an example of how to use the sum() function to compute the sum of a specific column in a DataFrame:</p><div class="language-py codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-py codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> pyspark</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sql</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">functions </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> </span><span class="token builtin">sum</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Compute the sum of the &quot;value&quot; column</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">df</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">select</span><span class="token punctuation" style="color:#393A34">(</span><span class="token builtin">sum</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;value&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">show</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Once you have read your data, you can use Spark to perform various data processing tasks. The following code snippet shows how to perform a simple groupby operation on the data:</p><div class="language-py codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-py codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> pyspark</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">sql</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">functions </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> count</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Group the data by the &quot;category&quot; column and count the number of occurrences</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">grouped_data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> df</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">groupBy</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;category&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">agg</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">count</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;*&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">alias</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;count&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In this example, we are using the groupBy() function to group the data by the “category” column and the agg() function to count the number of occurrences in each group. We then store the result in a new DataFrame called grouped_data.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="using-filter-and-where-on-dataframe">Using Filter and Where on DataFrame<a class="hash-link" href="#using-filter-and-where-on-dataframe" title="Direct link to heading">​</a></h2><p>The <code>where()</code> and <code>filter()</code> methods are used to select rows from a DataFrame based on one or more conditions. Both methods are used to filter data based on a specified condition, and they are often used interchangeably.</p><p>The <code>where()</code> method is a synonym for the <code>filter()</code> method, and they have the same syntax.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="different-types-of-joins-in-pyspark">Different Types of Joins in PySpark<a class="hash-link" href="#different-types-of-joins-in-pyspark" title="Direct link to heading">​</a></h2><p>There are several types of joins in PySpark, including inner join, outer join, left join, right join, and cross join.</p><p>The most commonly used join in PySpark is the inner join, which returns only the rows that have matching keys in both DataFrames.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="using-union-and-union-all-on-dataframes">Using Union and Union All on DataFrames<a class="hash-link" href="#using-union-and-union-all-on-dataframes" title="Direct link to heading">​</a></h2><p>In PySpark, <code>union()</code> and <code>unionAll()</code> are methods used to combine two or more DataFrames vertically, i.e., they stack rows from one DataFrame on top of another.</p><p>The main difference between the two methods is that <code>union()</code> removes duplicate rows, while <code>unionAll()</code> retains all rows.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="working-with-columns-using-withcolumn">Working with Columns Using withColumn<a class="hash-link" href="#working-with-columns-using-withcolumn" title="Direct link to heading">​</a></h2><p>In PySpark, <code>withColumn()</code> is a method used to add a new column to a DataFrame or replace an existing column with a modified version.</p><p>The method takes two parameters: the name of the new column, and an expression that defines the values for the new column.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="where-to-use-withcolumnrenamed">Where to Use withColumnRenamed<a class="hash-link" href="#where-to-use-withcolumnrenamed" title="Direct link to heading">​</a></h2><p>In PySpark, <code>withColumnRenamed()</code> is a method used to rename a column in a DataFrame.</p><p>The method takes two parameters: the current name of the column, and the new name of the column.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="aggregation-and-filtering-using-groupby">Aggregation and Filtering Using groupBy<a class="hash-link" href="#aggregation-and-filtering-using-groupby" title="Direct link to heading">​</a></h2><p>In PySpark, <code>groupBy()</code> is a method used to group rows of a DataFrame based on one or more columns, and apply aggregation functions on each group.</p><p>This method is useful for summarizing and analyzing data based on certain criteria.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-clean-your-data-using-drop">How to Clean your Data Using drop<a class="hash-link" href="#how-to-clean-your-data-using-drop" title="Direct link to heading">​</a></h2><p>In PySpark, <code>drop()</code> is a method used to remove one or more columns from a DataFrame.</p><p>The method takes one or more column names as parameters and returns a new DataFrame with the specified columns removed.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-pivot-in-pyspark">How to Pivot in PySpark<a class="hash-link" href="#how-to-pivot-in-pyspark" title="Direct link to heading">​</a></h2><p>In PySpark, <code>pivot()</code> is a method used to transform a DataFrame from a long format to a wide format, by rotating values from a column into separate columns.</p><p>This method is useful for summarizing and analyzing data in a different format.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="eliminate-duplicate-data-with-distinct">Eliminate Duplicate Data with distinct<a class="hash-link" href="#eliminate-duplicate-data-with-distinct" title="Direct link to heading">​</a></h2><p>In PySpark, <code>distinct()</code> is a method used to return a DataFrame with distinct rows based on all columns or a subset of columns.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-use-map-and-mappartitions">How to Use map and mapPartitions<a class="hash-link" href="#how-to-use-map-and-mappartitions" title="Direct link to heading">​</a></h2><p>In PySpark, <code>map()</code> and <code>mapPartitions()</code> are methods used to transform the data in an RDD (Resilient Distributed Dataset).</p><p>The <code>map()</code> method applies a function to each element of an RDD and returns a new RDD with the transformed elements.</p><p>The <code>mapPartitions()</code> method applies a function to each partition of an RDD and returns a new RDD with the transformed partitions. This method is more efficient than <code>map()</code> when the function you&#x27;re applying to each element of the RDD requires some setup or teardown work.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-are-foreach-and-foreachpartition">What are foreach and foreachPartition<a class="hash-link" href="#what-are-foreach-and-foreachpartition" title="Direct link to heading">​</a></h2><p>In PySpark, <code>foreach()</code> and <code>foreachPartition()</code> are methods used to perform actions on each element of an RDD.</p><p>The <code>foreach()</code> method applies a function to each element of an RDD, without returning any result. It is typically used for side effects, such as writing the elements to a file or a database.</p><p>The <code>foreachPartition()</code> method applies a function to each partition of an RDD, instead of each element. This method is useful when you need to perform some expensive initialization or teardown work for each partition, such as establishing a database connection or opening a file.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-data-structures-using-structtype-and-structfield">Understanding Data Structures Using StructType and StructField<a class="hash-link" href="#understanding-data-structures-using-structtype-and-structfield" title="Direct link to heading">​</a></h2><p>In PySpark, <code>StructType</code> and <code>StructField</code> are classes used to define the schema of a DataFrame.</p><p><code>StructType</code> is a class that represents a schema, which is a collection of <code>StructField</code> objects. A schema defines the structure of a DataFrame, including the names, data types, and nullable flags of its columns.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="collect-vs-select-in-pyspark-best-practices">Collect vs Select in PySpark Best Practices<a class="hash-link" href="#collect-vs-select-in-pyspark-best-practices" title="Direct link to heading">​</a></h2><p>In PySpark, <code>collect()</code> and <code>select()</code> are methods used to extract data from a DataFrame or RDD.</p><p><code>collect()</code> is a method that returns all the data from a DataFrame or RDD as a list in the driver program. This method should be used with caution because it can potentially cause the driver program to run out of memory if the data is too large.</p><p><code>select()</code> is a method that returns a new DataFrame with only the specified columns. This method is used to filter the data and reduce the amount of data that needs to be processed.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-04-14T05:50:44.000Z">Apr 14, 2023</time></b> by <b>sparsh</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/foundations/language/pyspark/dataframe"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">PySpark DataFrame</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/foundations/language/pyspark/partitioning"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Partitioning</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#using-filter-and-where-on-dataframe" class="table-of-contents__link toc-highlight">Using Filter and Where on DataFrame</a></li><li><a href="#different-types-of-joins-in-pyspark" class="table-of-contents__link toc-highlight">Different Types of Joins in PySpark</a></li><li><a href="#using-union-and-union-all-on-dataframes" class="table-of-contents__link toc-highlight">Using Union and Union All on DataFrames</a></li><li><a href="#working-with-columns-using-withcolumn" class="table-of-contents__link toc-highlight">Working with Columns Using withColumn</a></li><li><a href="#where-to-use-withcolumnrenamed" class="table-of-contents__link toc-highlight">Where to Use withColumnRenamed</a></li><li><a href="#aggregation-and-filtering-using-groupby" class="table-of-contents__link toc-highlight">Aggregation and Filtering Using groupBy</a></li><li><a href="#how-to-clean-your-data-using-drop" class="table-of-contents__link toc-highlight">How to Clean your Data Using drop</a></li><li><a href="#how-to-pivot-in-pyspark" class="table-of-contents__link toc-highlight">How to Pivot in PySpark</a></li><li><a href="#eliminate-duplicate-data-with-distinct" class="table-of-contents__link toc-highlight">Eliminate Duplicate Data with distinct</a></li><li><a href="#how-to-use-map-and-mappartitions" class="table-of-contents__link toc-highlight">How to Use map and mapPartitions</a></li><li><a href="#what-are-foreach-and-foreachpartition" class="table-of-contents__link toc-highlight">What are foreach and foreachPartition</a></li><li><a href="#understanding-data-structures-using-structtype-and-structfield" class="table-of-contents__link toc-highlight">Understanding Data Structures Using StructType and StructField</a></li><li><a href="#collect-vs-select-in-pyspark-best-practices" class="table-of-contents__link toc-highlight">Collect vs Select in PySpark Best Practices</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Bootcamp. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.251db5a0.js"></script>
<script src="/assets/js/main.1462881d.js"></script>
</body>
</html>