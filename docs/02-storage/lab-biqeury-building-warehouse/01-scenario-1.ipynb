{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a MySQL database in CloudSQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to prepare our CloudSQL-MySQL environment. This step is not part of building a data warehouse. However, to simulate table extraction from application databases to GCS, this will be very helpful. So, let's start by creating the Cloud SQL instance. Here are the steps:\n",
    "\n",
    "1. Create a CloudSQL instance.\n",
    "2. Connect to the MySQL instance.\n",
    "3. Create a MySQL database.\n",
    "4. Create a table in the MySQL database.\n",
    "5. Import CSV data into the MySQL database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CloudSQL instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud sql instances create mysql-instance-source \\\n",
    "--database-version=MYSQL_5_7 \\\n",
    "--tier=db-g1-small \\\n",
    "--region=us-central1 \\\n",
    "--root-password=sparsh123 \\\n",
    "--availability-type=zonal \\\n",
    "--storage-size=10GB \\\n",
    "--storage-type=HDD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for around 5 minutes. After it's finished, refresh your browser or go back to your Cloud SQL home page and you will see that your MySQL instance is ready."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the MySQL instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud sql connect mysql-instance-source --user=root"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE DATABASE apps_db;\n",
    "SHOW DATABASE;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table in the MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TABLE apps_db.stations(\n",
    "station_id varchar(255),\n",
    "name varchar(255),\n",
    "region_id varchar(10),\n",
    "capacity integer\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV data into the MySQL database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real-life scenario, the tables will be used by applications, and the data will be inserted based on user interactions with the database. We will not go back too far to build a sample application that writes records to our table. We will just load CSV files to our tables from GCS.\n",
    "\n",
    "In a later section, we will export the MySQL table back to GCS, and you may be wondering why. The reason why we are doing this is to simplify the data generation the MySQL database. But for the later steps, given that the MySQL database is a genuine example of a data source, we will use it for simulating the *Extraction* step in an ETL process.\n",
    "\n",
    "To import the CSV data from GCS to MySQL, we can use the Cloud SQL console. \n",
    "\n",
    "Don't close the MySQL shell yet, since we want to check our imported data later using the **SELECT** statement.\n",
    "\n",
    "To upload the data, go to the Cloud SQL console:\n",
    "\n",
    "1.  Click the created **mysql-instance** source, and then find and click the **Import **button.\n",
    "1.  Choose the name of the data file in our GCS bucket under bucket-name/file-name:\n",
    "\n",
    "    **gs://[your project name]-data-bucket/stations/stations.csv**\n",
    "\n",
    "1.  Change the **File format** option to **CSV**.\n",
    "1.  Input the destination database, **apps_db**, and the table name, **stations**.\n",
    "1.  Once everything is complete, click the **Import** button.\n",
    "1.  Now we will return to Cloud Shell and try to access the **stations** table. In the MySQL shell, run the following query:\n",
    "\n",
    "    **mysql> SELECT * FROM apps_db.stations LIMIT 10;**\n",
    "\n",
    "Make sure you see some data there. Repeat the process if you can't see any records. If successful, exit from the MySQL shell by typing **exit**, as shown in the following code block:\n",
    "\n",
    "mysql > exit\n",
    "\n",
    "Now we have a simulation MySQL database as our data source. In the next section, we will do the extraction from MySQL to GCS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract data from MySQL to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bucket_name=[your gcs bucket name]\n",
    "\n",
    "!gcloud sql export csv mysql-instance-source \\\n",
    "gs://$bucket_name/mysql_export/stations/20180101/stations.csv \\\n",
    "--database=apps_db \\\n",
    "--offload \\\n",
    "--query='SELECT * FROM stations WHERE station_id <= 200;'\n",
    "\n",
    "!gcloud sql export csv mysql-instance-source \\\n",
    "gs://$bucket_name/mysql_export/stations/20180102/stations.csv \\\n",
    "--database=apps_db \\\n",
    "--offload \\\n",
    "--query='SELECT * FROM stations WHERE station_id <= 400;'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can delete the MySQL instance by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud sql instances delete mysql-instance-source"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Create View data mart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE VIEW `[your project id].dm_bikesharing.top_2_region_by_capacity`\n",
    "AS\n",
    "SELECT region_id, SUM(capacity) as total_capacity\n",
    "FROM `[your project id].staging.stations`\n",
    "WHERE region_id != ''\n",
    "GROUP BY region_id\n",
    "ORDER BY total_capacity desc\n",
    "LIMIT 2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM `[your project id].dm_regional_manager.top_2_region_by_capacity`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343191058819caea96d5cde1bd3b1a75b4807623ce2cda0e1c8499e39ac847e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
