{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Design and Load\n",
    "\n",
    "In this lab, you will use a set of eight tables based on the TPC Benchmark data model. You create these tables within your Redshift cluster then load these tables with sample data stored in S3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create 8 tables from TPC Benchmark data model, run create table statements. Given below is the data model for the tables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](https://user-images.githubusercontent.com/62965911/225864429-ee5f4dec-0a56-4d0c-855e-8fffa122c5c2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "DROP TABLE IF EXISTS partsupp;\n",
    "DROP TABLE IF EXISTS lineitem;\n",
    "DROP TABLE IF EXISTS supplier;\n",
    "DROP TABLE IF EXISTS part;\n",
    "DROP TABLE IF EXISTS orders;\n",
    "DROP TABLE IF EXISTS customer;\n",
    "DROP TABLE IF EXISTS nation;\n",
    "DROP TABLE IF EXISTS region;\n",
    "\n",
    "CREATE TABLE region (\n",
    "  R_REGIONKEY bigint NOT NULL,\n",
    "  R_NAME varchar(25),\n",
    "  R_COMMENT varchar(152))\n",
    "diststyle all;\n",
    "\n",
    "CREATE TABLE nation (\n",
    "  N_NATIONKEY bigint NOT NULL,\n",
    "  N_NAME varchar(25),\n",
    "  N_REGIONKEY bigint,\n",
    "  N_COMMENT varchar(152))\n",
    "diststyle all;\n",
    "\n",
    "create table customer (\n",
    "  C_CUSTKEY bigint NOT NULL,\n",
    "  C_NAME varchar(25),\n",
    "  C_ADDRESS varchar(40),\n",
    "  C_NATIONKEY bigint,\n",
    "  C_PHONE varchar(15),\n",
    "  C_ACCTBAL decimal(18,4),\n",
    "  C_MKTSEGMENT varchar(10),\n",
    "  C_COMMENT varchar(117))\n",
    "diststyle all;\n",
    "\n",
    "create table orders (\n",
    "  O_ORDERKEY bigint NOT NULL,\n",
    "  O_CUSTKEY bigint,\n",
    "  O_ORDERSTATUS varchar(1),\n",
    "  O_TOTALPRICE decimal(18,4),\n",
    "  O_ORDERDATE Date,\n",
    "  O_ORDERPRIORITY varchar(15),\n",
    "  O_CLERK varchar(15),\n",
    "  O_SHIPPRIORITY Integer,\n",
    "  O_COMMENT varchar(79))\n",
    "distkey (O_ORDERKEY)\n",
    "sortkey (O_ORDERDATE);\n",
    "\n",
    "create table part (\n",
    "  P_PARTKEY bigint NOT NULL,\n",
    "  P_NAME varchar(55),\n",
    "  P_MFGR  varchar(25),\n",
    "  P_BRAND varchar(10),\n",
    "  P_TYPE varchar(25),\n",
    "  P_SIZE integer,\n",
    "  P_CONTAINER varchar(10),\n",
    "  P_RETAILPRICE decimal(18,4),\n",
    "  P_COMMENT varchar(23))\n",
    "diststyle all;\n",
    "\n",
    "create table supplier (\n",
    "  S_SUPPKEY bigint NOT NULL,\n",
    "  S_NAME varchar(25),\n",
    "  S_ADDRESS varchar(40),\n",
    "  S_NATIONKEY bigint,\n",
    "  S_PHONE varchar(15),\n",
    "  S_ACCTBAL decimal(18,4),\n",
    "  S_COMMENT varchar(101))\n",
    "diststyle all;                                                              \n",
    "\n",
    "create table lineitem (\n",
    "  L_ORDERKEY bigint NOT NULL,\n",
    "  L_PARTKEY bigint,\n",
    "  L_SUPPKEY bigint,\n",
    "  L_LINENUMBER integer NOT NULL,\n",
    "  L_QUANTITY decimal(18,4),\n",
    "  L_EXTENDEDPRICE decimal(18,4),\n",
    "  L_DISCOUNT decimal(18,4),\n",
    "  L_TAX decimal(18,4),\n",
    "  L_RETURNFLAG varchar(1),\n",
    "  L_LINESTATUS varchar(1),\n",
    "  L_SHIPDATE date,\n",
    "  L_COMMITDATE date,\n",
    "  L_RECEIPTDATE date,\n",
    "  L_SHIPINSTRUCT varchar(25),\n",
    "  L_SHIPMODE varchar(10),\n",
    "  L_COMMENT varchar(44))\n",
    "distkey (L_ORDERKEY)\n",
    "sortkey (L_RECEIPTDATE);\n",
    "\n",
    "create table partsupp (\n",
    "  PS_PARTKEY bigint NOT NULL,\n",
    "  PS_SUPPKEY bigint NOT NULL,\n",
    "  PS_AVAILQTY integer,\n",
    "  PS_SUPPLYCOST decimal(18,4),\n",
    "  PS_COMMENT varchar(199))\n",
    "diststyle even;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A COPY command loads large amounts of data much more efficiently than using INSERT statements, and stores the data more effectively as well. Use a single COPY command to load data for one table from multiple files. Amazon Redshift then automatically loads the data in parallel. For your convenience, the sample data you will use is available in a public Amazon S3 bucket. To ensure that Redshift performs a compression analysis, set the COMPUPDATE parameter to ON in your COPY commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "COPY region FROM 's3://redshift-immersionday-labs/data/region/region.tbl.lzo'\n",
    "iam_role default\n",
    "region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;\n",
    "\n",
    "COPY nation FROM 's3://redshift-immersionday-labs/data/nation/nation.tbl.'\n",
    "iam_role default\n",
    "region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;\n",
    "\n",
    "copy customer from 's3://redshift-immersionday-labs/data/customer/customer.tbl.'\n",
    "iam_role default\n",
    "region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;\n",
    "\n",
    "copy orders from 's3://redshift-immersionday-labs/data/orders/orders.tbl.'\n",
    "iam_role default\n",
    "region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;\n",
    "\n",
    "copy part from 's3://redshift-immersionday-labs/data/part/part.tbl.'\n",
    "iam_role default\n",
    "region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;\n",
    "\n",
    "copy supplier from 's3://redshift-immersionday-labs/data/supplier/supplier.json' manifest\n",
    "iam_role default\n",
    "region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;\n",
    "\n",
    "copy lineitem from 's3://redshift-immersionday-labs/data/lineitem-part/'\n",
    "iam_role default\n",
    "region 'us-west-2' gzip delimiter '|' COMPUPDATE PRESET;\n",
    "\n",
    "copy partsupp from 's3://redshift-immersionday-labs/data/partsupp/partsupp.tbl.'\n",
    "iam_role default\n",
    "region 'us-west-2' lzop delimiter '|' COMPUPDATE PRESET;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated time to load the data is as follows, note you can check timing information on actions in the performance and query tabs on the redshift console:\n",
    "\n",
    "```\n",
    "REGION (5 rows) - 20s\n",
    "NATION (25 rows) - 2s\n",
    "CUSTOMER (15M rows) â€“ 31s\n",
    "ORDERS - (76M rows) - 13s\n",
    "PART - (20M rows) - 34s\n",
    "SUPPLIER - (1M rows) - 7s\n",
    "LINEITEM - (303M rows) - 48s\n",
    "PARTSUPPLIER - (80M rows) 12s\n",
    "```\n",
    "\n",
    "A few key takeaways from the above COPY statements:\n",
    "\n",
    "- COMPUPDATE PRESET ON will assign compression using the Amazon Redshift best practices related to the data type of the column but without analyzing the data in the table.\n",
    "- COPY for the REGION table points to a specfic file (region.tbl.lzo) while COPY for other tables point to a prefix to multiple files (lineitem.tbl.)\n",
    "- COPY for the SUPPLIER table points a manifest file (supplier.json)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vacuum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how VACUUM DELETE reclaims table space after delete operation.\n",
    "\n",
    "First, capture **tbl\\_rows**(Total number of rows in the table. This value includes rows marked for deletion, but not yet vacuumed) and **estimated\\_visible\\_rows**(The estimated visible rows in the table. This value does not include rows marked for deletion) for the ORDERS table. Copy the following command and run it.\n",
    "\n",
    "```sql\n",
    "select \"table\", size, tbl_rows, estimated_visible_rows\n",
    "from SVV_TABLE_INFO\n",
    "where \"table\" = 'orders';\n",
    "```\n",
    "\n",
    "| table | size | tbl\\_rows | estimated\\_visible\\_rows |\n",
    "| --- | --- | --- | --- |\n",
    "| orders | 6484 | 76000000 | 76000000 |\n",
    "\n",
    "Next, delete rows from the ORDERS table. Copy the following command and run it.\n",
    "\n",
    "```sql\n",
    "delete orders where o_orderdate between '1997-01-01' and '1998-01-01';\n",
    "```\n",
    "\n",
    "Next, capture the tbl\\_rows and estimated\\_visible\\_rows for ORDERS table after the deletion.\n",
    "\n",
    "Copy the following command and run it. Notice that the tbl\\_rows value hasn't changed, after deletion. This is because rows are marked for soft deletion, but VACUUM DELETE is not yet run to reclaim space.\n",
    "\n",
    "```sql\n",
    "select \"table\", size, tbl_rows, estimated_visible_rows\n",
    "from SVV_TABLE_INFO\n",
    "where \"table\" = 'orders';\n",
    "```\n",
    "\n",
    "| table | size | tbl\\_rows | estimated\\_visible\\_rows |\n",
    "| --- | --- | --- | --- |\n",
    "| orders | 6356 | 76000000 | 64436860 |\n",
    "\n",
    "Now, run the VACUUM DELETE command. Copy the following command and run it.\n",
    "\n",
    "```sql\n",
    "vacuum delete only orders;\n",
    "```\n",
    "\n",
    "Confirm that the VACUUM command reclaimed space by running the following query again and noting the tbl\\_rows value has changed.\n",
    "\n",
    "```sql\n",
    "select \"table\", size, tbl_rows, estimated_visible_rows\n",
    "from SVV_TABLE_INFO\n",
    "where \"table\" = 'orders';\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**orderdate** is the sort key on orders table. If you always load data into orders table where **orderdate** is the current date, since current date is forward incrementing, data will always be loaded in incremental sortkey(orderdate) order. Hence, in that case VACUUM SORT will not be needed for orders table.\n",
    "\n",
    "If you need to run VACUUM SORT, you can still manually run it as shown below. Copy the following command and run it.\n",
    "\n",
    "```sql\n",
    "vacuum sort only orders;\n",
    "```\n",
    "\n",
    "In order to run vacuum recluster on orders, copy the following command and run it.\n",
    "\n",
    "```sql\n",
    "vacuum recluster orders;\n",
    "```\n",
    "\n",
    "In order to run vacuum recluster on orders table in boost mode, copy the following command and run it.\n",
    "\n",
    "```sql\n",
    "vacuum recluster orders boost;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
