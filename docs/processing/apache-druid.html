<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-processing/apache-druid">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Druid | Recohut Data Bootcamp</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.recohut.com/docs/processing/apache-druid"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="data science, data engineering, data analytics"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Druid | Recohut Data Bootcamp"><meta data-rh="true" name="description" content="One database that meets all the criteria for real-time analytics application is Apache Druid. It enables subsecond performance at scale, provides high concurrency at the best value, and easily ingests and combines real-time streaming data and historical batch data. It is a high-performance, real-time analytics database that is flexible, efficient, and resilient."><meta data-rh="true" property="og:description" content="One database that meets all the criteria for real-time analytics application is Apache Druid. It enables subsecond performance at scale, provides high concurrency at the best value, and easily ingests and combines real-time streaming data and historical batch data. It is a high-performance, real-time analytics database that is flexible, efficient, and resilient."><link data-rh="true" rel="icon" href="/img/branding/favicon-black.svg"><link data-rh="true" rel="canonical" href="https://www.recohut.com/docs/processing/apache-druid"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/processing/apache-druid" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/processing/apache-druid" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut Data Bootcamp RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Data Bootcamp Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B4S1B1ZDTT"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-B4S1B1ZDTT",{})</script><link rel="stylesheet" href="/assets/css/styles.47c7b9d5.css">
<link rel="preload" href="/assets/js/runtime~main.251db5a0.js" as="script">
<link rel="preload" href="/assets/js/main.1462881d.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Bootcamp</b></a><a class="navbar__item navbar__link" href="/docs/introduction">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sparsh-ai/recohut" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Druid</h1><p>One database that meets all the criteria for real-time analytics application is Apache Druid. It enables subsecond performance at scale, provides high concurrency at the best value, and easily ingests and combines real-time streaming data and historical batch data. It is a high-performance, real-time analytics database that is flexible, efficient, and resilient.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="origins-of-druid">Origins of Druid<a class="hash-link" href="#origins-of-druid" title="Direct link to heading">​</a></h2><p>In 2011, the data team at a technology company had a problem. It needed to quickly aggregate and query real-time data coming from website users across the internet to analyze digital advertising auctions. This created large data sets, with millions or billions of rows.</p><p>The data team first implemented its product using relational databases. It worked but needed many machines to scale, and that was too expensive.</p><p>The team then tried the NoSQL database HBase, which was populated from Hadoop MapReduce jobs. These jobs took hours to build the aggregations necessary for the product. At one point, adding only three dimensions on a data set that numbered in the low millions of rows took the processing time from 9 hours to 24 hours.</p><p>So, in the words of Eric Tschetter, one of Druid’s creators, “we did something crazy: we rolled our own database.” And it worked! The first incarnation of Druid scanned, filtered, and aggregated one billion rows in 950 milliseconds.</p><p>Druid became open source a few years later and became a top-level project of the Apache Software Foundation in 2016.</p><p>As of 2023, over 1,400 organizations use Druid to generate insights that make data useful, in a wide variety of industries and a wide range of uses. There are over 10,000 developers active in the Druid global community.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="scalable-and-flexible">Scalable and Flexible<a class="hash-link" href="#scalable-and-flexible" title="Direct link to heading">​</a></h2><p>Druid has an elastic and distributed architecture to build any application at any scale, enabled by a unique storage-compute design with independent services.</p><p>During ingestion, data is split into segments, fully indexed, and optionally pre-aggregated. This enables unique value over other analytics databases, which force a choice between the performance of tightly coupled compute and storage or the scalability of loosely coupled compute and storage. Druid gets both performance and cost advantages by storing the segments on cloud storage and also prefetching them so they are ready when requested by the query engine.</p><p>Each service in Druid can scale independently of other services. Data nodes, which contain prefetched, indexed, segmented data, can be dynamically added or removed as data quantities change. Meanwhile, query nodes, which manage queries against streams and historical data, can be dynamically added or removed as the number and shape of queries change.</p><p>A small Druid cluster can run on a single computer, while large clusters span thousands of servers and are able to ingest multiple millions of stream events per second while querying billions of rows, usually in under one second.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="efficient-and-integrated">Efficient and Integrated<a class="hash-link" href="#efficient-and-integrated" title="Direct link to heading">​</a></h2><p>Performance is the key to interactivity. In Druid, the key to performance is “if it’s not needed, don’t do it.” This means minimizing the work the cluster has to do.</p><p>Druid doesn’t load data from disk to memory, or from memory to CPU, when it isn’t needed for a query. It doesn’t decode data when it can operate directly on encoded data. It doesn’t read the full data set when it can read a smaller index. It doesn’t start up new processes for each query when it can use a long-running process. It doesn’t send data unnecessarily across process boundaries or from server to server.</p><p>Druid achieves this level of efficiency through its tightly integrated query engine and storage format, designed in tandem to minimize the amount of work done by each data server. Druid also has a distributed design that partitions tables into segments, balances those segments automatically between servers, quickly identifies which segments (or replicas of segments) are relevant to a query, and then pushes as much computation as possible down to individual data servers.</p><p>The result of this unique relationship between compute and storage is very high performance at any scale, even for data sets of multiple petabytes.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="resilient-and-durable">Resilient and Durable<a class="hash-link" href="#resilient-and-durable" title="Direct link to heading">​</a></h2><p>Druid is self healing, self balancing, and fault tolerant. It is designed to run continuously without planned downtime for any reason, even for configuration changes and software updates. It is also durable and will not lose data, even in the event of major systems failures.</p><p>Whenever needed, you can add servers to scale out or remove servers to scale down. The Druid cluster rebalances itself automatically in the background without any downtime. When a Druid server fails, the system automatically understands the failure and continues to operate.</p><p>As part of ingestion, Druid safely stores a copy of the data segment in deep storage, creating an automated, continuous additional copy of the data in cloud storage or HDFS. It both makes the segment immediately available for queries and creates a replica of each data segment. You can always recover data from deep storage, even in the unlikely case that all Druid servers fail. For a limited failure that affects only a few Druid servers, automatic rebalancing ensures that queries are still possible and data is still available during system recoveries. When using cloud storage, such as Amazon S3, durability is 99.999999999% or greater per year (or a loss of no more than 1 record per 100 billion).</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="high-performance">High Performance<a class="hash-link" href="#high-performance" title="Direct link to heading">​</a></h2><p>The features of Druid combine to enable high performance at high concurrency by avoiding unneeded work. Pre-aggregated, sorted data avoids moving data across process boundaries or across servers and avoids processing data that isn’t needed for a query. Long-running processes avoid the need to start new processes for each query. Using indexes avoids costly reading of the full data set for each query. Acting directly on encoded, compressed data avoids the need to uncompress and decode. Using only the minimum data needed to answer each query avoids moving data from disk to memory and from memory to CPU.</p><p>In a paper published at the 22nd International Conference on Business Information Systems (May 2019), José Correia, Carlos Costa, and Maribel Yasmina Santos benchmarked performance of Hive, Presto, and Druid using a TPC-H-derived test of 13 queries run against a denormalized star schema on a cluster of 5 servers, each with an Intel i5 quad-core processor and 32 GB memory. Druid performance was measured as greater than 98% faster than Hive and greater than 90% faster than Presto in each of six test runs, using different configurations and data sizes. For Scale Factor 100 (a 100 GB database), for example, Druid required 3.72s, compared with 90s for Presto and 424s for Hive.</p><p><img loading="lazy" src="https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781098146597/files/assets/brta_0110.png" alt="Hive  Presto  and Druid results from" class="img_ev3q"></p><p>In November 2021, Imply published the results of a benchmark using the same star schema benchmark, with Druid on a single AWS c5.9xlarge instance (36 CPU and 72 GB memory) at Scale Factor 100 (a 100 GB database). The 13 queries executed in a total of 0.747s.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="high-concurrency">High Concurrency<a class="hash-link" href="#high-concurrency" title="Direct link to heading">​</a></h2><p>High concurrency was one of the original design goals for Druid, and many Druid clusters are supporting hundreds of thousands of queries per second.</p><p>The key to Druid concurrency is the unique relationship between storage and compute resources. Data is stored in segments, which are scanned in parallel by scatter/gather queries. Usually, scanning each segment requires about 250ms and rarely more than 500ms.</p><p>In Druid, there is no need to lock segments, so when multiple queries are trying to scan the same segment, the resources are released to a new query immediately upon scan completion. This keeps the computation time on each segment very small and enables a very high number of concurrent queries.</p><p>In addition, Druid automatically caches query results per segment from historical data while not caching, by default, data from fast-changing stream data. This further reduces query times and computation loads.</p><p>One of many examples of Druid concurrency was published by Nielsen Marketing, which compared response time as a function of concurrency in Druid with their previous Elasticsearch architecture.</p><p>Note that with 10 concurrent queries, average response time was 280ms. Increasing this twelvefold to 120 concurrent queries in Druid only increased the average response time by 18%. The contrast with Elasticsearch is clear.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="high-speed-data-ingestion">High-Speed Data Ingestion<a class="hash-link" href="#high-speed-data-ingestion" title="Direct link to heading">​</a></h2><p>In Druid,  <em>ingestion</em>, sometimes called <em>indexing</em>, is loading data into the database. Druid reads data from source systems, whether files or streams, and stores the data in segments.</p><p>The ingestion process both creates tables and loads data into them. All tables are always fully indexed, so there is no need to explicitly create or manage indexes.</p><p>When data is ingested into Druid, it is automatically indexed, partitioned, and, optionally, partially pre-aggregated. Compressed <strong>bitmap</strong> indexes enable fast filtering and searching across multiple columns. Data is partitioned by time and other fields.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="stream-ingestion">Stream Ingestion<a class="hash-link" href="#stream-ingestion" title="Direct link to heading">​</a></h2><p>Druid was specifically created to enable real-time analytics of stream data, which begins with stream ingestion. Druid includes built-in indexing services for both Apache Kafka and Amazon Kinesis, so additional stream connectors are not needed.</p><p>Stream data is immediately queryable by Druid as each event arrives.</p><p>Supervisor processes run on Druid management nodes to manage the ingestion processes, coordinating indexing processes on data nodes that read stream events and guarantee <em>exactly-once ingestion</em>. The indexing processes use the partition and offset mechanisms found in Kafka and the shard and sequence mechanisms found in Kinesis.</p><p>If there is a failure during stream ingestion, for example, a server or network outage on a data or management node, Druid automatically recovers and continues to ingest every event exactly once, even events that arrive during the outage. No data is lost.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="batch-ingestion">Batch Ingestion<a class="hash-link" href="#batch-ingestion" title="Direct link to heading">​</a></h2><p>It’s often useful to combine real-time stream data with historical data. Batch ingestion is used for loading the latter type of data. This approach to loading data is known as batch ingestion. Some Druid implementations use entirely historical files. Data from any source can take advantage of the interactive data conversations, easy scaling, high performance, high concurrency, and high reliability of Druid.</p><p>Druid usually ingests data from object stores—which include HDFS, Amazon S3, Azure Blob, and Google Cloud Storage—or from local storage. The datafiles can be in a number of common formats, including JSON, CSV, TSV, Parquet, ORC, Avro, or Protobuf. Druid can ingest directly from both standard and compressed files, using formats including  <em>.gz</em> ,  <em>.bz2</em> ,  <em>.xz</em> ,  <em>.zip</em> ,  <em>.sz</em> , and  <em>.zst</em> .</p><p>The easiest way to ingest batch data is with a SQL statement, using <code>INSERT INTO</code>. Since this uses SQL, the ingestion can also include whatever SQL statements are desired to filter, combine, or aggregate the data (<code>WHERE</code>, <code>JOIN</code>, <code>GROUP BY</code>, and others) as part of <strong>ingestion.</strong></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-04-09T13:34:30.000Z">Apr 9, 2023</time></b> by <b>sparsh</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#origins-of-druid" class="table-of-contents__link toc-highlight">Origins of Druid</a></li><li><a href="#scalable-and-flexible" class="table-of-contents__link toc-highlight">Scalable and Flexible</a></li><li><a href="#efficient-and-integrated" class="table-of-contents__link toc-highlight">Efficient and Integrated</a></li><li><a href="#resilient-and-durable" class="table-of-contents__link toc-highlight">Resilient and Durable</a></li><li><a href="#high-performance" class="table-of-contents__link toc-highlight">High Performance</a></li><li><a href="#high-concurrency" class="table-of-contents__link toc-highlight">High Concurrency</a></li><li><a href="#high-speed-data-ingestion" class="table-of-contents__link toc-highlight">High-Speed Data Ingestion</a></li><li><a href="#stream-ingestion" class="table-of-contents__link toc-highlight">Stream Ingestion</a></li><li><a href="#batch-ingestion" class="table-of-contents__link toc-highlight">Batch Ingestion</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Bootcamp. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.251db5a0.js"></script>
<script src="/assets/js/main.1462881d.js"></script>
</body>
</html>