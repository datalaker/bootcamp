<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-processing/lab-gcp-dataflow-stream-pipeline">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">GCP Dataflow Streaming Pipeline | Recohut Data Bootcamp</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.recohut.com/docs/processing/lab-gcp-dataflow-stream-pipeline"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="data science, data engineering, data analytics"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="GCP Dataflow Streaming Pipeline | Recohut Data Bootcamp"><meta data-rh="true" name="description" content="Objective"><meta data-rh="true" property="og:description" content="Objective"><link data-rh="true" rel="icon" href="/img/branding/favicon-black.svg"><link data-rh="true" rel="canonical" href="https://www.recohut.com/docs/processing/lab-gcp-dataflow-stream-pipeline"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/processing/lab-gcp-dataflow-stream-pipeline" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/processing/lab-gcp-dataflow-stream-pipeline" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut Data Bootcamp RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Data Bootcamp Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B4S1B1ZDTT"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-B4S1B1ZDTT",{})</script><link rel="stylesheet" href="/assets/css/styles.099cbecb.css">
<link rel="preload" href="/assets/js/runtime~main.1db50233.js" as="script">
<link rel="preload" href="/assets/js/main.c578965a.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Bootcamp</b></a><a class="navbar__item navbar__link" href="/docs/introduction">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sparsh-ai/recohut" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/getting-started">Getting Started</a><button aria-label="Toggle the collapsible sidebar category &#x27;Getting Started&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/foundations/cloud/cloud-computing">Cloud Computing</a><button aria-label="Toggle the collapsible sidebar category &#x27;Cloud Computing&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/language/sql/sql-basics">Programming</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/storage/serialization">Data Storage</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/processing/databricks">Data Processing</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/databricks">Databricks</a><button aria-label="Toggle the collapsible sidebar category &#x27;Databricks&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/aws-emr">AWS EMR</a><button aria-label="Toggle the collapsible sidebar category &#x27;AWS EMR&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/processing/lab-glue-advanced">AWS Glue Studio</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/aws-lambda">AWS Lambda Function</a><button aria-label="Toggle the collapsible sidebar category &#x27;AWS Lambda Function&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/aws-kinesis">Amazon Kinesis</a><button aria-label="Toggle the collapsible sidebar category &#x27;Amazon Kinesis&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/apache-beam">Apache Beam</a><button aria-label="Toggle the collapsible sidebar category &#x27;Apache Beam&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/processing/lab-gcp-dataflow-pipeline">GCP Dataflow</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/processing/lab-gcp-dataflow-pipeline">Lab: GCP Dataflow Pipeline - A Simple Dataflow Pipeline (Python)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/processing/lab-gcp-dataflow-batch-pipeline">Lab: GCP Dataflow Batch Pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/processing/lab-gcp-dataflow-side-inputs">Lab: GCP Dataflow Size Inputs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/processing/lab-gcp-dataflow-stream-pipeline">GCP Dataflow Streaming Pipeline</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/processing/lab-gcp-serverless-dataflow">Lab: GCP Serverless Dataflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/processing/lab-dataflow-bigquery-etl">Lab: ETL Processing on Google Cloud Using Dataflow and BigQuery</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/ray">Ray</a><button aria-label="Toggle the collapsible sidebar category &#x27;Ray&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/gcp-dataproc">GCP Dataproc</a><button aria-label="Toggle the collapsible sidebar category &#x27;GCP Dataproc&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/processing/lab-azure-hdinsight-simple-data-processing">Azure HDInsight</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/azure-synapse-analytics">Azure Synapse Analytics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Azure Synapse Analytics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/processing/lab-gcp-dataprep">GCP Dataprep</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/gcp-pubsub">GCP PubSub</a><button aria-label="Toggle the collapsible sidebar category &#x27;GCP PubSub&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/apache-kafka">Apache Kafka</a><button aria-label="Toggle the collapsible sidebar category &#x27;Apache Kafka&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/apache-flink">Apache Flink</a><button aria-label="Toggle the collapsible sidebar category &#x27;Apache Flink&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/dbt">dbt</a><button aria-label="Toggle the collapsible sidebar category &#x27;dbt&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/processing/snowpark">Snowpark</a><button aria-label="Toggle the collapsible sidebar category &#x27;Snowpark&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/data-modeling">Data Modeling</a><button aria-label="Toggle the collapsible sidebar category &#x27;Data Modeling&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/extraction/api">Data Extraction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/orchestration/airflow">Data Pipelines</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/visualization/flask">Data Visualization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/devops">DevOps</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/mathematics">Mathematics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Mathematics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/basics/origin">Data Science</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/category/case-studies">Extras</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Data Processing</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">GCP Dataflow</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">GCP Dataflow Streaming Pipeline</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>GCP Dataflow Streaming Pipeline</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="objective">Objective<a class="hash-link" href="#objective" title="Direct link to heading">​</a></h2><p>Serverless Data Processing with Dataflow - Using Dataflow for Streaming Analytics (Python)</p><p>In this lab, you take many of the concepts introduced in a batch context and apply them in a streaming context to create a pipeline similar to batch_minute_traffic_pipeline, but which operates in real time. The finished pipeline will first read JSON messages from Pub/Sub and parse those messages before branching. One branch writes some raw data to BigQuery and takes note of event and processing time. The other branch windows and aggregates the data and then writes the results to BigQuery.</p><p><strong>Objectives</strong></p><ul><li>Read data from a streaming source.</li><li>Write data to a streaming sink.</li><li>Window data in a streaming context.</li><li>Experimentally verify the effects of lag.</li></ul><p>You will build the following pipeline:</p><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/214003347-8efa44e9-831b-49f4-a1d1-a1261b6436de.png" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="preparation">Preparation<a class="hash-link" href="#preparation" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="jupyter-notebook-based-development-environment-setup">Jupyter notebook-based development environment setup<a class="hash-link" href="#jupyter-notebook-based-development-environment-setup" title="Direct link to heading">​</a></h3><ul><li>In the Console, expand the Navigation menu (Navigation menu icon), then select Vertex AI &gt; Workbench.</li><li>Enable Notebooks API.</li><li>At the top of the page click New Notebook, and select Smart Analytics Framework &gt; Apache Beam &gt; Without GPUs</li><li>In the dialog box that appears, set the region to us-central1 and then click CREATE at the bottom.</li><li>Once the environment is ready, click the OPEN JUPYTERLAB link next to your Notebook name. This will open up your environment in a new tab in your browser.</li><li>Next, click Terminal. This will open up a terminal where you can run all the commands in this lab.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="download-code-repository">Download Code Repository<a class="hash-link" href="#download-code-repository" title="Direct link to heading">​</a></h3><p>Next you will download a code repository for use in this lab.</p><ul><li>In the terminal you just opened, enter the following:</li></ul><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">git clone https://github.com/GoogleCloudPlatform/training-data-analyst</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /home/jupyter/training-data-analyst/quests/dataflow_python/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><p>On the left panel of your notebook environment, in the file browser, you will notice the training-data-analyst repo added.</p></li><li><p>Navigate into the cloned repo /training-data-analyst/quests/dataflow_python/. You will see a folder for each lab, which is further divided into a lab sub-folder with code to be completed by you, and a solution sub-folder with a fully workable example to reference if you get stuck.</p></li></ul><p>Note: To open a file for editing purposes, simply navigate to the file and click on it. This will open the file, where you can add or modify code.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="open-the-appropriate-lab">Open the appropriate lab<a class="hash-link" href="#open-the-appropriate-lab" title="Direct link to heading">​</a></h3><p>In your terminal, run the following commands to change to the directory you will use for this lab:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Change directory into the lab</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd 5_Streaming_Analytics/lab</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export BASE_DIR=$(pwd)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Before you can begin editing the actual pipeline code, you need to ensure that you have installed the necessary dependencies. Execute the following to create a virtual environment for your work in this lab:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sudo apt-get update &amp;&amp; sudo apt-get install -y python3-venv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 -m venv df-env</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source df-env/bin/activate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 -m pip install -q --upgrade pip setuptools wheel</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 -m pip install apache-beam[gcp]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gcloud services enable dataflow.googleapis.com</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Finally, grant the dataflow.worker role to the Compute Engine default service account:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">PROJECT_ID=$(gcloud config get-value project)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export PROJECT_NUMBER=$(gcloud projects list --filter=&quot;$PROJECT_ID&quot; --format=&quot;value(PROJECT_NUMBER)&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export serviceAccount=&quot;&quot;$PROJECT_NUMBER&quot;-compute@developer.gserviceaccount.com&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create GCS buckets and BQ dataset</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd $BASE_DIR/../..</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source create_streaming_sinks.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Generate event dataflow</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">source generate_batch_events.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Change to the directory containing the practice version of the code</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd $BASE_DIR</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-1-reading-from-a-streaming-source">Task 1. Reading from a streaming source<a class="hash-link" href="#task-1-reading-from-a-streaming-source" title="Direct link to heading">​</a></h2><p>In the previous labs, you used beam.io.ReadFromText to read from Google Cloud Storage. In this lab, instead of Google Cloud Storage, you use Pub/Sub. Pub/Sub is a fully managed real-time messaging service that allows publishers to send messages to a &quot;topic,&quot; to which subscribers can subscribe via a &quot;subscription.&quot;</p><p>The pipeline you create subscribes to a topic called <code>my_topic</code> that you just created via <code>create_streaming_sinks.sh</code> script. In a production situation, this topic will often be created by the publishing team. You can view it in the <a href="https://console.cloud.google.com/cloudpubsub/topic/list" target="_blank" rel="noopener noreferrer">Pub/Sub portion of the console</a>.</p><p>In the file explorer, navigate to <code>training-data-analyst/quest/dataflow_python/5_Streaming_Analytics/lab/</code> and open the <code>streaming_minute_traffic_pipeline.py</code> file.</p><p>To read from Pub/Sub using Apache Beam&#x27;s IO connectors, add a transform to the pipeline which uses the <a href="https://beam.apache.org/releases/pydoc/2.28.0/apache_beam.io.gcp.pubsub.html?highlight=pubsub#apache_beam.io.gcp.pubsub.ReadFromPubSub" target="_blank" rel="noopener noreferrer"><code>beam.io.ReadFromPubSub()</code></a> class. This class has attributes for specifying the source topic as well as the <code>timestamp_attribute</code>. By default, this attribute is set to the message publishing time.</p><p>Note: Publication time is the time when the Pub/Sub service first receives the message. In systems where there may be a delay between the actual event time and publish time (i.e., late data) and you would like to take this into account, the client code publishing the message needs to set a &#x27;timestamp&#x27; metadata attribute on the message and provide the actual event timestamp, since Pub/Sub will not natively know how to extract the event timestamp embedded in the payload. You can see the <a href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/efc7ed26b88d54bc1d8c0c0376ed01558d1f3b59/quests/dataflow/streaming_event_generator.py#L112" target="_blank" rel="noopener noreferrer">client code generating the messages you&#x27;ll use here</a>.</p><p>To complete this task:</p><ul><li>Add a transform that reads from the Pub/Sub topic specified by the <code>input_topic</code> command-line parameter.</li><li>Then, use the provided function, <code>parse_json</code> with <code>beam.Map</code> to convert each JSON string into a <code>CommonLog</code> instance.</li><li>Collect the results from this transform into a <code>PCollection</code> of <code>CommonLog</code> instances using <code>with_output_types()</code>.</li></ul><p>In the first <code>#TODO</code>, add the following code:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">beam.io.ReadFromPubSub(input_topic)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-2-window-the-data">Task 2. Window the data<a class="hash-link" href="#task-2-window-the-data" title="Direct link to heading">​</a></h2><p>In the <a href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/quests/dataflow_python/3_Batch_Analytics/solution/batch_minute_traffic_pipeline.py" target="_blank" rel="noopener noreferrer">previous non-SQL lab</a>, you implemented fixed-time windowing in order to group events by event time into mutually-exclusive windows of fixed size. Do the same thing here with the streaming inputs. Feel free to reference the <a href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/quests/dataflow_python/3_Batch_Analytics/solution/batch_minute_traffic_pipeline.py" target="_blank" rel="noopener noreferrer">previous lab&#x27;s code</a> or the <a href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/quests/dataflow_python/5_Streaming_Analytics/solution/streaming_minute_traffic_pipeline.py" target="_blank" rel="noopener noreferrer">solution</a> if you get stuck.</p><p><strong>Window into one-minute windows</strong></p><p>To complete this task:</p><ol><li>Add a transform to your pipeline that accepts the <code>PCollection</code> of <code>CommonLog</code> data and windows elements into windows of <code>window_duration</code> seconds long, with <code>window_duration</code> as another command-line parameter.</li><li>Use the following code to add a transform to your pipeline that windows elements into one-minute windows:</li></ol><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">&quot;WindowByMinute&quot; &gt;&gt; beam.WindowInto(beam.window.FixedWindows(60))</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-3-aggregate-the-data">Task 3. Aggregate the data<a class="hash-link" href="#task-3-aggregate-the-data" title="Direct link to heading">​</a></h2><p>In the previous lab, you used the <a href="https://beam.apache.org/releases/pydoc/2.28.0/apache_beam.transforms.combiners.html#apache_beam.transforms.combiners.Count" target="_blank" rel="noopener noreferrer"><code>CountCombineFn()</code></a> combiner to count the number of events per window. Do the same here.</p><p><strong>Count events per window</strong></p><p>To complete this task:</p><ol><li>Pass the windowed <code>PCollection</code> as input to a transform that counts the number of events per window.</li><li>After this, use the provided <code>DoFn</code>, <code>GetTimestampFn</code>, with <code>beam.ParDo</code> to include the window start timestamp.</li><li>Use the following code to add a transform to your pipeline that counts the number of events per window:</li></ol><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">&quot;CountPerMinute&quot; &gt;&gt; beam.CombineGlobally(CountCombineFn()).without_defaults()</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-4-write-to-bigquery">Task 4. Write to BigQuery<a class="hash-link" href="#task-4-write-to-bigquery" title="Direct link to heading">​</a></h2><p>This pipeline writes to BigQuery in two separate branches. The first branch writes the aggregated data to BigQuery. The second branch, which has already been authored for you, writes out some metadata regarding each raw event, including the event timestamp and the actual processing timestamp. Both write directly to BigQuery via streaming inserts.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="write-aggregated-data-to-bigquery">Write aggregated data to BigQuery<a class="hash-link" href="#write-aggregated-data-to-bigquery" title="Direct link to heading">​</a></h3><p>Writing to BigQuery has been covered extensively in previous labs, so the basic mechanics will not be covered in depth here.</p><p>To complete this task:</p><ul><li>Create a new command-line parameter called <code>agg_table_name</code> for the table intended to house aggregated data.</li><li>Add a transfrom as before that writes to BigQuery.</li></ul><p>Note: When in a streaming context, <code>beam.io.WriteToBigQuery()</code> does not support <code>write_disposition</code> of <code>WRITE_TRUNCATE</code> in which the table is dropped and recreated. In this example, use <code>WRITE_APPEND</code>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="bigquery-insertion-method">BigQuery insertion method<a class="hash-link" href="#bigquery-insertion-method" title="Direct link to heading">​</a></h3><p><code>beam.io.WriteToBigQuery</code> will default to either <a href="https://cloud.google.com/bigquery/streaming-data-into-bigquery" target="_blank" rel="noopener noreferrer">streaming inserts</a> for unbounded PCollections or <a href="https://cloud.google.com/bigquery/docs/loading-data-cloud-storage" target="_blank" rel="noopener noreferrer">batch file load jobs</a> for bounded PCollections. Streaming inserts can be particularly useful when you want data to show up in aggregations immediately, but does incur <a href="https://cloud.google.com/bigquery/pricing#streaming_pricing" target="_blank" rel="noopener noreferrer">extra charges</a>. In streaming use cases where you are OK with periodic batch uploads on the order of every couple minutes, you can specify this behavior via the <code>method</code> keyword argument, and also set the frequency with the <code>triggering_frequency</code> keyword argument. Learn more from the <a href="https://beam.apache.org/releases/pydoc/2.28.0/apache_beam.io.gcp.bigquery.html#apache_beam.io.gcp.bigquery.WriteToBigQuery" target="_blank" rel="noopener noreferrer">Write data to BigQuery section of the apache_beam.io.gcp.bigquery module documentation</a>.</p><p>Use the following code to add a transform to your pipeline that writes aggregated data to the BigQuery table.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">&#x27;WriteAggToBQ&#x27; &gt;&gt; beam.io.WriteToBigQuery(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  agg_table_name,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  schema=agg_table_schema,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  )</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-5-run-your-pipeline">Task 5. Run your pipeline<a class="hash-link" href="#task-5-run-your-pipeline" title="Direct link to heading">​</a></h2><p>Return to the terminal and execute the following code to run your pipeline:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">export PROJECT_ID=$(gcloud config get-value project)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export REGION=&#x27;us-central1&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export BUCKET=gs://${PROJECT_ID}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export PIPELINE_FOLDER=${BUCKET}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export RUNNER=DataflowRunner</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export PUBSUB_TOPIC=projects/${PROJECT_ID}/topics/my_topic</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export WINDOW_DURATION=60</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export AGGREGATE_TABLE_NAME=${PROJECT_ID}:logs.windowed_traffic</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">export RAW_TABLE_NAME=${PROJECT_ID}:logs.raw</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3 streaming_minute_traffic_pipeline.py\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--project=${PROJECT_ID}\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--region=${REGION}\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--staging_location=${PIPELINE_FOLDER}/staging\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--temp_location=${PIPELINE_FOLDER}/temp\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--runner=${RUNNER}\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--input_topic=${PUBSUB_TOPIC}\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--window_duration=${WINDOW_DURATION}\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--agg_table_name=${AGGREGATE_TABLE_NAME}\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">--raw_table_name=${RAW_TABLE_NAME}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Note: If you get a Dataflow pipeline failed error saying that it is unable to open the <code>pipeline.py</code> file, run the pipeline again and it should run with no issues.</p><p>Ensure in the <a href="https://console.cloud.google.com/dataflow/jobs" target="_blank" rel="noopener noreferrer">Dataflow UI</a> that it executes successfully without errors. Note that there is no data yet being created and ingested by the pipeline, so it will be running but not processing anything. You will introduce data in the next step.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-6-generate-lag-less-streaming-input">Task 6. Generate lag-less streaming input<a class="hash-link" href="#task-6-generate-lag-less-streaming-input" title="Direct link to heading">​</a></h2><p>Because this is a streaming pipeline, it subscribes to the streaming source and will await input; there is none currently. In this section, you generate data with no lag. Actual data will almost invariably contain lag. However, it is instructive to understand lag-less streaming inputs.</p><p>The code for this quest includes a script for publishing JSON events using Pub/Sub.</p><p>To complete this task and start publishing messages, open a new terminal side-by-side with your current one and run the following script. It will keep publishing messages until you kill the script. Make sure you are in the <code>training-data-analyst/quests/dataflow_python</code> folder.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bash generate_streaming_events.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="examine-the-results">Examine the results<a class="hash-link" href="#examine-the-results" title="Direct link to heading">​</a></h3><p>Wait a couple minutes for the data to start to populate. Then navigate to <a href="http://console.cloud.google.com/bigquery" target="_blank" rel="noopener noreferrer">BigQuery</a> and query the <code>logs.minute_traffic</code> table with the following query:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SELECT timestamp, page_views</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM `logs.windowed_traffic`</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ORDER BY timestamp ASC</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You should see that the number of pageviews hovered around 100 views a minute.</p><p>Alternatively, you can use the BigQuery command-line tool as a quick way to confirm results are being written:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bq head logs.raw</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bq head logs.windowed_traffic</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now, enter the following query:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  UNIX_MILLIS(TIMESTAMP(event_timestamp)) - min_millis.min_event_millis AS event_millis,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  UNIX_MILLIS(TIMESTAMP(processing_timestamp)) - min_millis.min_event_millis AS processing_millis,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  user_id,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -- added as unique label so we see all the points</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  CAST(UNIX_MILLIS(TIMESTAMP(event_timestamp)) - min_millis.min_event_millis AS STRING) AS label</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  `logs.raw`</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">CROSS JOIN (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    MIN(UNIX_MILLIS(TIMESTAMP(event_timestamp))) AS min_event_millis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  FROM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    `logs.raw`) min_millis</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">WHERE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  event_timestamp IS NOT NULL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ORDER BY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  event_millis ASC</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This query illustrates the gap between event time and processing time. However, it can be hard to see the big picture by looking at just the raw tabular data. We will use Data Studio, a lightweight data visualization and BI engine.</p><p>To enable Data Studio:</p><ul><li>Visit <a href="https://datastudio.google.com/" target="_blank" rel="noopener noreferrer">https://datastudio.google.com</a>.</li><li>Click Create in the upper left.</li><li>Click Report.</li><li>Click through the Terms of Service and then click Done.</li><li>Return to the BigQuery UI.</li><li>In the BigQuery UI, click on the Explore data button and choose Explore With Data Studio.</li><li>This will open a new window.</li><li>In the panel on the right-hand side of this window, select the scatter chart type.</li></ul><p>In the Data column of the panel on the right hand side, set the following values:</p><ul><li>Dimension: label</li><li>Hierarchy: disabled</li><li>Metric X: event_millis</li><li>Metric Y: processing_millis</li></ul><p>The chart will transform to be a scatterplot, where all points are on the diagonal. This is because in the streaming data currently being generated, events are processed immediately after they were generated --- there was no lag. If you started the data generation script quickly, i.e. before the Dataflow job was fully up and running, you may see a hockey stick, as there were messages queuing in Pub/Sub that were all processed more or less at once.</p><p>But in the real world, lag is something that pipelines need to cope with.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-7-introduce-lag-to-streaming-input">Task 7. Introduce lag to streaming input<a class="hash-link" href="#task-7-introduce-lag-to-streaming-input" title="Direct link to heading">​</a></h2><p>The streaming event script is capable of generating events with simulated lag.</p><p>This represents scenarios where there is a time delay between when the events are generated and published to Pub/Sub, for example when a mobile client goes into offline mode if a user has no service, but events are collected on the device and all published at once when the device is back online.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="generate-streaming-input-with-lag">Generate streaming input with lag<a class="hash-link" href="#generate-streaming-input-with-lag" title="Direct link to heading">​</a></h3><ol><li>First, close the Data Studio window.</li><li>Then, to turn on lag, return to the terminal and stop the running script using <code>CTRL+C</code>.</li><li>Then, run the following:</li></ol><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">bash generate_streaming_events.sh true</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="examine-the-results-1">Examine the results<a class="hash-link" href="#examine-the-results-1" title="Direct link to heading">​</a></h3><p>Return to the BigQuery UI, rerun the query, and then recreate the Data Studio view as before. The new data that arrive, which should appear on the right side of the chart, should no longer be perfect; instead, some will appear above the diagonal, indicating that they were processed after the events transpired.</p><p>Chart Type: Scatter</p><ul><li>Dimension: label</li><li>Hierarchy: disabled</li><li>Metric X: event_millis</li><li>Metric Y: processing_millis</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-04-09T13:34:30.000Z">Apr 9, 2023</time></b> by <b>sparsh</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/processing/lab-gcp-dataflow-side-inputs"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Lab: GCP Dataflow Size Inputs</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/processing/lab-gcp-serverless-dataflow"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Lab: GCP Serverless Dataflow</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#objective" class="table-of-contents__link toc-highlight">Objective</a></li><li><a href="#preparation" class="table-of-contents__link toc-highlight">Preparation</a><ul><li><a href="#jupyter-notebook-based-development-environment-setup" class="table-of-contents__link toc-highlight">Jupyter notebook-based development environment setup</a></li><li><a href="#download-code-repository" class="table-of-contents__link toc-highlight">Download Code Repository</a></li><li><a href="#open-the-appropriate-lab" class="table-of-contents__link toc-highlight">Open the appropriate lab</a></li></ul></li><li><a href="#task-1-reading-from-a-streaming-source" class="table-of-contents__link toc-highlight">Task 1. Reading from a streaming source</a></li><li><a href="#task-2-window-the-data" class="table-of-contents__link toc-highlight">Task 2. Window the data</a></li><li><a href="#task-3-aggregate-the-data" class="table-of-contents__link toc-highlight">Task 3. Aggregate the data</a></li><li><a href="#task-4-write-to-bigquery" class="table-of-contents__link toc-highlight">Task 4. Write to BigQuery</a><ul><li><a href="#write-aggregated-data-to-bigquery" class="table-of-contents__link toc-highlight">Write aggregated data to BigQuery</a></li><li><a href="#bigquery-insertion-method" class="table-of-contents__link toc-highlight">BigQuery insertion method</a></li></ul></li><li><a href="#task-5-run-your-pipeline" class="table-of-contents__link toc-highlight">Task 5. Run your pipeline</a></li><li><a href="#task-6-generate-lag-less-streaming-input" class="table-of-contents__link toc-highlight">Task 6. Generate lag-less streaming input</a><ul><li><a href="#examine-the-results" class="table-of-contents__link toc-highlight">Examine the results</a></li></ul></li><li><a href="#task-7-introduce-lag-to-streaming-input" class="table-of-contents__link toc-highlight">Task 7. Introduce lag to streaming input</a><ul><li><a href="#generate-streaming-input-with-lag" class="table-of-contents__link toc-highlight">Generate streaming input with lag</a></li><li><a href="#examine-the-results-1" class="table-of-contents__link toc-highlight">Examine the results</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Bootcamp. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.1db50233.js"></script>
<script src="/assets/js/main.c578965a.js"></script>
</body>
</html>