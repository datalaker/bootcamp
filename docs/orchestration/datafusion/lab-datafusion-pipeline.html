<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-orchestration/datafusion/lab-datafusion-pipeline/README">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Lab: Building and Executing a Pipeline Graph with Data Fusion | Recohut Data Bootcamp</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.recohut.com/docs/orchestration/datafusion/lab-datafusion-pipeline"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="data science, data engineering, data analytics"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Lab: Building and Executing a Pipeline Graph with Data Fusion | Recohut Data Bootcamp"><meta data-rh="true" name="description" content="Objective"><meta data-rh="true" property="og:description" content="Objective"><link data-rh="true" rel="icon" href="/img/branding/favicon-black.svg"><link data-rh="true" rel="canonical" href="https://www.recohut.com/docs/orchestration/datafusion/lab-datafusion-pipeline"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/orchestration/datafusion/lab-datafusion-pipeline" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/orchestration/datafusion/lab-datafusion-pipeline" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut Data Bootcamp RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Data Bootcamp Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B4S1B1ZDTT"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-B4S1B1ZDTT",{})</script><link rel="stylesheet" href="/assets/css/styles.47c7b9d5.css">
<link rel="preload" href="/assets/js/runtime~main.251db5a0.js" as="script">
<link rel="preload" href="/assets/js/main.1462881d.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Bootcamp</b></a><a class="navbar__item navbar__link" href="/docs/introduction">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sparsh-ai/recohut" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/introduction">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/basics/de-basics">Getting Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/cloud/cloud-basics">Cloud Computing</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/language/sql/sql-basics">Programming</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/storage/serialization">Data Storage</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/processing/databricks">Data Processing</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/data-modeling/sql-data-modeling">Data Modeling</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/extraction/api">Data Extraction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/orchestration/airflow">Data Pipelines</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/orchestration/airflow">Airflow</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/orchestration/azure-data-factory">Azure Data Factory</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/orchestration/datafusion">GCP Cloud DataFusion</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/orchestration/datafusion">Cloud Data Fusion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/orchestration/datafusion/lab-datafusion-pipeline">Lab: Building and Executing a Pipeline Graph with Data Fusion</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/orchestration/stepfunctions/lab-stepfunction-athena-sns">AWS Step Functions</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/visualization/flask">Data Visualization</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/devops">DevOps</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/mathematics">Mathematics</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/basics/origin">Data Science</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/casestudies/99group">Extras</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Data Pipelines</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">GCP Cloud DataFusion</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Lab: Building and Executing a Pipeline Graph with Data Fusion</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Lab: Building and Executing a Pipeline Graph with Data Fusion</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="objective">Objective<a class="hash-link" href="#objective" title="Direct link to heading">​</a></h2><p>This lab shows you how to use the Wrangler and Data Pipeline features in Cloud Data Fusion to clean, transform, and process taxi trip data for further analysis.</p><p>In this lab, you will:</p><ul><li>Connect Cloud Data Fusion to a couple of data sources</li><li>Apply basic transformations</li><li>Join two data sources</li><li>Write data to a sink</li></ul><p>Often times, data needs go through a number of pre-processing steps before analysts can leverage the data to glean insights. For example, data types may need to be adjusted, anomalies removed, and vague identifiers may need to be converted to more meaningful entries. Cloud Data Fusion is a service for efficiently building ETL/ELT data pipelines. Cloud Data Fusion uses Cloud Dataproc cluster to perform all transforms in the pipeline.</p><p>The use of Cloud Data Fusion will be exemplified in this tutorial by using a subset of the NYC TLC Taxi Trips dataset on BigQuery.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-1-creating-a-cloud-data-fusion-instance">Task 1. Creating a Cloud Data Fusion instance<a class="hash-link" href="#task-1-creating-a-cloud-data-fusion-instance" title="Direct link to heading">​</a></h2><p>Thorough directions for creating a Cloud Data Fusion instance can be found in the Creating a Cloud Data Fusion instance Guide. The essential steps are as follows:</p><ul><li>To ensure the training environment is properly configured you must first stop and restart the Cloud Data Fusion API. Run the command below in the Cloud Shell. It will take a few minutes to complete.</li></ul><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">gcloud services disable datafusion.googleapis.com</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gcloud services enable datafusion.googleapis.com</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><p>On the Navigation menu, select Data Fusion.</p></li><li><p>To create a Cloud Data Fusion instance, click Create an Instance.</p><ul><li>Enter a name for your instance.</li><li>Select Basic for the Edition type.</li><li>Under Authorization section, click Grant Permission.</li><li>Leave all other fields as their defaults and click Create.</li></ul></li></ul><p>Note: Creation of the instance can take around 15 minutes.</p><ul><li><p>Once the instance is created, you need one additional step to grant the service account associated with the instance permissions on your project. Navigate to the instance details page by clicking the instance name.</p></li><li><p>Copy the service account to your clipboard.</p></li><li><p>In the GCP Console navigate to the IAM &amp; Admin &gt; IAM.</p></li><li><p>On the IAM Permissions page, click +Grant Access add the service account you copied earlier as a new principals and grant the Cloud Data Fusion API Service Agent role.</p></li><li><p>Click Save.</p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-2-loading-the-data">Task 2. Loading the data<a class="hash-link" href="#task-2-loading-the-data" title="Direct link to heading">​</a></h2><p>Once the Cloud Data Fusion instance is up and running, you can start using Cloud Data Fusion. However, before Cloud Data Fusion can start ingesting data you have to take some preliminary steps.</p><ul><li>In this example, Cloud Data Fusion will read data out of a storage bucket. In the cloud shell console execute the following commands to create a new bucket and copy the relevant data into it:</li></ul><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">export BUCKET=$GOOGLE_CLOUD_PROJECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gsutil mb gs://$BUCKET</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gsutil cp gs://cloud-training/OCBL017/ny-taxi-2018-sample.csv gs://$BUCKET</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li>In the command line, execute the following command to create a bucket for temporary storage items that Cloud data Fusion will create:</li></ul><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">gsutil mb gs://$BUCKET-temp</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li>Click the View Instance link on the Data Fusion instances page, or the details page of an instance. Click username. If prompted to take a tour of the service click on No, Thanks. You should now be in the Cloud Data Fusion UI.</li></ul><p>Note: You may need to reload or refresh the Cloud Fusion UI pages to allow prompt loading of the page.</p><ul><li><p>Wrangler is an interactive, visual tool that lets you see the effects of transformations on a small subset of your data before dispatching large, parallel-processing jobs on the entire dataset. On the Cloud Data Fusion UI, choose Wrangler. On the left side, there is a panel with the pre-configured connections to your data, including the Cloud Storage connection.</p></li><li><p>Under GCS, select Cloud Storage Default.</p></li><li><p>Click on the bucket corresponding to your project name.</p></li><li><p>Select ny-taxi-2018-sample.csv. The data is loaded into the Wrangler screen in row/column form.</p></li><li><p>In the Parsing Options window, set Use First Row as Header as True. The data splits into multiple columns.</p></li><li><p>Click Confirm.</p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-3-cleaning-the-data">Task 3. Cleaning the data<a class="hash-link" href="#task-3-cleaning-the-data" title="Direct link to heading">​</a></h2><p>Now, you will perform some transformations to parse and clean the taxi data.</p><ul><li><p>Click the Down arrow next to the trip_distance column, select Change data type and then click on Float. Repeat for the total_amount column.</p></li><li><p>Click the Down arrow next to the pickup_location_id column, select Change data type and then click on String.</p></li><li><p>If you look at the data closely, you may find some anomalies, such as negative trip distances. You can avoid those negative values by filtering out in Wrangler. Click the Down arrow next to the trip_distance column and select Filter. Click if Custom condition and input &gt;0.0</p></li><li><p>Click on Apply.</p></li></ul><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/214003271-cc4e8517-9deb-4dfb-977b-1e76025407aa.png" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-4-creating-the-pipeline">Task 4. Creating the pipeline<a class="hash-link" href="#task-4-creating-the-pipeline" title="Direct link to heading">​</a></h2><p>Basic data cleansing is now complete and you&#x27;ve run transformations on a subset of your data. You can now create a batch pipeline to run transformations on all your data.</p><p>Cloud Data Fusion translates your visually built pipeline into an Apache Spark or MapReduce program that executes transformations on an ephemeral Cloud Dataproc cluster in parallel. This enables you to easily execute complex transformations over vast quantities of data in a scalable, reliable manner, without having to wrestle with infrastructure and technology.</p><ul><li><p>On the upper-right side of the Google Cloud Fusion UI, click Create a Pipeline.</p></li><li><p>In the dialog that appears, select Batch pipeline.</p></li><li><p>In the Data Pipelines UI, you will see a GCSFile source node connected to a Wrangler node. The Wrangler node contains all the transformations you applied in the Wrangler view captured as directive grammar. Hover over the Wrangler node and select Properties.</p></li></ul><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/214003274-67c56282-204c-4504-ac20-811dcbbb0f55.png" class="img_ev3q"></p><ul><li>At this stage, you can apply more transformations by clicking the Wrangle button. Delete the extra column by pressing the red trashcan icon beside its name. Click Validate on top right corner to check for any errors. To close the Wrangler tool click the X button in the top right corner.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-5-adding-a-data-source">Task 5. Adding a data source<a class="hash-link" href="#task-5-adding-a-data-source" title="Direct link to heading">​</a></h2><p>The taxi data contains several cryptic columns such as pickup_location_id, that aren&#x27;t immediately transparent to an analyst. You are going to add a data source to the pipeline that maps the pickup_location_id column to a relevant location name. The mapping information will be stored in a BigQuery table.</p><ul><li><p>In a separate tab, open the BigQuery UI in the Cloud Console. Click Done on the &#x27;Welcome to BigQuery in the Cloud Console&#x27; launch page.</p></li><li><p>In the Explorer section of the BigQuery UI, click the three dots beside your GCP Project ID.</p></li><li><p>On the menu that appears click the Create dataset link.</p></li><li><p>In the Dataset ID field type in <code>trips</code>.</p></li><li><p>Click on Create dataset.</p></li><li><p>To create the desired table in the newly created dataset, Go to editor window, navigate to More &gt; Query Settings. This process will ensure you can access your table from Cloud Data Fusion.</p></li><li><p>Select the item for <code>Set a destination table for query results</code>. For Dataset input <code>trips</code> select from the dropdown. Table Id input <code>zone_id_mapping</code>. Click Save.</p></li><li><p>Enter the following query in the Query Editor and then click Run:</p></li></ul><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  zone_id</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  zone_name</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  borough</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token identifier punctuation" style="color:#393A34">`</span><span class="token identifier">bigquery-public-data.new_york_taxi_trips.taxi_zone_geom</span><span class="token identifier punctuation" style="color:#393A34">`</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/214003169-24e75787-cf9a-4159-ac8c-949e30372d69.png" class="img_ev3q"></p><p>You can see that this table contains the mapping from zone_id to its name and borough.</p><ul><li><p>Now, you will add a source in your pipeline to access this BigQuery table. Return to tab where you have Cloud Data Fusion open, from the Plugin palette on the left, select BigQuery from the Source section. A BigQuery source node appears on the canvas with the two other nodes.</p></li><li><p>Hover over the new BigQuery source node and click Properties.</p></li><li><p>To configure the Reference Name, enter zone_mapping, which is used to identify this data source for lineage purposes.</p></li><li><p>The BigQuery Dataset and Table configurations are the Dataset and Table you setup in BigQuery a few steps earlier: <code>trips</code> and <code>zone_id_mapping</code>. For Temporary Bucket Name input the name of your project followed by &quot;-temp&quot;, which corresponds to the bucket you created in Task 2.</p></li><li><p>To populate the schema of this table from BigQuery, click Get Schema. The fields will appear on the right side of the wizard.</p></li><li><p>Click Validate on top right corner to check for any errors. To close the BigQuery Properties window click the X button in the top right corner.</p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-6-joining-two-sources">Task 6. Joining two sources<a class="hash-link" href="#task-6-joining-two-sources" title="Direct link to heading">​</a></h2><p>Now you can join the two data sources—taxi trip data and zone names—to generate more meaningful output.</p><ul><li><p>Under the Analytics section in the Plugin Palette, choose Joiner. A Joiner node appears on the canvas.</p></li><li><p>To connect the Wrangler node and the BigQuery node to the Joiner node: Drag a connection arrow &gt; on the right edge of the source node and drop on the destination node.</p></li></ul><p>To configure the Joiner node, which is similar to a SQL JOIN syntax:</p><ul><li>Click Properties of Joiner.</li><li>Leave the label as Joiner.</li><li>Change the Join Type to Inner</li><li>Set the Join Condition to join the pickup_location_id column in the Wrangler node to the zone_id column in the BigQuery node.</li><li>To generate the schema of the resultant join, click Get Schema.</li><li>In the Output Schema table on the right, remove the zone_id and pickup_location_id fields by hitting the red garbage can icon.</li><li>Click Validate on top right corner to check for any errors. Close the window by clicking the X button in the top right corner.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-7-storing-the-output-to-bigquery">Task 7. Storing the output to BigQuery<a class="hash-link" href="#task-7-storing-the-output-to-bigquery" title="Direct link to heading">​</a></h2><p>You will store the result of the pipeline into a BigQuery table. Where you store your data is called a sink.</p><ul><li><p>In the Sink section of the Plugin Palette, choose BigQuery.</p></li><li><p>Connect the Joiner node to the BigQuery node. Drag a connection arrow &gt; on the right edge of the source node and drop on the destination node.</p></li><li><p>Open the BigQuery2 node by hovering on it and then clicking Properties. You will use a configuration that&#x27;s similar to the existing BigQuery source. Provide bq_insert for the Reference Name field and then use trips for the Dataset and the name of your project followed by &quot;-temp&quot; as Temporary Bucket Name. You will write to a new table that will be created for this pipeline execution. In Table field, enter trips_pickup_name.</p></li><li><p>Click Validate on top right corner to check for any errors. Close the window by clicking the X button in the top right corner.</p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-8-deploying-and-running-the-pipeline">Task 8. Deploying and running the pipeline<a class="hash-link" href="#task-8-deploying-and-running-the-pipeline" title="Direct link to heading">​</a></h2><p>At this point you have created your first pipeline and can deploy and run the pipeline.</p><ul><li><p>Name your pipeline in the upper left corner of the Data Fusion UI and click Save.</p></li><li><p>Now you will deploy the pipeline. In the upper-right corner of the page, click Deploy.</p></li><li><p>On the next screen click Run to start processing data.</p></li><li><p>When you run a pipeline, Cloud Data Fusion provisions an ephemeral Cloud Dataproc cluster, runs the pipeline, and then tears down the cluster. This could take a few minutes. You can observe the status of the pipeline transition from Provisioning to Starting and from Starting to Running to Succeeded during this time.</p></li></ul><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/214003265-02ac63ea-b61c-46e7-bf5d-b1fc3c53b07d.png" class="img_ev3q"></p><p>Note: The pipeline transition may take 10-15 minutes to succeeded.</p><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/214003268-0968dec2-638d-47c4-8c3e-9171b2cd2282.png" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="task-9-viewing-the-results">Task 9. Viewing the results<a class="hash-link" href="#task-9-viewing-the-results" title="Direct link to heading">​</a></h2><p>To view the results after the pipeline runs:</p><p>Return to the tab where you have BigQuery open. Run the query below to see the values in the trips_pickup_name table:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">SELECT</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  *</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">FROM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  `trips.trips_pickup_name`</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/214003172-c3b919d2-ca23-4098-a8e7-78eb9c358b7e.png" class="img_ev3q"></p><p>Congratulations!</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-04-17T11:57:21.000Z">Apr 17, 2023</time></b> by <b>sparsh</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/orchestration/datafusion"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Cloud Data Fusion</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/orchestration/stepfunctions/lab-stepfunction-athena-sns"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Lab: Step Function Athena SNS</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#objective" class="table-of-contents__link toc-highlight">Objective</a></li><li><a href="#task-1-creating-a-cloud-data-fusion-instance" class="table-of-contents__link toc-highlight">Task 1. Creating a Cloud Data Fusion instance</a></li><li><a href="#task-2-loading-the-data" class="table-of-contents__link toc-highlight">Task 2. Loading the data</a></li><li><a href="#task-3-cleaning-the-data" class="table-of-contents__link toc-highlight">Task 3. Cleaning the data</a></li><li><a href="#task-4-creating-the-pipeline" class="table-of-contents__link toc-highlight">Task 4. Creating the pipeline</a></li><li><a href="#task-5-adding-a-data-source" class="table-of-contents__link toc-highlight">Task 5. Adding a data source</a></li><li><a href="#task-6-joining-two-sources" class="table-of-contents__link toc-highlight">Task 6. Joining two sources</a></li><li><a href="#task-7-storing-the-output-to-bigquery" class="table-of-contents__link toc-highlight">Task 7. Storing the output to BigQuery</a></li><li><a href="#task-8-deploying-and-running-the-pipeline" class="table-of-contents__link toc-highlight">Task 8. Deploying and running the pipeline</a></li><li><a href="#task-9-viewing-the-results" class="table-of-contents__link toc-highlight">Task 9. Viewing the results</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Bootcamp. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.251db5a0.js"></script>
<script src="/assets/js/main.1462881d.js"></script>
</body>
</html>