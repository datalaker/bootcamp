<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-datascience/metrics-and-evaluation">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Metrics and Evaluation | Recohut Data Bootcamp</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.recohut.com/docs/datascience/metrics-and-evaluation"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="data science, data engineering, data analytics"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Metrics and Evaluation | Recohut Data Bootcamp"><meta data-rh="true" name="description" content="In general terms, metrics are tools to set standards and evaluate the performance of models. In the field of machine learning and data science, obtaining a functional model is far from enough. We need to develop methods and assessment metrics to determine how well models perform on tasks that are given. Metrics used in machine learning are formulas and equations that provide specific quantitative measurements as to how well the developed methods perform on the data provided. Evaluation refers to the process of distinguishing between the better and the worse models by comparing metrics."><meta data-rh="true" property="og:description" content="In general terms, metrics are tools to set standards and evaluate the performance of models. In the field of machine learning and data science, obtaining a functional model is far from enough. We need to develop methods and assessment metrics to determine how well models perform on tasks that are given. Metrics used in machine learning are formulas and equations that provide specific quantitative measurements as to how well the developed methods perform on the data provided. Evaluation refers to the process of distinguishing between the better and the worse models by comparing metrics."><link data-rh="true" rel="icon" href="/img/branding/favicon-black.svg"><link data-rh="true" rel="canonical" href="https://www.recohut.com/docs/datascience/metrics-and-evaluation"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/datascience/metrics-and-evaluation" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/datascience/metrics-and-evaluation" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut Data Bootcamp RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Data Bootcamp Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B4S1B1ZDTT"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-B4S1B1ZDTT",{})</script><link rel="stylesheet" href="/assets/css/styles.e4e34528.css">
<link rel="preload" href="/assets/js/runtime~main.166317d0.js" as="script">
<link rel="preload" href="/assets/js/main.3580ce8c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Bootcamp</b></a><a class="navbar__item navbar__link" href="/docs/bootcamp">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sparsh-ai/recohut" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/bootcamp">Recohut Data Bootcamps</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/foundations/developer-foundations/install-anaconda">foundations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/storage/apache-couchdb">storage</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/processing/apache-beam">processing</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/data-modeling/3nf-data-modeling">data-modeling</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/extraction">Data Extraction</a><button aria-label="Toggle the collapsible sidebar category &#x27;Data Extraction&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/orchestration">Orchestration</a><button aria-label="Toggle the collapsible sidebar category &#x27;Orchestration&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/devops">DevOps</a><button aria-label="Toggle the collapsible sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/visualization">Visualization</a><button aria-label="Toggle the collapsible sidebar category &#x27;Visualization&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/docs/datascience/algorithms/decision-trees">datascience</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/datascience/algorithms/decision-trees">algorithms</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/datascience/basics/cross-domain">basics</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/datascience/bayesian-optimization">Bayesian Optimization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/datascience/bias-variance-tradeoff">Bias-Variance Trade-Off</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/datascience/challenges">Challenges</a><button aria-label="Toggle the collapsible sidebar category &#x27;Challenges&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/datascience/computer-vision">Computer Vision</a><button aria-label="Toggle the collapsible sidebar category &#x27;Computer Vision&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/datascience/data-encoding">Data Encoding</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/datascience/data-preparation">Data Preparation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/datascience/data-splits">Data Splits</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/datascience/deep-learning/deep-learning-basics">deep-learning</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/datascience/feature-selection">Feature Selection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/datascience/metrics-and-evaluation">Metrics and Evaluation</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/datascience/nlp">Natural Language Processing (NLP)</a><button aria-label="Toggle the collapsible sidebar category &#x27;Natural Language Processing (NLP)&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/datascience/recsys">Recommender Systems</a><button aria-label="Toggle the collapsible sidebar category &#x27;Recommender Systems&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/datascience/regression">Regression</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/datascience/reinforcement-learning">Experimentation</a><button aria-label="Toggle the collapsible sidebar category &#x27;Experimentation&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/datascience/sagemaker">Amazon Sagemaker</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/assignments">Assignments</a><button aria-label="Toggle the collapsible sidebar category &#x27;Assignments&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/capstones">Capstones</a><button aria-label="Toggle the collapsible sidebar category &#x27;Capstones&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/mlops">MLOps</a><button aria-label="Toggle the collapsible sidebar category &#x27;MLOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/a1-interviewprep">Interview Preparation</a><button aria-label="Toggle the collapsible sidebar category &#x27;Interview Preparation&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/a3-casestudies">Case Studies</a><button aria-label="Toggle the collapsible sidebar category &#x27;Case Studies&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/b3-misc/explore-further">b3-misc</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/mathematics">Mathematics</a><button aria-label="Toggle the collapsible sidebar category &#x27;Mathematics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">datascience</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Metrics and Evaluation</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Metrics and Evaluation</h1><p>In general terms, metrics are tools to set standards and evaluate the performance of models. In the field of machine learning and data science, obtaining a functional model is far from enough. We need to develop methods and assessment metrics to determine how well models perform on tasks that are given. Metrics used in machine learning are formulas and equations that provide specific quantitative measurements as to how well the developed methods perform on the data provided. Evaluation refers to the process of distinguishing between the better and the worse models by comparing metrics.</p><p>There are two general categories of problems that generally describe most datasets: regression and classification. Since for each type of problem the predictions produced by models vary greatly, there’s a clear distinction between classification metrics and regression metrics. Regression metrics evaluate continuous values, while classification deals with discrete ones. However, both types of evaluation methods require two types of inputs: the ground-truth value (the desired correct prediction) and the predicted value that the model outputs.</p><p>Similar to metrics, there are loss functions. Loss functions accomplish the same goals as those of metrics: they measure the performance or, in some cases, the error for certain model predictions. Although loss functions can be used as metrics, when we refer to loss functions, it usually represents a differentiable function that can be used to train gradient-based models. Gradient descent allows the model to converge to a local optimum by exploiting the differentiability of a loss function. The goal of a loss function is to provide an informative formula that can describe a model’s error that can be utilized by gradient descent. They are generally optimal for gradient descent but not necessarily wholly intuitive from our perspective. On the other hand, metrics prioritize an intuitive explanation of how effective the model performed on the given task instead of designing a formula targeted specifically to the optimization of gradient descent.</p><p>Some metrics simply cannot act as loss functions due to their undifferentiability. While sometimes loss functions are easily interpretable on a human scale and some metrics can be considered loss functions due to their differentiability, loss functions and metrics are generally seen as different tools with somewhat similar functionality.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="mean-absolute-error">Mean Absolute Error<a class="hash-link" href="#mean-absolute-error" title="Direct link to heading">​</a></h2><p>One of the most common regression metrics is the Mean Absolute Error (MAE). In simple terms, it calculates the difference between the ground-truth labels and the predictions of the model, averaged across all predictions.</p><p>For example, imagine a class of 50 students taking an exam that is scored out of 100 points. The teacher makes assumptions about each student’s expected score based on their classwork in the past. After grading the exams, the teacher realizes that their predictions aren’t exactly correct. They want to know how much they’re off from the ground-truth values, or the actual scores that the students received. Guided by intuition, they simply calculate the difference in scores between the prediction and the students’ results. The teacher finds it helpful to see how off they were for each student, but they also want a summative, aggregate-level idea of how generally wrong the predictions were. They do this by taking the average of each of the errors:</p><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/230722022-2a988ed5-46b7-4212-9124-6cabcabbde99.jpeg" alt="525591_1_En_1_Fig37_HTML" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="mean-squared-error-mse">Mean Squared Error (MSE)<a class="hash-link" href="#mean-squared-error-mse" title="Direct link to heading">​</a></h2><p>The Mean Absolute Error may be simple, but there are a few drawbacks. One major issue regarding MAE is that it does not punish outlier predictions. Consider two samples A1 and A2 that the model is 1% and 6% off on (absolute error divided by total possible domain value). Using the Mean Absolute Error, A2 is weighted 5% worse than A1. Now, consider two additional samples B1 and B2 that the model is 50% and 55% off on. Using the Mean Absolute Error, B2 is weighted 5% worse than B1. We should ask ourselves: Is a model degradation from 1% to 6% error the same as a model degradation from 50% to 55% error? A 50–55% error change is a lot worse than a 1–6% error change since in the latter case the model still performs reasonably well.</p><p>We can use the Mean Squared Error to disproportionately punish larger mistakes.</p><p>As the name suggests, the Mean Squared Error raises the difference between model predictions and the ground-truth label to the second power instead of taking the absolute value.</p><p>To further demonstrate, continuing with the student test score example from earlier, the teacher predicts a score of 58 instead of 83 for the student Cameron. Using the formula for MSE, we obtain 107.8. However, we do not have an intuition of how exactly the model is incorrect. Since we squared the result instead of taking the absolute value, the score we obtain doesn’t scale to the range of test scores as an average error of 107.8 is impossible for a test that’s scored between 0 and 100. To counter such an issue, we can take the square root of the result to “reverse” the operation of raising to the second power, putting the error into contextual scale while still emphasizing any outlier predictions. This metric is the Root Mean Squared Error (RMSE):</p><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/230722211-5a0ddf07-3ef1-484a-b3fd-0ef555a2a5fa.jpeg" alt="525591_1_En_1_Fig38_HTML" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="confusion-matrix">Confusion Matrix<a class="hash-link" href="#confusion-matrix" title="Direct link to heading">​</a></h2><p>Like regression metrics based on the concept of MAE, most classification metrics rely on the idea of a Confusion Matrix, which describes how much error is made and what type of error with a convenient visualization.</p><p>A Confusion Matrix has four components that describe model predictions compared against the ground-truth labels; they are true positives, false positives, true negatives, and false negatives. Let’s break down this terminology: the first word indicates whether the model prediction was correct or not (“true” if correct, “false” if not); the second indicates the ground-truth value (“positive” for the label 1 and “negative” for the label 0).</p><p>Let’s better understand these concepts with real-life examples. Say that a doctor is diagnosing possible cancerous patients based on their screening results. If the doctor deduces that an actual cancerous patient does in fact have cancer, it’s an example of a true positive. When the model, or in this case the doctor, predicts the positive class of being cancerous and the actual ground-truth label of whether the patient has cancer or not ends up positive too, it’s called a true positive. However, the doctor is not accurate every single time. When the doctor predicts the patient is not cancerous while the patient in fact has cancer, it’s an example of a false negative. When the doctor concludes that a patient is cancerous but in truth the patient is healthy, it’s an example of a false positive. If a patient is healthy and the doctor predicts healthy too, it’s an example of a true negative.</p><p>Let’s summarize these concepts into numeric language:</p><ul><li>When the model prediction is 1 and the ground truth is 1, it’s a true positive.</li><li>When the model prediction is 1 and the ground truth is 0, it’s a false positive.</li><li>When the model prediction is 0 and the ground truth is 0, it’s a true negative.</li><li>When the model prediction is 0 and the ground truth is 1, it’s a false negative.</li></ul><p>After we’ve identified all the cases of this within our model prediction against the ground-truth labels, we can conveniently organize these values into a matrix form, thus the name Confusion Matrix:</p><p><img loading="lazy" src="https://user-images.githubusercontent.com/62965911/230722287-9be25aad-7666-4b55-9506-aa1b51c85c81.jpeg" alt="525591_1_En_1_Fig39_HTML" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="accuracy">Accuracy<a class="hash-link" href="#accuracy" title="Direct link to heading">​</a></h2><p>One of the most straightforward ways to evaluate the performance of a classification model is accuracy. Accuracy is simply the percentage of values that the model predicted correctly. In more technical terms, it’s the number of true positives plus the number of true negatives divided by the number of all the prediction values.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="precision">Precision<a class="hash-link" href="#precision" title="Direct link to heading">​</a></h2><p>On the contrary, precision considers the issue of class imbalance in data. Precision calculates the accuracy only within all predicted positive classes, or the number of true positives divided by the sum of true positives and false positives. This will punish models that perform poorly on the positive class in an imbalanced dataset with a large number of negative values.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="recall">Recall<a class="hash-link" href="#recall" title="Direct link to heading">​</a></h2><p>Recall score, or the true positive rate, is slightly different from precision as instead of calculating the accuracy of when the model predicts positive, it returns the accuracy of the positive class as a whole. Recall cleverly solves the problem of accuracy by only calculating the correctness in the positive class or the percentage of true positives across all positive labels. The recall metric is useful when we only care about our model predicting the positive class accurately. For example, when diagnosing cancer and most diseases, avoiding having false negatives is much more crucial than avoiding having false positives when resources are limited to develop a perfect model. In cases like such, we would be optimizing for a higher recall as we want the model to be as accurate as possible, especially in predicting the positive class.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="f1-score">F1 Score<a class="hash-link" href="#f1-score" title="Direct link to heading">​</a></h2><p>The intuition behind the F1 score is creating a universal metric that measures the correctness of the positive class while having both the advantages of precision and recall. Thus, the F1 score is the harmonic mean between precision and recall. Note we used harmonic mean here since precision and recall are expressed as percentages/rates.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="area-under-the-receiver-operating-characteristics-curve-roc-auc">Area Under the Receiver Operating Characteristics Curve (ROC-AUC)<a class="hash-link" href="#area-under-the-receiver-operating-characteristics-curve-roc-auc" title="Direct link to heading">​</a></h2><p>Although the F1 score accounts for both the advantages of precision and recall, it only measures the positive class. Another major issue of the F1 score along with precision and recall is that we’re inputting binary values for evaluation. Those binary values are determined by a threshold, converting probabilities to binary targets usually during model predictions. In most cases, 0.5 is chosen as the threshold for converting probabilities to binary targets. This not only might not be the optimal threshold, but it also decreases the amount of information that we receive from the output as probabilities also show how confident the model is in its prediction. The Receiver Operating Characteristics (ROC) curve solves these issues cleverly: it plots the true positive rate against the false positive rate for various thresholds.</p><p>The true positive rate, or recall, gives us how many predictions are correct among all predicted positive labels, or the probability that the model will be correct when the prediction is positive. The false positive rate calculates the number of false negatives within the negative prediction. In sense, it gives a probability that the model will be incorrect when the prediction is negative. The ROC curve visualizes the values of both measurements on different thresholds, generating a plot where we can see what threshold gives the best values for true positive rate/false positive rate.</p><p>Furthermore, calculating the area under the curve (AUC) provides a measurement of how well the model distinguishes between classes. An area of 1 indicates a perfect distinction between classes, thus producing correct predictions. An area of 0 indicates complete opposite predictions, meaning that all predictions are reversed between 1 and 0 (labels – 1). An area of 0.5 represents complete random prediction where the model cannot distinguish between classes at all.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-04-09T13:34:30.000Z">Apr 9, 2023</time></b> by <b>sparsh</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/datascience/feature-selection"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Feature Selection</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/datascience/nlp"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Natural Language Processing (NLP)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#mean-absolute-error" class="table-of-contents__link toc-highlight">Mean Absolute Error</a></li><li><a href="#mean-squared-error-mse" class="table-of-contents__link toc-highlight">Mean Squared Error (MSE)</a></li><li><a href="#confusion-matrix" class="table-of-contents__link toc-highlight">Confusion Matrix</a></li><li><a href="#accuracy" class="table-of-contents__link toc-highlight">Accuracy</a></li><li><a href="#precision" class="table-of-contents__link toc-highlight">Precision</a></li><li><a href="#recall" class="table-of-contents__link toc-highlight">Recall</a></li><li><a href="#f1-score" class="table-of-contents__link toc-highlight">F1 Score</a></li><li><a href="#area-under-the-receiver-operating-characteristics-curve-roc-auc" class="table-of-contents__link toc-highlight">Area Under the Receiver Operating Characteristics Curve (ROC-AUC)</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Bootcamp. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.166317d0.js"></script>
<script src="/assets/js/main.3580ce8c.js"></script>
</body>
</html>