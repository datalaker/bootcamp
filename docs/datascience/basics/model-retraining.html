<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-datascience/basics/model-retraining">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Model Retraining | Recohut Data Bootcamp</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://www.recohut.com/docs/datascience/basics/model-retraining"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="keywords" content="data science, data engineering, data analytics"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Model Retraining | Recohut Data Bootcamp"><meta data-rh="true" name="description" content="Concept Drift"><meta data-rh="true" property="og:description" content="Concept Drift"><link data-rh="true" rel="icon" href="/img/branding/favicon-black.svg"><link data-rh="true" rel="canonical" href="https://www.recohut.com/docs/datascience/basics/model-retraining"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/datascience/basics/model-retraining" hreflang="en"><link data-rh="true" rel="alternate" href="https://www.recohut.com/docs/datascience/basics/model-retraining" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut Data Bootcamp RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Data Bootcamp Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B4S1B1ZDTT"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-B4S1B1ZDTT",{})</script><link rel="stylesheet" href="/assets/css/styles.47c7b9d5.css">
<link rel="preload" href="/assets/js/runtime~main.251db5a0.js" as="script">
<link rel="preload" href="/assets/js/main.1462881d.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/branding/favicon-color.svg" alt="Recohut Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Bootcamp</b></a><a class="navbar__item navbar__link" href="/docs/introduction">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sparsh-ai/recohut" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Model Retraining</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="concept-drift">Concept Drift<a class="hash-link" href="#concept-drift" title="Direct link to heading">​</a></h2><p>Model Drift refers to a model’s predictive performance degrading over time due to a change in the environment that violates the model’s assumptions. Predictive performance will degrade, it will degrade over some period of time and at some rate, and this degradation will be due to changes in the environment that violate the modeling assumptions. Each of these variables should be taken into account when determining how to diagnose model drift and how to correct it through model retraining.</p><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_S0QG"><p>Model drift is a bit of a misnomer because it’s not the model that is changing, but rather the environment in which the model is operating. For that reason, the term <a href="https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/" target="_blank" rel="noopener noreferrer">concept drift</a> may actually be a better name, but both terms describe the same phenomenon.</p></div></div><p>As soon as you deploy your machine learning model in production, the performance of your model degrades. This is because your model is sensitive to changes in the real world, and user behaviour keeps changing with time. Although all machine learning models decay, the speed of decay varies with time. This is mostly caused by data drift, concept drift, or both.</p><p><center><img loading="lazy" src="https://github.com/recohut/incremental-learning/raw/a6fdcde2e8af7ebfd9f5efd278c487e0e9560cb3/docs/_images/L194114_1.png" class="img_ev3q"></center></p><p>Data drift (covariate shift) is a change in the statistical distribution of production data from the baseline data used to train or build the model. Data from real-time serving can drift from the baseline data due to:</p><ul><li>Changes in the real world,</li><li>Training data not being a representation of the population,</li><li>Data quality issues like outliers in the dataset.</li></ul><p>For example, if you built a model with temperature data collected from a sensor in Celsius degrees, but the unit changed to Fahrenheit – it means there’s been a change in your input data, so the data has drifted.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-to-monitor-data-drift-in-production"><strong>How to monitor data drift in production</strong><a class="hash-link" href="#how-to-monitor-data-drift-in-production" title="Direct link to heading">​</a></h3><p>The best approach to handling data drift is to continuously monitor your data with advanced MLOps tools instead of using traditional rule-based methods. Rule based methods, like calculating the data range or comparing data attributes to detect alien values, can be time-consuming and are susceptible to error.</p><p><strong>Steps you can take to detect data drift:</strong></p><ol><li>Take advantage of the <a href="https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence" target="_blank" rel="noopener noreferrer">JS-Divergence algorithm</a> to identify prediction drift in real-time model output and compare it with training data.</li><li>Compare the data distribution from both upstream and downstream data to view the actual difference.</li></ol><p>As mentioned above, you can also take advantage of the <a href="https://www.fiddler.ai/" target="_blank" rel="noopener noreferrer">Fiddler AI</a> platform to monitor data drift in production.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-drift-vs-concept-drift"><strong>Data drift vs concept drift</strong><a class="hash-link" href="#data-drift-vs-concept-drift" title="Direct link to heading">​</a></h3><p>It’s an obvious fact that data is generated at every moment in the world. As data is collected from multiple sources, data itself is changing. This change can be due to the dynamic nature of the data, or it can be caused by changes in the real world.</p><p>If the input distribution changes but the true labels don’t (the probability of the model’s input changes but the probability of the target class given the probability of the model input doesn’t change), then this kind of change is considered as data drift.</p><p>Meanwhile, if there’s a change in the labels or target classes of your model, that is the probability of the target class changes given the probability of the input data. This means we’re detecting the effect of concept drift. Both data drift and concept drift cause model decay and should both be addressed separately.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="a-spectrum-of-model-freshness">A spectrum of model freshness<a class="hash-link" href="#a-spectrum-of-model-freshness" title="Direct link to heading">​</a></h2><p>We can think of model retraining approaches as a hierarchy:</p><ul><li><strong>Level 0:</strong> Train the model once and never retrain it. This is appropriate for “stationary” problems.</li><li><strong>Level 1 (“cold-start retraining”):</strong> Periodically retrain the whole model on a batch dataset.</li><li><strong>Level 2 (“warm-start retraining”):</strong> In addition to Level 1, if the model has personalized per-key components, retrain just these in bulk on data specific to each key (e.g., all impressions of an advertiser&#x27;s ads), once enough data has accumulated.</li><li><strong>Level 3 (“nearline retraining”):</strong> In addition to Level 2, retrain per-key components individually and asynchronously nearline on streaming data.</li></ul><p>These levels build upon each other. Depending on how fresh a model needs to be to perform well at its task, we may elect to stay at Level 0 for a stationary problem, all the way through to Level 3 for problems where incorporating new data within seconds makes a difference.</p><figure><p><center><img loading="lazy" src="https://github.com/recohut/incremental-learning/raw/a6fdcde2e8af7ebfd9f5efd278c487e0e9560cb3/docs/_images/L241645_1.png" class="img_ev3q"><figcaption>*A hierarchy of model retraining.*</figcaption></center></p></figure><p>If we arrange all of the model updates in Level 3 on a timeline, as depicted in the above, we’ll see three types of model update occurring. Occasionally, a Level 1 update will reset the whole model (both global model and all per-key components); this will be a batch offline update using a large accumulated dataset. More frequently, Level 2 updates will reset just the per-key components; this again will be an offline batch update, but won’t touch the large global model. Finally, “lightweight” Level 3 updates will occur almost continuously; any individual per-key component is tuned as soon as there is enough data to do so.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="scikit-warm-start">Scikit warm-start<a class="hash-link" href="#scikit-warm-start" title="Direct link to heading">​</a></h2><p>For some applications the amount of examples, features (or both) and/or the speed at which they need to be processed are challenging for traditional approaches. In these cases scikit-learn has a number of options you can consider to make your system scale.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="scaling-with-instances-using-out-of-core-learning">Scaling with instances using out-of-core learning<a class="hash-link" href="#scaling-with-instances-using-out-of-core-learning" title="Direct link to heading">​</a></h3><p>Out-of-core (or “external memory”) learning is a technique used to learn from data that cannot fit in a computer’s main memory (RAM).</p><p>Here is sketch of a system designed to achieve this goal:</p><ol><li>a way to stream instances</li><li>a way to extract features from instances</li><li>an incremental algorithm</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="streaming-instances">Streaming instances<a class="hash-link" href="#streaming-instances" title="Direct link to heading">​</a></h3><p>Basically, (1. a way to stream instances) may be a reader that yields instances from files on a hard drive, a database, from a network stream etc. However, details on how to achieve this are beyond the scope of this documentation.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="extracting-features">Extracting features<a class="hash-link" href="#extracting-features" title="Direct link to heading">​</a></h3><p>(2. a way to extract features from instances) could be any relevant way to extract features among the different <em><a href="https://scikit-learn.org/0.15/modules/feature_extraction.html#feature-extraction" target="_blank" rel="noopener noreferrer">feature extraction</a></em> methods supported by scikit-learn. However, when working with data that needs vectorization and where the set of features or values is not known in advance one should take explicit care. A good example is text classification where unknown terms are likely to be found during training. It is possible to use a stateful vectorizer if making multiple passes over the data is reasonable from an application point of view. Otherwise, one can turn up the difficulty by using a stateless feature extractor. Currently the preferred way to do this is to use the so-called <em><a href="https://scikit-learn.org/0.15/modules/feature_extraction.html#feature-hashing" target="_blank" rel="noopener noreferrer">hashing trick</a></em> as implemented by <strong><a href="https://scikit-learn.org/0.15/modules/generated/sklearn.feature_extraction.FeatureHasher.html#sklearn.feature_extraction.FeatureHasher" target="_blank" rel="noopener noreferrer">sklearn.feature_extraction.FeatureHasher</a></strong> for datasets with categorical variables represented as list of Python dicts or <strong><a href="https://scikit-learn.org/0.15/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer" target="_blank" rel="noopener noreferrer">sklearn.feature_extraction.text.HashingVectorizer</a></strong> for text documents.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="incremental-learning">Incremental learning<a class="hash-link" href="#incremental-learning" title="Direct link to heading">​</a></h3><p>Finally, for (3. an incremental algorithm), we have a number of options inside scikit-learn. Although all algorithms cannot learn incrementally (i.e. without seeing all the instances at once), all estimators implementing the partial_fit API are candidates. Actually, the ability to learn incrementally from a mini-batch of instances (sometimes called “online learning”) is key to out-of-core learning as it guarantees that at any given time there will be only a small amount of instances in the main memory. Choosing a good size for the mini-batch that balances relevancy and memory footprint could involve some tuning.</p><p>For classification, a somewhat important thing to note is that although a stateless feature extraction routine may be able to cope with new/unseen attributes, the incremental learner itself may be unable to cope with new/unseen targets classes. In this case you have to pass all the possible classes to the first partial_fit call using the classes= parameter.</p><p>Another aspect to consider when choosing a proper algorithm is that all of them don’t put the same importance on each example over time. Namely, the Perceptron is still sensitive to badly labeled examples even after many examples whereas the SGD<em> and PassiveAggressive</em> families are more robust to this kind of artifacts. Conversely, the later also tend to give less importance to remarkably different, yet properly labeled examples when they come late in the stream as their learning rate decreases over time.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a class="hash-link" href="#references" title="Direct link to heading">​</a></h2><ul><li><a href="https://pdfs.semanticscholar.org/4ccc/553d7774748be878002381877d70932b2717.pdf" target="_blank" rel="noopener noreferrer">Learning in the Presence of Concept Drift and Hidden Contexts</a></li><li><a href="http://www-ai.cs.uni-dortmund.de/LEHRE/FACHPROJEKT/SS12/paper/concept-drift/tsymbal2004.pdf" target="_blank" rel="noopener noreferrer">The problem of concept drift: definitions and related work</a></li><li><a href="https://arxiv.org/abs/1504.01044" target="_blank" rel="noopener noreferrer">Concept Drift Detection for Streaming Data</a></li><li><a href="https://arxiv.org/abs/1010.4784" target="_blank" rel="noopener noreferrer">Learning under Concept Drift: an Overview</a></li><li><a href="http://www.win.tue.nl/~mpechen/publications/pubs/CD_applications15.pdf" target="_blank" rel="noopener noreferrer">An overview of concept drift applications</a></li><li><a href="https://link.springer.com/chapter/10.1007/978-3-642-16438-5_17" target="_blank" rel="noopener noreferrer">What Is Concept Drift and How to Measure</a></li><li><a href="https://arxiv.org/abs/1704.00362" target="_blank" rel="noopener noreferrer">Understanding Concept Drift</a></li><li><a href="https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/" target="_blank" rel="noopener noreferrer">https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning</a></li><li><a href="https://en.wikipedia.org/wiki/Concept_drift" target="_blank" rel="noopener noreferrer">Concept drift on Wikipedia</a></li><li><a href="https://ieeexplore.ieee.org/document/6042653/" target="_blank" rel="noopener noreferrer">Handling Concept Drift: Importance, Challenges and Solutions</a></li><li><a href="https://mlinproduction.com/model-retraining/" target="_blank" rel="noopener noreferrer">https://mlinproduction.com/model-retraining</a></li><li><a href="https://docs.aws.amazon.com/machine-learning/latest/dg/retraining-models-on-new-data.html" target="_blank" rel="noopener noreferrer">Retraining Models on New Data</a></li><li><a href="https://www.quora.com/Should-a-machine-learning-model-be-retrained-each-time-new-observations-are-available" target="_blank" rel="noopener noreferrer">Should a machine learning model be retrained each time new observations are available?</a></li><li><a href="https://www.inawisdom.com/machine-learning/machine-learning-automated-model-retraining-sagemaker/" target="_blank" rel="noopener noreferrer">MACHINE LEARNING AND AUTOMATED MODEL RETRAINING WITH SAGEMAKER</a></li><li><a href="https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/" target="_blank" rel="noopener noreferrer">A Gentle Introduction to Concept Drift in Machine Learning</a></li><li><a href="https://www.oreilly.com/ideas/lessons-learned-turning-machine-learning-models-into-real-products-and-services" target="_blank" rel="noopener noreferrer">Lessons learned turning machine learning models into real products and services</a></li><li><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/45742.pdf" target="_blank" rel="noopener noreferrer">What’s your ML Test Score? A rubric for ML production systems</a></li><li><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/43146.pdf" target="_blank" rel="noopener noreferrer">Machine Learning: The High-Interest Credit Card of Technical Debt</a></li><li><a href="https://www.oreilly.com/ideas/lessons-learned-turning-machine-learning-models-into-real-products-and-services" target="_blank" rel="noopener noreferrer">Lessons learned turning machine learning models into real products and services</a></li><li><a href="https://neptune.ai/blog/retraining-model-during-deployment-continuous-training-continuous-testing" target="_blank" rel="noopener noreferrer">Machine learning models get stale with time</a></li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-04-09T13:34:30.000Z">Apr 9, 2023</time></b> by <b>sparsh</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#concept-drift" class="table-of-contents__link toc-highlight">Concept Drift</a><ul><li><a href="#how-to-monitor-data-drift-in-production" class="table-of-contents__link toc-highlight"><strong>How to monitor data drift in production</strong></a></li><li><a href="#data-drift-vs-concept-drift" class="table-of-contents__link toc-highlight"><strong>Data drift vs concept drift</strong></a></li></ul></li><li><a href="#a-spectrum-of-model-freshness" class="table-of-contents__link toc-highlight">A spectrum of model freshness</a></li><li><a href="#scikit-warm-start" class="table-of-contents__link toc-highlight">Scikit warm-start</a><ul><li><a href="#scaling-with-instances-using-out-of-core-learning" class="table-of-contents__link toc-highlight">Scaling with instances using out-of-core learning</a></li><li><a href="#streaming-instances" class="table-of-contents__link toc-highlight">Streaming instances</a></li><li><a href="#extracting-features" class="table-of-contents__link toc-highlight">Extracting features</a></li><li><a href="#incremental-learning" class="table-of-contents__link toc-highlight">Incremental learning</a></li></ul></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Bootcamp. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.251db5a0.js"></script>
<script src="/assets/js/main.1462881d.js"></script>
</body>
</html>