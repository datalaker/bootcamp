# Extract data from multiple sources and load into database

You are working in a startup developing an e-scooter-sharing system called Scoota. It aspires to operate in the most populous cities all around the world. In each city, your company will have hundreds of e-scooters parked in the streets and allow users to rent them by the minute.

The company wants to anticipate as much as possible scooter movements. Predictive modelling is certainly on the roadmap, but the first step is to collect more data, transform it and store it appropriately. This is where you comes in: your task will be to collect data from external sources that can potentially help your company in predicting e-scooter movements. Since data is needed every day, in real-time and accessible by everyone in the company, the challenge is going to be in assembling and automating a data pipeline in the cloud.

The purpose of this project is to learn dealing with API's and JSON files.

We can divide this requirement into 5 parts:

1. Web Scraping to collect demographical data;
2. Weather data using OWN API;
3. Collect flights data using the Aerodatabox API;
4. Storing Data in a Postgres Database;
5. Create a Pipeline and Automate. `Assignment`