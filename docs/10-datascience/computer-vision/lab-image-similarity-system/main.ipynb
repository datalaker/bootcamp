{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdcFFjIG8dot"
   },
   "source": [
    "# Similar Product Recommendations\n",
    "> A tutorial on building a recommender system that will find similar looking products\n",
    "\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [similarity, visual]\n",
    "- image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVHAW10n1F74",
    "outputId": "1bf9840e-03c4-4760-f45d-ef067a666ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqMPSQ8xsTbu",
    "outputId": "09d0e696-5c5a-45bb-a177-ac3c47ec9dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kaggle.json\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%%writefile kaggle.json\n",
    "{\"username\":\"<your kaggle username>\",\"key\":\"<your kaggle api key>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6tw-MsbsYpt",
    "outputId": "33c41e38-802e-4f05-eb84-ff6ac3eee4ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 4.8MB/s eta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=a1c2e751133a41cb90d9e999887f7e60f2ff4633694bd112a74efadb40970d7c\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "  Found existing installation: kaggle 1.5.12\n",
      "    Uninstalling kaggle-1.5.12:\n",
      "      Successfully uninstalled kaggle-1.5.12\n",
      "Successfully installed kaggle-1.5.12\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip install -q -U kaggle\n",
    "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1](https://user-images.githubusercontent.com/62965911/224650764-f092f79f-3674-406b-ac36-cadac6e71b05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GlqfNWm6ciB"
   },
   "source": [
    "### Choice of variables\n",
    "\n",
    "- Image Encoder: Any pre-trained image classification model can be selected. These models are commonly known as encoders because their job is to encode an image into a feature vector. In our case, we analyzed four encoders named 1) MobileNet, 2) EfficientNet, 3) ResNet and 4) [BiT](https://tfhub.dev/google/bit/m-r152x4/1). After some basic research, we decided to select BiT model because of its performance. I selected the BiT-M-50x3 variant of model which is of size 748 MB. More details about this architecture can be found on the official page [here](https://tfhub.dev/google/bit/m-r50x3/1).\n",
    "- Vector Similarity System: Images are represented in a fixed-length feature vector format. For the given input vector, we need to find the TopK most similar vectors, keeping the memory efficiency and real-time retrival objective in mind. We explored the most popular techniques and listed down five of them: Annoy, Cosine distance, L1 distance, Locally Sensitive Hashing (LSH) and Image Deep Ranking. We selected Annoy because of its fast and efficient nature. More details about Annoy can be found on the official page [here](https://github.com/spotify/annoy).\n",
    "- Dataset: This system is able to handle all kind of image dataset. Only the basic preprocessing (in step 1) would need some modifications depending on the dataset. We chose [Fashion Product Images (Small)](https://www.kaggle.com/bhaskar2443053/fashion-small?). Other examples can be [Food-11 image dataset](https://www.kaggle.com/trolukovich/food11-image-dataset?), and [Caltech 256 Image Dataset](https://www.kaggle.com/jessicali9530/caltech256?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ushnAKJ5VyfI"
   },
   "source": [
    "### Step 1: Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdAaHU-x5R7U"
   },
   "source": [
    "Download the raw image dataset into a directory. Categorize these images into their respective category directories. Make sure that images are of the same type, JPEG recommended. We will also process the metadata and store it in a serialized file, CSV recommended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q72U45CZtzAZ"
   },
   "outputs": [],
   "source": [
    "#hide-output\n",
    "# downloading raw images from kaggle\n",
    "!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
    "!unzip fashion-product-images-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xS6CNOmrUfmi",
    "outputId": "ce79c260-8082-42f7-b81f-d5685654ba2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44441/44441 [02:08<00:00, 346.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 44441 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from shutil import move\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.mkdir('/content/Fashion_data')\n",
    "os.chdir('/content/Fashion_data')\n",
    "\n",
    "df = pd.read_csv('/content/styles.csv', usecols=['id','masterCategory']).reset_index()\n",
    "df['id'] = df['id'].astype('str')\n",
    "\n",
    "all_images = os.listdir('/content/images/')\n",
    "co = 0\n",
    "os.mkdir('/content/Fashion_data/categories')\n",
    "for image in tqdm(all_images):\n",
    "    category = df[df['id'] == image.split('.')[0]]['masterCategory']\n",
    "    category = str(list(category)[0])\n",
    "    if not os.path.exists(os.path.join('/content/Fashion_data/categories', category)):\n",
    "        os.mkdir(os.path.join('/content/Fashion_data/categories', category))\n",
    "    path_from = os.path.join('/content/images', image)\n",
    "    path_to = os.path.join('/content/Fashion_data/categories', category, image)\n",
    "    move(path_from, path_to)\n",
    "    co += 1\n",
    "print('Moved {} images.'.format(co))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx-LREyDWEYK"
   },
   "source": [
    "### Step 2: Encoder Fine-tuning [optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEYVHxkN5U_K"
   },
   "source": [
    "Download the pre-trained image model and add two additional layers on top of that: the first layer is a feature vector layer and the second layer is the classification layer. We will only train these 2 layers on our data and after training, we will select the feature vector layer as the output of our fine-tuned encoder. After fine-tuning the model, we will save the feature extractor for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdpzJdFpUfiu",
    "outputId": "d97f458e-5054-45cf-c890-bfd59bcbb93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.4.1\n",
      "Hub version: 0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F5D6EK18Ufg_",
    "outputId": "9961fdde-8972-46bc-f07b-64ce2c3ffa8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using https://tfhub.dev/google/bit/m-r50x3/1 with input size (224, 224)\n"
     ]
    }
   ],
   "source": [
    "MODULE_HANDLE = 'https://tfhub.dev/google/bit/m-r50x3/1'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
    "BATCH_SIZE = 32 \n",
    "N_FEATURES = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6W9wx6VvUfff"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "data_dir = '/content/Fashion_data/categories'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGyqBujZUfd0",
    "outputId": "b918eebd-e801-4b4e-ff24-4d0c4afed25f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8886 images belonging to 7 classes.\n",
      "Found 35555 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
    "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "                   interpolation=\"bilinear\")\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
    "\n",
    "do_data_augmentation = False \n",
    "if do_data_augmentation:\n",
    "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      horizontal_flip=True,\n",
    "      width_shift_range=0.2, height_shift_range=0.2,\n",
    "      shear_range=0.2, zoom_range=0.2,\n",
    "      **datagen_kwargs)\n",
    "else:\n",
    "  train_datagen = valid_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acJCBUeiUfcC",
    "outputId": "6304df64-b293-47ff-a2b4-594c8f687410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with https://tfhub.dev/google/bit/m-r50x3/1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_1 (KerasLayer)   (None, 6144)              211174080 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               1573120   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 212,748,999\n",
      "Trainable params: 1,574,919\n",
      "Non-trainable params: 211,174,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model with\", MODULE_HANDLE)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(MODULE_HANDLE, trainable=False),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(N_FEATURES,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2CMlRLFUfZC"
   },
   "outputs": [],
   "source": [
    "# Define optimiser and loss\n",
    "lr = 0.003 * BATCH_SIZE / 512 \n",
    "SCHEDULE_LENGTH = 500\n",
    "SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
    "\n",
    "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES, \n",
    "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8lBtDaOUfWD",
    "outputId": "4214c3dd-0e5c-415a-d9ff-6ef83f4ccadc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1111/1111 [==============================] - 1221s 1s/step - loss: 0.4232 - accuracy: 0.9410 - val_loss: 0.1400 - val_accuracy: 0.9878\n",
      "Epoch 2/5\n",
      "1111/1111 [==============================] - 1210s 1s/step - loss: 0.2100 - accuracy: 0.9760 - val_loss: 0.1399 - val_accuracy: 0.9879\n",
      "Epoch 3/5\n",
      "1111/1111 [==============================] - 1210s 1s/step - loss: 0.2115 - accuracy: 0.9766 - val_loss: 0.1397 - val_accuracy: 0.9880\n",
      "Epoch 4/5\n",
      "1111/1111 [==============================] - 1210s 1s/step - loss: 0.2094 - accuracy: 0.9763 - val_loss: 0.1396 - val_accuracy: 0.9880\n",
      "Epoch 5/5\n",
      "1111/1111 [==============================] - 1210s 1s/step - loss: 0.1923 - accuracy: 0.9775 - val_loss: 0.1394 - val_accuracy: 0.9880\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=validation_steps).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "id": "NJKzJ1q1W6BO",
    "outputId": "cafa44c3-d4ad-4245-ce65-86859c113fc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f62d65abfd0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "plt.figure()\n",
    "plt.ylabel(\"Loss (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.plot(hist[\"val_loss\"])\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(hist[\"accuracy\"])\n",
    "plt.plot(hist[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NY6gNBhyW5-5",
    "outputId": "b6236a5b-0694-44a9-bdf8-4b2204e6699e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ImgSim/bit_feature_extractor/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ImgSim/bit_feature_extractor/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ImgSim/bit_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ImgSim/bit_model/assets\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('/content/drive/MyDrive/ImgSim/'):\n",
    "    os.mkdir('/content/drive/MyDrive/ImgSim/')\n",
    "\n",
    "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
    "feature_extractor.save('/content/drive/MyDrive/ImgSim/bit_feature_extractor', save_format='tf')\n",
    "\n",
    "saved_model_path = '/content/drive/MyDrive/ImgSim/bit_model'\n",
    "tf.saved_model.save(model, saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoymCsSMXOeu"
   },
   "source": [
    "### Step 3: Image Vectorization\n",
    "Now, we will use the encoder (prepared in step 2) to encode the images (prepared in step 1). We will save feature vector of each image as an array in a directory. After processing, we will save these embeddings for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbWu23iuW56S",
    "outputId": "f74fb73f-5929-4d27-e890-df0c88e6ee8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_USmBUpiW58t"
   },
   "outputs": [],
   "source": [
    "img_paths = []\n",
    "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
    "  img_paths.append(path)\n",
    "np.random.shuffle(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "992vULeyW5zD"
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  img = tf.image.resize_with_pad(img, 224, 224)\n",
    "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2B8cJuQgaT1r",
    "outputId": "8a6baf17-1403-4ac2-9004-6387d6e33910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#hide-output\n",
    "TRANSFER_LEARNING_FLAG = 1\n",
    "if TRANSFER_LEARNING_FLAG:\n",
    "  module = tf.keras.models.load_model('/content/drive/MyDrive/ImgSim/bit_feature_extractor')\n",
    "else:\n",
    "  module_handle = \"https://tfhub.dev/google/bit/s-r50x3/ilsvrc2012_classification/1\" \n",
    "  module = hub.load(module_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtfPQPWIW5wD"
   },
   "outputs": [],
   "source": [
    "imgvec_path = '/content/img_vectors/'\n",
    "Path(imgvec_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kLn4sOyW5sx",
    "outputId": "08e36c9e-406e-4e47-8871-2b54740694fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [08:58<00:00,  9.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for filename in tqdm(img_paths[:5000]):\n",
    "    img = load_img(str(filename))\n",
    "    features = module(img)\n",
    "    feature_set = np.squeeze(features)\n",
    "    outfile_name = os.path.basename(filename).split('.')[0] + \".npz\"\n",
    "    out_path_file = os.path.join(imgvec_path, outfile_name)\n",
    "    np.savetxt(out_path_file, feature_set, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsSVlCOhf5b0"
   },
   "source": [
    "### Step 4: Metadata and Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUMsk_kd5bPU"
   },
   "source": [
    "We will assign a unique id to each image and create dictionaries to locate information of this image: 1) Image id to Image name dictionary, 2) Image id to image feature vector dictionary, and 3) (optional) Image id to metadata product id dictionary. We will also create an image id to image feature vector indexing. Then we will save these dictionaries and index object for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21NzEoTegKxZ",
    "outputId": "31b52417-aa6c-4363-e568-1be0c2059b1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "!pip install -q annoy\n",
    "import json\n",
    "from annoy import AnnoyIndex\n",
    "from scipy import spatial\n",
    "import pickle\n",
    "from IPython.display import Image as dispImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "id": "9jv-lnwzHvlC",
    "outputId": "5f72ac85-c3fa-4e69-9305-bc3f4058b32b"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = '/content/Fashion_data/categories/Accessories/1941.jpg'\n",
    "dispImage(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1niXWpbXW5m3",
    "outputId": "98c52ad2-e0d8-4252-9f38-cc0df278b667"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6044: expected 10 fields, saw 11\\nSkipping line 6569: expected 10 fields, saw 11\\nSkipping line 7399: expected 10 fields, saw 11\\nSkipping line 7939: expected 10 fields, saw 11\\nSkipping line 9026: expected 10 fields, saw 11\\nSkipping line 10264: expected 10 fields, saw 11\\nSkipping line 10427: expected 10 fields, saw 11\\nSkipping line 10905: expected 10 fields, saw 11\\nSkipping line 11373: expected 10 fields, saw 11\\nSkipping line 11945: expected 10 fields, saw 11\\nSkipping line 14112: expected 10 fields, saw 11\\nSkipping line 14532: expected 10 fields, saw 11\\nSkipping line 15076: expected 10 fields, saw 12\\nSkipping line 29906: expected 10 fields, saw 11\\nSkipping line 31625: expected 10 fields, saw 11\\nSkipping line 33020: expected 10 fields, saw 11\\nSkipping line 35748: expected 10 fields, saw 11\\nSkipping line 35962: expected 10 fields, saw 11\\nSkipping line 37770: expected 10 fields, saw 11\\nSkipping line 38105: expected 10 fields, saw 11\\nSkipping line 38275: expected 10 fields, saw 11\\nSkipping line 38404: expected 10 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "#hide-output\n",
    "styles = pd.read_csv('/content/styles.csv', error_bad_lines=False)\n",
    "styles['id'] = styles['id'].astype('str')\n",
    "styles.to_csv(root_path+'/styles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-nFnff8W5j7"
   },
   "outputs": [],
   "source": [
    "def match_id(fname):\n",
    "  return styles.index[styles.id==fname].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fq594UchW5hz"
   },
   "outputs": [],
   "source": [
    "# Defining data structures as empty dict\n",
    "file_index_to_file_name = {}\n",
    "file_index_to_file_vector = {}\n",
    "file_index_to_product_id = {}\n",
    "\n",
    "# Configuring annoy parameters\n",
    "dims = 256\n",
    "n_nearest_neighbors = 20\n",
    "trees = 10000\n",
    "\n",
    "# Reads all file names which stores feature vectors \n",
    "allfiles = glob.glob('/content/img_vectors/*.npz')\n",
    "\n",
    "t = AnnoyIndex(dims, metric='angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvKGnMU-W5fh",
    "outputId": "0787700d-abec-44af-82c6-742da632ead3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:17, 279.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for findex, fname in tqdm(enumerate(allfiles)):\n",
    "  file_vector = np.loadtxt(fname)\n",
    "  file_name = os.path.basename(fname).split('.')[0]\n",
    "  file_index_to_file_name[findex] = file_name\n",
    "  file_index_to_file_vector[findex] = file_vector\n",
    "  try:\n",
    "    file_index_to_product_id[findex] = match_id(file_name)\n",
    "  except IndexError:\n",
    "    pass \n",
    "  t.add_item(findex, file_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHB-JNObW5cs",
    "outputId": "7cbe28ed-e6cf-4392-c6a5-750983234c0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide-output\n",
    "t.build(trees)\n",
    "t.save('t.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-6vhz4Dhjz3"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "file_path = '/content/drive/MyDrive/ImgSim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKzVD4PdW5ZD"
   },
   "outputs": [],
   "source": [
    "t.save(file_path+'indexer.ann')\n",
    "pickle.dump(file_index_to_file_name, open(file_path+\"file_index_to_file_name.p\", \"wb\"))\n",
    "pickle.dump(file_index_to_file_vector, open(file_path+\"file_index_to_file_vector.p\", \"wb\"))\n",
    "pickle.dump(file_index_to_product_id, open(file_path+\"file_index_to_product_id.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ9BN_MsiwSy"
   },
   "source": [
    "## Step 5: Local Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k1SHCwd5fO8"
   },
   "source": [
    "We will load a random image and find top-K most similar images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QK_ChEiYf1n0"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "V32QozZfHtDU",
    "outputId": "da444127-620d-471e-a316-c6801362c2fd"
   },
   "outputs": [],
   "source": [
    "img_addr = 'https://images-na.ssl-images-amazon.com/images/I/81%2Bd6eSA0eL._UL1500_.jpg'\n",
    "\n",
    "!wget -q -O img.jpg $img_addr\n",
    "test_img = 'img.jpg'\n",
    "topK = 4\n",
    "\n",
    "test_vec = np.squeeze(module(load_img(test_img)))\n",
    "\n",
    "basewidth = 224\n",
    "img = Image.open(test_img)\n",
    "wpercent = (basewidth/float(img.size[0]))\n",
    "hsize = int((float(img.size[1])*float(wpercent)))\n",
    "img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3](https://user-images.githubusercontent.com/62965911/224650783-b2fcf759-2609-476e-9bc9-f72d4fcbfd91.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "HFs56RynGrjO",
    "outputId": "08c14364-79de-4d4e-8dfc-b17e4c4d4b0d"
   },
   "outputs": [],
   "source": [
    "path_dict = {}\n",
    "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
    "  path_dict[path.name] = path\n",
    "\n",
    "nns = t.get_nns_by_vector(test_vec, n=topK)\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(topK):\n",
    "  x = file_index_to_file_name[nns[i]]\n",
    "  x = path_dict[x+'.jpg']\n",
    "  y = file_index_to_product_id[nns[i]]\n",
    "  title = '\\n'.join([str(j) for j in list(styles.loc[y].values[-5:])])\n",
    "  plt.subplot(1, topK, i+1)\n",
    "  plt.title(title)\n",
    "  plt.imshow(mpimg.imread(x))\n",
    "  plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](https://user-images.githubusercontent.com/62965911/224650771-0ab0404d-2dd0-433f-9f67-013ac6a39ad2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-pbfJyqkS9T"
   },
   "source": [
    "## Step 6: API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lATZdqAI5iQU"
   },
   "source": [
    "We will build two kinds of API - 1) UI based API using Streamlit, and 2) REST API using Flask. In both the cases, we will receive an image from user, encode it with our image encoder, find TopK similar vectors using Indexing object, and retrieve the image (and metadata) using dictionaries. We send these images (and metadata) back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEuchptAlDIK"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xqniAiWk-da"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "root_path = '/content/drive/MyDrive/ImgSim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kUXYz5QZBiDG",
    "outputId": "a6a4fa70-7924-4ad4-9c4b-5042836ee97c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "### ----utils.py---- ###\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "root_path = '/content/drive/MyDrive/ImgSim'\n",
    "\n",
    "class Encoder:\n",
    "  encoder = tf.keras.models.load_model(os.path.join(root_path, 'bit_feature_extractor'))\n",
    "\n",
    "class Indexer:\n",
    "  dims = 256\n",
    "  topK = 6\n",
    "  indexer = AnnoyIndex(dims, 'angular')\n",
    "  indexer.load(os.path.join(root_path, 'indexer.ann'))\n",
    "  \n",
    "encoder = Encoder()\n",
    "indexer = Indexer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSO01jdL5rHK"
   },
   "source": [
    "### Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2xGrUSvyAHt",
    "outputId": "c6865549-15e6-4342-de56-202c021cc913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "### ----app.py---- ###\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from annoy import AnnoyIndex\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tarfile\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import time\n",
    "from utils import encoder, indexer\n",
    "\n",
    "root_path = '/content/drive/MyDrive/ImgSim'\n",
    "\n",
    "start_time = time.time()\n",
    "encoder = encoder.encoder\n",
    "print(\"---Encoder--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "topK = 6\n",
    "\n",
    "start_time = time.time()\n",
    "t = indexer.indexer\n",
    "print(\"---Indexer--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# load the meta data\n",
    "meta_data = pd.read_csv(os.path.join(root_path, 'styles.csv'))\n",
    "\n",
    "# load the mappings\n",
    "file_index_to_file_name = pickle.load(open(os.path.join(root_path ,'file_index_to_file_name.p'), 'rb'))\n",
    "file_index_to_file_vector = pickle.load(open(os.path.join(root_path ,'file_index_to_file_vector.p'), 'rb'))\n",
    "file_index_to_product_id = pickle.load(open(os.path.join(root_path ,'file_index_to_product_id.p'), 'rb'))\n",
    "\n",
    "# load image path mapping\n",
    "path_dict = {}\n",
    "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
    "  path_dict[path.name] = path\n",
    "\n",
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  img = tf.image.resize_with_pad(img, 224, 224)\n",
    "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  return img\n",
    "\n",
    "query_path = '/content/user_query.jpg'\n",
    "\n",
    "st.title(\"Image Similarity App\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=\"jpg\")\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    image.save(query_path)\n",
    "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
    "    st.write(\"\")\n",
    "    st.write(\"Top similar images...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    test_vec = np.squeeze(encoder(load_img(query_path)))\n",
    "    print(\"---Encoding--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    start_time = time.time()\n",
    "    nns = t.get_nns_by_vector(test_vec, n=topK)\n",
    "    print(\"---SimilarityIndex--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    img_files = []\n",
    "    img_captions = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i in nns:\n",
    "      #image files\n",
    "      img_path = str(path_dict[file_index_to_file_name[i]+'.jpg'])\n",
    "      img_file = Image.open(img_path)\n",
    "      img_files.append(img_file)\n",
    "      #image captions\n",
    "      item_id = file_index_to_product_id[i]\n",
    "      img_caption = '\\n'.join([str(j) for j in list(meta_data.loc[item_id].values[-5:])])\n",
    "      img_captions.append(img_caption)\n",
    "    print(\"---Output--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    st.image(img_files, caption=img_captions, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTGShJ4HvhOr"
   },
   "outputs": [],
   "source": [
    "! pip install -q pyngrok\n",
    "! pip install -q streamlit\n",
    "! pip install -q colab-everything\n",
    "\n",
    "from colab_everything import ColabStreamlit\n",
    "ColabStreamlit('app.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUAHHR5ZjWi1"
   },
   "source": [
    "### Flask API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlPaLLHq4ENq"
   },
   "source": [
    "#### server-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fahnFX0lWUp"
   },
   "outputs": [],
   "source": [
    "%%writefile flask_app.py\n",
    "### ----flask_app.py---- ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from annoy import AnnoyIndex\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tarfile\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import time\n",
    "from utils import encoder, indexer\n",
    "import io\n",
    "import base64\n",
    "\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "\n",
    "_PPATH = '/content/drive/MyDrive/ImgSim/'\n",
    "\n",
    "start_time = time.time()\n",
    "encoder = encoder.encoder\n",
    "print(\"---Encoder--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "topK = 6\n",
    "\n",
    "start_time = time.time()\n",
    "t = indexer.indexer\n",
    "print(\"---Indexer--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# load the meta data\n",
    "meta_data = pd.read_csv(_PPATH+'styles.csv')\n",
    "\n",
    "# load the mappings\n",
    "file_index_to_file_name = pickle.load(open(_PPATH+'file_index_to_file_name.p', 'rb'))\n",
    "file_index_to_file_vector = pickle.load(open(_PPATH+'file_index_to_file_vector.p', 'rb'))\n",
    "file_index_to_product_id = pickle.load(open(_PPATH+'file_index_to_product_id.p', 'rb'))\n",
    "\n",
    "# load image path mapping\n",
    "path_dict = {}\n",
    "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
    "  path_dict[path.name] = path\n",
    "\n",
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  img = tf.image.resize_with_pad(img, 224, 224)\n",
    "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  return img\n",
    "\n",
    "query_path = '/content/user_query.jpg'\n",
    "\n",
    "def get_encoded_img(img):\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    img.save(img_byte_arr, format='PNG')\n",
    "    my_encoded_img = base64.encodebytes(img_byte_arr.getvalue()).decode('ascii')\n",
    "    return my_encoded_img\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/fashion\", methods=[\"POST\"])\n",
    "def home():\n",
    "    file = request.files['image']\n",
    "    # Read the image via file.stream\n",
    "    img = Image.open(file.stream)\n",
    "    img.save(query_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "    test_vec = np.squeeze(encoder(load_img(query_path)))\n",
    "    print(\"---Encoding--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    start_time = time.time()\n",
    "    nns = t.get_nns_by_vector(test_vec, n=topK)\n",
    "    print(\"---SimilarityIndex--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    img_files = {}\n",
    "    img_captions = {}\n",
    "\n",
    "    start_time = time.time()\n",
    "    for count, i in enumerate(nns):\n",
    "      #image files\n",
    "      img_path = str(path_dict[file_index_to_file_name[i]+'.jpg'])\n",
    "      img_file = Image.open(img_path)\n",
    "      img_files[count] = get_encoded_img(img_file)\n",
    "      #image captions\n",
    "      item_id = file_index_to_product_id[i]\n",
    "      img_caption = '\\n'.join([str(j) for j in list(meta_data.loc[item_id].values[-5:])])\n",
    "      img_captions[count] = img_caption\n",
    "    print(\"---Output--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    return jsonify(img_files)\n",
    "\n",
    "app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0ktfvwxlWQt",
    "outputId": "3faa21d0-362e-4936-cc9c-a8fb33d44a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: appending output to 'nohup.out'\n"
     ]
    }
   ],
   "source": [
    "!nohup python3 -u flask_app.py &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k63_TOdX3_jU"
   },
   "source": [
    "#### client-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DX7NLTjUIx-4"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "!wget -O 'img.jpg' -q 'https://images-na.ssl-images-amazon.com/images/I/61utX8kBDlL._UL1100_.jpg'\n",
    "\n",
    "url = 'http://localhost:5000/fashion'\n",
    "my_img = {'image': open('img.jpg', 'rb')}\n",
    "r = requests.post(url, files=my_img)\n",
    "\n",
    "imgs = []\n",
    "for i in range(6):\n",
    "  img = base64.decodebytes(r.json()[str(i)].encode('ascii'))\n",
    "  img = Image.open(BytesIO(img)).convert('RGBA')\n",
    "  imgs.append(img)\n",
    "\n",
    "imgs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dasr882iulPo"
   },
   "source": [
    "## Step 7: Deployment on AWS Elastic BeanStalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlGzPLof6AQ5"
   },
   "source": [
    "The API was deployed on AWS cloud infrastructure using AWS Elastic Beanstalk service."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4](https://user-images.githubusercontent.com/62965911/224650786-5b352f7d-f898-468e-8079-b2b2e1a6f6b6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-flZYOU3UHC"
   },
   "source": [
    "### application.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQFwCf4Du_w6"
   },
   "outputs": [],
   "source": [
    "#collapse\n",
    "%%writefile ./ebsapp/application.py\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from shutil import move\n",
    "from pandas import read_csv\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from annoy import AnnoyIndex\n",
    "from scipy import spatial\n",
    "import pickle\n",
    "import time\n",
    "from PIL import Image\n",
    "import tarfile\n",
    "import io\n",
    "import base64\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask import redirect, url_for, flash, render_template\n",
    "\n",
    "# path = Path(__file__)\n",
    "# _PPATH = str(path.parents[1])+'/'\n",
    "_PPATH = os.path.join(os.getcwd(), 'mytemp')\n",
    "\n",
    "def load_img(path):\n",
    "  img = tf.io.read_file(path)\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  img = tf.image.resize_with_pad(img, 224, 224)\n",
    "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "  return img\n",
    "\n",
    "module_handle = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "module = hub.load(module_handle)\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "topK = 5\n",
    "threshold = 0.3\n",
    "UPLOAD_FOLDER = _PPATH\n",
    "ALLOWED_EXTENSIONS = set(['zip'])\n",
    "\n",
    "application = Flask(__name__)\n",
    "           \n",
    "@application.route('/')\n",
    "def hello_world():\n",
    "    return \"Hello world!\"\n",
    "\n",
    "@application.route('/original_images', methods=['POST'])\n",
    "def upload_zip1():\n",
    "  os.makedirs(_PPATH, exist_ok=True)\n",
    "  shutil.rmtree(_PPATH)\n",
    "  os.makedirs(_PPATH, exist_ok=True)\n",
    "  os.chdir(_PPATH)\n",
    "  file = request.files['file']\n",
    "  if file and allowed_file(file.filename):\n",
    "      file.save(os.path.join(UPLOAD_FOLDER, 'zip1.zip'))\n",
    "\n",
    "  zip1_path = os.path.join(_PPATH, 'zip1.zip')\n",
    "  zip1_ipath = os.path.join(_PPATH, 'zip1')\n",
    "  os.makedirs(zip1_ipath, exist_ok=True)\n",
    "  with zipfile.ZipFile(zip1_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.path.join(_PPATH, 'zip1'))\n",
    "\n",
    "  img_paths = []\n",
    "  for path in Path(zip1_ipath).rglob('*.jpg'):\n",
    "    img_paths.append(path)\n",
    "\n",
    "  imgvec_path = os.path.join(_PPATH, 'vecs1')\n",
    "  Path(imgvec_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  for filename in tqdm(img_paths):\n",
    "    outfile_name = os.path.basename(filename).split('.')[0] + \".npz\"\n",
    "    out_path_file = os.path.join(imgvec_path, outfile_name)\n",
    "    if not os.path.exists(out_path_file):\n",
    "      img = load_img(str(filename))\n",
    "      features = module(img)\n",
    "      feature_set = np.squeeze(features)\n",
    "      print(features.shape)\n",
    "      np.savetxt(out_path_file, feature_set, delimiter=',')\n",
    "\n",
    "  # Defining data structures as empty dict\n",
    "  file_index_to_file_name = {}\n",
    "  file_index_to_file_vector = {}\n",
    "\n",
    "  # Configuring annoy parameters\n",
    "  dims = 2048\n",
    "  n_nearest_neighbors = 20\n",
    "  trees = 10000\n",
    "\n",
    "  # Reads all file names which stores feature vectors \n",
    "  allfiles = glob.glob(os.path.join(_PPATH, 'vecs1', '*.npz'))\n",
    "\n",
    "  t = AnnoyIndex(dims, metric='angular')\n",
    "\n",
    "  for findex, fname in tqdm(enumerate(allfiles)):\n",
    "    file_vector = np.loadtxt(fname)\n",
    "    file_name = os.path.basename(fname).split('.')[0]\n",
    "    file_index_to_file_name[findex] = file_name\n",
    "    file_index_to_file_vector[findex] = file_vector\n",
    "    t.add_item(findex, file_vector)\n",
    "\n",
    "  t.build(trees)\n",
    "\n",
    "  file_path = os.path.join(_PPATH,'models/indices/')\n",
    "  Path(file_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  t.save(file_path+'indexer.ann')\n",
    "  pickle.dump(file_index_to_file_name, open(file_path+\"file_index_to_file_name.p\", \"wb\"))\n",
    "  pickle.dump(file_index_to_file_vector, open(file_path+\"file_index_to_file_vector.p\", \"wb\"))\n",
    "\n",
    "  return 'File processed on the server status OK!'\n",
    "\n",
    "@application.route('/test_images', methods=['POST'])\n",
    "def upload_zip2():\n",
    "  os.chdir(_PPATH)\n",
    "  file = request.files['file']\n",
    "  if file and allowed_file(file.filename):\n",
    "      file.save(os.path.join(UPLOAD_FOLDER, 'zip2.zip'))\n",
    "\n",
    "  zip2_path = os.path.join(_PPATH, 'zip2.zip')\n",
    "  zip2_ipath = os.path.join(_PPATH, 'zip2')\n",
    "  os.makedirs(zip2_ipath, exist_ok=True)\n",
    "  with zipfile.ZipFile(zip2_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.path.join(_PPATH, 'zip2'))\n",
    "\n",
    "  query_files = []\n",
    "  for path in Path(zip2_ipath).rglob('*.jpg'):\n",
    "    query_files.append(path)\n",
    "  \n",
    "  dims = 2048\n",
    "  indexer = AnnoyIndex(dims, 'angular')\n",
    "  indexer.load(os.path.join(_PPATH,'models/indices/indexer.ann'))\n",
    "  file_index_to_file_name = pickle.load(open(os.path.join(_PPATH,'models/indices/file_index_to_file_name.p'), 'rb'))\n",
    "\n",
    "  results = pd.DataFrame(columns=['qid','fname','dist'])\n",
    "\n",
    "  for q in query_files:\n",
    "    temp_vec = np.squeeze(module(load_img(str(q))))\n",
    "    nns = indexer.get_nns_by_vector(temp_vec, n=topK, include_distances=True)\n",
    "    col1 = [q.stem]*topK\n",
    "    col2 = [file_index_to_file_name[x] for x in nns[0]]\n",
    "    col3 = nns[1]\n",
    "    results = results.append(pd.DataFrame({'qid':col1,'fname':col2,'dist':col3}))\n",
    "    results = results[results.dist<=threshold]\n",
    "  \n",
    "  results = results.reset_index(drop=True).T.to_json()\n",
    "  return results\n",
    "  \n",
    " # run the app.\n",
    "if __name__ == \"__main__\":\n",
    "    # Setting debug to True enables debug output. This line should be\n",
    "    # removed before deploying a production app.\n",
    "    application.debug = True\n",
    "    application.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckTHq6dl3bp0"
   },
   "source": [
    "### requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHjFGVqDu_ut"
   },
   "outputs": [],
   "source": [
    "#collapse\n",
    "%%writefile ./ebsapp/requirements.txt\n",
    "annoy==1.16.3\n",
    "Pillow==2.2.2\n",
    "click==7.1.2\n",
    "Flask==1.1.2\n",
    "itsdangerous==1.1.0\n",
    "Jinja2==2.11.2\n",
    "MarkupSafe==1.1.1\n",
    "Werkzeug==1.0.1\n",
    "numpy==1.18.5\n",
    "pandas==1.0.5\n",
    "pathlib==1.0.1\n",
    "pip-tools==4.5.1\n",
    "requests==2.23.0\n",
    "scipy==1.4.1\n",
    "tensorflow==2.0.0b1\n",
    "tensorflow-hub==0.8.0\n",
    "tqdm==4.41.1\n",
    "urllib3==1.24.3\n",
    "zipfile36==0.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQ2y7D2L3d6h"
   },
   "source": [
    "### packages.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kc9FLbpVvj4S"
   },
   "outputs": [],
   "source": [
    "#collapse\n",
    "%%writefile ./ebsapp/.ebextensions/01_packages.config\n",
    "packages:\n",
    "  yum:\n",
    "    gcc-c++: []\n",
    "    unixODBC-devel: []\n",
    "files:\n",
    "  \"/etc/httpd/conf.d/wsgi_custom.conf\":\n",
    "    mode: \"000644\"\n",
    "    owner: root\n",
    "    group: root\n",
    "    content: |\n",
    "      WSGIApplicationGroup %{GLOBAL}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0y_hOmR3pPq"
   },
   "source": [
    "### extras\n",
    "some handy EBS commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJRxjqlwtIu_"
   },
   "outputs": [],
   "source": [
    "#collapse\n",
    "# !pip install aws.sam.cli\n",
    "# !sam init\n",
    "\n",
    "# %cd my-app\n",
    "\n",
    "# !git config --global user.email \"<email>\"\n",
    "# !git config --global user.name  \"sparsh-ai\"\n",
    "# !git init\n",
    "# !git status\n",
    "# !git add .\n",
    "# !git commit -m 'commit'\n",
    "\n",
    "# !pip install awscli\n",
    "# !aws configure\n",
    "\n",
    "# !sam build && sam deploy\n",
    "# !pip install flask-lambda-python36\n",
    "\n",
    "# !aws ec2 create-key-pair --key-name MyKeyPair --query 'KeyMaterial' --output text > MyKeyPair.pem\n",
    "# !chmod 400 MyKeyPair.pem\n",
    "# !aws ec2 describe-instances --filters \"Name=instance-type,Values=t2.micro\" --query \"Reservations[].Instances[].InstanceId\"\n",
    "# !ssh -i MyKeyPair.pem ec2-user@ec2-50-xx-xx-xxx.compute-1.amazonaws.com\n",
    "\n",
    "# !git clone https://github.com/aws/aws-elastic-beanstalk-cli-setup.git\n",
    "# build-essential zlib1g-dev libssl-dev libncurses-dev libffi-dev libsqlite3-dev libreadline-dev libbz2-dev\n",
    "\n",
    "# !pip install awscli\n",
    "# !pip install awsebcli\n",
    "# !aws configure\n",
    "\n",
    "# !mkdir eb-flask\n",
    "# %cd eb-flask\n",
    "\n",
    "# python --version\n",
    "# pip install awsebcli --upgrade --user\n",
    "# eb --version\n",
    "# mkdir eb-flask\n",
    "# cd eb-flask\n",
    "# pip install virtualenv\n",
    "# virtualenv virt\n",
    "# source virt/bin/activate\n",
    "# pip install flask\n",
    "# pip freeze\n",
    "# pip freeze > requirements.txt\n",
    "# python application.py\n",
    "# eb init -p python-3.6 my-app --region us-east-1\n",
    "# pip install zip-files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5](https://user-images.githubusercontent.com/62965911/224650791-0cf1b599-5291-43ca-882e-df9c30c4e6a7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wy8NfNTA6JwS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "2021-04-27-image-similarity-recommendations.ipynb",
   "provenance": [
    {
     "file_id": "https://gist.github.com/sparsh-ai/46f91c6fe9f608e75d0b60f9d56d9395#file-reco-medium-imgsim-ipynb",
     "timestamp": 1619503835636
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
