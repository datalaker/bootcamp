# Lab: Connect AWS to PySpark and build an ETL pipeline

```
├── [9.9K]  assets
│   ├── [8.2K]  lab-databricks-pyspark-s3.dbc
│   └── [1.6K]  lab-databricks-pyspark-s3.py
├── [ 24K]  img
│   └── [ 24K]  process-flow.drawio.svg
├── [  57]  index.md
├── [6.5K]  main.ipynb
└── [ 17K]  parquet-s3.ipynb

  57K used in 2 directories, 6 files
```

[![Github](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/sparsh-ai/recohut/tree/main/docs/03-processing/databricks/lab-databricks-pyspark-s3)