{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Zookeeper and Kafka Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run in 2 seperate terminals and keep terminals open.\n",
    "# zookeeper-server-start.sh ~/kafka_2.12-3.2.0/config/zookeeper.properties\n",
    "# kafka-server-start.sh ~/kafka_2.12-3.2.0/config/server.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers=\"localhost:9092\"\n",
    "topic_name=\"kafka-localhost-python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    " bootstrap_servers=bootstrap_servers,\n",
    " value_serializer=lambda v: json.dumps(v).encode('ascii'),\n",
    " key_serializer=lambda v: json.dumps(v).encode('ascii')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Producer is created, we can produce a couple events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(\n",
    " topic_name,\n",
    " key={\"id\":1},\n",
    " value={\"name\":\"üë® Francesco\", \"pizza\":\"Margherita üçï\"}\n",
    ")\n",
    "\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(\n",
    " topic_name,\n",
    " key={\"id\":2},\n",
    " value={\"name\":\"üë© Adele\", \"pizza\":\"Hawaii üçï+üçç+ü•ì\"}\n",
    ")\n",
    "\n",
    "producer.send(\n",
    " topic_name,\n",
    " key={\"id\":3},\n",
    " value={\"name\":\"üë¶ Mark\", \"pizza\":\"Choccolate üçï+üç´\"}\n",
    ")\n",
    "\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(\n",
    " topic_name,\n",
    " key={\"id\":4},\n",
    " value={\"name\":\"üë® Dan\", \"pizza\":\"Fries üçï+üçü\"}\n",
    ")\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers=\"localhost:9092\"\n",
    "topic_name=\"kafka-localhost-python\"\n",
    "group_id = \"my_pizza_group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    " bootstrap_servers = bootstrap_servers,\n",
    " group_id = group_id,\n",
    " auto_offset_reset='smallest',\n",
    " value_deserializer = lambda v: json.loads(v.decode('ascii')),\n",
    " key_deserializer = lambda v: json.loads(v.decode('ascii')),\n",
    " max_poll_records = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first-topic', 'kafka-localhost-python', 'second-topic'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer.topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.subscribe(topics=[topic_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kafka-localhost-python'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer.subscription()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in consumer:\n",
    "    print (\"%d:%d: k=%s v=%s\" % (message.partition,\n",
    "                                 message.offset,\n",
    "                                 message.key,\n",
    "                                 message.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "from kafka import KafkaConsumer\n",
    "from kafka import TopicPartition\n",
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers=\"localhost:9092\"\n",
    "topic_name=\"kafka-localhost-python\"\n",
    "group_id = \"my_pizza_group\"\n",
    "topic_name_partitioned = topic_name +\"-partitioned\"\n",
    "timeout_ms=\"5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    " bootstrap_servers=bootstrap_servers,\n",
    " value_serializer=lambda v: json.dumps(v).encode('ascii'),\n",
    " key_serializer=lambda v: json.dumps(v).encode('ascii')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a topic with two partitions, check num_partitions=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreateTopicsResponse_v3(throttle_time_ms=0, topic_errors=[(topic='kafka-localhost-python-partitioned', error_code=0, error_message=None)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin = KafkaAdminClient(\n",
    "        client_id ='admin',\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "    )\n",
    "\n",
    "topic=NewTopic(name=topic_name_partitioned, num_partitions=2, replication_factor=1)\n",
    "\n",
    "admin.create_topics([topic], timeout_ms=int(timeout_ms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now push data to the two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(topic_name_partitioned,\n",
    "              key={\"id\":1},\n",
    "              value={\"name\":\"üë® Frank\", \"pizza\":\"Margherita üçï\"},\n",
    "              partition=0\n",
    "             )\n",
    "producer.send(topic_name_partitioned,\n",
    "              key={\"id\":2},\n",
    "              value={\"name\":\"üë© Adele\", \"pizza\":\"Hawaii üçï+üçç+ü•ì\"},\n",
    "              partition=1\n",
    "             )\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(topic_name_partitioned,\n",
    "              key={\"id\":1},\n",
    "              value={\"name\":\"üôé Mark\", \"pizza\":\"Banana üçï+üçå\"},\n",
    "              partition=0\n",
    "             )\n",
    "producer.send(topic_name_partitioned,\n",
    "              key={\"id\":2},\n",
    "              value={\"name\":\"üë® Jan\", \"pizza\":\"Mushrooms üçï+üçÑ\"},\n",
    "              partition=1\n",
    "             )\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from partition 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_partition_0 = KafkaConsumer(\n",
    "        group_id=group_id+\"-partitioned\",\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_deserializer = lambda v: json.loads(v.decode('ascii')),\n",
    "        key_deserializer = lambda v: json.loads(v.decode('ascii')),\n",
    "        auto_offset_reset='earliest',\n",
    "        max_poll_records = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=0 o=0 value={'name': 'üë® Frank', 'pizza': 'Margherita üçï'}\n",
      "p=0 o=1 value={'name': 'üôé Mark', 'pizza': 'Banana üçï+üçå'}\n"
     ]
    }
   ],
   "source": [
    "tp = TopicPartition(topic_name_partitioned, 0)\n",
    "\n",
    "#register to the topic\n",
    "consumer_partition_0.assign([tp])\n",
    "\n",
    "consumer_partition_0.seek_to_beginning(tp) \n",
    "\n",
    "# obtain the last offset value\n",
    "lastOffset = consumer_partition_0.end_offsets([tp])[tp]\n",
    "\n",
    "for message in consumer_partition_0:\n",
    "    print (\"p=%d o=%d value=%s\" % (message.partition,\n",
    "                                   message.offset,\n",
    "                                   message.value))\n",
    "    if message.offset == lastOffset - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from partition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_partition_1 = KafkaConsumer(\n",
    "        group_id=group_id+\"-partitioned\",\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_deserializer = lambda v: json.loads(v.decode('ascii')),\n",
    "        key_deserializer = lambda v: json.loads(v.decode('ascii')),\n",
    "        auto_offset_reset='earliest',\n",
    "        max_poll_records = 10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "p=1 o=0 value={'name': 'üë© Adele', 'pizza': 'Hawaii üçï+üçç+ü•ì'}\n",
      "2\n",
      "p=1 o=1 value={'name': 'üë® Jan', 'pizza': 'Mushrooms üçï+üçÑ'}\n"
     ]
    }
   ],
   "source": [
    "tp = TopicPartition(topic_name_partitioned, 1)\n",
    "\n",
    "#register to the topic\n",
    "consumer_partition_1.assign([tp])\n",
    "\n",
    "consumer_partition_1.seek_to_beginning(tp) \n",
    "\n",
    "# obtain the last offset value\n",
    "lastOffset = consumer_partition_1.end_offsets([tp])[tp]\n",
    "\n",
    "for message in consumer_partition_1:\n",
    "    print(lastOffset)\n",
    "    print (\"p=%d o=%d value=%s\" % (message.partition,\n",
    "                                   message.offset,\n",
    "                                   message.value))\n",
    "    if message.offset == lastOffset - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Consumer Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW group_id #########\n",
    "group_id='my_NEW_pizza_group'\n",
    "bootstrap_servers=\"localhost:9092\"\n",
    "topic_name=\"kafka-localhost-python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_new_group = KafkaConsumer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        value_deserializer = lambda v: json.loads(v.decode('ascii')),\n",
    "        key_deserializer = lambda v: json.loads(v.decode('ascii')),\n",
    "        auto_offset_reset='earliest',\n",
    "        max_poll_records = 10,\n",
    "        consumer_timeout_ms=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kafka-localhost-python'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_new_group.subscribe(topics=[topic_name])\n",
    "consumer_new_group.subscription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0: key={'id': 1} value={'name': 'üë® Francesco', 'pizza': 'Margherita üçï'}\n",
      "0:1: key={'id': 2} value={'name': 'üë© Adele', 'pizza': 'Hawaii üçï+üçç+ü•ì'}\n",
      "0:2: key={'id': 3} value={'name': 'üë¶ Mark', 'pizza': 'Choccolate üçï+üç´'}\n",
      "0:3: key={'id': 4} value={'name': 'üë® Dan', 'pizza': 'Fries üçï+üçü'}\n"
     ]
    }
   ],
   "source": [
    "for message in consumer_new_group:\n",
    "    print (\"%d:%d: key=%s value=%s\" % (message.partition,\n",
    "                                       message.offset,\n",
    "                                       message.key,\n",
    "                                       message.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env-spacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343191058819caea96d5cde1bd3b1a75b4807623ce2cda0e1c8499e39ac847e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
