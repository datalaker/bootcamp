{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "FQtJGRjXxnog"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD9e7UCyv2na"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install \"ray[rllib, serve, tune]==2.2.0\"\n",
        "! pip install \"pyarrow==10.0.0\"\n",
        "! pip install \"tensorflow>=2.9.0\"\n",
        "! pip install \"transformers>=4.24.0\"\n",
        "! pip install \"pygame==2.1.2\" \"gym==0.25.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "ray.init()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "wS4FtvmuwCI0",
        "outputId": "7df7a5b1-08c0-414a-f6c4-4c562eaf3b82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-18 08:06:40,198\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.9.16', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '172.28.0.12', 'raylet_ip_address': '172.28.0.12', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2023-03-18_08-06-38_406744_143/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2023-03-18_08-06-38_406744_143/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2023-03-18_08-06-38_406744_143', 'metrics_export_port': 60779, 'gcs_address': '172.28.0.12:65344', 'address': '172.28.0.12:65344', 'dashboard_agent_listen_port': 52365, 'node_id': '27974db376b5f037d5ecee86766164767031248463d83c0df94c00c5'})"
            ],
            "text/html": [
              "<div>\n",
              "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
              "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
              "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
              "            <g id=\"layer-1\">\n",
              "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
              "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
              "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
              "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
              "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
              "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
              "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
              "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
              "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
              "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
              "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
              "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
              "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
              "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
              "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
              "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
              "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
              "            </g>\n",
              "        </svg>\n",
              "        <table>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
              "                <td style=\"text-align: left\"><b>3.9.16</b></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
              "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
              "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
              "</tr>\n",
              "\n",
              "        </table>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing with Ray Datasets"
      ],
      "metadata": {
        "id": "HiGe5Ap8xmzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following simple example creates a distributed `Dataset` on your local Ray Cluster from a Python data structure. Specifically, you’ll create a dataset from a Python dictionary containing a string `name` and an integer-valued `data` for 10,000 entries:"
      ],
      "metadata": {
        "id": "Mq7fZnbux0TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "items = [{\"name\": str(i), \"data\": i} for i in range(10000)]\n",
        "ds = ray.data.from_items(items)\n",
        "ds.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9QX6I8wYyv",
        "outputId": "7d3dde00-a408-42d2-f3b3-9944ee12ddcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': '0', 'data': 0}\n",
            "{'name': '1', 'data': 1}\n",
            "{'name': '2', 'data': 2}\n",
            "{'name': '3', 'data': 3}\n",
            "{'name': '4', 'data': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now you have some rows, but what can you do with that data? The `Dataset` API bets heavily on functional programming, as this paradigm is well suited for data transformations.\n",
        "\n",
        "Even though Python 3 made a point of hiding some of its functional programming capabilities, you’re probably familiar with functionality such as `map`, `filter`, `flat_map`, and others. If not, it’s easy enough to pick up: `map` takes each element of your dataset and transforms it into something else, in parallel; `filter` removes data points according to a Boolean filter function; and the slightly more elaborate `flat_map` first maps values similarly to `map`, but then it also “flattens” the result. For instance, if `map` produced a list of lists, `flat_map` would flatten out the nested lists and give you just a list. Equipped with these three functional API calls, let’s see how easily you can transform your dataset `ds`:"
      ],
      "metadata": {
        "id": "CYC7ISHBysIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We map each row of ds to only keep the square value of its data entry.\n",
        "squares = ds.map(lambda x: x[\"data\"] ** 2)\n",
        "\n",
        "#Then we filter the squares to keep only even numbers (a total of five thousand elements).\n",
        "evens = squares.filter(lambda x: x % 2 == 0)\n",
        "evens.count()\n",
        "\n",
        "#We then use flat_map to augment the remaining values with their respective cubes.\n",
        "cubes = evens.flat_map(lambda x: [x, x**3])\n",
        "\n",
        "#To take a total of 10 values means to leave Ray and return a Python list with \n",
        "#these values that we can print.\n",
        "sample = cubes.take(10)\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz_AjO7Qx7WI",
        "outputId": "7dc7539a-194e-47eb-c928-4dc2ae54e5b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-18 08:17:43,549\tWARNING dataset.py:4233 -- The `map`, `flat_map`, and `filter` operations are unvectorized and can be very slow. Consider using `.map_batches()` instead.\n",
            "Map: 100%|██████████| 200/200 [00:02<00:00, 78.04it/s] \n",
            "Filter: 100%|██████████| 200/200 [00:00<00:00, 403.82it/s]\n",
            "Flat_Map: 100%|██████████| 200/200 [00:00<00:00, 329.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 4, 64, 16, 4096, 36, 46656, 64, 262144]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The drawback of `Dataset` transformations is that each step gets executed synchronously. In this example that is a nonissue, but for complex tasks that, for example, mix reading files and processing data, you would want an execution that can overlap individual tasks. `DatasetPipeline` does exactly that. Let’s rewrite the previous example into a pipeline:"
      ],
      "metadata": {
        "id": "YPNhaq04zYtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You can turn a Dataset into a pipeline by calling .window() on it.\n",
        "pipe = ds.window()\n",
        "\n",
        "#Pipeline steps can be chained to yield the same result as before.\n",
        "result = pipe\\\n",
        "    .map(lambda x: x[\"data\"] ** 2)\\\n",
        "    .filter(lambda x: x % 2 == 0)\\\n",
        "    .flat_map(lambda x: [x, x**3])\n",
        "result.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSvfmsGMy7NT",
        "outputId": "1e45da66-f4e7-4639-81f4-8c2436cec4e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-18 08:20:49,252\tINFO dataset.py:3693 -- Created DatasetPipeline with 20 windows: 7390b min, 8000b max, 7944b mean\n",
            "2023-03-18 08:20:49,255\tINFO dataset.py:3703 -- Blocks per window: 10 min, 10 max, 10 mean\n",
            "2023-03-18 08:20:49,262\tINFO dataset.py:3725 -- ✔️  This pipeline's per-window parallelism is high enough to fully utilize the cluster.\n",
            "2023-03-18 08:20:49,266\tINFO dataset.py:3742 -- ✔️  This pipeline's windows likely fit in object store memory without spilling.\n",
            "Stage 0:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Stage 1:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
            "Stage 1:   5%|▌         | 1/20 [00:00<00:03,  5.80it/s]\n",
            "Stage 0:  10%|█         | 2/20 [00:00<00:01, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "4\n",
            "64\n",
            "16\n",
            "4096\n",
            "36\n",
            "46656\n",
            "64\n",
            "262144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "Zn_gPX6K0AX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving on to the next set of libraries, let’s look at the distributed training capabilities of Ray. For that, you have access to two libraries. One is dedicated to reinforcement learning specifically; the other one has a different scope and is aimed primarily at supervised learning tasks."
      ],
      "metadata": {
        "id": "kUPZm7JSz_f0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reinforcement learning with Ray RLlib"
      ],
      "metadata": {
        "id": "XEAxXoYC0DyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s start with _Ray RLlib_ for reinforcement learning (RL). This library is powered by the modern ML frameworks TensorFlow and PyTorch, and you can choose which one to use. Both frameworks seem to converge more and more conceptually, so you can pick the one you like most without losing much in the process."
      ],
      "metadata": {
        "id": "TJyK7NSy0Ccv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the easiest ways to run examples with RLlib is to use the command-line tool `rllib`, which we already installed implicitly when we ran `pip install \"ray[rllib]\"`.\n",
        "\n",
        "We’ll look at a fairly classic control problem of balancing a pole on a cart. Imagine you have a pole like the one in figure below, fixed at a joint of a cart, and subject to gravity. The cart is free to move along a frictionless track, and you can manipulate the cart by giving it a push from the left or the right with a fixed force. If you do this well enough, the pole will remain in an upright position. For each time step the pole didn’t fall over, we get a reward of 1. Collecting a high reward is our goal, and the question is whether we can teach a reinforcement learning algorithm to do this for us."
      ],
      "metadata": {
        "id": "89JWvdci0al7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![2](https://user-images.githubusercontent.com/62965911/226094441-f0ea908f-e6ec-44a1-81e5-24719c7279c6.png)"
      ],
      "metadata": {
        "id": "NpGCHIv60xmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Specifically, we want to train a reinforcement learning agent that can carry out two actions, namely, push to the left or to the right, observe what happens when interacting with the environment in that way, and learn from the experience by maximizing the reward.\n",
        "\n",
        "To tackle this problem with Ray RLlib, we can use a so-called _tuned_ example, which is a preconfigured algorithm that runs well for a given problem. You can run a tuned example with a single command. RLlib comes with many such examples, and you can list them all with `rllib example list`."
      ],
      "metadata": {
        "id": "E-W3RyN71JMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rllib example list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27hHsias2Vlx",
        "outputId": "ccf81543-dd31-4839-dac5-21ae298170a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[3m                                 RLlib Examples                                 \u001b[0m\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mExample ID                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mDescription                               \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36matari-a2c                      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns grid search over several Atari games \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mon A2C.                                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36matari-dqn                      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun grid search on Atari environments with\u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mDQN.                                      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36matari-duel-ddqn                \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun grid search on Atari environments with\u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mduelling double DQN.                      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36matari-impala                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun grid search over several atari games  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mwith IMPALA.                              \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36matari-ppo                      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun grid search over several atari games  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mwith PPO.                                 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36matari-sac                      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun grid search on several atari games    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mwith SAC.                                 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbreakout-apex-dqn              \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns Apex DQN on BreakoutNoFrameskip-v4.  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mbreakout-ddppo                 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns DDPPO on BreakoutNoFrameskip-v4.     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-a2c                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns A2C on the CartPole-v1 environment.  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-a2c-micro             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns A2C on the CartPole-v1 environment,  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35musing micro-batches.                      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-a3c                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns A3C on the CartPole-v1 environment.  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-alpha-zero            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns AlphaZero on a Cartpole with sparse  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mrewards.                                  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-apex-dqn              \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns Apex DQN on CartPole-v1.             \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-appo                  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns APPO on CartPole-v1.                 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-ars                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns ARS on CartPole-v1.                  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-bc                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns BC on CartPole-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-crr                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun CRR on CartPole-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-ddppo                 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns DDPPO on CartPole-v1                 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-dqn                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun DQN on CartPole-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-dt                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun DT on CartPole-v1.                    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-es                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun ES on CartPole-v1.                    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-impala                \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun IMPALA on CartPole-v1.                \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-maml                  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun MAML on CartPole-v1.                  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-marwil                \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun MARWIL on CartPole-v1.                \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-mbmpo                 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun MBMPO on a CartPole environment       \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mwrapper.                                  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-pg                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PG on CartPole-v1                     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-ppo                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on CartPole-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-sac                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun SAC on CartPole-v1                    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mcartpole-simpleq               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun SimpleQ on CartPole-v1                \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mdm-control-dreamer             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun DREAMER on a suite of control problems\u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mby Deepmind.                              \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mfrozenlake-appo                \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns APPO on FrozenLake-v1.               \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhalfcheetah-appo               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns APPO on HalfCheetah-v2.              \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhalfcheetah-bullet-ddpg        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns DDPG on HalfCheetahBulletEnv-v0.     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhalfcheetah-cql                \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns grid search on HalfCheetah           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35menvironments with CQL.                    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhalfcheetah-ddpg               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns DDPG on HalfCheetah-v2.              \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhalfcheetah-maml               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun MAML on a custom HalfCheetah          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35menvironment.                              \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhalfcheetah-mbmpo              \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun MBMPO on a HalfCheetah environment    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mwrapper.                                  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhalfcheetah-ppo                \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on HalfCheetah-v2.                \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhalfcheetah-sac                \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun SAC on HalfCheetah-v3.                \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhopper-bullet-ddpg             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns DDPG on HopperBulletEnv-v0.          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhopper-cql                     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns grid search on Hopper environments   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mwith CQL.                                 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhopper-mbmpo                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun MBMPO on a Hopper environment wrapper.\u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhopper-ppo                     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on Hopper-v1.                     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhumanoid-es                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun ES on Humanoid-v2.                    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mhumanoid-ppo                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on Humanoid-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36minverted-pendulum-td3          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun TD3 on InvertedPendulum-v2.           \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mmountaincar-apex-ddpg          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns Apex DDPG on                         \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mMountainCarContinuous-v0.                 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mmountaincar-ddpg               \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns DDPG on MountainCarContinuous-v0.    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mmujoco-td3                     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun TD3 against four of the hardest MuJoCo\u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mtasks.                                    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mmulti-agent-cartpole-alpha-star\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns AlphaStar on 4 CartPole agents.      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mmulti-agent-cartpole-appo      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns APPO on RLlib's MultiAgentCartPole   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mmulti-agent-cartpole-impala    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun IMPALA on RLlib's MultiAgentCartPole  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpacman-sac                     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun SAC on MsPacmanNoFrameskip-v4.        \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-apex-ddpg             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns Apex DDPG on Pendulum-v1.            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-appo                  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns APPO on Pendulum-v1.                 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-cql                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns CQL on Pendulum-v1.                  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-crr                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun CRR on Pendulum-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-ddpg                  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns DDPG on Pendulum-v1.                 \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-ddppo                 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns DDPPO on Pendulum-v1.                \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-dt                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun DT on Pendulum-v1.                    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-impala                \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun IMPALA on Pendulum-v1.                \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-maml                  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun MAML on a custom Pendulum environment.\u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-mbmpo                 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun MBMPO on a Pendulum environment       \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mwrapper.                                  \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-ppo                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on Pendulum-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-sac                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun SAC on Pendulum-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpendulum-td3                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun TD3 on Pendulum-v1.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpong-a3c                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns A3C on the PongDeterministic-v4      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35menvironment.                              \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpong-apex-dqn                  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns Apex DQN on PongNoFrameskip-v4.      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpong-appo                      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns APPO on PongNoFrameskip-v4.          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpong-dqn                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun DQN on PongDeterministic-v4.          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpong-impala                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun IMPALA on PongNoFrameskip-v4.         \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpong-ppo                       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on PongNoFrameskip-v4.            \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mpong-rainbow                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun Rainbow on PongDeterministic-v4.      \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mrecsys-bandits                 \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns BanditLinUCB on a Recommendation     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSimulation environment.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mrecsys-long-term-slateq        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun SlateQ on a recommendation system     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35maimed at long-term satisfaction.          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mrecsys-parametric-slateq       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSlateQ run on a recommendation system.    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mrecsys-ppo                     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on a recommender system example   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mfrom RLlib.                               \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mrecsys-slateq                  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mSlateQ run on a recommendation system.    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mrepeatafterme-ppo              \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on RLlib's RepeatAfterMe          \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35menvironment.                              \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mstateless-cartpole-r2d2        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun R2D2 on a stateless cart pole         \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35menvironment.                              \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mswimmer-ars                    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRuns ARS on Swimmer-v2.                   \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mtwo-step-game-maddpg           \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun RLlib's Two-step game with multi-agent\u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m                                 \u001b[0m│\u001b[35m \u001b[0m\u001b[35mDDPG.                                     \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mtwo-step-game-qmix             \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun QMIX on RLlib's two-step game.        \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36mwalker2d-ppo                   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35mRun PPO on the Walker2d-v1 environment.   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└─────────────────────────────────┴────────────────────────────────────────────┘\n",
            "Run any RLlib example as using \u001b[32m'rllib example run \u001b[0m\u001b[32m<\u001b[0m\u001b[32mExample\u001b[0m\u001b[32m ID\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m.See \u001b[32m'rllib \u001b[0m\n",
            "\u001b[32mexample run --help'\u001b[0m for more information.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the available examples is `cartpole-ppo`, a tuned example that uses the PPO algorithm to solve the cart–pole problem, specifically, the `CartPole-v1` environment from OpenAI Gym.\n",
        "\n",
        "```yaml\n",
        "cartpole-ppo:\n",
        "    env: CartPole-v1  [1]\n",
        "    run: PPO  [2]\n",
        "    stop:\n",
        "        episode_reward_mean: 150  [3]\n",
        "        timesteps_total: 100000\n",
        "    config: [4]\n",
        "        framework: tf\n",
        "        gamma: 0.99\n",
        "        lr: 0.0003\n",
        "        num_workers: 1\n",
        "        observation_filter: MeanStdFilter\n",
        "        num_sgd_iter: 6\n",
        "        vf_loss_coeff: 0.01\n",
        "        model:\n",
        "            fcnet_hiddens: [32]\n",
        "            fcnet_activation: linear\n",
        "            vf_share_layers: true\n",
        "        enable_connectors: True\n",
        "```\n",
        "\n",
        "1. The `CartPole-v1` environment simulates the problem we just described.\n",
        "2. Use a powerful RL algorithm called Proximal Policy Optimization, or PPO.\n",
        "3. Once we reach a reward of 150, stop the experiment.\n",
        "4. PPO needs some RL-specific configuration to make it work for this problem.\n",
        "\n",
        "The details of this configuration file don’t matter much at this point, so don’t get distracted by them. The important part is that you specify the `Cartpole-v1` environment and sufficient RL-specific configuration to ensure the training procedure works. Running this configuration doesn’t require any special hardware and finishes in a matter of minutes."
      ],
      "metadata": {
        "id": "vt436VCm2TUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rllib example run cartpole-ppo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPX_S8y1zobf",
        "outputId": "c0eafbd3-d06c-4f71-a05d-88a5836c6cbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2023-03-18 08:34:37 (running for 00:03:28.54)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      5 |          168.401 | 20000 |   108.29 |                  500 |                   13 |             108.29 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:34:42 (running for 00:03:33.55)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      5 |          168.401 | 20000 |   108.29 |                  500 |                   13 |             108.29 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:34:47 (running for 00:03:38.55)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      5 |          168.401 | 20000 |   108.29 |                  500 |                   13 |             108.29 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "Result for PPO_CartPole-v1_3bb16_00000:\n",
            "  agent_timesteps_total: 24000\n",
            "  counters:\n",
            "    num_agent_steps_sampled: 24000\n",
            "    num_agent_steps_trained: 24000\n",
            "    num_env_steps_sampled: 24000\n",
            "    num_env_steps_trained: 24000\n",
            "  custom_metrics: {}\n",
            "  date: 2023-03-18_08-34-48\n",
            "  done: false\n",
            "  episode_len_mean: 142.47\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 500.0\n",
            "  episode_reward_mean: 142.47\n",
            "  episode_reward_min: 13.0\n",
            "  episodes_this_iter: 12\n",
            "  episodes_total: 429\n",
            "  experiment_id: db1de6e2783647b49113496fff88c803\n",
            "  hostname: 0738217da70e\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        diff_num_grad_updates_vs_sampler_policy: 95.5\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 0.0003000000142492354\n",
            "          entropy: 0.5886597633361816\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0035236419644206762\n",
            "          policy_loss: -0.002459704177454114\n",
            "          total_loss: 0.09718986600637436\n",
            "          vf_explained_var: 0.0019282136345282197\n",
            "          vf_loss: 9.947339057922363\n",
            "        num_agent_steps_trained: 125.0\n",
            "        num_grad_updates_lifetime: 1056.5\n",
            "    num_agent_steps_sampled: 24000\n",
            "    num_agent_steps_trained: 24000\n",
            "    num_env_steps_sampled: 24000\n",
            "    num_env_steps_trained: 24000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.12\n",
            "  num_agent_steps_sampled: 24000\n",
            "  num_agent_steps_trained: 24000\n",
            "  num_env_steps_sampled: 24000\n",
            "  num_env_steps_sampled_this_iter: 4000\n",
            "  num_env_steps_trained: 24000\n",
            "  num_env_steps_trained_this_iter: 4000\n",
            "  num_faulty_episodes: 0\n",
            "  num_healthy_workers: 1\n",
            "  num_in_flight_async_reqs: 0\n",
            "  num_remote_worker_restarts: 0\n",
            "  num_steps_trained_this_iter: 4000\n",
            "  perf:\n",
            "    cpu_util_percent: 73.82000000000001\n",
            "    ram_util_percent: 23.102222222222224\n",
            "  pid: 7624\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.15060454694754802\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.1447757987134971\n",
            "    mean_inference_ms: 4.981463969697947\n",
            "    mean_raw_obs_processing_ms: 0.9265207062667011\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 142.47\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 500.0\n",
            "    episode_reward_mean: 142.47\n",
            "    episode_reward_min: 13.0\n",
            "    episodes_this_iter: 12\n",
            "    hist_stats:\n",
            "      episode_lengths: [99, 13, 16, 58, 74, 14, 71, 48, 162, 37, 67, 13, 152, 24, 34,\n",
            "        61, 140, 13, 24, 25, 77, 87, 60, 39, 29, 21, 30, 125, 14, 18, 147, 71, 14, 123,\n",
            "        20, 169, 18, 57, 235, 23, 134, 92, 94, 127, 225, 139, 187, 174, 163, 101, 39,\n",
            "        97, 65, 140, 41, 35, 17, 65, 142, 55, 169, 275, 315, 33, 155, 139, 151, 73,\n",
            "        52, 183, 65, 305, 274, 500, 83, 231, 191, 144, 248, 267, 363, 37, 162, 159,\n",
            "        500, 92, 138, 282, 286, 212, 56, 219, 452, 329, 500, 232, 398, 332, 491, 500]\n",
            "      episode_reward: [99.0, 13.0, 16.0, 58.0, 74.0, 14.0, 71.0, 48.0, 162.0, 37.0,\n",
            "        67.0, 13.0, 152.0, 24.0, 34.0, 61.0, 140.0, 13.0, 24.0, 25.0, 77.0, 87.0, 60.0,\n",
            "        39.0, 29.0, 21.0, 30.0, 125.0, 14.0, 18.0, 147.0, 71.0, 14.0, 123.0, 20.0, 169.0,\n",
            "        18.0, 57.0, 235.0, 23.0, 134.0, 92.0, 94.0, 127.0, 225.0, 139.0, 187.0, 174.0,\n",
            "        163.0, 101.0, 39.0, 97.0, 65.0, 140.0, 41.0, 35.0, 17.0, 65.0, 142.0, 55.0,\n",
            "        169.0, 275.0, 315.0, 33.0, 155.0, 139.0, 151.0, 73.0, 52.0, 183.0, 65.0, 305.0,\n",
            "        274.0, 500.0, 83.0, 231.0, 191.0, 144.0, 248.0, 267.0, 363.0, 37.0, 162.0, 159.0,\n",
            "        500.0, 92.0, 138.0, 282.0, 286.0, 212.0, 56.0, 219.0, 452.0, 329.0, 500.0, 232.0,\n",
            "        398.0, 332.0, 491.0, 500.0]\n",
            "    num_faulty_episodes: 0\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.15060454694754802\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.1447757987134971\n",
            "      mean_inference_ms: 4.981463969697947\n",
            "      mean_raw_obs_processing_ms: 0.9265207062667011\n",
            "  time_since_restore: 199.58355569839478\n",
            "  time_this_iter_s: 31.182859659194946\n",
            "  time_total_s: 199.58355569839478\n",
            "  timers:\n",
            "    learn_throughput: 456.437\n",
            "    learn_time_ms: 8763.54\n",
            "    synch_weights_time_ms: 5.189\n",
            "    training_iteration_time_ms: 33240.144\n",
            "  timestamp: 1679128488\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 24000\n",
            "  training_iteration: 6\n",
            "  trial_id: 3bb16_00000\n",
            "  warmup_time: 11.70189356803894\n",
            "  \n",
            "\u001b[2m\u001b[36m(PPO pid=7624)\u001b[0m 2023-03-18 08:34:48,893\tINFO filter_manager.py:34 -- Synchronizing filters ...\n",
            "\u001b[2m\u001b[36m(PPO pid=7624)\u001b[0m 2023-03-18 08:34:48,899\tINFO filter_manager.py:55 -- Updating remote filters ...\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:34:54 (running for 00:03:44.79)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      6 |          199.584 | 24000 |   142.47 |                  500 |                   13 |             142.47 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:34:59 (running for 00:03:49.80)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      6 |          199.584 | 24000 |   142.47 |                  500 |                   13 |             142.47 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:35:04 (running for 00:03:54.80)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      6 |          199.584 | 24000 |   142.47 |                  500 |                   13 |             142.47 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:35:09 (running for 00:03:59.81)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      6 |          199.584 | 24000 |   142.47 |                  500 |                   13 |             142.47 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:35:14 (running for 00:04:04.82)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      6 |          199.584 | 24000 |   142.47 |                  500 |                   13 |             142.47 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:35:19 (running for 00:04:09.82)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 RUNNING)\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | RUNNING  | 172.28.0.12:7624 |      6 |          199.584 | 24000 |   142.47 |                  500 |                   13 |             142.47 |\n",
            "+-----------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "Result for PPO_CartPole-v1_3bb16_00000:\n",
            "  agent_timesteps_total: 28000\n",
            "  counters:\n",
            "    num_agent_steps_sampled: 28000\n",
            "    num_agent_steps_trained: 28000\n",
            "    num_env_steps_sampled: 28000\n",
            "    num_env_steps_trained: 28000\n",
            "  custom_metrics: {}\n",
            "  date: 2023-03-18_08-35-21\n",
            "  done: true\n",
            "  episode_len_mean: 178.85\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 500.0\n",
            "  episode_reward_mean: 178.85\n",
            "  episode_reward_min: 13.0\n",
            "  episodes_this_iter: 9\n",
            "  episodes_total: 438\n",
            "  experiment_id: db1de6e2783647b49113496fff88c803\n",
            "  hostname: 0738217da70e\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        custom_metrics: {}\n",
            "        diff_num_grad_updates_vs_sampler_policy: 95.5\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 0.0003000000142492354\n",
            "          entropy: 0.5833122730255127\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003216453595086932\n",
            "          policy_loss: -0.0005987154436297715\n",
            "          total_loss: 0.09903717041015625\n",
            "          vf_explained_var: -0.0003911629319190979\n",
            "          vf_loss: 9.955548286437988\n",
            "        num_agent_steps_trained: 125.0\n",
            "        num_grad_updates_lifetime: 1248.5\n",
            "    num_agent_steps_sampled: 28000\n",
            "    num_agent_steps_trained: 28000\n",
            "    num_env_steps_sampled: 28000\n",
            "    num_env_steps_trained: 28000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.12\n",
            "  num_agent_steps_sampled: 28000\n",
            "  num_agent_steps_trained: 28000\n",
            "  num_env_steps_sampled: 28000\n",
            "  num_env_steps_sampled_this_iter: 4000\n",
            "  num_env_steps_trained: 28000\n",
            "  num_env_steps_trained_this_iter: 4000\n",
            "  num_faulty_episodes: 0\n",
            "  num_healthy_workers: 1\n",
            "  num_in_flight_async_reqs: 0\n",
            "  num_remote_worker_restarts: 0\n",
            "  num_steps_trained_this_iter: 4000\n",
            "  perf:\n",
            "    cpu_util_percent: 78.09347826086956\n",
            "    ram_util_percent: 23.099999999999998\n",
            "  pid: 7624\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.15010584224508902\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.14444693410492337\n",
            "    mean_inference_ms: 4.976027958863329\n",
            "    mean_raw_obs_processing_ms: 0.9240927234928833\n",
            "  sampler_results:\n",
            "    custom_metrics: {}\n",
            "    episode_len_mean: 178.85\n",
            "    episode_media: {}\n",
            "    episode_reward_max: 500.0\n",
            "    episode_reward_mean: 178.85\n",
            "    episode_reward_min: 13.0\n",
            "    episodes_this_iter: 9\n",
            "    hist_stats:\n",
            "      episode_lengths: [37, 67, 13, 152, 24, 34, 61, 140, 13, 24, 25, 77, 87, 60, 39,\n",
            "        29, 21, 30, 125, 14, 18, 147, 71, 14, 123, 20, 169, 18, 57, 235, 23, 134, 92,\n",
            "        94, 127, 225, 139, 187, 174, 163, 101, 39, 97, 65, 140, 41, 35, 17, 65, 142,\n",
            "        55, 169, 275, 315, 33, 155, 139, 151, 73, 52, 183, 65, 305, 274, 500, 83, 231,\n",
            "        191, 144, 248, 267, 363, 37, 162, 159, 500, 92, 138, 282, 286, 212, 56, 219,\n",
            "        452, 329, 500, 232, 398, 332, 491, 500, 424, 500, 500, 500, 500, 500, 500, 500,\n",
            "        269]\n",
            "      episode_reward: [37.0, 67.0, 13.0, 152.0, 24.0, 34.0, 61.0, 140.0, 13.0, 24.0,\n",
            "        25.0, 77.0, 87.0, 60.0, 39.0, 29.0, 21.0, 30.0, 125.0, 14.0, 18.0, 147.0, 71.0,\n",
            "        14.0, 123.0, 20.0, 169.0, 18.0, 57.0, 235.0, 23.0, 134.0, 92.0, 94.0, 127.0,\n",
            "        225.0, 139.0, 187.0, 174.0, 163.0, 101.0, 39.0, 97.0, 65.0, 140.0, 41.0, 35.0,\n",
            "        17.0, 65.0, 142.0, 55.0, 169.0, 275.0, 315.0, 33.0, 155.0, 139.0, 151.0, 73.0,\n",
            "        52.0, 183.0, 65.0, 305.0, 274.0, 500.0, 83.0, 231.0, 191.0, 144.0, 248.0, 267.0,\n",
            "        363.0, 37.0, 162.0, 159.0, 500.0, 92.0, 138.0, 282.0, 286.0, 212.0, 56.0, 219.0,\n",
            "        452.0, 329.0, 500.0, 232.0, 398.0, 332.0, 491.0, 500.0, 424.0, 500.0, 500.0,\n",
            "        500.0, 500.0, 500.0, 500.0, 500.0, 269.0]\n",
            "    num_faulty_episodes: 0\n",
            "    policy_reward_max: {}\n",
            "    policy_reward_mean: {}\n",
            "    policy_reward_min: {}\n",
            "    sampler_perf:\n",
            "      mean_action_processing_ms: 0.15010584224508902\n",
            "      mean_env_render_ms: 0.0\n",
            "      mean_env_wait_ms: 0.14444693410492337\n",
            "      mean_inference_ms: 4.976027958863329\n",
            "      mean_raw_obs_processing_ms: 0.9240927234928833\n",
            "  time_since_restore: 232.44457721710205\n",
            "  time_this_iter_s: 32.861021518707275\n",
            "  time_total_s: 232.44457721710205\n",
            "  timers:\n",
            "    learn_throughput: 470.055\n",
            "    learn_time_ms: 8509.634\n",
            "    synch_weights_time_ms: 5.025\n",
            "    training_iteration_time_ms: 33183.327\n",
            "  timestamp: 1679128521\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 28000\n",
            "  training_iteration: 7\n",
            "  trial_id: 3bb16_00000\n",
            "  warmup_time: 11.70189356803894\n",
            "  \n",
            "\u001b[2m\u001b[36m(PPO pid=7624)\u001b[0m 2023-03-18 08:35:21,839\tINFO filter_manager.py:34 -- Synchronizing filters ...\n",
            "\u001b[2m\u001b[36m(PPO pid=7624)\u001b[0m 2023-03-18 08:35:21,848\tINFO filter_manager.py:55 -- Updating remote filters ...\n",
            "== Status ==\n",
            "Current time: 2023-03-18 08:35:21 (running for 00:04:12.69)\n",
            "Memory usage on this node: 2.9/12.7 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects\n",
            "Result logdir: /root/ray_results/cartpole-ppo\n",
            "Number of trials: 1/1 (1 TERMINATED)\n",
            "+-----------------------------+------------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "| Trial name                  | status     | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
            "|-----------------------------+------------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
            "| PPO_CartPole-v1_3bb16_00000 | TERMINATED | 172.28.0.12:7624 |      7 |          232.445 | 28000 |   178.85 |                  500 |                   13 |             178.85 |\n",
            "+-----------------------------+------------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
            "\n",
            "\n",
            "2023-03-18 08:35:22,135\tINFO tune.py:762 -- Total run time: 252.92 seconds (252.67 seconds for the tuning loop).\n",
            "\n",
            "Your training finished.\n",
            "Best available checkpoint for each trial:\n",
            "  \u001b[35m/root/ray_results/cartpole-ppo/PPO_CartPole-v1_3bb16_00000_0_2023-03-18_08-31-\u001b[0m\n",
            "\u001b[35m09/\u001b[0m\u001b[95mcheckpoint_000007\u001b[0m\n",
            "\n",
            "You can now evaluate your trained algorithm from any checkpoint, e.g. by \n",
            "running:\n",
            "╭──────────────────────────────────────────────────────────────────────────────╮\n",
            "│ \u001b[32m  rllib evaluate \u001b[0m                                                            │\n",
            "│ \u001b[32m/root/ray_results/cartpole-ppo/PPO_CartPole-v1_3bb16_00000_0_2023-03-18_08-3\u001b[0m │\n",
            "│ \u001b[32m1-09/checkpoint_000007 --algo PPO\u001b[0m                                            │\n",
            "╰──────────────────────────────────────────────────────────────────────────────╯\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your local Ray checkpoint folder is _~/ray-results_ by default. For the training configuration we used, your _<checkpoint-path>_ should be of the form _~/ray\\_results/cartpole-ppo/PPO\\_CartPole-v1\\_\\<experiment\\_id>_. During the training procedure, your intermediate and final model checkpoints get generated into this folder.\n",
        "\n",
        "To evaluate the performance of your trained RL algorithm, you can now evaluate it _from checkpoint_ by copying the command the previous example training run printed.\n",
        "\n",
        "Running this command will print evaluation results, namely, the rewards achieved by your trained RL algorithm on the `CartPole-v1` environment."
      ],
      "metadata": {
        "id": "zHM0oAxH3Gaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rllib evaluate /root/ray_results/cartpole-ppo/PPO_CartPole-v1_3bb16_00000_0_2023-03-18_08-31-09/checkpoint_000007 --algo PPO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftHsQQsl17Pg",
        "outputId": "2b6cbc3a-55d5-42c4-ca35-cd19a4e3feb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-18 08:40:10,744\tINFO algorithm.py:1005 -- Ran round 1 of parallel evaluation (1/1 episodes done)\n",
            "Episode #23: reward: 500.0\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distributed training with Ray Train"
      ],
      "metadata": {
        "id": "QHUgaJrB4dOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ray RLlib is dedicated to reinforcement learning, but what do you do if you need to train models for other types of machine learning, like supervised learning? You can use another Ray library for distributed training in this case: _Ray Train_."
      ],
      "metadata": {
        "id": "w0-iFR-n4bzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning with Ray Tune"
      ],
      "metadata": {
        "id": "4ZiXZqcC5TBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import tune\n",
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "#Simulate an expensive training function that depends on two hyperparameters, x and y, read from a config.\n",
        "def training_function(config):\n",
        "    x, y = config[\"x\"], config[\"y\"]\n",
        "    time.sleep(10)\n",
        "    score = objective(x, y)\n",
        "    #After sleeping for 10 seconds to simulate training and computing the objective, the \n",
        "    #score is reported to tune.\n",
        "    tune.report(score=score)\n",
        "\n",
        "\n",
        "#The objective computes the mean of the squares of x and y and returns the square root \n",
        "#of this term. This type of objective is fairly common in ML.\n",
        "def objective(x, y):\n",
        "    return math.sqrt((x**2 + y**2)/2)\n",
        "\n",
        "\n",
        "#Use tune.run to initialize hyperparameter optimization on our training_function.\n",
        "result = tune.run(\n",
        "    training_function,\n",
        "    config={\n",
        "        #A key part is to provide a parameter space for x and y for tune to search over.\n",
        "        \"x\": tune.grid_search([-1, -.5, 0, .5, 1]),\n",
        "        \"y\": tune.grid_search([-1, -.5, 0, .5, 1])\n",
        "    })\n",
        "\n",
        "print(result.get_best_config(metric=\"score\", mode=\"min\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cROZqGKn3rdO",
        "outputId": "a7d79270-e3af-4476-da88-18eea615dd48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2023-03-18 08:52:36</td></tr>\n",
              "<tr><td>Running for: </td><td>00:02:15.24        </td></tr>\n",
              "<tr><td>Memory:      </td><td>1.5/12.7 GiB       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/3.69 GiB objects\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name                   </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">   x</th><th style=\"text-align: right;\">   y</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   score</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>training_function_e994b_00000</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.193 </td><td style=\"text-align: right;\">1       </td></tr>\n",
              "<tr><td>training_function_e994b_00001</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.05  </td><td style=\"text-align: right;\">0.790569</td></tr>\n",
              "<tr><td>training_function_e994b_00002</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0499</td><td style=\"text-align: right;\">0.707107</td></tr>\n",
              "<tr><td>training_function_e994b_00003</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0483</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
              "<tr><td>training_function_e994b_00004</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0472</td><td style=\"text-align: right;\">1       </td></tr>\n",
              "<tr><td>training_function_e994b_00005</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0501</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
              "<tr><td>training_function_e994b_00006</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0503</td><td style=\"text-align: right;\">0.5     </td></tr>\n",
              "<tr><td>training_function_e994b_00007</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0493</td><td style=\"text-align: right;\">0.353553</td></tr>\n",
              "<tr><td>training_function_e994b_00008</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0502</td><td style=\"text-align: right;\">0.5     </td></tr>\n",
              "<tr><td>training_function_e994b_00009</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0474</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
              "<tr><td>training_function_e994b_00010</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0501</td><td style=\"text-align: right;\">0.707107</td></tr>\n",
              "<tr><td>training_function_e994b_00011</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0506</td><td style=\"text-align: right;\">0.353553</td></tr>\n",
              "<tr><td>training_function_e994b_00012</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0502</td><td style=\"text-align: right;\">0       </td></tr>\n",
              "<tr><td>training_function_e994b_00013</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0485</td><td style=\"text-align: right;\">0.353553</td></tr>\n",
              "<tr><td>training_function_e994b_00014</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0495</td><td style=\"text-align: right;\">0.707107</td></tr>\n",
              "<tr><td>training_function_e994b_00015</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0494</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
              "<tr><td>training_function_e994b_00016</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0458</td><td style=\"text-align: right;\">0.5     </td></tr>\n",
              "<tr><td>training_function_e994b_00017</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0489</td><td style=\"text-align: right;\">0.353553</td></tr>\n",
              "<tr><td>training_function_e994b_00018</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0503</td><td style=\"text-align: right;\">0.5     </td></tr>\n",
              "<tr><td>training_function_e994b_00019</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0503</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
              "<tr><td>training_function_e994b_00020</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0499</td><td style=\"text-align: right;\">1       </td></tr>\n",
              "<tr><td>training_function_e994b_00021</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0504</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
              "<tr><td>training_function_e994b_00022</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0494</td><td style=\"text-align: right;\">0.707107</td></tr>\n",
              "<tr><td>training_function_e994b_00023</td><td>TERMINATED</td><td>172.28.0.12:13186</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0468</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
              "<tr><td>training_function_e994b_00024</td><td>TERMINATED</td><td>172.28.0.12:13138</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.05  </td><td style=\"text-align: right;\">1       </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name                   </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag       </th><th>hostname    </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip    </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">   score</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>training_function_e994b_00000</td><td>2023-03-18_08-50-35</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>0_x=-1,y=-1          </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">             10.193 </td><td style=\"text-align: right;\">           10.193 </td><td style=\"text-align: right;\">       10.193 </td><td style=\"text-align: right;\"> 1679129435</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00000</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00001</td><td>2023-03-18_08-50-38</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>1_x=-0.5000,y=-1     </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.05  </td><td style=\"text-align: right;\">           10.05  </td><td style=\"text-align: right;\">       10.05  </td><td style=\"text-align: right;\"> 1679129438</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00001</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00002</td><td>2023-03-18_08-50-45</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>2_x=0,y=-1           </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0.707107</td><td style=\"text-align: right;\">             10.0499</td><td style=\"text-align: right;\">           10.0499</td><td style=\"text-align: right;\">       10.0499</td><td style=\"text-align: right;\"> 1679129445</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00002</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00003</td><td>2023-03-18_08-50-48</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>3_x=0.5000,y=-1      </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0483</td><td style=\"text-align: right;\">           10.0483</td><td style=\"text-align: right;\">       10.0483</td><td style=\"text-align: right;\"> 1679129448</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00003</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00004</td><td>2023-03-18_08-50-55</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>4_x=1,y=-1           </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">             10.0472</td><td style=\"text-align: right;\">           10.0472</td><td style=\"text-align: right;\">       10.0472</td><td style=\"text-align: right;\"> 1679129455</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00004</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00005</td><td>2023-03-18_08-50-59</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>5_x=-1,y=-0.5000     </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0501</td><td style=\"text-align: right;\">           10.0501</td><td style=\"text-align: right;\">       10.0501</td><td style=\"text-align: right;\"> 1679129459</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00005</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00006</td><td>2023-03-18_08-51-05</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>6_x=-0.5000,y=-0.5000</td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">             10.0503</td><td style=\"text-align: right;\">           10.0503</td><td style=\"text-align: right;\">       10.0503</td><td style=\"text-align: right;\"> 1679129465</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00006</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00007</td><td>2023-03-18_08-51-09</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>7_x=0,y=-0.5000      </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.353553</td><td style=\"text-align: right;\">             10.0493</td><td style=\"text-align: right;\">           10.0493</td><td style=\"text-align: right;\">       10.0493</td><td style=\"text-align: right;\"> 1679129469</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00007</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00008</td><td>2023-03-18_08-51-15</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>8_x=0.5000,y=-0.5000 </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">             10.0502</td><td style=\"text-align: right;\">           10.0502</td><td style=\"text-align: right;\">       10.0502</td><td style=\"text-align: right;\"> 1679129475</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00008</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00009</td><td>2023-03-18_08-51-19</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>9_x=1,y=-0.5000      </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0474</td><td style=\"text-align: right;\">           10.0474</td><td style=\"text-align: right;\">       10.0474</td><td style=\"text-align: right;\"> 1679129479</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00009</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00010</td><td>2023-03-18_08-51-25</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>10_x=-1,y=0          </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0.707107</td><td style=\"text-align: right;\">             10.0501</td><td style=\"text-align: right;\">           10.0501</td><td style=\"text-align: right;\">       10.0501</td><td style=\"text-align: right;\"> 1679129485</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00010</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00011</td><td>2023-03-18_08-51-29</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>11_x=-0.5000,y=0     </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.353553</td><td style=\"text-align: right;\">             10.0506</td><td style=\"text-align: right;\">           10.0506</td><td style=\"text-align: right;\">       10.0506</td><td style=\"text-align: right;\"> 1679129489</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00011</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00012</td><td>2023-03-18_08-51-35</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>12_x=0,y=0           </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">             10.0502</td><td style=\"text-align: right;\">           10.0502</td><td style=\"text-align: right;\">       10.0502</td><td style=\"text-align: right;\"> 1679129495</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00012</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00013</td><td>2023-03-18_08-51-39</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>13_x=0.5000,y=0      </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.353553</td><td style=\"text-align: right;\">             10.0485</td><td style=\"text-align: right;\">           10.0485</td><td style=\"text-align: right;\">       10.0485</td><td style=\"text-align: right;\"> 1679129499</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00013</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00014</td><td>2023-03-18_08-51-45</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>14_x=1,y=0           </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0.707107</td><td style=\"text-align: right;\">             10.0495</td><td style=\"text-align: right;\">           10.0495</td><td style=\"text-align: right;\">       10.0495</td><td style=\"text-align: right;\"> 1679129505</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00014</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00015</td><td>2023-03-18_08-51-49</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>15_x=-1,y=0.5000     </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0494</td><td style=\"text-align: right;\">           10.0494</td><td style=\"text-align: right;\">       10.0494</td><td style=\"text-align: right;\"> 1679129509</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00015</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00016</td><td>2023-03-18_08-51-56</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>16_x=-0.5000,y=0.5000</td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">             10.0458</td><td style=\"text-align: right;\">           10.0458</td><td style=\"text-align: right;\">       10.0458</td><td style=\"text-align: right;\"> 1679129516</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00016</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00017</td><td>2023-03-18_08-51-59</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>17_x=0,y=0.5000      </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.353553</td><td style=\"text-align: right;\">             10.0489</td><td style=\"text-align: right;\">           10.0489</td><td style=\"text-align: right;\">       10.0489</td><td style=\"text-align: right;\"> 1679129519</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00017</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00018</td><td>2023-03-18_08-52-06</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>18_x=0.5000,y=0.5000 </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">             10.0503</td><td style=\"text-align: right;\">           10.0503</td><td style=\"text-align: right;\">       10.0503</td><td style=\"text-align: right;\"> 1679129526</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00018</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00019</td><td>2023-03-18_08-52-09</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>19_x=1,y=0.5000      </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0503</td><td style=\"text-align: right;\">           10.0503</td><td style=\"text-align: right;\">       10.0503</td><td style=\"text-align: right;\"> 1679129529</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00019</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00020</td><td>2023-03-18_08-52-16</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>20_x=-1,y=1          </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">             10.0499</td><td style=\"text-align: right;\">           10.0499</td><td style=\"text-align: right;\">       10.0499</td><td style=\"text-align: right;\"> 1679129536</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00020</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00021</td><td>2023-03-18_08-52-19</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>21_x=-0.5000,y=1     </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0504</td><td style=\"text-align: right;\">           10.0504</td><td style=\"text-align: right;\">       10.0504</td><td style=\"text-align: right;\"> 1679129539</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00021</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00022</td><td>2023-03-18_08-52-26</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>22_x=0,y=1           </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">0.707107</td><td style=\"text-align: right;\">             10.0494</td><td style=\"text-align: right;\">           10.0494</td><td style=\"text-align: right;\">       10.0494</td><td style=\"text-align: right;\"> 1679129546</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00022</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "<tr><td>training_function_e994b_00023</td><td>2023-03-18_08-52-30</td><td>True  </td><td>                </td><td>96496a0a28f24fc7904fb5b942aa64f1</td><td>23_x=0.5000,y=1      </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13186</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0468</td><td style=\"text-align: right;\">           10.0468</td><td style=\"text-align: right;\">       10.0468</td><td style=\"text-align: right;\"> 1679129550</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00023</td><td style=\"text-align: right;\">   0.00650549</td></tr>\n",
              "<tr><td>training_function_e994b_00024</td><td>2023-03-18_08-52-36</td><td>True  </td><td>                </td><td>a2865e213e9242f5a4c2741709618e0a</td><td>24_x=1,y=1           </td><td>0738217da70e</td><td style=\"text-align: right;\">                         1</td><td>172.28.0.12</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">             10.05  </td><td style=\"text-align: right;\">           10.05  </td><td style=\"text-align: right;\">       10.05  </td><td style=\"text-align: right;\"> 1679129556</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>e994b_00024</td><td style=\"text-align: right;\">   0.0200734 </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-18 08:52:36,761\tINFO tune.py:762 -- Total run time: 136.82 seconds (135.23 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': 0, 'y': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the output of this run is structurally similar to what you saw in the RLlib example. That’s no coincidence, as RLlib (like many other Ray libraries) uses Ray Tune under the hood. If you look closely, you will see `PENDING` runs that wait for execution, as well as `RUNNING` and `TERMINATED` runs. Tune takes care of selecting, scheduling, and executing your training runs automatically.\n",
        "\n",
        "Specifically, this Tune example finds the best possible choices of parameters `x` and `y` for a `training_function` with a given `objective` we want to minimize. Even though the objective function might look a little intimidating at first, since we compute the sum of squares of `x` and `y`, all values will be non-negative. That means the smallest value is obtained at `x=0` and `y=0`, which evaluates the objective function to `0`.\n",
        "\n",
        "We do a so-called _grid search_ over all possible parameter combinations. As we explicitly pass in 5 possible values for both `x` and `y`, that’s a total of 25 combinations that get fed into the training function. Since we instruct `training_function` to sleep for 10 seconds, testing all combinations of hyperparameters sequentially would take more than 4 minutes total. Since Ray is smart about parallelizing this workload, this whole experiment took only about 35 seconds for us, but it might take much longer, depending on where you run it."
      ],
      "metadata": {
        "id": "1N9UpAHv6W4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Serving with Ray Serve"
      ],
      "metadata": {
        "id": "4zMgEzgA7ght"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last of Ray’s high-level libraries we’ll discuss specializes in model serving and is simply called Ray Serve. To see an example of it in action, you need a trained ML model to serve. Luckily, nowadays, you can find many interesting models on the internet that have already been trained for you. For instance, Hugging Face has a variety of models available for you to download directly in Python. The model we’ll use is a language model called GPT-2 that takes text as input and produces text to continue or complete the input. For example, you can prompt a question and GPT-2 will try to complete it.\n",
        "\n",
        "Serving such a model is a good way to make it accessible. You may not know how to load and run a TensorFlow model on your computer, but you do know how to ask a question in plain English. Model serving hides the implementation details of a solution and lets users focus on providing inputs and understanding outputs of a model.\n",
        "\n",
        "To proceed, make sure to run `pip install transformers` to install the Hugging Face library that has the model we want to use. With that we can now import and start an instance of Ray’s serve library, load and deploy a GPT-2 model, and ask it for the meaning of life, like so:"
      ],
      "metadata": {
        "id": "N1yGFzos70ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ray import serve\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "\n",
        "\n",
        "#Start serve locally.\n",
        "serve.start()\n",
        "\n",
        "\n",
        "#The @serve.deployment decorator turns a function with a request parameter into a serve deployment.\n",
        "@serve.deployment\n",
        "def model(request):\n",
        "    #Loading language_model inside the model function for every request is inefficient, \n",
        "    #but it’s the quickest way to show you a deployment.\n",
        "    language_model = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "    query = request.query_params[\"query\"]\n",
        "    #Ask the model to give us at most 100 characters to continue our query.\n",
        "    return language_model(query, max_length=100)\n",
        "\n",
        "\n",
        "#Formally deploy the model so that it can start receiving requests over HTTP.\n",
        "model.deploy()"
      ],
      "metadata": {
        "id": "C85MLZG474po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What's the meaning of life?\"\n",
        "#Use the indispensable requests library to get a response for any question you might have.\n",
        "response = requests.get(f\"http://localhost:8000/model?query={query}\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoDZNab88d7u",
        "outputId": "f094acc0-4f0d-4e1a-a399-21796e0346ea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"generated_text\": \"What's the meaning of life?\\n\\nThe meaning of life is the idea that \\\"being alive\\\" isn't just a \\\"real life experience\\\". There's a lot of life around you, to be human. Life can seem strange at first and confusing at first, but it's the same when you know it is happening. When you have your life, you can be alive. And you can stay in it.\\n\\nHow are you feeling now?\\n\\nIt feels like I'm at\"}]\n"
          ]
        }
      ]
    }
  ]
}