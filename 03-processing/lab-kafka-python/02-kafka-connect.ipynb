{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kafka connect are prebuilt connectors that can be used to integrate Kafka with other sources or targets (souces or sinks in Kafka terms). Let's create a postgreSQL one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_servers=\"localhost:9092\"\n",
    "topic_name=\"kafka-localhost-python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(\n",
    " bootstrap_servers=bootstrap_servers,\n",
    " value_serializer=lambda v: json.dumps(v).encode('ascii'),\n",
    " key_serializer=lambda v: json.dumps(v).encode('ascii')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new stream, adding the schema to it.\n",
    "\n",
    "Kafka Connect JDBC Sink requires a schema to be attached to the stream defining the its fields in detail. We have two choices:\n",
    "\n",
    "- Attaching the schema to each JSON message\n",
    "- Use schema registry with AVRO format\n",
    "\n",
    "For the sake of this example we'll include the schema definition to the JSON message. Let's define the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_schema = {\n",
    "    \"type\": \"struct\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"type\": \"int32\",\n",
    "            \"optional\": False,\n",
    "            \"field\": \"id\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "value_schema = {\n",
    "    \"type\": \"struct\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"type\": \"string\",\n",
    "            \"optional\": False,\n",
    "            \"field\": \"name\"\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"string\",\n",
    "            \"optional\": False,\n",
    "            \"field\": \"pizza\"}]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And send some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer.send(\n",
    "    topic_name+\"-schema\", \n",
    "    key={\"schema\": key_schema, \"payload\": {\"id\":1}},\n",
    "    value={\"schema\": value_schema, \n",
    "           \"payload\": {\"name\":\"üë® Frank\", \"pizza\":\"Margherita üçï\"}}\n",
    ")\n",
    "\n",
    "producer.send(\n",
    "    topic_name+\"-schema\",\n",
    "    key={\"schema\": key_schema, \"payload\": {\"id\":2}},\n",
    "    value={\"schema\": value_schema, \n",
    "           \"payload\": {\"name\":\"üë® Dan\", \"pizza\":\"Fries üçï+üçü\"}}\n",
    ")\n",
    "\n",
    "producer.send(\n",
    "    topic_name+\"-schema\",\n",
    "    key={\"schema\": key_schema, \"payload\": {\"id\":3}},\n",
    "    value={\"schema\": value_schema,\n",
    "           \"payload\": {\"name\":\"üë® Jan\", \"pizza\":\"Mushrooms üçï+üçÑ\"}}\n",
    ")\n",
    "\n",
    "producer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the Kafka Connect Postgres Connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connect-console-sink.properties   consumer.properties\n",
      "connect-console-source.properties \u001b[34mkraft\u001b[m\u001b[m\n",
      "connect-distributed.properties    log4j.properties\n",
      "connect-file-sink.properties      producer.properties\n",
      "connect-file-source.properties    server.properties\n",
      "connect-log4j.properties          tools-log4j.properties\n",
      "connect-mirror-maker.properties   trogdor.conf\n",
      "connect-standalone.properties     zookeeper.properties\n"
     ]
    }
   ],
   "source": [
    "!ls ~/kafka_2.12-3.2.0/config/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /Users/sparshagarwal/kafka_2.12-3.2.0/config/connect-distributed-local.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/kafka_2.12-3.2.0/config/connect-distributed-local.properties\n",
    "bootstrap.servers=localhost:9092\n",
    "group.id=local-connect-cluster\n",
    "\n",
    "key.converter=org.apache.kafka.connect.json.JsonConverter\n",
    "value.converter=org.apache.kafka.connect.json.JsonConverter\n",
    "key.converter.schemas.enable=true\n",
    "value.converter.schemas.enable=true\n",
    "\n",
    "internal.key.converter=org.apache.kafka.connect.json.JsonConverter\n",
    "internal.value.converter=org.apache.kafka.connect.json.JsonConverter\n",
    "internal.key.converter.schemas.enable=false\n",
    "internal.value.converter.schemas.enable=false\n",
    "\n",
    "offset.storage.topic=connect-local-stg-offsets\n",
    "config.storage.topic=connect-local-stg-configs\n",
    "status.storage.topic=connect-local-stg-status\n",
    "\n",
    "consumer.max.poll.records=1\n",
    "consumer.enable.auto.commit=false\n",
    "consumer.auto.offset.reset=latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mconnect-distributed.sh\u001b[m\u001b[m             \u001b[31mkafka-mirror-maker.sh\u001b[m\u001b[m\n",
      "\u001b[31mconnect-mirror-maker.sh\u001b[m\u001b[m            \u001b[31mkafka-producer-perf-test.sh\u001b[m\u001b[m\n",
      "\u001b[31mconnect-standalone.sh\u001b[m\u001b[m              \u001b[31mkafka-reassign-partitions.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-acls.sh\u001b[m\u001b[m                      \u001b[31mkafka-replica-verification.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-broker-api-versions.sh\u001b[m\u001b[m       \u001b[31mkafka-run-class.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-cluster.sh\u001b[m\u001b[m                   \u001b[31mkafka-server-start.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-configs.sh\u001b[m\u001b[m                   \u001b[31mkafka-server-stop.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-console-consumer.sh\u001b[m\u001b[m          \u001b[31mkafka-storage.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-console-producer.sh\u001b[m\u001b[m          \u001b[31mkafka-streams-application-reset.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-consumer-groups.sh\u001b[m\u001b[m           \u001b[31mkafka-topics.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-consumer-perf-test.sh\u001b[m\u001b[m        \u001b[31mkafka-transactions.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-delegation-tokens.sh\u001b[m\u001b[m         \u001b[31mkafka-verifiable-consumer.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-delete-records.sh\u001b[m\u001b[m            \u001b[31mkafka-verifiable-producer.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-dump-log.sh\u001b[m\u001b[m                  \u001b[31mtrogdor.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-features.sh\u001b[m\u001b[m                  \u001b[34mwindows\u001b[m\u001b[m\n",
      "\u001b[31mkafka-get-offsets.sh\u001b[m\u001b[m               \u001b[31mzookeeper-security-migration.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-leader-election.sh\u001b[m\u001b[m           \u001b[31mzookeeper-server-start.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-log-dirs.sh\u001b[m\u001b[m                  \u001b[31mzookeeper-server-stop.sh\u001b[m\u001b[m\n",
      "\u001b[31mkafka-metadata-shell.sh\u001b[m\u001b[m            \u001b[31mzookeeper-shell.sh\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls ~/kafka_2.12-3.2.0/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic connect-local-stg-offsets.\n",
      "Created topic connect-local-stg-configs.\n",
      "Created topic connect-local-stg-status.\n",
      "WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.\n",
      "Created topic kctopic_for_sink.\n"
     ]
    }
   ],
   "source": [
    "!kafka-topics.sh --bootstrap-server localhost:9092 --create --replication-factor 1 --partitions 1 --topic connect-local-stg-offsets\n",
    "!kafka-topics.sh --bootstrap-server localhost:9092 --create --replication-factor 1 --partitions 1 --topic connect-local-stg-configs\n",
    "!kafka-topics.sh --bootstrap-server localhost:9092 --create --replication-factor 1 --partitions 1 --topic connect-local-stg-status\n",
    "!kafka-topics.sh --bootstrap-server localhost:9092 --create --replication-factor 1 --partitions 1 --topic kctopic_for_sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /usr/local/share/java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../assets/jars/*.jar /usr/local/share/java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 26912\n",
      "drwxr-xr-x  10 sparshagarwal  admin      320 Jul 16 16:06 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxrwxr-x  45 sparshagarwal  admin     1440 Jul 16 16:04 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 sparshagarwal  admin    99087 Jul 16 16:06 connect-api-3.2.0.jar\n",
      "-rw-r--r--@  1 sparshagarwal  admin    15340 Jul 16 16:06 connect-file-3.2.0.jar\n",
      "-rw-r--r--@  1 sparshagarwal  admin   126898 Jul 16 16:06 javax.ws.rs-api-2.1.1.jar\n",
      "-rw-r--r--@  1 sparshagarwal  admin  4941003 Jul 16 16:06 kafka-clients-3.2.0.jar\n",
      "-rw-r--r--@  1 sparshagarwal  admin   682804 Jul 16 16:06 lz4-java-1.8.0.jar\n",
      "-rw-r--r--@  1 sparshagarwal  admin    41125 Jul 16 16:06 slf4j-api-1.7.36.jar\n",
      "-rw-r--r--@  1 sparshagarwal  admin  1970939 Jul 16 16:06 snappy-java-1.1.8.4.jar\n",
      "-rw-r--r--@  1 sparshagarwal  admin  5885445 Jul 16 16:06 zstd-jni-1.5.2-1.jar\n"
     ]
    }
   ],
   "source": [
    "!ls -al /usr/local/share/java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../test.txt\n",
    "Hello\n",
    "This is first message to kafka connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../test.txt\n",
    "This is the third message to kafka connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env-spacy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343191058819caea96d5cde1bd3b1a75b4807623ce2cda0e1c8499e39ac847e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
