"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[86250],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>m});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),d=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=d(e.components);return n.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=d(a),m=o,h=u["".concat(l,".").concat(m)]||u[m]||c[m]||r;return a?n.createElement(h,i(i({ref:t},p),{},{components:a})):n.createElement(h,i({ref:t},p))}));function m(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,i=new Array(r);i[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var d=2;d<r;d++)i[d]=a[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},90824:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>r,metadata:()=>s,toc:()=>d});var n=a(87462),o=(a(67294),a(3905));const r={},i="dbt",s={unversionedId:"processing/dbt",id:"processing/dbt",title:"dbt",description:"Transform your data in warehouse",source:"@site/docs/03-processing/dbt.md",sourceDirName:"03-processing",slug:"/processing/dbt",permalink:"/docs/processing/dbt",draft:!1,tags:[],version:"current",lastUpdatedBy:"sparsh",lastUpdatedAt:1681047270,formattedLastUpdatedAt:"Apr 9, 2023",frontMatter:{},sidebar:"docs",previous:{title:"Lab: Flink Kafka Source",permalink:"/docs/processing/lab-flink-kafka-source/"},next:{title:"Lab: Building an ELT pipeline for a cab service company using dbt and Postgres",permalink:"/docs/processing/lab-dbt-nyctaxi/"}},l={},d=[{value:"Key Concepts",id:"key-concepts",level:2},{value:"Data modeling techniques for more modularity",id:"data-modeling-techniques-for-more-modularity",level:2},{value:"What Do Airflow and dbt Solve?",id:"what-do-airflow-and-dbt-solve",level:2},{value:"Trainings",id:"trainings",level:2},{value:"Commands",id:"commands",level:2},{value:"Case Studies",id:"case-studies",level:2},{value:"99 Group",id:"99-group",level:3},{value:"Data Transformation with Snowpark Python and dbt",id:"data-transformation-with-snowpark-python-and-dbt",level:2},{value:"Makefile",id:"makefile",level:2},{value:"Profiles",id:"profiles",level:2},{value:"Installation",id:"installation",level:2},{value:"More Resources",id:"more-resources",level:2}],p={toc:d};function c(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"dbt"},"dbt"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Transform your data in warehouse")),(0,o.kt)("p",null,"dbt (data build tool) is an open source Python package that enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications. dbt allows you to build your data transformation pipeline using SQL queries."),(0,o.kt)("p",null,"dbt fits nicely into the modern BI stack, coupling with products like Stitch, Fivetran, Redshift, Snowflake, BigQuery, Looker, and Mode. Here\u2019s how the pieces fit together:"),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://www.getdbt.com/ui/img/blog/what-exactly-is-dbt/1-BogoeTTK1OXFU1hPfUyCFw.png",alt:null})),(0,o.kt)("p",null,"dbt is the T in ELT. It doesn\u2019t extract or load data, but it\u2019s extremely good at transforming data that\u2019s already loaded into your warehouse. This \u201ctransform after load\u201d architecture is becoming known as ELT (extract, load, transform)."),(0,o.kt)("p",null,"ELT has become commonplace because of the power of modern analytic databases. Data warehouses like Redshift, Snowflake, and BigQuery are extremely performant and very scalable such that at this point most data transformation use cases can be much more effectively handled in-database rather than in some external processing layer. Add to this the separation of compute and storage and there are decreasingly few reasons to want to execute your data transformation jobs elsewhere."),(0,o.kt)("p",null,"dbt is a tool to help you write and execute the data transformation jobs that run inside your warehouse. dbt\u2019s only function is to take code, compile it to SQL, and then run against your database."),(0,o.kt)("h2",{id:"key-concepts"},"Key Concepts"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"dbt CLI\xa0--- CLI stands for Command Line Interface. When you have\xa0",(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/get-started/installation?ref=blef-fr"}),(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/get-started/installation?ref=blef-fr"},"installed"),"\xa0dbt you have available in your terminal the\xa0",(0,o.kt)("inlineCode",{parentName:"li"},"dbt"),"\xa0command. Thanks to this you can run\xa0",(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/reference/dbt-commands?ref=blef-fr"},"a lot of different commands"),"."),(0,o.kt)("li",{parentName:"ul"},"a dbt project\xa0---\xa0",(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/build/projects?ref=blef-fr"},"a dbt project"),"\xa0is a folder that contains all the dbt objects needed to work. You can initialise a project with the CLI command:\xa0",(0,o.kt)("inlineCode",{parentName:"li"},"dbt init"),"."),(0,o.kt)("li",{parentName:"ul"},"YAML\xa0--- in the modern data era\xa0",(0,o.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/YAML?ref=blef-fr"},"YAML"),"\xa0files are everywhere. In dbt you define a lot of configurations in YAML files. In a dbt project you can define YAML file everywhere. You have to imagine that in the end dbt will concatenate all the files to create a big configuration out of it. In dbt we use the\xa0",(0,o.kt)("em",{parentName:"li"},".yml"),"\xa0extension."),(0,o.kt)("li",{parentName:"ul"},"profiles.yml\xa0---\xa0",(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/reference/profiles.yml?ref=blef-fr"},"This file contains the credentials"),"\xa0to connect your dbt project to your data warehouse. By default this file is located in your\xa0",(0,o.kt)("inlineCode",{parentName:"li"},"$HOME/.dbt/"),"\xa0folder. I recommend you to create your own profiles file and to specify the\xa0",(0,o.kt)("inlineCode",{parentName:"li"},"--profiles-dir"),"\xa0",(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/get-started/connection-profiles?ref=blef-fr#advanced-customizing-a-profile-directory"},"option"),"\xa0to the dbt CLI. A connection to a warehouse requires a\xa0",(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/docs/supported-data-platforms?ref=blef-fr"},"dbt adapter"),"\xa0to be installed."),(0,o.kt)("li",{parentName:"ul"},"a model\xa0--- a model is a select statement that can be materialised as a table or as a view. The models are most the important dbt object because they are your data assets. All your business logic will be in the model select statements. You should also know that model are defined in\xa0",(0,o.kt)("em",{parentName:"li"},".sql"),"\xa0files and that the filename is the name of the model by default. You can also add metadata on models (in YAML)."),(0,o.kt)("li",{parentName:"ul"},"a source\xa0--- a source refers to a table that has been extracted and load---EL---by something outside of dbt. You have to define sources in YAML files."),(0,o.kt)("li",{parentName:"ul"},"Jinja templating\xa0---\xa0",(0,o.kt)("a",{parentName:"li",href:"https://en.wikipedia.org/wiki/Jinja_(template_engine)?ref=blef-fr"},"Jinja is a templating engine"),'\xa0that seems to exist forever in Python. A templating engine is a mechanism that takes a template with "stuff" that will be replaced when the template will be rendered by the engine. Contextualised to dbt it means that a SQL query is a template that will be rendered---or compiled---to SQL query ready to be executed against your data warehouse. By default you can recognise a Jinja syntax with the double curly brackets---e.g.\xa0',(0,o.kt)("inlineCode",{parentName:"li"},"{{ something }}"),"\xa0."),(0,o.kt)("li",{parentName:"ul"},"a macro\xa0--- a macro is a Jinja function that either do something or return SQL or partial SQL code. Macro can be imported from other dbt packages or defined within a dbt project."),(0,o.kt)("li",{parentName:"ul"},"ref / source macros\xa0---\xa0",(0,o.kt)("inlineCode",{parentName:"li"},"ref"),"\xa0and\xa0",(0,o.kt)("inlineCode",{parentName:"li"},"source"),"\xa0macros are the most important macros you'll use. When writing a model you'll use these macros to define the relationships between models. Thanks to that dbt will be able to create a dependency tree of all the relation between the models. We call this a DAG. Obviously\xa0",(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/reference/dbt-jinja-functions/source?ref=blef-fr"},"source"),"\xa0define a relation to source and\xa0",(0,o.kt)("a",{parentName:"li",href:"https://docs.getdbt.com/reference/dbt-jinja-functions/ref?ref=blef-fr"},"ref"),"\xa0to another model---it can also be other kind of dbt resources.")),(0,o.kt)("h2",{id:"data-modeling-techniques-for-more-modularity"},"Data modeling techniques for more modularity"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://www.getdbt.com/analytics-engineering/modular-data-modeling-technique/"},"https://www.getdbt.com/analytics-engineering/modular-data-modeling-technique/")),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/62965911/214275837-a9c09ea9-81a0-4e8d-aed0-42abb31e1c5f.png",alt:null})),(0,o.kt)("p",null,"dbt (data build tool) is an open source Python package that enables data analysts and engineers to transform their data using the same practices that software engineers use to build applications. dbt allows you to build your data transformation pipeline using SQL queries."),(0,o.kt)("h2",{id:"what-do-airflow-and-dbt-solve"},"What Do Airflow and dbt Solve?"),(0,o.kt)("p",null,"Airflow and dbt share the same high-level purpose: to help teams deliver reliable data to the people they work with, using a common interface to collaborate on that work."),(0,o.kt)("p",null,"But the two tools handle different parts of that workflow:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Airflow helps\xa0",(0,o.kt)("strong",{parentName:"li"},"orchestrate"),"\xa0jobs that extract data, load it into a warehouse, and handle machine-learning processes."),(0,o.kt)("li",{parentName:"ul"},"dbt hones in on a subset of those jobs \u2013 enabling team members who use SQL to\xa0",(0,o.kt)("strong",{parentName:"li"},"transform"),"\xa0data that has already landed in the warehouse.")),(0,o.kt)("p",null,"With a combination of dbt\xa0",(0,o.kt)("strong",{parentName:"p"},"and"),"\xa0Airflow, each member of a data team can focus on what they do best, with clarity across\xa0",(0,o.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/blog/dbt-airflow-spiritual-alignment#pipeline-observability-for-analysts"},"analysts"),"\xa0and\xa0",(0,o.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/blog/dbt-airflow-spiritual-alignment#transformation-observability-for-engineers"},"engineers"),"\xa0on who needs to dig in (and where to start) when data pipeline issues come up."),(0,o.kt)("h2",{id:"trainings"},"Trainings"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://courses.getdbt.com/courses/fundamentals"},"Learn the Fundamentals of Analytics Engineering with dbt")),(0,o.kt)("h2",{id:"commands"},"Commands"),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/62965911/214275903-c30fbcbc-febb-4c4a-a3ab-499ef4688e7c.png",alt:null})),(0,o.kt)("h2",{id:"case-studies"},"Case Studies"),(0,o.kt)("h3",{id:"99-group"},"99 Group"),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/62965911/215028713-24229628-977d-4c0a-94bf-7620380b9ceb.png",alt:"99-group"})),(0,o.kt)("h2",{id:"data-transformation-with-snowpark-python-and-dbt"},"Data Transformation with Snowpark Python and dbt"),(0,o.kt)("p",null,"dbt is one of the most popular data transformation tools today. And until now dbt has been entirely a SQL-based transformation tool. But with the announcement of dbt Python models, things have changed. It's now possible to create both SQL and Python based models in dbt! Here's how dbt explains it:"),(0,o.kt)("p",null,"dbt Python (\"dbt-py\") models will help you solve use cases that can't be solved with SQL. You can perform analyses using tools available in the open source Python ecosystem, including state-of-the-art packages for data science and statistics. Before, you would have needed separate infrastructure and orchestration to run Python transformations in production. By defining your Python transformations in dbt, they're just models in your project, with all the same capabilities around testing, documentation, and lineage. (",(0,o.kt)("a",{parentName:"p",href:"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/python-models"},"dbt Python models"),"). Python based dbt models are made possible by Snowflake's new native Python support and Snowpark API for Python. With Snowflake's native Python support and DataFrame API, you no longer need to maintain and pay for separate infrastructure/services to run Python code, it can be run directly within Snowflake's Enterprise grade data platform!"),(0,o.kt)("h2",{id:"makefile"},"Makefile"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-Makefile"},"init:\n    dbt init ${PROJECT_NAME}\ndebug:\n    dbt debug\nrun:\n# If you are in dbt directory already, you don't need to export the `DBT_PROFILES_DIR` environment variable otherwise you can export it to run dbt from other folders also\n    export DBT_PROFILES_DIR=path/to/directory\n    dbt run\n# Alternative way is to directly mention the profile path while running the dbt project\n    dbt run --profiles-dir path/to/directory\ntest:\n# Running dbt test without mentioning any models will test all the models in the dbt project\n    dbt test\n# If you want to test only specific models, you can use this format\n    dbt test -m model1 [model2]\nseed:\n    dbt seed\nvenv:\n    pipenv --python 3.9.7\n    pipenv install\n    pipenv shell\n    pipenv --venv\n    pipenv --rm\n")),(0,o.kt)("h2",{id:"profiles"},"Profiles"),(0,o.kt)("p",null,(0,o.kt)("inlineCode",{parentName:"p"},"profiles.yml")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"postgres:\n  outputs:\n    dev:\n      type: postgres\n      threads: 1\n      host: <host>\n      port: 5432\n      user: postgres\n      pass: <pass>\n      dbname: postgres\n      schema: public\n    prod:\n      type: postgres\n      threads: 1\n      host: <host>\n      port: 5432\n      user: postgres\n      pass: <pass>\n      dbname: postgres\n      schema: public\n  target: dev\n  \ndatabricks:\n  outputs:\n    dev:\n      host: {HOST}\n      http_path: {HTTP_PATH}\n      schema: default\n      threads: 1\n      token: {TOKEN}\n      type: databricks\n  target: dev\n")),(0,o.kt)("h2",{id:"installation"},"Installation"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"dbt-core\ndbt-databricks\ndbt-postgres\ndbt-snowflake\ndbt-bigquery\n")),(0,o.kt)("h2",{id:"more-resources"},"More Resources"),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://platform.deloitte.com.au/articles/transform-your-data-with-dbt-and-serverless-architecture"},"Transform your data with dbt and Serverless architecture")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://www.getdbt.com/success-stories/jetblue/"},"How JetBlue is eliminating the data engineering bottlenecks with dbt")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://medium.com/vimeo-engineering-blog/dbt-development-at-vimeo-fe1ad9eb212"},"dbt development at Vimeo")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://airbyte.com/blog/sql-data-modeling-with-dbt"},"Best practices for data modeling with SQL and dbt")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://www.getdbt.com/analytics-engineering/start-here"},"https://www.getdbt.com/analytics-engineering/start-here")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://www.getdbt.com/blog/what-exactly-is-dbt/"},"https://www.getdbt.com/blog/what-exactly-is-dbt/")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://medium.com/@montadhar/four-reasons-that-make-dbt-a-great-time-saver-for-data-engineers-4c4ceb721522"},"Four Reasons that make DBT a great time saver for Data Engineers")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("a",{parentName:"li",href:"https://courses.getdbt.com/courses/fundamentals"},"https://courses.getdbt.com/courses/fundamentals"))),(0,o.kt)("p",null,"Read these"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://www.getdbt.com/blog/what-exactly-is-dbt/"},"What, exactly, is dbt?")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://medium.com/@rahulxsharma/dbt-vs-delta-live-tables-ef629b627e0"},"dbt vs Delta Live Tables")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://medium.com/@montadhar/four-reasons-that-make-dbt-a-great-time-saver-for-data-engineers-4c4ceb721522"},"Four Reasons that make DBT a great time saver for Data Engineers"))),(0,o.kt)("p",null,"Watch these videos"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=8FZZivIfJVo"},"https://www.youtube.com/watch?v=8FZZivIfJVo")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://www.youtube.com/watch?v=efsqqD_Gak0"},"https://www.youtube.com/watch?v=efsqqD_Gak0")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://www.youtube.com/playlist?list=PLy4OcwImJzBLJzLYxpxaPUmCWp8j1esvT"},"https://www.youtube.com/playlist?list=PLy4OcwImJzBLJzLYxpxaPUmCWp8j1esvT")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://youtu.be/8FZZivIfJVo"},"What Is DBT and Why Is It So Popular - Intro To Data Infrastructure Part 3")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://youtu.be/efsqqD_Gak0"},"What is dbt Data Build Tool? | What problem does it solve? | Real-world use cases")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://youtu.be/lHjLAdbPiuc"},"What is dbt(Data Build Tool)?")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://youtu.be/3gfRw9qBmF8"},"DBT Tutorial (data built tool)")),(0,o.kt)("li",{parentName:"ul"},"This is the playlist if you get into deep-dive : ",(0,o.kt)("a",{parentName:"li",href:"https://www.youtube.com/playlist?list=PLy4OcwImJzBLJzLYxpxaPUmCWp8j1esvT"},"Data Build Tool (dbt)"))))}c.isMDXComponent=!0}}]);