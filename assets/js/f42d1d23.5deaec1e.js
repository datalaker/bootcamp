"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[78372],{3905:(e,t,r)=>{r.d(t,{Zo:()=>l,kt:()=>m});var a=r(67294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function c(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var s=a.createContext({}),p=function(e){var t=a.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},l=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),d=p(r),m=n,b=d["".concat(s,".").concat(m)]||d[m]||u[m]||i;return r?a.createElement(b,o(o({ref:t},l),{},{components:r})):a.createElement(b,o({ref:t},l))}));function m(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,o=new Array(i);o[0]=d;var c={};for(var s in t)hasOwnProperty.call(t,s)&&(c[s]=t[s]);c.originalType=e,c.mdxType="string"==typeof e?e:n,o[1]=c;for(var p=2;p<i;p++)o[p]=r[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,r)}d.displayName="MDXCreateElement"},17423:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>c,toc:()=>p});var a=r(87462),n=(r(67294),r(3905));const i={},o="BedBricks",c={unversionedId:"processing/databricks/project-bedbricks/README",id:"processing/databricks/project-bedbricks/README",title:"BedBricks",description:"Databricks PySpark Ecommerce Data Processing Case Study",source:"@site/docs/03-processing/databricks/project-bedbricks/README.md",sourceDirName:"03-processing/databricks/project-bedbricks",slug:"/processing/databricks/project-bedbricks/",permalink:"/docs/processing/databricks/project-bedbricks/",draft:!1,tags:[],version:"current",lastUpdatedBy:"sparsh",lastUpdatedAt:1681047270,formattedLastUpdatedAt:"Apr 9, 2023",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"AdvancedBricks",permalink:"/docs/processing/databricks/project-advancedbricks/"},next:{title:"Data Engineering with Databricks",permalink:"/docs/processing/databricks/project-databricks-de/"}},s={},p=[{value:"Learning objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2}],l={toc:p};function u(e){let{components:t,...r}=e;return(0,n.kt)("wrapper",(0,a.Z)({},l,r,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"bedbricks"},"BedBricks"),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},"Databricks PySpark Ecommerce Data Processing Case Study")),(0,n.kt)("p",null,"Welcome to the Apache Spark Programming with Databricks course. This course is part of the Apache Spark Developer learning pathway and was designed to help you prepare for the Apache Spark Developer Certification exam."),(0,n.kt)("p",null,"In this course, you will start by visualizing and applying Spark architecture concepts in example scenarios. Then, you will explore and preprocess datasets by applying a variety of DataFrame transformations and actions. After ingesting data from various file formats, you will apply these preprocessing steps and write them to Delta tables. The case study then expands to stream from Delta in an analytics use case that demonstrates core Structured Streaming concepts. Lastly, you will explore the Spark UI and how query optimization, partitioning, and caching affect performance."),(0,n.kt)("h2",{id:"learning-objectives"},"Learning objectives"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Identify core features of Spark and Databricks."),(0,n.kt)("li",{parentName:"ul"},"Describe how DataFrames are created and evaluated in Spark."),(0,n.kt)("li",{parentName:"ul"},"Apply the DataFrame transformation API to process and analyze data."),(0,n.kt)("li",{parentName:"ul"},"Demonstrate how Spark is optimized and executed on a cluster."),(0,n.kt)("li",{parentName:"ul"},"Apply Delta and Structured Streaming to process streaming data.")),(0,n.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"Familiarity with basic SQL concepts (select, filter, groupby, join, etc)"),(0,n.kt)("li",{parentName:"ul"},"Beginner programming experience with Python or Scala (syntax, conditions, loops, functions)")))}u.isMDXComponent=!0}}]);