"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[83030],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>h});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function r(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,l=e.originalType,s=e.parentName,c=r(e,["components","mdxType","originalType","parentName"]),d=p(a),h=i,m=d["".concat(s,".").concat(h)]||d[h]||u[h]||l;return a?n.createElement(m,o(o({ref:t},c),{},{components:a})):n.createElement(m,o({ref:t},c))}));function h(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var l=a.length,o=new Array(l);o[0]=d;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r.mdxType="string"==typeof e?e:i,o[1]=r;for(var p=2;p<l;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},64005:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>r,toc:()=>p});var n=a(87462),i=(a(67294),a(3905));const l={},o="Lab: GCP Dataflow Size Inputs",r={unversionedId:"processing/lab-gcp-dataflow-side-inputs",id:"processing/lab-gcp-dataflow-side-inputs",title:"Lab: GCP Dataflow Size Inputs",description:"Objective",source:"@site/docs/03-processing/lab-gcp-dataflow-side-inputs.md",sourceDirName:"03-processing",slug:"/processing/lab-gcp-dataflow-side-inputs",permalink:"/docs/processing/lab-gcp-dataflow-side-inputs",draft:!1,tags:[],version:"current",lastUpdatedBy:"sparsh",lastUpdatedAt:1681732641,formattedLastUpdatedAt:"Apr 17, 2023",frontMatter:{},sidebar:"docs",previous:{title:"Lab: GCP Dataflow Batch Pipeline",permalink:"/docs/processing/lab-gcp-dataflow-batch-pipeline"},next:{title:"GCP Dataflow Streaming Pipeline",permalink:"/docs/processing/lab-gcp-dataflow-stream-pipeline"}},s={},p=[{value:"Objective",id:"objective",level:2},{value:"Task 1. Preparation",id:"task-1-preparation",level:2},{value:"Ensure that the Dataflow API is successfully enabled",id:"ensure-that-the-dataflow-api-is-successfully-enabled",level:3},{value:"Open the SSH terminal and connect to the training VM",id:"open-the-ssh-terminal-and-connect-to-the-training-vm",level:3},{value:"Download Code Repository",id:"download-code-repository",level:3},{value:"Create a Cloud Storage bucket",id:"create-a-cloud-storage-bucket",level:3},{value:"Task 2. Try using BigQuery query",id:"task-2-try-using-bigquery-query",level:2},{value:"Task 3. Explore the pipeline code",id:"task-3-explore-the-pipeline-code",level:2},{value:"Task 4. Execute the pipeline",id:"task-4-execute-the-pipeline",level:2}],c={toc:p};function u(e){let{components:t,...a}=e;return(0,i.kt)("wrapper",(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"lab-gcp-dataflow-size-inputs"},"Lab: GCP Dataflow Size Inputs"),(0,i.kt)("h2",{id:"objective"},"Objective"),(0,i.kt)("p",null,"Serverless Data Analysis with Dataflow - Side Inputs (Python)"),(0,i.kt)("p",null,"In this lab, you learn how to load data into BigQuery and run complex queries. Next, you will execute a Dataflow pipeline that can carry out Map and Reduce operations, use side inputs and stream into BigQuery."),(0,i.kt)("p",null,"In this lab, you learn how to use BigQuery as a data source into Dataflow, and how to use the results of a pipeline as a side input to another pipeline."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Read data from BigQuery into Dataflow"),(0,i.kt)("li",{parentName:"ul"},"Use the output of a pipeline as a side-input to another pipeline")),(0,i.kt)("h2",{id:"task-1-preparation"},"Task 1. Preparation"),(0,i.kt)("h3",{id:"ensure-that-the-dataflow-api-is-successfully-enabled"},"Ensure that the Dataflow API is successfully enabled"),(0,i.kt)("p",null,"To ensure access to the necessary API, restart the connection to the Dataflow API."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"In the Cloud Console, enter\xa0Dataflow API\xa0in the top search bar. Click on the result for\xa0Dataflow API."),(0,i.kt)("li",{parentName:"ol"},"Click\xa0Manage."),(0,i.kt)("li",{parentName:"ol"},"Click\xa0Disable API."),(0,i.kt)("li",{parentName:"ol"},"If asked to confirm, click\xa0Disable."),(0,i.kt)("li",{parentName:"ol"},"Click\xa0Enable.")),(0,i.kt)("p",null,"When the API has been enabled again, the page will show the option to disable."),(0,i.kt)("h3",{id:"open-the-ssh-terminal-and-connect-to-the-training-vm"},"Open the SSH terminal and connect to the training VM"),(0,i.kt)("p",null,"You will be running all code from a curated training VM."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"In the Console, on the\xa0Navigation menu, click\xa0Compute Engine\xa0>\xa0VM instances."),(0,i.kt)("li",{parentName:"ol"},"Locate the line with the instance called\xa0training-vm."),(0,i.kt)("li",{parentName:"ol"},"On the far right, under\xa0Connect, click on\xa0SSH\xa0to open a terminal window."),(0,i.kt)("li",{parentName:"ol"},"In this lab, you will enter CLI commands on the\xa0training-vm.")),(0,i.kt)("h3",{id:"download-code-repository"},"Download Code Repository"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Next you will download a code repository for use in this lab. In the\xa0training-vm\xa0SSH terminal enter the following:")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n")),(0,i.kt)("h3",{id:"create-a-cloud-storage-bucket"},"Create a Cloud Storage bucket"),(0,i.kt)("p",null,"Follow these instructions to create a bucket."),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"In the Console, on the\xa0Navigation menu, click\xa0Home."),(0,i.kt)("li",{parentName:"ol"},"Select and copy\xa0the Project ID."),(0,i.kt)("li",{parentName:"ol"},"In the Console, on the\xa0Navigation menu, click\xa0Cloud Storage\xa0>\xa0Browser."),(0,i.kt)("li",{parentName:"ol"},"Click\xa0Create Bucket."),(0,i.kt)("li",{parentName:"ol"},"Specify the following, and leave the remaining settings as their defaults:\n| Property | Value (type value or select option as specified) |\n| Name | ",(0,i.kt)("inlineCode",{parentName:"li"},"<your unique bucket name (Project ID)>")," |\n| Location type | ",(0,i.kt)("inlineCode",{parentName:"li"},"Multi-Region")," |\n| Location | ",(0,i.kt)("inlineCode",{parentName:"li"},"<Your location>")," |"),(0,i.kt)("li",{parentName:"ol"},"Click\xa0Create. Record the name of your bucket. You will need it in subsequent tasks."),(0,i.kt)("li",{parentName:"ol"},'In the\xa0training-vm\xa0SSH terminal enter the following to create two environment variables. One named "BUCKET" and the other named "PROJECT". Verify that each exists with the echo command:',(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre"},'BUCKET="<your unique bucket name (Project ID)>"\necho $BUCKET\nPROJECT="<your unique project name (Project ID)>"\necho $PROJECT\n')))),(0,i.kt)("h2",{id:"task-2-try-using-bigquery-query"},"Task 2. Try using BigQuery query"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"In the console, on the\xa0Navigation menu, click\xa0BigQuery."),(0,i.kt)("li",{parentName:"ol"},"If prompted click\xa0Done."),(0,i.kt)("li",{parentName:"ol"},"Click\xa0Compose new query\xa0and type the following query:",(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\ncontent\nFROM\n`cloud-training-demos.github_repos.contents_java`\nLIMIT\n10\n"))),(0,i.kt)("li",{parentName:"ol"},"Click on\xa0Run.")),(0,i.kt)("p",null,"What is being returned?"),(0,i.kt)("p",null,"The BigQuery table\xa0",(0,i.kt)("inlineCode",{parentName:"p"},"fh-bigquery.github_extracts.contents_java_2016"),"\xa0contains the content (and some metadata) of all the Java files present in GitHub in 2016."),(0,i.kt)("p",null,"To find out how many Java files this table has, type the following query and click\xa0Run:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n  COUNT(*)\nFROM\n  `cloud-training-demos.github_repos.contents_java`\n")),(0,i.kt)("p",null,"Q: Why do you think zero bytes of data were processed to return the result?"),(0,i.kt)("ul",{className:"contains-task-list"},(0,i.kt)("li",{parentName:"ul",className:"task-list-item"},(0,i.kt)("input",{parentName:"li",type:"checkbox",checked:!1,disabled:!0})," ","There were 0 records returned in the result."),(0,i.kt)("li",{parentName:"ul",className:"task-list-item"},(0,i.kt)("input",{parentName:"li",type:"checkbox",checked:!1,disabled:!0})," ","BigQuery stores common metadata about the table (like row count). Querying metadata processes 0 bytes."),(0,i.kt)("li",{parentName:"ul",className:"task-list-item"},(0,i.kt)("input",{parentName:"li",type:"checkbox",checked:!1,disabled:!0})," ","This dataset is not properly set up for billing."),(0,i.kt)("li",{parentName:"ul",className:"task-list-item"},(0,i.kt)("input",{parentName:"li",type:"checkbox",checked:!1,disabled:!0})," ","Cache is enabled so all queries process 0 bytes.")),(0,i.kt)("p",null,"Q: How many files are there in this dataset?"),(0,i.kt)("p",null,"Q: Is this a dataset you want to process locally or on the cloud?"),(0,i.kt)("h2",{id:"task-3-explore-the-pipeline-code"},"Task 3. Explore the pipeline code"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Return to the\xa0training-vm\xa0SSH terminal and navigate to the directory\xa0",(0,i.kt)("inlineCode",{parentName:"p"},"/training-data-analyst/courses/data_analysis/lab2/python"),"\xa0and view the file\xa0",(0,i.kt)("inlineCode",{parentName:"p"},"JavaProjectsThatNeedHelp.py"),".")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"View the file with Nano.\xa0Do not make any changes to the code.\xa0Press\xa0Ctrl+X\xa0to exit Nano."))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"cd ~/training-data-analyst/courses/data_analysis/lab2/python\nnano JavaProjectsThatNeedHelp.py\n")),(0,i.kt)("p",null,"Refer to this diagram as you read the code. The pipeline looks like this:"),(0,i.kt)("p",null,(0,i.kt)("img",{parentName:"p",src:"https://user-images.githubusercontent.com/62965911/214003265-02ac63ea-b61c-46e7-bf5d-b1fc3c53b07d.png",alt:null})),(0,i.kt)("p",null,"Answer the following questions:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Looking at the class documentation at the very top, what is the purpose of this pipeline?"),(0,i.kt)("li",{parentName:"ul"},"Where does the content come from?"),(0,i.kt)("li",{parentName:"ul"},"What does the left side of the pipeline do?"),(0,i.kt)("li",{parentName:"ul"},"What does the right side of the pipeline do?"),(0,i.kt)("li",{parentName:"ul"},"What does ToLines do? (Hint: look at the content field of the BigQuery result)"),(0,i.kt)("li",{parentName:"ul"},"Why is the result of ReadFromBQ stored in a named PCollection instead of being directly passed to another step?"),(0,i.kt)("li",{parentName:"ul"},"What are the two actions carried out on the PCollection generated from ReadFromBQ?"),(0,i.kt)("li",{parentName:"ul"},"If a file has 3 FIXMEs and 2 TODOs in its content (on different lines), how many calls for help are associated with it?"),(0,i.kt)("li",{parentName:"ul"},"If a file is in the package com.google.devtools.build, what are the packages that it is associated with?"),(0,i.kt)("li",{parentName:"ul"},"popular_packages and help_packages are both named PCollections and both used in the Scores (side inputs) step of the pipeline. Which one is the main input and which is the side input?"),(0,i.kt)("li",{parentName:"ul"},"What is the method used in the Scores step?"),(0,i.kt)("li",{parentName:"ul"},"What Python data type is the side input converted into in the Scores step?")),(0,i.kt)("p",null,"Note:\xa0The Java version of this program is slightly different from the Python version. The Java SDK supports AsMap and the Python SDK doesn't. It supports AsDict instead. In Java, the PCollection is converted into a View as a preparatory step before it is used. In Python, the PCollection conversion occurs in the step where it is used."),(0,i.kt)("h2",{id:"task-4-execute-the-pipeline"},"Task 4. Execute the pipeline"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"The program requires BUCKET and PROJECT values and whether you want to run the pipeline locally using\xa0",(0,i.kt)("inlineCode",{parentName:"p"},"--DirectRunner"),"\xa0or on the cloud using\xa0",(0,i.kt)("inlineCode",{parentName:"p"},"--DataFlowRunner"),".")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Execute the pipeline locally by typing the following into the\xa0training-vm\xa0SSH terminal:"))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python3 JavaProjectsThatNeedHelp.py --bucket $BUCKET --project $PROJECT --DirectRunner\n")),(0,i.kt)("p",null,"Note:\xa0Please ignore the warning if any and move forward."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Once the pipeline has finished executing, On the\xa0Navigation menu, click\xa0Cloud Storage > Browser\xa0and click on your bucket. You will find the results in the\xa0javahelp\xa0folder. Click on the\xa0Result\xa0object to examine the output.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Execute the pipeline on the cloud by typing the following into the\xa0training-vm\xa0SSH terminal:"))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python3 JavaProjectsThatNeedHelp.py --bucket $BUCKET --project $PROJECT --DataFlowRunner\n")),(0,i.kt)("p",null,"Note:\xa0Please ignore the warning if any and move forward."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Return to the browser tab for Console. On the\xa0Navigation menu, click\xa0Dataflow\xa0and click on your job to monitor progress.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Once the pipeline has finished executing, On the\xa0Navigation menu, click\xa0Cloud Storage > Browser\xa0and click on your bucket. You will find the results in the\xa0javahelp\xa0folder. Click on the\xa0Result\xa0object to examine the output. The file name will be the same but you will notice that the file creation time is more recent."))))}u.isMDXComponent=!0}}]);