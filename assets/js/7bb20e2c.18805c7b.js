"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[28917],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>f});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var c=n.createContext({}),s=function(e){var t=n.useContext(c),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},p=function(e){var t=s(e.components);return n.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,c=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=s(a),f=r,y=d["".concat(c,".").concat(f)]||d[f]||u[f]||o;return a?n.createElement(y,i(i({ref:t},p),{},{components:a})):n.createElement(y,i({ref:t},p))}));function f(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=d;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var s=2;s<o;s++)i[s]=a[s];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},92126:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>s});var n=a(87462),r=(a(67294),a(3905));const o={},i="Lab: Building Data Ingestion Pipelines Using Azure Data Factory",l={unversionedId:"orchestration/azure-data-factory/lab-data-ingestion-pipeline/README",id:"orchestration/azure-data-factory/lab-data-ingestion-pipeline/README",title:"Lab: Building Data Ingestion Pipelines Using Azure Data Factory",description:"Azure Data Factory is the bread and butter for a data engineer and understanding its fundamentals is extremely essential in building efficient pipelines. By the end of the lab, you will know how to provision a data factory account, copy data from an Azure SQL database to a data lake using copy activity, use control flow activities, move data from SQL Server to a data lake, and choose options to trigger a data factory pipeline.",source:"@site/docs/06-orchestration/azure-data-factory/lab-data-ingestion-pipeline/README.md",sourceDirName:"06-orchestration/azure-data-factory/lab-data-ingestion-pipeline",slug:"/orchestration/azure-data-factory/lab-data-ingestion-pipeline/",permalink:"/docs/orchestration/azure-data-factory/lab-data-ingestion-pipeline/",draft:!1,tags:[],version:"current",lastUpdatedBy:"sparsh",lastUpdatedAt:1681732641,formattedLastUpdatedAt:"Apr 17, 2023",frontMatter:{},sidebar:"docs",previous:{title:"Lab: Azure Data Factory and Synapse Analytics",permalink:"/docs/orchestration/azure-data-factory/lab-batch-processing-solution/"},next:{title:"Cloud Data Fusion",permalink:"/docs/orchestration/datafusion/"}},c={},s=[{value:"Notebook",id:"notebook",level:2}],p={toc:s};function u(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"lab-building-data-ingestion-pipelines-using-azure-data-factory"},"Lab: Building Data Ingestion Pipelines Using Azure Data Factory"),(0,r.kt)("p",null,"Azure Data Factory is the bread and butter for a data engineer and understanding its fundamentals is extremely essential in building efficient pipelines. By the end of the lab, you will know how to provision a data factory account, copy data from an Azure SQL database to a data lake using copy activity, use control flow activities, move data from SQL Server to a data lake, and choose options to trigger a data factory pipeline."),(0,r.kt)("p",null,"In this lab, we\u2019ll cover the following recipes:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Provisioning Azure Data Factory"),(0,r.kt)("li",{parentName:"ul"},"Copying files to a database from a data lake using a control flow and copy activity"),(0,r.kt)("li",{parentName:"ul"},"Triggering a pipeline in Azure Data Factory"),(0,r.kt)("li",{parentName:"ul"},"Copying data from a SQL Server virtual machine to a data lake using the Copy data wizard")),(0,r.kt)("h2",{id:"notebook"},"Notebook"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://nbviewer.org/github/sparsh-ai/recohut/blob/main/docs/06-orchestration/azure-data-factory/lab-data-ingestion-pipeline/main.ipynb"},(0,r.kt)("img",{parentName:"a",src:"https://img.shields.io/badge/jupyter-notebook-informational?logo=jupyter",alt:"nbviewer"}))))}u.isMDXComponent=!0}}]);