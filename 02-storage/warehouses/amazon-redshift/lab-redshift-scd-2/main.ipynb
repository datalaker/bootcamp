{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading into a SCD table involves a first-time bulk data loading, referred to as the _initial data load_. This is followed by continuous or regular data loading, referred to as an _incremental data load_, to keep the records up to date with changes in the source tables.\n",
    "\n",
    "To demonstrate the solution, we walk through the following steps for initial data load (1–7) and incremental data load (8–12):\n",
    "\n",
    "1. Land the source data files in an Amazon S3 location, using one subfolder per source table.\n",
    "2. Use an [AWS Glue](https://aws.amazon.com/glue) crawler to parse the data files and register tables in the AWS Glue Data Catalog.\n",
    "3. Create an external schema in Amazon Redshift to point to the AWS Glue database containing these tables.\n",
    "4. In Amazon Redshift, create one view per source table to fetch the latest version of the record for each primary key (`customer_id`) value.\n",
    "5. Create the `dim_customer` table in Amazon Redshift, which contains attributes from all relevant source tables.\n",
    "6. Create a view in Amazon Redshift joining the source table views from Step 4 to project the attributes modeled in the dimension table.\n",
    "7. Populate the initial data from the view created in Step 6 into the `dim_customer` table, generating `customer_sk`.\n",
    "8. Land the incremental data files for each source table in their respective Amazon S3 location.\n",
    "9. In Amazon Redshift, create a temporary table to accommodate the change-only records.\n",
    "10. Join the view from Step 6 and `dim_customer` and identify change records comparing the combined hash value of attributes. Populate the change records into the temporary table with an `I`, `U`, or `D` indicator.\n",
    "11. Update `rec_exp_dt` in `dim_customer` for all `U` and `D` records from the temporary table.\n",
    "12. Insert records into `dim_customer`, querying all `I` and `U` records from the temporary table."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img.drawio.svg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name, region_name=\"us-east-1\"):\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name)\n",
    "    get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    get_secret_value_response = json.loads(get_secret_value_response['SecretString'])\n",
    "    return get_secret_value_response\n",
    "\n",
    "creds = get_secret(\"wysde\")\n",
    "USERNAME = creds[\"REDSHIFT_USERNAME\"]\n",
    "PASSWORD = creds[\"REDSHIFT_PASSWORD\"]\n",
    "HOST = creds[\"REDSHIFT_HOST\"]\n",
    "PORT = 5439\n",
    "DATABASE = 'dev'\n",
    "\n",
    "conn_str = 'postgresql://{0}:{1}@{2}:{3}/{4}'.format(USERNAME, PASSWORD, HOST, PORT, DATABASE)\n",
    "\n",
    "%config SqlMagic.autopandas=True\n",
    "%config SqlMagic.displaycon=False\n",
    "%config SqlMagic.feedback=False\n",
    "%config SqlMagic.displaylimit=5\n",
    "%reload_ext sql\n",
    "%sql {conn_str}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land data from source tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data from source\n",
    "! wget -q --show-progress https://github.com/datalaker/assets/files/11010509/customer_address_with_ts.csv -O data/customer_address_with_ts.csv\n",
    "! wget -q --show-progress https://github.com/datalaker/assets/files/11010510/customer_master_with_ts.csv -O data/customer_master_with_ts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./customer_address_with_ts.csv to s3://wysde-datasets/customers/customer_address/customer_address_with_ts.csv\n",
      "upload: ./customer_master_with_ts.csv to s3://wysde-datasets/customers/customer_master/customer_master_with_ts.csv\n"
     ]
    }
   ],
   "source": [
    "#load into s3\n",
    "! aws s3 cp data/customer_address_with_ts.csv s3://wysde-datasets/customers/customer_address/customer_address_with_ts.csv\n",
    "! aws s3 cp data/customer_master_with_ts.csv s3://wysde-datasets/customers/customer_master/customer_master_with_ts.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register source tables in the AWS Glue Data Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create crawler    \n",
    "!aws glue create-crawler \\\n",
    "    --name rs-dimension \\\n",
    "    --role service-role/AWSGlueServiceRole-FullS3Access \\\n",
    "    --database-name datalake \\\n",
    "    --targets file://glue-targets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run crawler\n",
    "!aws glue start-crawler \\\n",
    "    --name rs-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Status\": \"SUCCEEDED\",\n",
      "    \"LogGroup\": \"/aws-glue/crawlers\",\n",
      "    \"LogStream\": \"rs-dimension\",\n",
      "    \"MessagePrefix\": \"fc9ed2c2-0937-4f04-bdfb-57ae9aabf73d\",\n",
      "    \"StartTime\": \"2023-03-19T14:21:58+05:30\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#check status\n",
    "!aws glue get-crawler \\\n",
    "    --name rs-dimension \\\n",
    "    --query \"Crawler.LastCrawl\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create schemas in Amazon Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "create external schema spectrum_dim\n",
    "from data catalog database 'datalake' iam_role default;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the tables registered in the Data Catalog in the preceding section are visible from within Amazon Redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>employer_name</th>\n",
       "      <th>row_audit_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Gladys</td>\n",
       "      <td>Rim</td>\n",
       "      <td>RIM Inc.</td>\n",
       "      <td>2019-05-03 14:52:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Yuki</td>\n",
       "      <td>Whobrey</td>\n",
       "      <td>Reims Collectables</td>\n",
       "      <td>2019-05-03 14:52:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Fletcher</td>\n",
       "      <td>Flosi</td>\n",
       "      <td>Lyon Souveniers</td>\n",
       "      <td>2019-05-03 14:52:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bette</td>\n",
       "      <td>Nicka</td>\n",
       "      <td>Toys4GrownUps.com</td>\n",
       "      <td>2019-05-03 14:52:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vinouye</td>\n",
       "      <td>Foller</td>\n",
       "      <td>Corporate Gift Ideas Co.</td>\n",
       "      <td>2019-05-03 14:52:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id first_name last_name             employer_name  \\\n",
       "0            1     Gladys       Rim                  RIM Inc.   \n",
       "1            2       Yuki   Whobrey        Reims Collectables   \n",
       "2            3   Fletcher     Flosi           Lyon Souveniers   \n",
       "3            4      Bette     Nicka         Toys4GrownUps.com   \n",
       "4            5    Vinouye    Foller  Corporate Gift Ideas Co.   \n",
       "\n",
       "          row_audit_ts  \n",
       "0  2019-05-03 14:52:31  \n",
       "1  2019-05-03 14:52:32  \n",
       "2  2019-05-03 14:52:33  \n",
       "3  2019-05-03 14:52:34  \n",
       "4  2019-05-03 14:52:35  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select *\n",
    "from spectrum_dim.customer_master\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>email_id</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>row_audit_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gladys.rim@rim.org</td>\n",
       "      <td>NYC</td>\n",
       "      <td>USA</td>\n",
       "      <td>2019-05-03 14:52:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>yuki_whobrey@aol.com</td>\n",
       "      <td>Reims</td>\n",
       "      <td>France</td>\n",
       "      <td>2019-05-03 14:52:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>fletcher.flosi@yahoo.com</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>2019-05-03 14:52:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bette_nicka@cox.net</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>USA</td>\n",
       "      <td>2019-05-03 14:52:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>vinouye@aol.com</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>USA</td>\n",
       "      <td>2019-05-03 14:52:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id                  email_id           city country  \\\n",
       "0            1        gladys.rim@rim.org            NYC     USA   \n",
       "1            2      yuki_whobrey@aol.com          Reims  France   \n",
       "2            3  fletcher.flosi@yahoo.com          Paris  France   \n",
       "3            4       bette_nicka@cox.net       Pasadena     USA   \n",
       "4            5           vinouye@aol.com  San Francisco     USA   \n",
       "\n",
       "          row_audit_ts  \n",
       "0  2019-05-03 14:52:36  \n",
       "1  2019-05-03 14:52:37  \n",
       "2  2019-05-03 14:52:38  \n",
       "3  2019-05-03 14:52:39  \n",
       "4  2019-05-03 14:52:40  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select *\n",
    "from spectrum_dim.customer_address\n",
    "limit 10;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another schema in Amazon Redshift to host the table, dim_customer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "create schema rs_dim;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create views to fetch the latest records from each source table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a view for the customer_master table, naming it `vw_cust_mstr_latest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "create view rs_dim.vw_cust_mstr_latest as with rows_numbered as (\n",
    "    select customer_id,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        employer_name,\n",
    "        row_audit_ts,\n",
    "        row_number() over(\n",
    "            partition by customer_id\n",
    "            order by row_audit_ts desc\n",
    "        ) as rnum\n",
    "    from spectrum_dim.customer_master\n",
    ")\n",
    "select customer_id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    employer_name,\n",
    "    row_audit_ts,\n",
    "    rnum\n",
    "from rows_numbered\n",
    "where rnum = 1 with no schema binding;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding query uses [row\\_number](https://docs.aws.amazon.com/redshift/latest/dg/r_WF_ROW_NUMBER.html), which is a window function provided by Amazon Redshift. Using window functions enables you to create analytic business queries more efficiently. Window functions operate on a partition of a result set, and return a value for every row in that window. The `row_number` window function determines the ordinal number of the current row within a group of rows, counting from 1, based on the ORDER BY expression in the OVER clause. By including the PARTITION BY clause as `customer_id`, groups are created for each value of `customer_id` and ordinal numbers are reset for each group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a view for the `customer_address` table, naming it `vw_cust_addr_latest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "create view rs_dim.vw_cust_addr_latest as with rows_numbered as (\n",
    "    select customer_id,\n",
    "        email_id,\n",
    "        city,\n",
    "        country,\n",
    "        row_audit_ts,\n",
    "        row_number() over(\n",
    "            partition by customer_id\n",
    "            order by row_audit_ts desc\n",
    "        ) as rnum\n",
    "    from spectrum_dim.customer_address\n",
    ")\n",
    "select customer_id,\n",
    "    email_id,\n",
    "    city,\n",
    "    country,\n",
    "    row_audit_ts,\n",
    "    rnum\n",
    "from rows_numbered\n",
    "where rnum = 1 with no schema binding;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both view definitions use the `row_number` window function of Amazon Redshift, ordering the records by descending order of the `row_audit_ts` column (the audit timestamp column). The condition `rnum=1` fetches the latest record for each `customer_id` value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dim\\_customer table in Amazon Redshift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `dim_customer` as an internal table in Amazon Redshift within the `rs_dim` schema. The dimension table includes the column `customer_sk`, that acts as the surrogate key column and enables us to capture a time-sensitive version of each customer record. The validity period for each record is defined by the columns `rec_eff_dt` and `rec_exp_dt`, representing record effective date and record expiry date, respectively. See the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "create table rs_dim.dim_customer (\n",
    "  customer_sk bigint, \n",
    "  customer_id bigint, \n",
    "  first_name varchar(100), \n",
    "  last_name varchar(100), \n",
    "  employer_name varchar(100), \n",
    "  email_id varchar(100), \n",
    "  city varchar(100), \n",
    "  country varchar(100), \n",
    "  rec_eff_dt date, \n",
    "  rec_exp_dt date\n",
    ") diststyle auto;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a view to consolidate the latest version of source records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the view `vw_dim_customer_src`, which consolidates the latest records from both source tables using `left outer join`, keeping them ready to be populated into the Amazon Redshift dimension table. This view fetches data from the latest views defined in the section “Create views to fetch the latest records from each source table”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "create view rs_dim.vw_dim_customer_src as\n",
    "select m.customer_id,\n",
    "    m.first_name,\n",
    "    m.last_name,\n",
    "    m.employer_name,\n",
    "    a.email_id,\n",
    "    a.city,\n",
    "    a.country\n",
    "from rs_dim.vw_cust_mstr_latest as m\n",
    "    left join rs_dim.vw_cust_addr_latest as a on m.customer_id = a.customer_id\n",
    "order by m.customer_id with no schema binding;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, this view fetches the initial data for loading into the `dim_customer` table that we are about to create. In your use-case, use a similar approach to create and join the required source table views to populate your target dimension table."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate initial data into dim\\_customer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate the initial data into the `dim_customer` table by querying the view `vw_dim_customer_src`. Because this is the initial data load, running row numbers generated by the `row_number` window function will suffice to populate a unique value in the `customer_sk` column starting from 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into rs_dim.dim_customer\n",
    "select row_number() over() as customer_sk,\n",
    "    customer_id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    employer_name,\n",
    "    email_id,\n",
    "    city,\n",
    "    country,\n",
    "    cast('2022-07-01' as date) rec_eff_dt,\n",
    "    cast('9999-12-31' as date) rec_exp_dt\n",
    "from rs_dim.vw_dim_customer_src;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this query, we have specified `’2022-07-01’` as the value in `rec_eff_dt` for all initial data records. For your use-case, you can modify this date value as appropriate to your situation.\n",
    "\n",
    "The preceding steps complete the initial data loading into the `dim_customer` table. In the next steps, we proceed with populating incremental data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Data Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land ongoing change data files in Amazon S3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial load, the source systems provide data files on an ongoing basis, either containing only new and change records or a full extract containing all records for a particular table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data from source\n",
    "! wget -q --show-progress https://github.com/datalaker/assets/files/11010580/customer_address_with_ts_incr.csv -O data/customer_address_with_ts_incr.csv\n",
    "! wget -q --show-progress https://github.com/datalaker/assets/files/11010581/customer_master_with_ts_incr.csv -O data/customer_master_with_ts_incr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/customer_address_with_ts_incr.csv to s3://wysde-datasets/customers/customer_address/customer_address_with_ts_incr.csv\n",
      "upload: data/customer_master_with_ts_incr.csv to s3://wysde-datasets/customers/customer_master/customer_master_with_ts_incr.csv\n"
     ]
    }
   ],
   "source": [
    "#load into s3\n",
    "! aws s3 cp data/customer_address_with_ts_incr.csv s3://wysde-datasets/customers/customer_address/customer_address_with_ts_incr.csv\n",
    "! aws s3 cp data/customer_master_with_ts_incr.csv s3://wysde-datasets/customers/customer_master/customer_master_with_ts_incr.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we have uploaded the incremental data for the `customer_master` and `customer_address` source tables with a few `customer_id` records receiving updates and a few new records being added."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a temporary table to capture change records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the temporary table `temp_dim_customer` to store all changes that need to be applied to the target `dim_customer` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "create temp table temp_dim_customer (\n",
    "    customer_sk bigint,\n",
    "    customer_id bigint,\n",
    "    first_name varchar(100),\n",
    "    last_name varchar(100),\n",
    "    employer_name varchar(100),\n",
    "    email_id varchar(100),\n",
    "    city varchar(100),\n",
    "    country varchar(100),\n",
    "    rec_eff_dt date,\n",
    "    rec_exp_dt date,\n",
    "    iud_operation character(1)\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the temporary table with new and changed records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a multi-step process that can be combined into a single complex SQL. Complete the following steps:\n",
    "\n",
    "1. Fetch the latest version of all customer attributes by querying the view `vw_dim_customer_src`.\n",
    "\n",
    "Amazon Redshift offers hashing functions such as [sha2](https://docs.aws.amazon.com/redshift/latest/dg/SHA2.html), which converts a variable length string input into a fixed length character output. The output string is a text representation of the hexadecimal value of the checksum with the specified number of bits. In this case, we pass a concatenated set of customer attributes whose change we want to track, specifying the number of bits as 512. We’ll use the output of the hash function to determine if any of the attributes have undergone a change. This dataset will be called `newver` (new version).\n",
    "\n",
    "Because we landed the ongoing change data in the same location as the initial data files, the records retrieved from the preceding query (in `newver`) include all records, even the unchanged ones. But because of the definition of the view `vw_dim_customer_src`, we get only one record per customerid, which is its latest version based on `row_audit_ts`.\n",
    "\n",
    "2. In a similar manner, retrieve the latest version of all customer records from `dim_customer`, which are identified by `rec_exp_dt=‘9999-12-31’`. While doing so, also retrieve the `sha2` value of all customer attributes available in `dim_customer`. This dataset will be called oldver (old or existing version).\n",
    "3. Identify the current maximum surrogate key value from the `dim_customer` table.\n",
    "\n",
    "This value (maxval) will be added to the row_number before being used as the customer_sk value for the change records that need to be inserted.\n",
    "\n",
    "4. Perform a full outer join of the old version of records (`oldver`) and the new version (`newver`) of records on the `customer_id` column. Then compare the old and new hash values generated by the `sha2` function to determine if the change record is an insert, update, or delete.\n",
    "\n",
    "We tag the records as follows:\n",
    "\n",
    "- If the `customer_id` is non-existent in the `oldver` dataset (`oldver.customer_id is null`), it’s tagged as an insert (`‘I'`).\n",
    "- Otherwise, if the `customer_id` is non-existent in the `newver` dataset (`newver.customer_id is null`), it’s tagged as a delete (`‘D'`).\n",
    "- Otherwise, if the old `hash_value` and new `hash_value` are different, these records represent an update (`‘U'`).\n",
    "- Otherwise, it indicates that the record has not undergone any change and therefore can be ignored or marked as not-to-be-processed (`‘N'`).\n",
    "\n",
    "Make sure to modify the preceding logic if the source extract contains `rec_source_status` to identify deleted records.\n",
    "\n",
    "Although `sha2` output maps a possibly infinite set of input strings to a finite set of output strings, the chances of collision of hash values for the original row values and changed row values are very unlikely. Instead of individually comparing each column value before and after, we compare the hash values generated by `sha2` to conclude if there has been a change in any of the attributes of the customer record. For your use-case, we recommend you choose a [hash function](https://docs.aws.amazon.com/redshift/latest/dg/hash-functions.html) that works for your data conditions after adequate testing. Instead, you can compare individual column values if none of the hash functions satisfactorily meet your expectations.\n",
    "\n",
    "5. Combining the outputs from the preceding steps, let’s create the INSERT statement that captures only change records to populate the temporary table."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since we are receiving incremental data from source we will receive only I's, U's In case D records are also received, it is expected that there will be a STATUS column with INACTIVE as value Which will be treated as U and existing latest record will be expired. In case of full refresh, the below query will also retrieve D type records against all PK values which are absent in the latest snapshot."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate all new inserts and updates to the temp_dim_customer table by using query below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into temp_dim_customer (\n",
    "        customer_sk,\n",
    "        customer_id,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        employer_name,\n",
    "        email_id,\n",
    "        city,\n",
    "        country,\n",
    "        rec_eff_dt,\n",
    "        rec_exp_dt,\n",
    "        iud_operation\n",
    "    ) with newt as (\n",
    "        select customer_id,\n",
    "            sha2(\n",
    "                coalesce(first_name, '') || coalesce(last_name, '') || coalesce(employer_name, '') || coalesce(email_id, '') || coalesce(city, '') || coalesce(country, ''),\n",
    "                512\n",
    "            ) as hash_value,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            employer_name,\n",
    "            email_id,\n",
    "            city,\n",
    "            country,\n",
    "            current_date rec_eff_dt,\n",
    "            cast('9999-12-31' as date) rec_exp_dt\n",
    "        from rs_dim.vw_dim_customer_src\n",
    "    ),\n",
    "    oldt as (\n",
    "        select customer_id,\n",
    "            sha2(\n",
    "                coalesce(first_name, '') || coalesce(last_name, '') || coalesce(employer_name, '') || coalesce(email_id, '') || coalesce(city, '') || coalesce(country, ''),\n",
    "                512\n",
    "            ) as hash_value,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            employer_name,\n",
    "            email_id,\n",
    "            city,\n",
    "            country\n",
    "        from rs_dim.dim_customer\n",
    "        where rec_exp_dt = '9999-12-31'\n",
    "    ),\n",
    "    maxsk as (\n",
    "        select max(customer_sk) as maxval\n",
    "        from rs_dim.dim_customer\n",
    "    ),\n",
    "    allrecs as (\n",
    "        select coalesce(oldt.customer_id, newt.customer_id) as customer_id,\n",
    "            case\n",
    "                when oldt.customer_id is null then 'I'\n",
    "                when newt.customer_id is null then 'D'\n",
    "                when oldt.hash_value != newt.hash_value then 'U'\n",
    "                else 'N'\n",
    "            end as iud_op,\n",
    "            newt.first_name,\n",
    "            newt.last_name,\n",
    "            newt.employer_name,\n",
    "            newt.email_id,\n",
    "            newt.city,\n",
    "            newt.country,\n",
    "            newt.rec_eff_dt,\n",
    "            newt.rec_exp_dt\n",
    "        from oldt\n",
    "            full outer join newt on oldt.customer_id = newt.customer_id\n",
    "    )\n",
    "select (maxval +(row_number() over())) as customer_sk,\n",
    "    customer_id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    employer_name,\n",
    "    email_id,\n",
    "    city,\n",
    "    country,\n",
    "    rec_eff_dt,\n",
    "    rec_exp_dt,\n",
    "    iud_op\n",
    "from allrecs,\n",
    "    maxsk\n",
    "where iud_op != 'N';"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expire updated customer records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `temp_dim_customer` table now containing only the change records (either `‘I’`, `‘U’`, or `‘D’`), the same can be applied on the target `dim_customer` table.\n",
    "\n",
    "Let’s first fetch all records with values `‘U’` or `‘D’` in the `iud_op` column. These are records that have either been deleted or updated in the source system. Because `dim_customer` is a slowly changing dimension, it needs to reflect the validity period of each customer record. In this case, we expire the presently active records that have been updated or deleted. We expire these records as of yesterday (by setting `rec_exp_dt=current_date-1`) matching on the `customer_id` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "update rs_dim.dim_customer\n",
    "set rec_exp_dt = current_date -1\n",
    "where customer_id in (\n",
    "        select customer_id\n",
    "        from temp_dim_customer as t\n",
    "        where iud_operation in ('U', 'D')\n",
    "    )\n",
    "    and rec_exp_dt = '9999-12-31';"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert new and changed records"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, we need to insert the newer version of updated records along with all first-time inserts. These are indicated by `‘U’` and `‘I’`, respectively, in the `iud_op` column in the `temp_dim_customer` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "insert into rs_dim.dim_customer (\n",
    "        customer_sk,\n",
    "        customer_id,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        employer_name,\n",
    "        email_id,\n",
    "        city,\n",
    "        country,\n",
    "        rec_eff_dt,\n",
    "        rec_exp_dt\n",
    "    )\n",
    "select customer_sk,\n",
    "    customer_id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    employer_name,\n",
    "    email_id,\n",
    "    city,\n",
    "    country,\n",
    "    rec_eff_dt,\n",
    "    rec_exp_dt\n",
    "from temp_dim_customer\n",
    "where iud_operation in ('I', 'U');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the SQL client setting, you might want to run a `commit transaction;` command to verify that the preceding changes are persisted successfully in Amazon Redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql commit;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the final output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following query and see that the `dim_customer` table now contains both the initial data records plus the incremental data records, capturing multiple versions for those `customer_id` values that got changed as part of incremental data loading. The output also indicates that each record has been populated with appropriate values in `rec_eff_dt` and `rec_exp_dt` corresponding to the record validity period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_sk</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>employer_name</th>\n",
       "      <th>email_id</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>rec_eff_dt</th>\n",
       "      <th>rec_exp_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Gladys</td>\n",
       "      <td>Rim</td>\n",
       "      <td>RIM Inc.</td>\n",
       "      <td>gladys.rim@rim.org</td>\n",
       "      <td>NYC</td>\n",
       "      <td>USA</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Yuki</td>\n",
       "      <td>Whobrey</td>\n",
       "      <td>Reims Collectables</td>\n",
       "      <td>yuki_whobrey@aol.com</td>\n",
       "      <td>Reims</td>\n",
       "      <td>France</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2023-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Yuki</td>\n",
       "      <td>Whobrey</td>\n",
       "      <td>Collectica Inc</td>\n",
       "      <td>yuki_whobrey@collectica.com</td>\n",
       "      <td>Reims</td>\n",
       "      <td>France</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Fletcher</td>\n",
       "      <td>Flosi</td>\n",
       "      <td>Lyon Souveniers</td>\n",
       "      <td>fletcher.flosi@yahoo.com</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Bette</td>\n",
       "      <td>Nicka</td>\n",
       "      <td>Toys4GrownUps.com</td>\n",
       "      <td>bette_nicka@cox.net</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>USA</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2023-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Bette</td>\n",
       "      <td>Nicka</td>\n",
       "      <td>Souveniers Inc</td>\n",
       "      <td>bette_nicka@souveniers.com</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Vinouye</td>\n",
       "      <td>Foller</td>\n",
       "      <td>Corporate Gift Ideas Co.</td>\n",
       "      <td>vinouye@aol.com</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>USA</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>101</td>\n",
       "      <td>Arun</td>\n",
       "      <td>Raman</td>\n",
       "      <td>Land of Toys Inc.</td>\n",
       "      <td>arun.raman@lotoys.org</td>\n",
       "      <td>NYC</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>102</td>\n",
       "      <td>Ganapathy</td>\n",
       "      <td>Krish</td>\n",
       "      <td>Amazing Toys</td>\n",
       "      <td>krish.ganapathy@amazingtoys.com</td>\n",
       "      <td>Reims</td>\n",
       "      <td>France</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>103</td>\n",
       "      <td>William</td>\n",
       "      <td>Butt</td>\n",
       "      <td>Toyzomaniac Inc.</td>\n",
       "      <td>william.butt@yahoo.com</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>2023-03-19</td>\n",
       "      <td>9999-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_sk  customer_id first_name last_name             employer_name  \\\n",
       "0            1            1     Gladys       Rim                  RIM Inc.   \n",
       "1            5            2       Yuki   Whobrey        Reims Collectables   \n",
       "2            9            2       Yuki   Whobrey            Collectica Inc   \n",
       "3            3            3   Fletcher     Flosi           Lyon Souveniers   \n",
       "4            2            4      Bette     Nicka         Toys4GrownUps.com   \n",
       "5            6            4      Bette     Nicka            Souveniers Inc   \n",
       "6            4            5    Vinouye    Foller  Corporate Gift Ideas Co.   \n",
       "7            7          101       Arun     Raman         Land of Toys Inc.   \n",
       "8            8          102  Ganapathy     Krish              Amazing Toys   \n",
       "9           10          103    William      Butt          Toyzomaniac Inc.   \n",
       "\n",
       "                          email_id           city country  rec_eff_dt  \\\n",
       "0               gladys.rim@rim.org            NYC     USA  2022-07-01   \n",
       "1             yuki_whobrey@aol.com          Reims  France  2022-07-01   \n",
       "2      yuki_whobrey@collectica.com          Reims  France  2023-03-19   \n",
       "3         fletcher.flosi@yahoo.com          Paris  France  2022-07-01   \n",
       "4              bette_nicka@cox.net       Pasadena     USA  2022-07-01   \n",
       "5       bette_nicka@souveniers.com       Pasadena     USA  2023-03-19   \n",
       "6                  vinouye@aol.com  San Francisco     USA  2022-07-01   \n",
       "7            arun.raman@lotoys.org            NYC     USA  2023-03-19   \n",
       "8  krish.ganapathy@amazingtoys.com          Reims  France  2023-03-19   \n",
       "9           william.butt@yahoo.com          Paris  France  2023-03-19   \n",
       "\n",
       "   rec_exp_dt  \n",
       "0  9999-12-31  \n",
       "1  2023-03-18  \n",
       "2  9999-12-31  \n",
       "3  9999-12-31  \n",
       "4  2023-03-18  \n",
       "5  9999-12-31  \n",
       "6  9999-12-31  \n",
       "7  9999-12-31  \n",
       "8  9999-12-31  \n",
       "9  9999-12-31  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "select *\n",
    "from rs_dim.dim_customer\n",
    "order by customer_id,\n",
    "    customer_sk;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you learned how to simplify data loading into Type-2 SCD tables in Amazon Redshift, covering both initial data loading and incremental data loading. The approach deals with multiple source tables populating a target dimension table, capturing the latest version of source records as of each run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
