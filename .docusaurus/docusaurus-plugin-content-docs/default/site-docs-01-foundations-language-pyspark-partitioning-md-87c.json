{
  "unversionedId": "foundations/language/pyspark/partitioning",
  "id": "foundations/language/pyspark/partitioning",
  "title": "Partitioning",
  "description": "A partition in spark is a logical chunk of data mapped to a single node in a cluster. Partitions are basic units of parallelism. Each partition is processed by a single task slot. In a multicore system, total slots for tasks will be num of executors x number of cores. Hence the number of partitions decides the task parallelism.",
  "source": "@site/docs/01-foundations/language/pyspark/partitioning.md",
  "sourceDirName": "01-foundations/language/pyspark",
  "slug": "/foundations/language/pyspark/partitioning",
  "permalink": "/docs/foundations/language/pyspark/partitioning",
  "draft": false,
  "tags": [],
  "version": "current",
  "lastUpdatedBy": "sparsh",
  "lastUpdatedAt": 1681451444,
  "formattedLastUpdatedAt": "Apr 14, 2023",
  "frontMatter": {},
  "sidebar": "docs",
  "previous": {
    "title": "Methods, Operations and Functions",
    "permalink": "/docs/foundations/language/pyspark/methods-operations"
  },
  "next": {
    "title": "Lazy Processing",
    "permalink": "/docs/foundations/language/pyspark/lazy-processing"
  }
}