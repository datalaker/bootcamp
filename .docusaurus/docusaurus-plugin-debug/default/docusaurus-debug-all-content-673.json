{
  "docusaurus-plugin-content-docs": {
    "default": {
      "loadedVersions": [
        {
          "versionName": "current",
          "label": "Next",
          "banner": null,
          "badge": false,
          "noIndex": false,
          "className": "docs-version-current",
          "path": "/docs",
          "tagsPath": "/docs/tags",
          "isLast": true,
          "routePriority": -1,
          "sidebarFilePath": "/Users/sparshagarwal/Desktop/projects/de/de-main/sidebars.js",
          "contentPath": "/Users/sparshagarwal/Desktop/projects/de/de-main/docs",
          "contentPathLocalized": "/Users/sparshagarwal/Desktop/projects/de/de-main/i18n/en/docusaurus-plugin-content-docs/current",
          "docs": [
            {
              "unversionedId": "assignments/bellabeat-analysis/README",
              "id": "assignments/bellabeat-analysis/README",
              "title": "Bellabeat Case Study",
              "description": "How can a wellness company play it smart?",
              "source": "@site/docs/11-assignments/bellabeat-analysis/README.md",
              "sourceDirName": "11-assignments/bellabeat-analysis",
              "slug": "/assignments/bellabeat-analysis/",
              "permalink": "/docs/assignments/bellabeat-analysis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/cyclistic-analysis/README",
              "id": "assignments/cyclistic-analysis/README",
              "title": "Cyclistic Case Study",
              "description": "How does a bike-share navigate speedy success?",
              "source": "@site/docs/11-assignments/cyclistic-analysis/README.md",
              "sourceDirName": "11-assignments/cyclistic-analysis",
              "slug": "/assignments/cyclistic-analysis/",
              "permalink": "/docs/assignments/cyclistic-analysis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/florida-panthers/README",
              "id": "assignments/florida-panthers/README",
              "title": "NHLAPI - SQL and Python Assignment",
              "description": "Objective",
              "source": "@site/docs/11-assignments/florida-panthers/README.md",
              "sourceDirName": "11-assignments/florida-panthers",
              "slug": "/assignments/florida-panthers/",
              "permalink": "/docs/assignments/florida-panthers/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/healthverity/README",
              "id": "assignments/healthverity/README",
              "title": "HealthVerity",
              "description": "Thank you for taking the time to consider HealthVerity and our Data QA Engineer position. Your skills and experience line up well with what we are seeking in this role and we'd like to have you move forward in the process. Below are a few questions we'd invite you to consider and respond to in a separate text document.",
              "source": "@site/docs/11-assignments/healthverity/README.md",
              "sourceDirName": "11-assignments/healthverity",
              "slug": "/assignments/healthverity/",
              "permalink": "/docs/assignments/healthverity/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/klodars-datalake-design/README",
              "id": "assignments/klodars-datalake-design/README",
              "title": "Klodars Datalake Design",
              "description": "Problem Statement",
              "source": "@site/docs/11-assignments/klodars-datalake-design/README.md",
              "sourceDirName": "11-assignments/klodars-datalake-design",
              "slug": "/assignments/klodars-datalake-design/",
              "permalink": "/docs/assignments/klodars-datalake-design/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/logsense/README",
              "id": "assignments/logsense/README",
              "title": "Logsense",
              "description": "Lab 1: Apache Server Log Analysis",
              "source": "@site/docs/11-assignments/logsense/README.md",
              "sourceDirName": "11-assignments/logsense",
              "slug": "/assignments/logsense/",
              "permalink": "/docs/assignments/logsense/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/mistplay-takehome/README",
              "id": "assignments/mistplay-takehome/README",
              "title": "Mistplay Data Engineer Take Home Challenge",
              "description": "This is an exercise for you to demonstrate your design and implementation skills to solve a typical data engineering problem.",
              "source": "@site/docs/11-assignments/mistplay-takehome/README.md",
              "sourceDirName": "11-assignments/mistplay-takehome",
              "slug": "/assignments/mistplay-takehome/",
              "permalink": "/docs/assignments/mistplay-takehome/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/mysql-s3-incremental/README",
              "id": "assignments/mysql-s3-incremental/README",
              "title": "Reading data from MySQL in CSV and saving into S3",
              "description": "In this lab, we are loading the data from RDS MySQL Database into CSV and then saving that csv into S3 using Boto3.",
              "source": "@site/docs/11-assignments/mysql-s3-incremental/README.md",
              "sourceDirName": "11-assignments/mysql-s3-incremental",
              "slug": "/assignments/mysql-s3-incremental/",
              "permalink": "/docs/assignments/mysql-s3-incremental/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/olx-python/README",
              "id": "assignments/olx-python/README",
              "title": "OLX Data Engineering Challenge",
              "description": "Tasks",
              "source": "@site/docs/11-assignments/olx-python/README.md",
              "sourceDirName": "11-assignments/olx-python",
              "slug": "/assignments/olx-python/",
              "permalink": "/docs/assignments/olx-python/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/sakila/README",
              "id": "assignments/sakila/README",
              "title": "Batch and Stream Unified analytics for Sakila Music Company",
              "description": "Problem Statement",
              "source": "@site/docs/11-assignments/sakila/README.md",
              "sourceDirName": "11-assignments/sakila",
              "slug": "/assignments/sakila/",
              "permalink": "/docs/assignments/sakila/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/spiff-takehome/README",
              "id": "assignments/spiff-takehome/README",
              "title": "Spiff Data Engineering Candidate Coding Exercises",
              "description": "This is the repo for the data engineering exercise that is part of the interview process for a data engineering role at Spiff.",
              "source": "@site/docs/11-assignments/spiff-takehome/README.md",
              "sourceDirName": "11-assignments/spiff-takehome",
              "slug": "/assignments/spiff-takehome/",
              "permalink": "/docs/assignments/spiff-takehome/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/spotify-extract-load/README",
              "id": "assignments/spotify-extract-load/README",
              "title": "Spotify Extract Load Airflow",
              "description": "arch drawio",
              "source": "@site/docs/11-assignments/spotify-extract-load/README.md",
              "sourceDirName": "11-assignments/spotify-extract-load",
              "slug": "/assignments/spotify-extract-load/",
              "permalink": "/docs/assignments/spotify-extract-load/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/ternary/README",
              "id": "assignments/ternary/README",
              "title": "Ternary",
              "description": "Prompt",
              "source": "@site/docs/11-assignments/ternary/README.md",
              "sourceDirName": "11-assignments/ternary",
              "slug": "/assignments/ternary/",
              "permalink": "/docs/assignments/ternary/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "assignments/twitter-s3/README",
              "id": "assignments/twitter-s3/README",
              "title": "Assignment: Extract Data from Twitter API and Load into AWS S3",
              "description": "",
              "source": "@site/docs/11-assignments/twitter-s3/README.md",
              "sourceDirName": "11-assignments/twitter-s3",
              "slug": "/assignments/twitter-s3/",
              "permalink": "/docs/assignments/twitter-s3/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/acled/README",
              "id": "capstones/acled/README",
              "title": "ACLED",
              "description": "Objective",
              "source": "@site/docs/12-capstones/acled/README.md",
              "sourceDirName": "12-capstones/acled",
              "slug": "/capstones/acled/",
              "permalink": "/docs/capstones/acled/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Serverless Streaming Data on AWS",
                "permalink": "/docs/capstones/ServerlessStreamingApp/"
              },
              "next": {
                "title": "Citi Bike Trip Histories",
                "permalink": "/docs/capstones/citibike-trip-histories/"
              }
            },
            {
              "unversionedId": "capstones/citibike-trip-histories/README",
              "id": "capstones/citibike-trip-histories/README",
              "title": "Citi Bike Trip Histories",
              "description": "The goal of this capstone is to build an end-to-end data pipeline:",
              "source": "@site/docs/12-capstones/citibike-trip-histories/README.md",
              "sourceDirName": "12-capstones/citibike-trip-histories",
              "slug": "/capstones/citibike-trip-histories/",
              "permalink": "/docs/capstones/citibike-trip-histories/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "ACLED",
                "permalink": "/docs/capstones/acled/"
              },
              "next": {
                "title": "Air Pollution Pipeline",
                "permalink": "/docs/capstones/city-pollution/"
              }
            },
            {
              "unversionedId": "capstones/city-pollution/README",
              "id": "capstones/city-pollution/README",
              "title": "Air Pollution Pipeline",
              "description": "",
              "source": "@site/docs/12-capstones/city-pollution/README.md",
              "sourceDirName": "12-capstones/city-pollution",
              "slug": "/capstones/city-pollution/",
              "permalink": "/docs/capstones/city-pollution/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Citi Bike Trip Histories",
                "permalink": "/docs/capstones/citibike-trip-histories/"
              },
              "next": {
                "title": "Airflow - City Traffic Drone",
                "permalink": "/docs/capstones/city-traffic-drone/"
              }
            },
            {
              "unversionedId": "capstones/city-traffic-drone/README",
              "id": "capstones/city-traffic-drone/README",
              "title": "Airflow - City Traffic Drone",
              "description": "City Vehicle Trajactories Data extraction and warehousing for Traffic analysis",
              "source": "@site/docs/12-capstones/city-traffic-drone/README.md",
              "sourceDirName": "12-capstones/city-traffic-drone",
              "slug": "/capstones/city-traffic-drone/",
              "permalink": "/docs/capstones/city-traffic-drone/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Air Pollution Pipeline",
                "permalink": "/docs/capstones/city-pollution/"
              },
              "next": {
                "title": "Global Historical Climatology Network Daily Data Pipeline",
                "permalink": "/docs/capstones/climate/"
              }
            },
            {
              "unversionedId": "capstones/climate/README",
              "id": "capstones/climate/README",
              "title": "Global Historical Climatology Network Daily Data Pipeline",
              "description": "Objective",
              "source": "@site/docs/12-capstones/climate/README.md",
              "sourceDirName": "12-capstones/climate",
              "slug": "/capstones/climate/",
              "permalink": "/docs/capstones/climate/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Airflow - City Traffic Drone",
                "permalink": "/docs/capstones/city-traffic-drone/"
              },
              "next": {
                "title": "Building End to end data pipeline in AWS",
                "permalink": "/docs/capstones/cloudmaze/"
              }
            },
            {
              "unversionedId": "capstones/cloudmaze/README",
              "id": "capstones/cloudmaze/README",
              "title": "Building End to end data pipeline in AWS",
              "description": "Architecture Diagram",
              "source": "@site/docs/12-capstones/cloudmaze/README.md",
              "sourceDirName": "12-capstones/cloudmaze",
              "slug": "/capstones/cloudmaze/",
              "permalink": "/docs/capstones/cloudmaze/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Global Historical Climatology Network Daily Data Pipeline",
                "permalink": "/docs/capstones/climate/"
              },
              "next": {
                "title": "README",
                "permalink": "/docs/capstones/dbt-redshift/"
              }
            },
            {
              "unversionedId": "capstones/dbt-redshift/README",
              "id": "capstones/dbt-redshift/README",
              "title": "README",
              "description": "Objective",
              "source": "@site/docs/12-capstones/dbt-redshift/README.md",
              "sourceDirName": "12-capstones/dbt-redshift",
              "slug": "/capstones/dbt-redshift/",
              "permalink": "/docs/capstones/dbt-redshift/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Building End to end data pipeline in AWS",
                "permalink": "/docs/capstones/cloudmaze/"
              },
              "next": {
                "title": "DigitalSkola",
                "permalink": "/docs/capstones/digitalskola/"
              }
            },
            {
              "unversionedId": "capstones/digitalskola/README",
              "id": "capstones/digitalskola/README",
              "title": "DigitalSkola",
              "description": "Objective",
              "source": "@site/docs/12-capstones/digitalskola/README.md",
              "sourceDirName": "12-capstones/digitalskola",
              "slug": "/capstones/digitalskola/",
              "permalink": "/docs/capstones/digitalskola/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "README",
                "permalink": "/docs/capstones/dbt-redshift/"
              },
              "next": {
                "title": "Disaster Response Pipeline",
                "permalink": "/docs/capstones/disaster-response/"
              }
            },
            {
              "unversionedId": "capstones/disaster-response/README",
              "id": "capstones/disaster-response/README",
              "title": "Disaster Response Pipeline",
              "description": "wall",
              "source": "@site/docs/12-capstones/disaster-response/README.md",
              "sourceDirName": "12-capstones/disaster-response",
              "slug": "/capstones/disaster-response/",
              "permalink": "/docs/capstones/disaster-response/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "DigitalSkola",
                "permalink": "/docs/capstones/digitalskola/"
              },
              "next": {
                "title": "Funflix",
                "permalink": "/docs/capstones/funflix/"
              }
            },
            {
              "unversionedId": "capstones/funflix/README",
              "id": "capstones/funflix/README",
              "title": "Funflix",
              "description": "You are working as a data engineer in an Australian media company Funflix. You got the following requirements and tasks to solve.",
              "source": "@site/docs/12-capstones/funflix/README.md",
              "sourceDirName": "12-capstones/funflix",
              "slug": "/capstones/funflix/",
              "permalink": "/docs/capstones/funflix/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Disaster Response Pipeline",
                "permalink": "/docs/capstones/disaster-response/"
              },
              "next": {
                "title": "Datalake Schema Correction",
                "permalink": "/docs/capstones/hmc/"
              }
            },
            {
              "unversionedId": "capstones/hmc/README",
              "id": "capstones/hmc/README",
              "title": "Datalake Schema Correction",
              "description": "Objective",
              "source": "@site/docs/12-capstones/hmc/README.md",
              "sourceDirName": "12-capstones/hmc",
              "slug": "/capstones/hmc/",
              "permalink": "/docs/capstones/hmc/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Funflix",
                "permalink": "/docs/capstones/funflix/"
              },
              "next": {
                "title": "Log Analytics and Processing in Real-Time",
                "permalink": "/docs/capstones/kinesis-flink-beam/"
              }
            },
            {
              "unversionedId": "capstones/kinesis-flink-beam/README",
              "id": "capstones/kinesis-flink-beam/README",
              "title": "Log Analytics and Processing in Real-Time",
              "description": "Lab 1: Apache Flink on Amazon Kinesis Data Analytics",
              "source": "@site/docs/12-capstones/kinesis-flink-beam/README.md",
              "sourceDirName": "12-capstones/kinesis-flink-beam",
              "slug": "/capstones/kinesis-flink-beam/",
              "permalink": "/docs/capstones/kinesis-flink-beam/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Datalake Schema Correction",
                "permalink": "/docs/capstones/hmc/"
              },
              "next": {
                "title": "Streaming ETL pipeline with Apache Flink and Amazon Kinesis Data Analytics",
                "permalink": "/docs/capstones/kinesis-flink-etl/"
              }
            },
            {
              "unversionedId": "capstones/kinesis-flink-etl/README",
              "id": "capstones/kinesis-flink-etl/README",
              "title": "Streaming ETL pipeline with Apache Flink and Amazon Kinesis Data Analytics",
              "description": "We will create an Amazon Kinesis Data Analytics for Apache Flink application with Amazon Kinesis Data Streams as a source and a Amazon S3 bucket as a sink. Random data is ingested using Amazon Kinesis Data Generator. The Apache Flink application code performs a word count on the streaming random data using a tumbling window of 5 minutes. The generated word count is then stored in the specified Amazon S3 bucket. Amazon Athena is used to query data generated in the Amazon S3 bucket to validate the end results.",
              "source": "@site/docs/12-capstones/kinesis-flink-etl/README.md",
              "sourceDirName": "12-capstones/kinesis-flink-etl",
              "slug": "/capstones/kinesis-flink-etl/",
              "permalink": "/docs/capstones/kinesis-flink-etl/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Log Analytics and Processing in Real-Time",
                "permalink": "/docs/capstones/kinesis-flink-beam/"
              },
              "next": {
                "title": "Kortex",
                "permalink": "/docs/capstones/kortex/"
              }
            },
            {
              "unversionedId": "capstones/kortex/README",
              "id": "capstones/kortex/README",
              "title": "Kortex",
              "description": "Objectives",
              "source": "@site/docs/12-capstones/kortex/README.md",
              "sourceDirName": "12-capstones/kortex",
              "slug": "/capstones/kortex/",
              "permalink": "/docs/capstones/kortex/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Streaming ETL pipeline with Apache Flink and Amazon Kinesis Data Analytics",
                "permalink": "/docs/capstones/kinesis-flink-etl/"
              },
              "next": {
                "title": "Lufthansa API",
                "permalink": "/docs/capstones/lufthansa/"
              }
            },
            {
              "unversionedId": "capstones/lufthansa/README",
              "id": "capstones/lufthansa/README",
              "title": "Lufthansa API",
              "description": "Objective",
              "source": "@site/docs/12-capstones/lufthansa/README.md",
              "sourceDirName": "12-capstones/lufthansa",
              "slug": "/capstones/lufthansa/",
              "permalink": "/docs/capstones/lufthansa/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Kortex",
                "permalink": "/docs/capstones/kortex/"
              },
              "next": {
                "title": "Movie Review Sentiment Analysis Pipeline",
                "permalink": "/docs/capstones/movie-sentiment/"
              }
            },
            {
              "unversionedId": "capstones/movie-sentiment/README",
              "id": "capstones/movie-sentiment/README",
              "title": "Movie Review Sentiment Analysis Pipeline",
              "description": "Build a pipeline that expresses the fact artist review sentiment and film review sentiment, based on the data provided by IMDb and TMDb.",
              "source": "@site/docs/12-capstones/movie-sentiment/README.md",
              "sourceDirName": "12-capstones/movie-sentiment",
              "slug": "/capstones/movie-sentiment/",
              "permalink": "/docs/capstones/movie-sentiment/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lufthansa API",
                "permalink": "/docs/capstones/lufthansa/"
              },
              "next": {
                "title": "Multi-touch Attribution",
                "permalink": "/docs/capstones/multi-touch-attribution/"
              }
            },
            {
              "unversionedId": "capstones/multi-touch-attribution/README",
              "id": "capstones/multi-touch-attribution/README",
              "title": "Multi-touch Attribution",
              "description": "Abstract",
              "source": "@site/docs/12-capstones/multi-touch-attribution/README.md",
              "sourceDirName": "12-capstones/multi-touch-attribution",
              "slug": "/capstones/multi-touch-attribution/",
              "permalink": "/docs/capstones/multi-touch-attribution/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Movie Review Sentiment Analysis Pipeline",
                "permalink": "/docs/capstones/movie-sentiment/"
              },
              "next": {
                "title": "Building Recommender System from Scratch",
                "permalink": "/docs/capstones/recofront/"
              }
            },
            {
              "unversionedId": "capstones/other/covid19-datalake/README",
              "id": "capstones/other/covid19-datalake/README",
              "title": "Covid-19 Data Pipeline",
              "description": "Objective",
              "source": "@site/docs/12-capstones/other/covid19-datalake/README.md",
              "sourceDirName": "12-capstones/other/covid19-datalake",
              "slug": "/capstones/other/covid19-datalake/",
              "permalink": "/docs/capstones/other/covid19-datalake/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/data-ingestion-pulumi-lambda-snowflake/README",
              "id": "capstones/other/data-ingestion-pulumi-lambda-snowflake/README",
              "title": "paas-data-ingestion",
              "description": "Ingest and prepare data with AWS lambdas, Snowflake and dbt in a scalable, fully replayable manner.",
              "source": "@site/docs/12-capstones/other/data-ingestion-pulumi-lambda-snowflake/README.md",
              "sourceDirName": "12-capstones/other/data-ingestion-pulumi-lambda-snowflake",
              "slug": "/capstones/other/data-ingestion-pulumi-lambda-snowflake/",
              "permalink": "/docs/capstones/other/data-ingestion-pulumi-lambda-snowflake/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/equitize/README",
              "id": "capstones/other/equitize/README",
              "title": "Equitize Data Migration",
              "description": "Financial Data Extraction and Storage",
              "source": "@site/docs/12-capstones/other/equitize/README.md",
              "sourceDirName": "12-capstones/other/equitize",
              "slug": "/capstones/other/equitize/",
              "permalink": "/docs/capstones/other/equitize/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/fireflow/airflow/notes",
              "id": "capstones/other/fireflow/airflow/notes",
              "title": "notes",
              "description": "1. How to set project",
              "source": "@site/docs/12-capstones/other/fireflow/airflow/notes.md",
              "sourceDirName": "12-capstones/other/fireflow/airflow",
              "slug": "/capstones/other/fireflow/airflow/notes",
              "permalink": "/docs/capstones/other/fireflow/airflow/notes",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/fireflow/README",
              "id": "capstones/other/fireflow/README",
              "title": "Build an ELT pipeline with NYC Taxi dataset",
              "description": "Objective",
              "source": "@site/docs/12-capstones/other/fireflow/README.md",
              "sourceDirName": "12-capstones/other/fireflow",
              "slug": "/capstones/other/fireflow/",
              "permalink": "/docs/capstones/other/fireflow/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/loop-analytics/README",
              "id": "capstones/other/loop-analytics/README",
              "title": "Loop Analytics",
              "description": "Extracing data and loading it to Redshift, and a dbt project for transforming it.",
              "source": "@site/docs/12-capstones/other/loop-analytics/README.md",
              "sourceDirName": "12-capstones/other/loop-analytics",
              "slug": "/capstones/other/loop-analytics/",
              "permalink": "/docs/capstones/other/loop-analytics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/patent-analytics/README",
              "id": "capstones/other/patent-analytics/README",
              "title": "Patent Analytics Data Pipeline",
              "description": "front",
              "source": "@site/docs/12-capstones/other/patent-analytics/README.md",
              "sourceDirName": "12-capstones/other/patent-analytics",
              "slug": "/capstones/other/patent-analytics/",
              "permalink": "/docs/capstones/other/patent-analytics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/patent-analytics/REPORT",
              "id": "capstones/other/patent-analytics/REPORT",
              "title": "Patent Analytics Data Pipeline",
              "description": "Introduction",
              "source": "@site/docs/12-capstones/other/patent-analytics/REPORT.md",
              "sourceDirName": "12-capstones/other/patent-analytics",
              "slug": "/capstones/other/patent-analytics/REPORT",
              "permalink": "/docs/capstones/other/patent-analytics/REPORT",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/patent-analytics/SETUP",
              "id": "capstones/other/patent-analytics/SETUP",
              "title": "Getting Started",
              "description": "Prerequisites",
              "source": "@site/docs/12-capstones/other/patent-analytics/SETUP.md",
              "sourceDirName": "12-capstones/other/patent-analytics",
              "slug": "/capstones/other/patent-analytics/SETUP",
              "permalink": "/docs/capstones/other/patent-analytics/SETUP",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/patent-analytics/spark/README",
              "id": "capstones/other/patent-analytics/spark/README",
              "title": "Patents Analytics Spark",
              "description": "This folder contains the pyspark scripts used for cleaning, performing keyword extraction, and doing the ETL job for patents analytics data.",
              "source": "@site/docs/12-capstones/other/patent-analytics/spark/README.md",
              "sourceDirName": "12-capstones/other/patent-analytics/spark",
              "slug": "/capstones/other/patent-analytics/spark/",
              "permalink": "/docs/capstones/other/patent-analytics/spark/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/reddit-kafka-sparkstream-bigquery/README",
              "id": "capstones/other/reddit-kafka-sparkstream-bigquery/README",
              "title": "reddit-data-engineering of r/FedEx",
              "description": "- Create Kafka cluster using docker-compose hosted on GCP VM",
              "source": "@site/docs/12-capstones/other/reddit-kafka-sparkstream-bigquery/README.md",
              "sourceDirName": "12-capstones/other/reddit-kafka-sparkstream-bigquery",
              "slug": "/capstones/other/reddit-kafka-sparkstream-bigquery/",
              "permalink": "/docs/capstones/other/reddit-kafka-sparkstream-bigquery/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/resale-price-realtime/README",
              "id": "capstones/other/resale-price-realtime/README",
              "title": "Machine Learning Streamming with Kafka, Debezium and BentoML",
              "description": "This is a personal project created to simulate a Machine Learning real-time application.",
              "source": "@site/docs/12-capstones/other/resale-price-realtime/README.md",
              "sourceDirName": "12-capstones/other/resale-price-realtime",
              "slug": "/capstones/other/resale-price-realtime/",
              "permalink": "/docs/capstones/other/resale-price-realtime/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/sqs-postgres-etl/README",
              "id": "capstones/other/sqs-postgres-etl/README",
              "title": "Data Engineering Take Home - ETL off a SQS Qeueue",
              "description": "This challenge will focus on your ability to write a small application that can read from an AWS SQS Qeueue, transform that data, then write to a Postgres database. Your objective is to read JSON data containing user login behavior from an AWS SQS Queue. Fetch wants to hide personal identifiable information (PII). The fields device_id and ip should be masked, but in a way where it is easy for data analysts to identify duplicate values in those fields. Once you have flattened the JSON data object and masked those two fields, write each record to a Postgres database.",
              "source": "@site/docs/12-capstones/other/sqs-postgres-etl/README.md",
              "sourceDirName": "12-capstones/other/sqs-postgres-etl",
              "slug": "/capstones/other/sqs-postgres-etl/",
              "permalink": "/docs/capstones/other/sqs-postgres-etl/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/star-jeans-etl/README",
              "id": "capstones/other/star-jeans-etl/README",
              "title": "ETL Building for an E-commerce Jeans Company",
              "description": "Obs: The company and business problem are both fictitious, although the data is real.",
              "source": "@site/docs/12-capstones/other/star-jeans-etl/README.md",
              "sourceDirName": "12-capstones/other/star-jeans-etl",
              "slug": "/capstones/other/star-jeans-etl/",
              "permalink": "/docs/capstones/other/star-jeans-etl/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/taxi-fare-prediction/README",
              "id": "capstones/other/taxi-fare-prediction/README",
              "title": "NYC Taxi Fare Prediction",
              "description": "Objective",
              "source": "@site/docs/12-capstones/other/taxi-fare-prediction/README.md",
              "sourceDirName": "12-capstones/other/taxi-fare-prediction",
              "slug": "/capstones/other/taxi-fare-prediction/",
              "permalink": "/docs/capstones/other/taxi-fare-prediction/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/text-speech-data-pipeline/README",
              "id": "capstones/other/text-speech-data-pipeline/README",
              "title": "Data Pipeline for Text to Speech translation model",
              "description": "Problem Statement",
              "source": "@site/docs/12-capstones/other/text-speech-data-pipeline/README.md",
              "sourceDirName": "12-capstones/other/text-speech-data-pipeline",
              "slug": "/capstones/other/text-speech-data-pipeline/",
              "permalink": "/docs/capstones/other/text-speech-data-pipeline/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/topic-modeling-pipeline/README",
              "id": "capstones/other/topic-modeling-pipeline/README",
              "title": "Machine Learning with Big Data",
              "description": "Use big-data tools (PySpark) to run topic modeling (unsupervised machine learning) on Twitter data streamed using AWS Kinesis Firehose.",
              "source": "@site/docs/12-capstones/other/topic-modeling-pipeline/README.md",
              "sourceDirName": "12-capstones/other/topic-modeling-pipeline",
              "slug": "/capstones/other/topic-modeling-pipeline/",
              "permalink": "/docs/capstones/other/topic-modeling-pipeline/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/topic-modeling-pipeline/v2/scoping",
              "id": "capstones/other/topic-modeling-pipeline/v2/scoping",
              "title": "Scoping",
              "description": "Objective",
              "source": "@site/docs/12-capstones/other/topic-modeling-pipeline/v2/scoping.md",
              "sourceDirName": "12-capstones/other/topic-modeling-pipeline/v2",
              "slug": "/capstones/other/topic-modeling-pipeline/v2/scoping",
              "permalink": "/docs/capstones/other/topic-modeling-pipeline/v2/scoping",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/twitter-sentiment-realtime/README",
              "id": "capstones/other/twitter-sentiment-realtime/README",
              "title": "Twitter Sentiment Realtime",
              "description": "Objective",
              "source": "@site/docs/12-capstones/other/twitter-sentiment-realtime/README.md",
              "sourceDirName": "12-capstones/other/twitter-sentiment-realtime",
              "slug": "/capstones/other/twitter-sentiment-realtime/",
              "permalink": "/docs/capstones/other/twitter-sentiment-realtime/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/twitter-snowpipe/README",
              "id": "capstones/other/twitter-snowpipe/README",
              "title": "Auto-Ingest Twitter Data into Snowflake",
              "description": "Follow this:",
              "source": "@site/docs/12-capstones/other/twitter-snowpipe/README.md",
              "sourceDirName": "12-capstones/other/twitter-snowpipe",
              "slug": "/capstones/other/twitter-snowpipe/",
              "permalink": "/docs/capstones/other/twitter-snowpipe/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/us-job-vacancies/README",
              "id": "capstones/other/us-job-vacancies/README",
              "title": "Work around the world Job vacancies analysis",
              "description": "Problem Statement",
              "source": "@site/docs/12-capstones/other/us-job-vacancies/README.md",
              "sourceDirName": "12-capstones/other/us-job-vacancies",
              "slug": "/capstones/other/us-job-vacancies/",
              "permalink": "/docs/capstones/other/us-job-vacancies/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/other/youtube-insights/README",
              "id": "capstones/other/youtube-insights/README",
              "title": "YouTube Trend Analysis Workshop",
              "description": "youtube_trending",
              "source": "@site/docs/12-capstones/other/youtube-insights/README.md",
              "sourceDirName": "12-capstones/other/youtube-insights",
              "slug": "/capstones/other/youtube-insights/",
              "permalink": "/docs/capstones/other/youtube-insights/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/README",
              "id": "capstones/README",
              "title": "Capstones",
              "description": "More Ideas",
              "source": "@site/docs/12-capstones/README.md",
              "sourceDirName": "12-capstones",
              "slug": "/capstones/",
              "permalink": "/docs/capstones/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/recofront/README",
              "id": "capstones/recofront/README",
              "title": "Building Recommender System from Scratch",
              "description": "Overview",
              "source": "@site/docs/12-capstones/recofront/README.md",
              "sourceDirName": "12-capstones/recofront",
              "slug": "/capstones/recofront/",
              "permalink": "/docs/capstones/recofront/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Multi-touch Attribution",
                "permalink": "/docs/capstones/multi-touch-attribution/"
              },
              "next": {
                "title": "Reddit Submissions, Authors and Subreddits analysis",
                "permalink": "/docs/capstones/reddit/"
              }
            },
            {
              "unversionedId": "capstones/reddit/README",
              "id": "capstones/reddit/README",
              "title": "Reddit Submissions, Authors and Subreddits analysis",
              "description": "Problem Statement",
              "source": "@site/docs/12-capstones/reddit/README.md",
              "sourceDirName": "12-capstones/reddit",
              "slug": "/capstones/reddit/",
              "permalink": "/docs/capstones/reddit/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Building Recommender System from Scratch",
                "permalink": "/docs/capstones/recofront/"
              },
              "next": {
                "title": "AWS Kafka and DynamoDB for real time fraud detection",
                "permalink": "/docs/capstones/redshield/"
              }
            },
            {
              "unversionedId": "capstones/redshield/README",
              "id": "capstones/redshield/README",
              "title": "AWS Kafka and DynamoDB for real time fraud detection",
              "description": "Problem Statement",
              "source": "@site/docs/12-capstones/redshield/README.md",
              "sourceDirName": "12-capstones/redshield",
              "slug": "/capstones/redshield/",
              "permalink": "/docs/capstones/redshield/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Reddit Submissions, Authors and Subreddits analysis",
                "permalink": "/docs/capstones/reddit/"
              },
              "next": {
                "title": "Data Pipeline with dbt, Airflow and Great Expectations",
                "permalink": "/docs/capstones/robust-data-pipeline/"
              }
            },
            {
              "unversionedId": "capstones/robust-data-pipeline/README",
              "id": "capstones/robust-data-pipeline/README",
              "title": "Data Pipeline with dbt, Airflow and Great Expectations",
              "description": "In this project, we will learn how to combine the functions of three open source tools - Airflow, dbt and Great expectations - to build, test, validate, document, and orchestrate an entire pipeline, end to end, from scratch. We are going to load the NYC Taxi data into Redshift warehouse and then transform + validate the data using dbt and great expectations.",
              "source": "@site/docs/12-capstones/robust-data-pipeline/README.md",
              "sourceDirName": "12-capstones/robust-data-pipeline",
              "slug": "/capstones/robust-data-pipeline/",
              "permalink": "/docs/capstones/robust-data-pipeline/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "AWS Kafka and DynamoDB for real time fraud detection",
                "permalink": "/docs/capstones/redshield/"
              },
              "next": {
                "title": "Smartcity",
                "permalink": "/docs/capstones/smartcity/"
              }
            },
            {
              "unversionedId": "capstones/ServerlessStreamingApp/README",
              "id": "capstones/ServerlessStreamingApp/README",
              "title": "Serverless Streaming Data on AWS",
              "description": "https://youtu.be/abaVSFFdU-c",
              "source": "@site/docs/12-capstones/ServerlessStreamingApp/README.md",
              "sourceDirName": "12-capstones/ServerlessStreamingApp",
              "slug": "/capstones/ServerlessStreamingApp/",
              "permalink": "/docs/capstones/ServerlessStreamingApp/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Capstones",
                "permalink": "/docs/category/capstones"
              },
              "next": {
                "title": "ACLED",
                "permalink": "/docs/capstones/acled/"
              }
            },
            {
              "unversionedId": "capstones/smartcity/analytics/flink-cdk/README",
              "id": "capstones/smartcity/analytics/flink-cdk/README",
              "title": "Welcome to your CDK Python project!",
              "description": "This is a blank project for Python development with CDK.",
              "source": "@site/docs/12-capstones/smartcity/03-analytics/flink-cdk/README.md",
              "sourceDirName": "12-capstones/smartcity/03-analytics/flink-cdk",
              "slug": "/capstones/smartcity/analytics/flink-cdk/",
              "permalink": "/docs/capstones/smartcity/analytics/flink-cdk/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/smartcity/analytics/producer-app/readme",
              "id": "capstones/smartcity/analytics/producer-app/readme",
              "title": "readme",
              "description": "",
              "source": "@site/docs/12-capstones/smartcity/03-analytics/producer-app/readme.md",
              "sourceDirName": "12-capstones/smartcity/03-analytics/producer-app",
              "slug": "/capstones/smartcity/analytics/producer-app/",
              "permalink": "/docs/capstones/smartcity/analytics/producer-app/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/smartcity/analytics/producer-cdk/README",
              "id": "capstones/smartcity/analytics/producer-cdk/README",
              "title": "README",
              "description": "<<<<<<< HEAD",
              "source": "@site/docs/12-capstones/smartcity/03-analytics/producer-cdk/README.md",
              "sourceDirName": "12-capstones/smartcity/03-analytics/producer-cdk",
              "slug": "/capstones/smartcity/analytics/producer-cdk/",
              "permalink": "/docs/capstones/smartcity/analytics/producer-cdk/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/smartcity/dataStream/README",
              "id": "capstones/smartcity/dataStream/README",
              "title": "Amazon Kinesis Data Streams",
              "description": "Register Enhanced Fan-Out Consumer",
              "source": "@site/docs/12-capstones/smartcity/01-dataStream/README.md",
              "sourceDirName": "12-capstones/smartcity/01-dataStream",
              "slug": "/capstones/smartcity/dataStream/",
              "permalink": "/docs/capstones/smartcity/dataStream/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/smartcity/firehose/README",
              "id": "capstones/smartcity/firehose/README",
              "title": "Amazon Kinesis Data Firehose",
              "description": "Description of files",
              "source": "@site/docs/12-capstones/smartcity/02-firehose/README.md",
              "sourceDirName": "12-capstones/smartcity/02-firehose",
              "slug": "/capstones/smartcity/firehose/",
              "permalink": "/docs/capstones/smartcity/firehose/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "capstones/smartcity/README",
              "id": "capstones/smartcity/README",
              "title": "Smartcity",
              "description": "Files",
              "source": "@site/docs/12-capstones/smartcity/README.md",
              "sourceDirName": "12-capstones/smartcity",
              "slug": "/capstones/smartcity/",
              "permalink": "/docs/capstones/smartcity/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Pipeline with dbt, Airflow and Great Expectations",
                "permalink": "/docs/capstones/robust-data-pipeline/"
              },
              "next": {
                "title": "Sparkify",
                "permalink": "/docs/capstones/sparkify/"
              }
            },
            {
              "unversionedId": "capstones/sparkify/README",
              "id": "capstones/sparkify/README",
              "title": "Sparkify",
              "description": "Sparkify SQL Data Modeling with Postgres",
              "source": "@site/docs/12-capstones/sparkify/README.md",
              "sourceDirName": "12-capstones/sparkify",
              "slug": "/capstones/sparkify/",
              "permalink": "/docs/capstones/sparkify/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Smartcity",
                "permalink": "/docs/capstones/smartcity/"
              },
              "next": {
                "title": "Spotify",
                "permalink": "/docs/capstones/spotify/"
              }
            },
            {
              "unversionedId": "capstones/spotify/README",
              "id": "capstones/spotify/README",
              "title": "Spotify",
              "description": "Implement Complete Data Pipeline Data Engineering Project using Spotify",
              "source": "@site/docs/12-capstones/spotify/README.md",
              "sourceDirName": "12-capstones/spotify",
              "slug": "/capstones/spotify/",
              "permalink": "/docs/capstones/spotify/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Sparkify",
                "permalink": "/docs/capstones/sparkify/"
              },
              "next": {
                "title": "Twitter data Topic Analysis and Realtime Sentiment Analysis",
                "permalink": "/docs/capstones/twitter-sentiment-glue/"
              }
            },
            {
              "unversionedId": "capstones/twitter-sentiment-glue/README",
              "id": "capstones/twitter-sentiment-glue/README",
              "title": "Twitter data Topic Analysis and Realtime Sentiment Analysis",
              "description": "Problem Statement",
              "source": "@site/docs/12-capstones/twitter-sentiment-glue/README.md",
              "sourceDirName": "12-capstones/twitter-sentiment-glue",
              "slug": "/capstones/twitter-sentiment-glue/",
              "permalink": "/docs/capstones/twitter-sentiment-glue/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Spotify",
                "permalink": "/docs/capstones/spotify/"
              },
              "next": {
                "title": "US Immigration analysis and data pipeline",
                "permalink": "/docs/capstones/us-immigration/"
              }
            },
            {
              "unversionedId": "capstones/us-immigration/README",
              "id": "capstones/us-immigration/README",
              "title": "US Immigration analysis and data pipeline",
              "description": "Problem Statement",
              "source": "@site/docs/12-capstones/us-immigration/README.md",
              "sourceDirName": "12-capstones/us-immigration",
              "slug": "/capstones/us-immigration/",
              "permalink": "/docs/capstones/us-immigration/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Twitter data Topic Analysis and Realtime Sentiment Analysis",
                "permalink": "/docs/capstones/twitter-sentiment-glue/"
              },
              "next": {
                "title": "Interview Preparation",
                "permalink": "/docs/interviewprep/"
              }
            },
            {
              "unversionedId": "casestudies/99group",
              "id": "casestudies/99group",
              "title": "99 Group",
              "description": "References",
              "source": "@site/docs/casestudies/99group.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/99group",
              "permalink": "/docs/casestudies/99group",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Case Studies",
                "permalink": "/docs/category/case-studies"
              },
              "next": {
                "title": "Airbnb",
                "permalink": "/docs/casestudies/airbnb"
              }
            },
            {
              "unversionedId": "casestudies/airbnb",
              "id": "casestudies/airbnb",
              "title": "Airbnb",
              "description": "Watch this video//www.youtube.com/watch?v=iokqkMfyIfo",
              "source": "@site/docs/casestudies/airbnb.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/airbnb",
              "permalink": "/docs/casestudies/airbnb",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "99 Group",
                "permalink": "/docs/casestudies/99group"
              },
              "next": {
                "title": "Amazon",
                "permalink": "/docs/casestudies/amazon"
              }
            },
            {
              "unversionedId": "casestudies/amazon",
              "id": "casestudies/amazon",
              "title": "Amazon",
              "description": "Amazon Migrates 50 PB of Analytics Data from Oracle to AWS",
              "source": "@site/docs/casestudies/amazon.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/amazon",
              "permalink": "/docs/casestudies/amazon",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Airbnb",
                "permalink": "/docs/casestudies/airbnb"
              },
              "next": {
                "title": "Booking.com",
                "permalink": "/docs/casestudies/bookingdotcom"
              }
            },
            {
              "unversionedId": "casestudies/bookingdotcom",
              "id": "casestudies/bookingdotcom",
              "title": "Booking.com",
              "description": "An online travel agency for reservations",
              "source": "@site/docs/casestudies/bookingdotcom.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/bookingdotcom",
              "permalink": "/docs/casestudies/bookingdotcom",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Amazon",
                "permalink": "/docs/casestudies/amazon"
              },
              "next": {
                "title": "Expedia",
                "permalink": "/docs/casestudies/expedia"
              }
            },
            {
              "unversionedId": "casestudies/expedia",
              "id": "casestudies/expedia",
              "title": "Expedia",
              "description": "Technology company that powers travel",
              "source": "@site/docs/casestudies/expedia.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/expedia",
              "permalink": "/docs/casestudies/expedia",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Booking.com",
                "permalink": "/docs/casestudies/bookingdotcom"
              },
              "next": {
                "title": "Fair",
                "permalink": "/docs/casestudies/fair"
              }
            },
            {
              "unversionedId": "casestudies/fair",
              "id": "casestudies/fair",
              "title": "Fair",
              "description": "Data Ingestion with a Cloud Data Platform",
              "source": "@site/docs/casestudies/fair.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/fair",
              "permalink": "/docs/casestudies/fair",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Expedia",
                "permalink": "/docs/casestudies/expedia"
              },
              "next": {
                "title": "Harmony",
                "permalink": "/docs/casestudies/harmony"
              }
            },
            {
              "unversionedId": "casestudies/harmony",
              "id": "casestudies/harmony",
              "title": "Harmony",
              "description": "Responsive Data Pipeline",
              "source": "@site/docs/casestudies/harmony.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/harmony",
              "permalink": "/docs/casestudies/harmony",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Fair",
                "permalink": "/docs/casestudies/fair"
              },
              "next": {
                "title": "Helpshift",
                "permalink": "/docs/casestudies/helpshift"
              }
            },
            {
              "unversionedId": "casestudies/helpshift",
              "id": "casestudies/helpshift",
              "title": "Helpshift",
              "description": "Technology company that powers travel",
              "source": "@site/docs/casestudies/helpshift.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/helpshift",
              "permalink": "/docs/casestudies/helpshift",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Harmony",
                "permalink": "/docs/casestudies/harmony"
              },
              "next": {
                "title": "HomeToGo",
                "permalink": "/docs/casestudies/hometogo"
              }
            },
            {
              "unversionedId": "casestudies/hometogo",
              "id": "casestudies/hometogo",
              "title": "HomeToGo",
              "description": "Vacation Rentals, Cabins, Condos, Villas, & More",
              "source": "@site/docs/casestudies/hometogo.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/hometogo",
              "permalink": "/docs/casestudies/hometogo",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Helpshift",
                "permalink": "/docs/casestudies/helpshift"
              },
              "next": {
                "title": "Intuit",
                "permalink": "/docs/casestudies/intuit"
              }
            },
            {
              "unversionedId": "casestudies/intuit",
              "id": "casestudies/intuit",
              "title": "Intuit",
              "description": "Complete Financial Confidence",
              "source": "@site/docs/casestudies/intuit.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/intuit",
              "permalink": "/docs/casestudies/intuit",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "HomeToGo",
                "permalink": "/docs/casestudies/hometogo"
              },
              "next": {
                "title": "LinkedIn",
                "permalink": "/docs/casestudies/linkedin"
              }
            },
            {
              "unversionedId": "casestudies/linkedin",
              "id": "casestudies/linkedin",
              "title": "LinkedIn",
              "description": "World's largest professional network on the internet",
              "source": "@site/docs/casestudies/linkedin.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/linkedin",
              "permalink": "/docs/casestudies/linkedin",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Intuit",
                "permalink": "/docs/casestudies/intuit"
              },
              "next": {
                "title": "Myntra",
                "permalink": "/docs/casestudies/myntra"
              }
            },
            {
              "unversionedId": "casestudies/myntra",
              "id": "casestudies/myntra",
              "title": "Myntra",
              "description": "1. Janus : Data processing framework at Myntra",
              "source": "@site/docs/casestudies/myntra.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/myntra",
              "permalink": "/docs/casestudies/myntra",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "LinkedIn",
                "permalink": "/docs/casestudies/linkedin"
              },
              "next": {
                "title": "Outfit7",
                "permalink": "/docs/casestudies/outfit7"
              }
            },
            {
              "unversionedId": "casestudies/outfit7",
              "id": "casestudies/outfit7",
              "title": "Outfit7",
              "description": "Multinational video game developer",
              "source": "@site/docs/casestudies/outfit7.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/outfit7",
              "permalink": "/docs/casestudies/outfit7",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Myntra",
                "permalink": "/docs/casestudies/myntra"
              },
              "next": {
                "title": "Panoramic",
                "permalink": "/docs/casestudies/panoramic"
              }
            },
            {
              "unversionedId": "casestudies/panoramic",
              "id": "casestudies/panoramic",
              "title": "Panoramic",
              "description": "Simplifying Data Ingestion, Transformation, And Delivery",
              "source": "@site/docs/casestudies/panoramic.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/panoramic",
              "permalink": "/docs/casestudies/panoramic",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Outfit7",
                "permalink": "/docs/casestudies/outfit7"
              },
              "next": {
                "title": "Plexure",
                "permalink": "/docs/casestudies/plexure"
              }
            },
            {
              "unversionedId": "casestudies/plexure",
              "id": "casestudies/plexure",
              "title": "Plexure",
              "description": "Data-Driven Personalized Customer Experiences",
              "source": "@site/docs/casestudies/plexure.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/plexure",
              "permalink": "/docs/casestudies/plexure",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Panoramic",
                "permalink": "/docs/casestudies/panoramic"
              },
              "next": {
                "title": "Spotify Discover Weekly Playlist",
                "permalink": "/docs/casestudies/spotify"
              }
            },
            {
              "unversionedId": "casestudies/README",
              "id": "casestudies/README",
              "title": "Case Studies",
              "description": "More",
              "source": "@site/docs/casestudies/README.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/",
              "permalink": "/docs/casestudies/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "casestudies/spotify",
              "id": "casestudies/spotify",
              "title": "Spotify Discover Weekly Playlist",
              "description": "This case study uses information from various presentations that engineers from Spotify delivered in 2015, mainly the “From Idea to Execution: Spotify’s Discover Weekly” presentation. They may no longer use some of the techniques or technologies discussed, but the core takeaways from this case study are still relevant.",
              "source": "@site/docs/casestudies/spotify.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/spotify",
              "permalink": "/docs/casestudies/spotify",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Plexure",
                "permalink": "/docs/casestudies/plexure"
              },
              "next": {
                "title": "Starbucks",
                "permalink": "/docs/casestudies/starbucks"
              }
            },
            {
              "unversionedId": "casestudies/starbucks",
              "id": "casestudies/starbucks",
              "title": "Starbucks",
              "description": "Multinational chain of coffeehouses and roastery reserves",
              "source": "@site/docs/casestudies/starbucks.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/starbucks",
              "permalink": "/docs/casestudies/starbucks",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Spotify Discover Weekly Playlist",
                "permalink": "/docs/casestudies/spotify"
              },
              "next": {
                "title": "Trivago",
                "permalink": "/docs/casestudies/trivago"
              }
            },
            {
              "unversionedId": "casestudies/trivago",
              "id": "casestudies/trivago",
              "title": "Trivago",
              "description": "Compare hotel prices worldwide",
              "source": "@site/docs/casestudies/trivago.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/trivago",
              "permalink": "/docs/casestudies/trivago",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Starbucks",
                "permalink": "/docs/casestudies/starbucks"
              },
              "next": {
                "title": "Twilio",
                "permalink": "/docs/casestudies/twilio"
              }
            },
            {
              "unversionedId": "casestudies/twilio",
              "id": "casestudies/twilio",
              "title": "Twilio",
              "description": "Presto on AWS at Twilio - Lesson Learned and Optimization",
              "source": "@site/docs/casestudies/twilio.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/twilio",
              "permalink": "/docs/casestudies/twilio",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Trivago",
                "permalink": "/docs/casestudies/trivago"
              },
              "next": {
                "title": "Twitter",
                "permalink": "/docs/casestudies/twitter"
              }
            },
            {
              "unversionedId": "casestudies/twitter",
              "id": "casestudies/twitter",
              "title": "Twitter",
              "description": "Watch this video//www.youtube.com/watch?v=OQPpEEMm6Gg",
              "source": "@site/docs/casestudies/twitter.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/twitter",
              "permalink": "/docs/casestudies/twitter",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Twilio",
                "permalink": "/docs/casestudies/twilio"
              },
              "next": {
                "title": "Uber",
                "permalink": "/docs/casestudies/uber"
              }
            },
            {
              "unversionedId": "casestudies/uber",
              "id": "casestudies/uber",
              "title": "Uber",
              "description": "Uber's Big Data Platform: 100+ Petabytes with Minute Latency",
              "source": "@site/docs/casestudies/uber.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/uber",
              "permalink": "/docs/casestudies/uber",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Twitter",
                "permalink": "/docs/casestudies/twitter"
              },
              "next": {
                "title": "Technology-Driven Video Advertising",
                "permalink": "/docs/casestudies/video-stream"
              }
            },
            {
              "unversionedId": "casestudies/video-stream",
              "id": "casestudies/video-stream",
              "title": "Technology-Driven Video Advertising",
              "description": "A global leader in cable and video advertising collects data from more than six billion devices. This data is accurate, rich, and valuable as part of its strategy for providing customized, targeted advertising. The problem was that this data was huge, and the resources required to provide near-real-time targeted advertising were immense. To meet the need, the company established several hundred Hadoop servers and used them to batch process and pre-aggregate the data. Still, with this huge investment in hardware and tools, the process took one to three days to send a targeted ad to a customer.",
              "source": "@site/docs/casestudies/video-stream.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/video-stream",
              "permalink": "/docs/casestudies/video-stream",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Uber",
                "permalink": "/docs/casestudies/uber"
              },
              "next": {
                "title": "Webshoes",
                "permalink": "/docs/casestudies/webshoes"
              }
            },
            {
              "unversionedId": "casestudies/webshoes",
              "id": "casestudies/webshoes",
              "title": "Webshoes",
              "description": "Webshoes is a fictitious sales company of shoes and accessories that is being created. The company's business areas have defined that Webshoes will have an online store and that the store will need to have personalized experiences. The requirements that the business areas have passed to the project development team are as follows:",
              "source": "@site/docs/casestudies/webshoes.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/webshoes",
              "permalink": "/docs/casestudies/webshoes",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Technology-Driven Video Advertising",
                "permalink": "/docs/casestudies/video-stream"
              },
              "next": {
                "title": "Woot.com",
                "permalink": "/docs/casestudies/woot"
              }
            },
            {
              "unversionedId": "casestudies/woot",
              "id": "casestudies/woot",
              "title": "Woot.com",
              "description": "Online Shopping",
              "source": "@site/docs/casestudies/woot.md",
              "sourceDirName": "casestudies",
              "slug": "/casestudies/woot",
              "permalink": "/docs/casestudies/woot",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Webshoes",
                "permalink": "/docs/casestudies/webshoes"
              },
              "next": {
                "title": "Capstones",
                "permalink": "/docs/category/capstones"
              }
            },
            {
              "unversionedId": "data-modeling/3nf-data-modeling",
              "id": "data-modeling/3nf-data-modeling",
              "title": "3NF/ Relational Modeling",
              "description": "Owing its origins to the entity-relationship modeling methodology, 3NF is also widely used in data warehousing to serve as a normalized layer to the further layers. It provides tremendous flexibility but can end up having really verbose queries. It is usually found in OLTP systems.",
              "source": "@site/docs/04-data-modeling/3nf-data-modeling.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/3nf-data-modeling",
              "permalink": "/docs/data-modeling/3nf-data-modeling",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Stages of Data Modeling",
                "permalink": "/docs/data-modeling/data-modeling-stages"
              },
              "next": {
                "title": "Dimensional Modeling",
                "permalink": "/docs/data-modeling/dimensional-modeling"
              }
            },
            {
              "unversionedId": "data-modeling/cap-theorem",
              "id": "data-modeling/cap-theorem",
              "title": "CAP Theorem",
              "description": "https://en.wikipedia.org/wiki/CAP_theorem",
              "source": "@site/docs/04-data-modeling/cap-theorem.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/cap-theorem",
              "permalink": "/docs/data-modeling/cap-theorem",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Normalization vs Denormalization",
                "permalink": "/docs/data-modeling/normalization-vs-denormalization"
              },
              "next": {
                "title": "Quiz",
                "permalink": "/docs/data-modeling/quiz"
              }
            },
            {
              "unversionedId": "data-modeling/data-modeling-stages",
              "id": "data-modeling/data-modeling-stages",
              "title": "Stages of Data Modeling",
              "description": "Conceptual Data Model",
              "source": "@site/docs/04-data-modeling/data-modeling-stages.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/data-modeling-stages",
              "permalink": "/docs/data-modeling/data-modeling-stages",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Inmon versus the Kimball data model",
                "permalink": "/docs/data-modeling/inmon-vs-kimball"
              },
              "next": {
                "title": "3NF/ Relational Modeling",
                "permalink": "/docs/data-modeling/3nf-data-modeling"
              }
            },
            {
              "unversionedId": "data-modeling/data-modeling-steps",
              "id": "data-modeling/data-modeling-steps",
              "title": "Steps of Building Data Models",
              "description": "Gathering requirements",
              "source": "@site/docs/04-data-modeling/data-modeling-steps.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/data-modeling-steps",
              "permalink": "/docs/data-modeling/data-modeling-steps",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Vault Modeling",
                "permalink": "/docs/data-modeling/data-vault-modeling"
              },
              "next": {
                "title": "Designing SCDs",
                "permalink": "/docs/data-modeling/designing-scd"
              }
            },
            {
              "unversionedId": "data-modeling/data-vault-modeling",
              "id": "data-modeling/data-vault-modeling",
              "title": "Data Vault Modeling",
              "description": "A hybrid between 3NF and dimensional modeling, the Data Vault model is much closer to 3NF than to the dimensional model. It tries to keep the best features of 3NF, such as ease of querying highly granular, historical data, and still restructures the data into new types of tables, such as satellites, links, hubs, bridges, and PITs. A Data Vault is a more recent data modeling design pattern used to build data warehouses for enterprise-scale analytics compared to Kimball and Inmon methods. Data Vaults organize data into three different types:  hubs ,  links , and  satellites . Hubs represent core business entities, links represent relationships between hubs, and satellites store attributes about hubs or links. Data Vault focuses on agile data warehouse development where scalability, data integration/ETL and development speed are important.",
              "source": "@site/docs/04-data-modeling/data-vault-modeling.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/data-vault-modeling",
              "permalink": "/docs/data-modeling/data-vault-modeling",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Dimensional Modeling",
                "permalink": "/docs/data-modeling/dimensional-modeling"
              },
              "next": {
                "title": "Steps of Building Data Models",
                "permalink": "/docs/data-modeling/data-modeling-steps"
              }
            },
            {
              "unversionedId": "data-modeling/data-warehousing",
              "id": "data-modeling/data-warehousing",
              "title": "Data Warehousing",
              "description": "In today's data-driven world, businesses need to have the ability to store and analyze large amounts of data in order to make informed decisions. One way to achieve this is by designing and developing a data warehouse. A data warehouse is a centralized repository that allows organizations to store and manage data from various sources in a structured manner. In this note, we will discuss seven key steps involved in designing and developing a data warehouse.",
              "source": "@site/docs/04-data-modeling/data-warehousing.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/data-warehousing",
              "permalink": "/docs/data-modeling/data-warehousing",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Designing for incremental loading",
                "permalink": "/docs/data-modeling/designing-incremental-loading"
              },
              "next": {
                "title": "Normalization vs Denormalization",
                "permalink": "/docs/data-modeling/normalization-vs-denormalization"
              }
            },
            {
              "unversionedId": "data-modeling/designing-incremental-loading",
              "id": "data-modeling/designing-incremental-loading",
              "title": "Designing for incremental loading",
              "description": "Incremental loading or delta loading refers to the process of loading smaller increments of data into a storage solution—for example, we could have daily data that is being loaded into a data lake or hourly data flowing into an extract, transform, load (ETL) pipeline, and so on. During data-ingestion scenarios, it is very common to do a bulk upload followed by scheduled incremental loads.",
              "source": "@site/docs/04-data-modeling/designing-incremental-loading.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/designing-incremental-loading",
              "permalink": "/docs/data-modeling/designing-incremental-loading",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Designing SCDs",
                "permalink": "/docs/data-modeling/designing-scd"
              },
              "next": {
                "title": "Data Warehousing",
                "permalink": "/docs/data-modeling/data-warehousing"
              }
            },
            {
              "unversionedId": "data-modeling/designing-scd",
              "id": "data-modeling/designing-scd",
              "title": "Designing SCDs",
              "description": "Whereas operational source systems contain only the latest version of master data, the star schema enables time travel queries to reproduce dimension attribute values on past dates when the fact transaction or event actually happened. The star schema data model allows analytical users to query historical data tying metrics to corresponding dimensional attribute values over time. Time travel is possible because dimension tables contain the exact version of the associated attributes at different time ranges. Relative to the metrics data that keeps changing on a daily or even hourly basis, the dimension attributes change less frequently. Therefore, dimensions in a star schema that keeps track of changes over time are referred to as slowly changing dimensions (SCDs).",
              "source": "@site/docs/04-data-modeling/designing-scd.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/designing-scd",
              "permalink": "/docs/data-modeling/designing-scd",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Steps of Building Data Models",
                "permalink": "/docs/data-modeling/data-modeling-steps"
              },
              "next": {
                "title": "Designing for incremental loading",
                "permalink": "/docs/data-modeling/designing-incremental-loading"
              }
            },
            {
              "unversionedId": "data-modeling/dimensional-modeling",
              "id": "data-modeling/dimensional-modeling",
              "title": "Dimensional Modeling",
              "description": "Dimensional modeling is a bottom-up approach to designing data warehouses in order to optimize them for analytics. Dimensional models are used to denormalize business data into dimensions (like time and product) and facts (like transactions in amounts and quantities), and different subject areas are connected via conformed dimensions to navigate to different fact tables. It is usually found in OLAP systems.",
              "source": "@site/docs/04-data-modeling/dimensional-modeling.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/dimensional-modeling",
              "permalink": "/docs/data-modeling/dimensional-modeling",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "3NF/ Relational Modeling",
                "permalink": "/docs/data-modeling/3nf-data-modeling"
              },
              "next": {
                "title": "Data Vault Modeling",
                "permalink": "/docs/data-modeling/data-vault-modeling"
              }
            },
            {
              "unversionedId": "data-modeling/inmon-vs-kimball",
              "id": "data-modeling/inmon-vs-kimball",
              "title": "Inmon versus the Kimball data model",
              "description": "If you look at the internet, there will be many references to data modeling, but two of the most famous approaches are the Inmon method (data-driven) and the Kimball method (user-driven).",
              "source": "@site/docs/04-data-modeling/inmon-vs-kimball.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/inmon-vs-kimball",
              "permalink": "/docs/data-modeling/inmon-vs-kimball",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Data Modeling",
                "permalink": "/docs/data-modeling/sql-data-modeling"
              },
              "next": {
                "title": "Stages of Data Modeling",
                "permalink": "/docs/data-modeling/data-modeling-stages"
              }
            },
            {
              "unversionedId": "data-modeling/lab-airbnb-postgres-datamodel/README",
              "id": "data-modeling/lab-airbnb-postgres-datamodel/README",
              "title": "Lab: AirBnB Postgres Datamodel",
              "description": "Objective",
              "source": "@site/docs/04-data-modeling/lab-airbnb-postgres-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-airbnb-postgres-datamodel",
              "slug": "/data-modeling/lab-airbnb-postgres-datamodel/",
              "permalink": "/docs/data-modeling/lab-airbnb-postgres-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Quiz",
                "permalink": "/docs/data-modeling/quiz"
              },
              "next": {
                "title": "Lab: Car company Data Model in MySQL",
                "permalink": "/docs/data-modeling/lab-cars-mysql-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-cars-mysql-datamodel/datamodel-cars",
              "id": "data-modeling/lab-cars-mysql-datamodel/datamodel-cars",
              "title": "Cars Data Modeling MySQL",
              "description": "ETL, data modeling and Data quality runs on cars and dealership dataset",
              "source": "@site/docs/04-data-modeling/lab-cars-mysql-datamodel/datamodel-cars.md",
              "sourceDirName": "04-data-modeling/lab-cars-mysql-datamodel",
              "slug": "/data-modeling/lab-cars-mysql-datamodel/datamodel-cars",
              "permalink": "/docs/data-modeling/lab-cars-mysql-datamodel/datamodel-cars",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "data-modeling/lab-cars-mysql-datamodel/README",
              "id": "data-modeling/lab-cars-mysql-datamodel/README",
              "title": "Lab: Car company Data Model in MySQL",
              "description": "Files",
              "source": "@site/docs/04-data-modeling/lab-cars-mysql-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-cars-mysql-datamodel",
              "slug": "/data-modeling/lab-cars-mysql-datamodel/",
              "permalink": "/docs/data-modeling/lab-cars-mysql-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: AirBnB Postgres Datamodel",
                "permalink": "/docs/data-modeling/lab-airbnb-postgres-datamodel/"
              },
              "next": {
                "title": "Lab: Create a star schema from 3NF schema on DVD rental Pagila dataset",
                "permalink": "/docs/data-modeling/lab-dvd-rental-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-cassandra-digital-music-library/README",
              "id": "data-modeling/lab-cassandra-digital-music-library/README",
              "title": "Lab: Create a Data Model for a Digital Music Library",
              "description": "Conceptual Data Model",
              "source": "@site/docs/04-data-modeling/lab-cassandra-digital-music-library/README.md",
              "sourceDirName": "04-data-modeling/lab-cassandra-digital-music-library",
              "slug": "/data-modeling/lab-cassandra-digital-music-library/",
              "permalink": "/docs/data-modeling/lab-cassandra-digital-music-library/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "NoSQL Data Modeling",
                "permalink": "/docs/data-modeling/nosql-data-modeling"
              },
              "next": {
                "title": "Create a Data Model for an Email System",
                "permalink": "/docs/data-modeling/lab-cassandra-email-data-model/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-cassandra-email-data-model/README",
              "id": "data-modeling/lab-cassandra-email-data-model/README",
              "title": "Create a Data Model for an Email System",
              "description": "Conceptual Data Model",
              "source": "@site/docs/04-data-modeling/lab-cassandra-email-data-model/README.md",
              "sourceDirName": "04-data-modeling/lab-cassandra-email-data-model",
              "slug": "/data-modeling/lab-cassandra-email-data-model/",
              "permalink": "/docs/data-modeling/lab-cassandra-email-data-model/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Create a Data Model for a Digital Music Library",
                "permalink": "/docs/data-modeling/lab-cassandra-digital-music-library/"
              },
              "next": {
                "title": "Hotel Reservations Data Modeling with Cassandra",
                "permalink": "/docs/data-modeling/lab-cassandra-hotel-reservations/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-cassandra-hotel-reservations/README",
              "id": "data-modeling/lab-cassandra-hotel-reservations/README",
              "title": "Hotel Reservations Data Modeling with Cassandra",
              "description": "Learning CQL Query Clauses",
              "source": "@site/docs/04-data-modeling/lab-cassandra-hotel-reservations/README.md",
              "sourceDirName": "04-data-modeling/lab-cassandra-hotel-reservations",
              "slug": "/data-modeling/lab-cassandra-hotel-reservations/",
              "permalink": "/docs/data-modeling/lab-cassandra-hotel-reservations/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Create a Data Model for an Email System",
                "permalink": "/docs/data-modeling/lab-cassandra-email-data-model/"
              },
              "next": {
                "title": "Create a Data Model for Investment Accounts or Portfolios",
                "permalink": "/docs/data-modeling/lab-cassandra-investment-data-model/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-cassandra-investment-data-model/README",
              "id": "data-modeling/lab-cassandra-investment-data-model/README",
              "title": "Create a Data Model for Investment Accounts or Portfolios",
              "description": "Conceptual Data Model",
              "source": "@site/docs/04-data-modeling/lab-cassandra-investment-data-model/README.md",
              "sourceDirName": "04-data-modeling/lab-cassandra-investment-data-model",
              "slug": "/data-modeling/lab-cassandra-investment-data-model/",
              "permalink": "/docs/data-modeling/lab-cassandra-investment-data-model/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Hotel Reservations Data Modeling with Cassandra",
                "permalink": "/docs/data-modeling/lab-cassandra-hotel-reservations/"
              },
              "next": {
                "title": "Create a Data Model for Temperature Monitoring Sensor Networks",
                "permalink": "/docs/data-modeling/lab-cassandra-sensor-data-model/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-cassandra-sensor-data-model/README",
              "id": "data-modeling/lab-cassandra-sensor-data-model/README",
              "title": "Create a Data Model for Temperature Monitoring Sensor Networks",
              "description": "Conceptual Data Model",
              "source": "@site/docs/04-data-modeling/lab-cassandra-sensor-data-model/README.md",
              "sourceDirName": "04-data-modeling/lab-cassandra-sensor-data-model",
              "slug": "/data-modeling/lab-cassandra-sensor-data-model/",
              "permalink": "/docs/data-modeling/lab-cassandra-sensor-data-model/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Create a Data Model for Investment Accounts or Portfolios",
                "permalink": "/docs/data-modeling/lab-cassandra-investment-data-model/"
              },
              "next": {
                "title": "Create a Data Model for Online Shopping Carts",
                "permalink": "/docs/data-modeling/lab-cassandra-shopping-cart-data-model/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-cassandra-shopping-cart-data-model/README",
              "id": "data-modeling/lab-cassandra-shopping-cart-data-model/README",
              "title": "Create a Data Model for Online Shopping Carts",
              "description": "Conceptual Data Model",
              "source": "@site/docs/04-data-modeling/lab-cassandra-shopping-cart-data-model/README.md",
              "sourceDirName": "04-data-modeling/lab-cassandra-shopping-cart-data-model",
              "slug": "/data-modeling/lab-cassandra-shopping-cart-data-model/",
              "permalink": "/docs/data-modeling/lab-cassandra-shopping-cart-data-model/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Create a Data Model for Temperature Monitoring Sensor Networks",
                "permalink": "/docs/data-modeling/lab-cassandra-sensor-data-model/"
              },
              "next": {
                "title": "Data Extraction from APIs",
                "permalink": "/docs/extraction/api/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-disease-diagnosis/README",
              "id": "data-modeling/lab-disease-diagnosis/README",
              "title": "Disease Diagnosis and Medic Recommendation System",
              "description": "In our ever-evolving world, there are those who frequently relocate to new locations, such as students like us, expats, who without giving a thought to their safety and well being engage in extensive social interaction, consume unusual delicacies, follow unhealthy lifestyles which includes erratic sleep activity, unsafe sexual practices, intense smoking and drinking, and little to no physical exercise. This may result in anumber of illnesses and other health issues that are difficult to treat promptly. Being away from one's own country is difficult but at times not knowing where to reach for the right medical care can even cause death. The main goal of this lab is to aid expats and students who are away from home in finding and obtaining medical care as soon as possible.",
              "source": "@site/docs/04-data-modeling/lab-disease-diagnosis/README.md",
              "sourceDirName": "04-data-modeling/lab-disease-diagnosis",
              "slug": "/data-modeling/lab-disease-diagnosis/",
              "permalink": "/docs/data-modeling/lab-disease-diagnosis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "data-modeling/lab-dvd-rental-datamodel/README",
              "id": "data-modeling/lab-dvd-rental-datamodel/README",
              "title": "Lab: Create a star schema from 3NF schema on DVD rental Pagila dataset",
              "description": "Objective",
              "source": "@site/docs/04-data-modeling/lab-dvd-rental-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-dvd-rental-datamodel",
              "slug": "/data-modeling/lab-dvd-rental-datamodel/",
              "permalink": "/docs/data-modeling/lab-dvd-rental-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Car company Data Model in MySQL",
                "permalink": "/docs/data-modeling/lab-cars-mysql-datamodel/"
              },
              "next": {
                "title": "Lab: Create a Postgres data model of Google Playstore dataset",
                "permalink": "/docs/data-modeling/lab-google-playstore-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-google-playstore-datamodel/README",
              "id": "data-modeling/lab-google-playstore-datamodel/README",
              "title": "Lab: Create a Postgres data model of Google Playstore dataset",
              "description": "Data model",
              "source": "@site/docs/04-data-modeling/lab-google-playstore-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-google-playstore-datamodel",
              "slug": "/data-modeling/lab-google-playstore-datamodel/",
              "permalink": "/docs/data-modeling/lab-google-playstore-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Create a star schema from 3NF schema on DVD rental Pagila dataset",
                "permalink": "/docs/data-modeling/lab-dvd-rental-datamodel/"
              },
              "next": {
                "title": "Lab: Inegi Snowflake Datamodel",
                "permalink": "/docs/data-modeling/lab-inegi-snowflake-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-inegi-snowflake-datamodel/README",
              "id": "data-modeling/lab-inegi-snowflake-datamodel/README",
              "title": "Lab: Inegi Snowflake Datamodel",
              "description": "National Institute of Statistics and Geography",
              "source": "@site/docs/04-data-modeling/lab-inegi-snowflake-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-inegi-snowflake-datamodel",
              "slug": "/data-modeling/lab-inegi-snowflake-datamodel/",
              "permalink": "/docs/data-modeling/lab-inegi-snowflake-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Create a Postgres data model of Google Playstore dataset",
                "permalink": "/docs/data-modeling/lab-google-playstore-datamodel/"
              },
              "next": {
                "title": "Lab: Northwind Data Model in MySQL",
                "permalink": "/docs/data-modeling/lab-mysql-northwind-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-mysql-northwind-datamodel/README",
              "id": "data-modeling/lab-mysql-northwind-datamodel/README",
              "title": "Lab: Northwind Data Model in MySQL",
              "description": "Process Flow",
              "source": "@site/docs/04-data-modeling/lab-mysql-northwind-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-mysql-northwind-datamodel",
              "slug": "/data-modeling/lab-mysql-northwind-datamodel/",
              "permalink": "/docs/data-modeling/lab-mysql-northwind-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Inegi Snowflake Datamodel",
                "permalink": "/docs/data-modeling/lab-inegi-snowflake-datamodel/"
              },
              "next": {
                "title": "Lab: Retail Store Data Model in MySQL",
                "permalink": "/docs/data-modeling/lab-mysql-retail-store-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-mysql-retail-store-datamodel/README",
              "id": "data-modeling/lab-mysql-retail-store-datamodel/README",
              "title": "Lab: Retail Store Data Model in MySQL",
              "description": "Process Flow",
              "source": "@site/docs/04-data-modeling/lab-mysql-retail-store-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-mysql-retail-store-datamodel",
              "slug": "/data-modeling/lab-mysql-retail-store-datamodel/",
              "permalink": "/docs/data-modeling/lab-mysql-retail-store-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Northwind Data Model in MySQL",
                "permalink": "/docs/data-modeling/lab-mysql-northwind-datamodel/"
              },
              "next": {
                "title": "Lab: Creating a Bus Rapid Transit (BRT) Database in Postgres",
                "permalink": "/docs/data-modeling/lab-postgres-busrapid-transit/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-postgres-busrapid-transit/README",
              "id": "data-modeling/lab-postgres-busrapid-transit/README",
              "title": "Lab: Creating a Bus Rapid Transit (BRT) Database in Postgres",
              "description": "Creating a Bus Rapid Transit (BRT) Database",
              "source": "@site/docs/04-data-modeling/lab-postgres-busrapid-transit/README.md",
              "sourceDirName": "04-data-modeling/lab-postgres-busrapid-transit",
              "slug": "/data-modeling/lab-postgres-busrapid-transit/",
              "permalink": "/docs/data-modeling/lab-postgres-busrapid-transit/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Retail Store Data Model in MySQL",
                "permalink": "/docs/data-modeling/lab-mysql-retail-store-datamodel/"
              },
              "next": {
                "title": "Lab: Create Fact and Dimension Tables from Denormalized Raw Data",
                "permalink": "/docs/data-modeling/lab-postgres-elt-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-postgres-demographics-datamodel",
              "id": "data-modeling/lab-postgres-demographics-datamodel",
              "title": "lab-postgres-demographics-datamodel",
              "description": "Create Fact and Dimension Tables from Denormalized Raw Data",
              "source": "@site/docs/04-data-modeling/lab-postgres-demographics-datamodel.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/lab-postgres-demographics-datamodel",
              "permalink": "/docs/data-modeling/lab-postgres-demographics-datamodel",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "data-modeling/lab-postgres-elt-datamodel/README",
              "id": "data-modeling/lab-postgres-elt-datamodel/README",
              "title": "Lab: Create Fact and Dimension Tables from Denormalized Raw Data",
              "description": "In data warehousing world there are occasions where developers have to reverse engineer model from flat csv files. We will understand this with simple example.",
              "source": "@site/docs/04-data-modeling/lab-postgres-elt-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-postgres-elt-datamodel",
              "slug": "/data-modeling/lab-postgres-elt-datamodel/",
              "permalink": "/docs/data-modeling/lab-postgres-elt-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Creating a Bus Rapid Transit (BRT) Database in Postgres",
                "permalink": "/docs/data-modeling/lab-postgres-busrapid-transit/"
              },
              "next": {
                "title": "Lab: Postgres e-Wallet Data Model",
                "permalink": "/docs/data-modeling/lab-postgres-ewallet-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-postgres-ewallet-datamodel/README",
              "id": "data-modeling/lab-postgres-ewallet-datamodel/README",
              "title": "Lab: Postgres e-Wallet Data Model",
              "description": "In this lab, we will design a data model for an eWallet company.",
              "source": "@site/docs/04-data-modeling/lab-postgres-ewallet-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-postgres-ewallet-datamodel",
              "slug": "/data-modeling/lab-postgres-ewallet-datamodel/",
              "permalink": "/docs/data-modeling/lab-postgres-ewallet-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Create Fact and Dimension Tables from Denormalized Raw Data",
                "permalink": "/docs/data-modeling/lab-postgres-elt-datamodel/"
              },
              "next": {
                "title": "Lab: Housing Data Model with CDC and SCD Type 2",
                "permalink": "/docs/data-modeling/lab-postgres-housing-cdc-scd/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-postgres-housing-cdc-scd/README",
              "id": "data-modeling/lab-postgres-housing-cdc-scd/README",
              "title": "Lab: Housing Data Model with CDC and SCD Type 2",
              "description": "A critical aspect of data engineering is dealing with data change from one date to the next. In this case, we want both the current and historical value. There are many techniques and patterns to create a historical-friendly model during the ingestion and modeling phases. In this lab, we will build a data model that uses Change Data Capture and Slowly Changing Dimension Type 2 modelization to track housing prices. The code is written in Python. pandas and sqlalchemy library is used to load data from CSV files and execute SQL queries against the data warehouse.",
              "source": "@site/docs/04-data-modeling/lab-postgres-housing-cdc-scd/README.md",
              "sourceDirName": "04-data-modeling/lab-postgres-housing-cdc-scd",
              "slug": "/data-modeling/lab-postgres-housing-cdc-scd/",
              "permalink": "/docs/data-modeling/lab-postgres-housing-cdc-scd/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Postgres e-Wallet Data Model",
                "permalink": "/docs/data-modeling/lab-postgres-ewallet-datamodel/"
              },
              "next": {
                "title": "Lab: Credit Debit Finance Data Model in Snowflake",
                "permalink": "/docs/data-modeling/lab-snowflake-creditdebit-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-sales-datamodel/README",
              "id": "data-modeling/lab-sales-datamodel/README",
              "title": "Sales Datamodel",
              "description": "Create dimension tables",
              "source": "@site/docs/04-data-modeling/lab-sales-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-sales-datamodel",
              "slug": "/data-modeling/lab-sales-datamodel/",
              "permalink": "/docs/data-modeling/lab-sales-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "data-modeling/lab-snowflake-creditdebit-datamodel/README",
              "id": "data-modeling/lab-snowflake-creditdebit-datamodel/README",
              "title": "Lab: Credit Debit Finance Data Model in Snowflake",
              "description": "Notebooks",
              "source": "@site/docs/04-data-modeling/lab-snowflake-creditdebit-datamodel/README.md",
              "sourceDirName": "04-data-modeling/lab-snowflake-creditdebit-datamodel",
              "slug": "/data-modeling/lab-snowflake-creditdebit-datamodel/",
              "permalink": "/docs/data-modeling/lab-snowflake-creditdebit-datamodel/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Housing Data Model with CDC and SCD Type 2",
                "permalink": "/docs/data-modeling/lab-postgres-housing-cdc-scd/"
              },
              "next": {
                "title": "Lab: Sparkify Music Company Data Model in Postgres",
                "permalink": "/docs/data-modeling/lab-sparkify-data-model-postgres/"
              }
            },
            {
              "unversionedId": "data-modeling/lab-sparkify-data-model-postgres/README",
              "id": "data-modeling/lab-sparkify-data-model-postgres/README",
              "title": "Lab: Sparkify Music Company Data Model in Postgres",
              "description": "In this, we will model the data with Postgres and build an ETL pipeline using Python. The fact and dimension tables for a star database schema for a particular analytic focus is defined, and an ETL pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL was developed.",
              "source": "@site/docs/04-data-modeling/lab-sparkify-data-model-postgres/README.md",
              "sourceDirName": "04-data-modeling/lab-sparkify-data-model-postgres",
              "slug": "/data-modeling/lab-sparkify-data-model-postgres/",
              "permalink": "/docs/data-modeling/lab-sparkify-data-model-postgres/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Credit Debit Finance Data Model in Snowflake",
                "permalink": "/docs/data-modeling/lab-snowflake-creditdebit-datamodel/"
              },
              "next": {
                "title": "NoSQL Data Modeling",
                "permalink": "/docs/data-modeling/nosql-data-modeling"
              }
            },
            {
              "unversionedId": "data-modeling/normalization-vs-denormalization",
              "id": "data-modeling/normalization-vs-denormalization",
              "title": "Normalization vs Denormalization",
              "description": "Normalization is Trying to increase data integrity by reducing the number of copies of the data. Data that needs to be added or updated will be done in as few places as possible. Denormalization is Trying to increase performance by reducing the number of joins between tables (as joins can be slow). Data integrity will take a bit of a potential hit, as there will be more copies of the data (to reduce JOINS).",
              "source": "@site/docs/04-data-modeling/normalization-vs-denormalization.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/normalization-vs-denormalization",
              "permalink": "/docs/data-modeling/normalization-vs-denormalization",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Warehousing",
                "permalink": "/docs/data-modeling/data-warehousing"
              },
              "next": {
                "title": "CAP Theorem",
                "permalink": "/docs/data-modeling/cap-theorem"
              }
            },
            {
              "unversionedId": "data-modeling/nosql-data-modeling",
              "id": "data-modeling/nosql-data-modeling",
              "title": "NoSQL Data Modeling",
              "description": "What is a NoSQL data model?",
              "source": "@site/docs/04-data-modeling/nosql-data-modeling.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/nosql-data-modeling",
              "permalink": "/docs/data-modeling/nosql-data-modeling",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Sparkify Music Company Data Model in Postgres",
                "permalink": "/docs/data-modeling/lab-sparkify-data-model-postgres/"
              },
              "next": {
                "title": "Lab: Create a Data Model for a Digital Music Library",
                "permalink": "/docs/data-modeling/lab-cassandra-digital-music-library/"
              }
            },
            {
              "unversionedId": "data-modeling/quiz",
              "id": "data-modeling/quiz",
              "title": "Quiz",
              "description": "1. What is Data Normalization?",
              "source": "@site/docs/04-data-modeling/quiz.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/quiz",
              "permalink": "/docs/data-modeling/quiz",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "CAP Theorem",
                "permalink": "/docs/data-modeling/cap-theorem"
              },
              "next": {
                "title": "Lab: AirBnB Postgres Datamodel",
                "permalink": "/docs/data-modeling/lab-airbnb-postgres-datamodel/"
              }
            },
            {
              "unversionedId": "data-modeling/sql-data-modeling",
              "id": "data-modeling/sql-data-modeling",
              "title": "SQL Data Modeling",
              "description": "What is data modeling? Data modeling is a process for representing the database objects in our real-world or business perspective. Objects in warehouses can be datasets, tables, or views. Representing the objects as close as possible to the real world is important because the end users of the data are human. Some of the most common end users are business analysts, data analysts, data scientists, BI users, or any other roles that require access to the data for business purposes.",
              "source": "@site/docs/04-data-modeling/sql-data-modeling.md",
              "sourceDirName": "04-data-modeling",
              "slug": "/data-modeling/sql-data-modeling",
              "permalink": "/docs/data-modeling/sql-data-modeling",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Modeling",
                "permalink": "/docs/category/data-modeling"
              },
              "next": {
                "title": "Inmon versus the Kimball data model",
                "permalink": "/docs/data-modeling/inmon-vs-kimball"
              }
            },
            {
              "unversionedId": "datascience/algorithms/decision-trees",
              "id": "datascience/algorithms/decision-trees",
              "title": "Decision Trees",
              "description": "The concept of Decision Trees appeared in the 1960s in the field of psychology for modeling the concept of human learning, visually presenting possible outcomes to potential situations that stem from one prompt. It was around that time when people discovered the usefulness of Decision Trees in programming and mathematics. The first paper that was able to develop a concept of “Decision Tree” mathematically was published by William Belson in 1959. In 1977, various professors from Berkley and Stanford developed an algorithm known as Classification and Regression Trees (CART), which, true to its name, consisted of Classification and Regression Trees. To this day, CART still stands as an important algorithm for data analysis. In the field of ML, Decision Tree serves as one of the most popular algorithms for real-world data science problems.",
              "source": "@site/docs/10-datascience/algorithms/decision-trees.md",
              "sourceDirName": "10-datascience/algorithms",
              "slug": "/datascience/algorithms/decision-trees",
              "permalink": "/docs/datascience/algorithms/decision-trees",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Logistic Regression",
                "permalink": "/docs/datascience/algorithms/logistic-regression"
              },
              "next": {
                "title": "Random Forest",
                "permalink": "/docs/datascience/algorithms/random-forest"
              }
            },
            {
              "unversionedId": "datascience/algorithms/gradient-boosting",
              "id": "datascience/algorithms/gradient-boosting",
              "title": "Gradient Boosting",
              "description": "Gradient Boosting describes a certain technique in modeling with a variety of different algorithms that are based upon it. The first successful algorithm that utilizes Gradient Boosting is AdaBoost (Adaptive Gradient Boosting) in 1998 formulated by Leo Breiman. In 1999, Jerome Friedman composed the generalization of boosting algorithms emerging at this time, such as AdaBoost, into a single method: Gradient Boosting Machines. Quickly, the idea of Gradient Boosting Machines became extremely popular and proved to be high performing in many real-life tabular datasets. To this day, various Gradient Boosting algorithms such as AdaBoost, XGBoost, and LightGBM are the first choice for many data scientists operating on large, difficult datasets.",
              "source": "@site/docs/10-datascience/algorithms/gradient-boosting.md",
              "sourceDirName": "10-datascience/algorithms",
              "slug": "/datascience/algorithms/gradient-boosting",
              "permalink": "/docs/datascience/algorithms/gradient-boosting",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "K-Nearest Neighbors",
                "permalink": "/docs/datascience/algorithms/knn"
              },
              "next": {
                "title": "Prophet",
                "permalink": "/docs/datascience/timeseries/prophet"
              }
            },
            {
              "unversionedId": "datascience/algorithms/knn",
              "id": "datascience/algorithms/knn",
              "title": "K-Nearest Neighbors",
              "description": "K-Nearest Neighbors, or KNN, is one of the simplest and the most intuitive classical machine learning algorithms. KNN was first proposed by Evelyn Fix and Joseph Lawson Hodges Jr. during a technical analysis produced for USAF in 1951. It was unique at its time as the method proposed is nonparametric: the algorithm does not make any assumptions about the statistical properties of the data. Although the paper wasn’t ever published due to the confidential nature of the work, it laid out the groundwork for the first-ever nonparametric classification method, K-Nearest Neighbors. The beauty of KNN lies in its simplicity, and unlike most other algorithms, KNN does not contain a training phase. Additional data can be incorporated seamlessly as the algorithm is memory-based, easily adapting to any new data. Over seven decades later, KNN still stands as a popular classification algorithm, and innovations are still constantly being proposed surrounding it.",
              "source": "@site/docs/10-datascience/algorithms/knn.md",
              "sourceDirName": "10-datascience/algorithms",
              "slug": "/datascience/algorithms/knn",
              "permalink": "/docs/datascience/algorithms/knn",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Random Forest",
                "permalink": "/docs/datascience/algorithms/random-forest"
              },
              "next": {
                "title": "Gradient Boosting",
                "permalink": "/docs/datascience/algorithms/gradient-boosting"
              }
            },
            {
              "unversionedId": "datascience/algorithms/linear-regression",
              "id": "datascience/algorithms/linear-regression",
              "title": "Linear Regression",
              "description": "The earliest form of regression analysis, Linear Regression using Least Squares, was first published by Adrien-Marie Legendre in 1805 and then again by Carl Friedrich Gauss in 1809. Both used them to predict astronomical orbitals, specifically bodies that orbit the sun. Later in 1821, Gauss published his continued work on the Least Square Theory; however, the term regression wasn’t coined until the late nineteenth century by Francis Galton. Galton discovered a linear relationship between the weights of mother and daughter seeds across generations. To Galton, regression was merely a term to describe a biological phenomenon. It was not until Udny Yule and Karl Pearson expanded this method to a more general statistics view.",
              "source": "@site/docs/10-datascience/algorithms/linear-regression.md",
              "sourceDirName": "10-datascience/algorithms",
              "slug": "/datascience/algorithms/linear-regression",
              "permalink": "/docs/datascience/algorithms/linear-regression",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Feature Selection",
                "permalink": "/docs/datascience/feature-selection"
              },
              "next": {
                "title": "Logistic Regression",
                "permalink": "/docs/datascience/algorithms/logistic-regression"
              }
            },
            {
              "unversionedId": "datascience/algorithms/logistic-regression",
              "id": "datascience/algorithms/logistic-regression",
              "title": "Logistic Regression",
              "description": "The logistic function first appeared in Pierre Francois Verhulst’s publication “Correspondance mathmematique et physique” in 1838. Then later in 1845, a more detailed version of the logistic function was published by him. However, the first practical application of such a function wasn’t apparent until 1943 when Wilson and Worcester used the logistic function in bioassay. In the following years, various advances were made toward the function, but the original logistic function is used for Logistic Regression. The Logistic Regression model found its use not only in areas related to biology but also widely in social science.",
              "source": "@site/docs/10-datascience/algorithms/logistic-regression.md",
              "sourceDirName": "10-datascience/algorithms",
              "slug": "/datascience/algorithms/logistic-regression",
              "permalink": "/docs/datascience/algorithms/logistic-regression",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Linear Regression",
                "permalink": "/docs/datascience/algorithms/linear-regression"
              },
              "next": {
                "title": "Decision Trees",
                "permalink": "/docs/datascience/algorithms/decision-trees"
              }
            },
            {
              "unversionedId": "datascience/algorithms/ml-eda/README",
              "id": "datascience/algorithms/ml-eda/README",
              "title": "ml-eda",
              "description": "",
              "source": "@site/docs/10-datascience/algorithms/ml-eda/README.md",
              "sourceDirName": "10-datascience/algorithms/ml-eda",
              "slug": "/datascience/algorithms/ml-eda/",
              "permalink": "/docs/datascience/algorithms/ml-eda/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/algorithms/ml-eda/variable-distribution-analysis/README",
              "id": "datascience/algorithms/ml-eda/variable-distribution-analysis/README",
              "title": "README",
              "description": "We looked at some common techniques for exploring data. We learned how to retrieve subsets of data when that is required for our analysis. We also used pandas methods to generate key statistics on features such as mean, interquartile range, and skew. This gave us a better sense of the central tendency, spread, and shape of the distribution of each feature. It also put us in a better position to identify outliers. Finally, we used the Matplotlib and Seaborn libraries to create histograms, boxplots, and violin plots. This yielded additional insights about the distribution of features, such as the length of the tail and divergence from the normal distribution.",
              "source": "@site/docs/10-datascience/algorithms/ml-eda/variable-distribution-analysis/README.md",
              "sourceDirName": "10-datascience/algorithms/ml-eda/variable-distribution-analysis",
              "slug": "/datascience/algorithms/ml-eda/variable-distribution-analysis/",
              "permalink": "/docs/datascience/algorithms/ml-eda/variable-distribution-analysis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/algorithms/random-forest",
              "id": "datascience/algorithms/random-forest",
              "title": "Random Forest",
              "description": "Random Forest is an algorithm that provides some crucial improvements to the design of Decision Trees. Simply put, Random Forest is an ensemble of many smaller Decision Trees working together. Random Forest uses the simple concept that the wisdom of crowds is always better than one strong individual. By using lowly correlated small Decision Trees, their ensemble of predictions can outperform any single Decision Tree. The technique that Random Forest uses to ensemble smaller Decision Trees is called bagging. Bagging, also known as bootstrap aggregation, is randomly drawing different subsets, with replacements, from the training data, and the final prediction is decided by majority voting.",
              "source": "@site/docs/10-datascience/algorithms/random-forest.md",
              "sourceDirName": "10-datascience/algorithms",
              "slug": "/datascience/algorithms/random-forest",
              "permalink": "/docs/datascience/algorithms/random-forest",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Decision Trees",
                "permalink": "/docs/datascience/algorithms/decision-trees"
              },
              "next": {
                "title": "K-Nearest Neighbors",
                "permalink": "/docs/datascience/algorithms/knn"
              }
            },
            {
              "unversionedId": "datascience/basics/cross-domain",
              "id": "datascience/basics/cross-domain",
              "title": "Cross-domain",
              "description": "A common challenge for most current recommender systems is the cold-start problem. Due to the lack of user-item interactions, the fine-tuned recommender systems are unable to handle situations with new users or new items. Recently, some works introduce the meta-optimization idea into the recommendation scenarios, i.e. predicting the user preference by only a few of past interacted items. The core idea is learning a global sharing initialization parameter for all users and then learning the local parameters for each user separately. However, most meta-learning based recommendation approaches adopt model-agnostic meta-learning for parameter initialization, where the global sharing parameter may lead the model into local optima for some users.",
              "source": "@site/docs/10-datascience/basics/cross-domain.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/cross-domain",
              "permalink": "/docs/datascience/basics/cross-domain",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/graph-embeddings",
              "id": "datascience/basics/graph-embeddings",
              "title": "Graph Embeddings",
              "description": "Due to their nature, graphs can be analyzed at different levels of granularity: at the node, edge, and graph level (the whole graph), as depicted in the following figure. For each of those levels, different problems could be faced and, as a consequence, specific algorithms should be used.",
              "source": "@site/docs/10-datascience/basics/graph-embeddings.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/graph-embeddings",
              "permalink": "/docs/datascience/basics/graph-embeddings",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/graph-networks",
              "id": "datascience/basics/graph-networks",
              "title": "Graph Networks",
              "description": "Item-Item Co-Occurrence Graph",
              "source": "@site/docs/10-datascience/basics/graph-networks.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/graph-networks",
              "permalink": "/docs/datascience/basics/graph-networks",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/incremental-learning",
              "id": "datascience/basics/incremental-learning",
              "title": "Incremental Learning",
              "description": "Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference.",
              "source": "@site/docs/10-datascience/basics/incremental-learning.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/incremental-learning",
              "permalink": "/docs/datascience/basics/incremental-learning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/meta-learning",
              "id": "datascience/basics/meta-learning",
              "title": "Meta Learning",
              "description": "Meta learning covers a wide range of topics and has contributed to a booming study trend. Few-shot learning is one of successful branches of meta learning. We retrospect some representative meta-learning models with strong connections to our work.",
              "source": "@site/docs/10-datascience/basics/meta-learning.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/meta-learning",
              "permalink": "/docs/datascience/basics/meta-learning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/model-retraining",
              "id": "datascience/basics/model-retraining",
              "title": "Model Retraining",
              "description": "Concept Drift",
              "source": "@site/docs/10-datascience/basics/model-retraining.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/model-retraining",
              "permalink": "/docs/datascience/basics/model-retraining",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/multi-objective-optimization",
              "id": "datascience/basics/multi-objective-optimization",
              "title": "Multi-Objective Optimization",
              "description": "Recommender systems have been widely applied to several domains and applications. Traditional recommender systems usually deal with a single objective, such as minimizing the prediction errors or maximizing the ranking of the recommendation list. There is an emerging demand for multi-objective optimization so that the development of recommendation models can take multiple objectives into consideration, especially in the area of multi-stakeholder and multi-task recommender systems.",
              "source": "@site/docs/10-datascience/basics/multi-objective-optimization.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/multi-objective-optimization",
              "permalink": "/docs/datascience/basics/multi-objective-optimization",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/multitask-learning",
              "id": "datascience/basics/multitask-learning",
              "title": "Multi-Task Learning",
              "description": "Generally, as soon as you find yourself optimizing more than one loss function, you are effectively doing multi-task learning (in contrast to single-task learning). In those scenarios, it helps to think about what you are trying to do explicitly in terms of MTL and to draw insights from it.",
              "source": "@site/docs/10-datascience/basics/multitask-learning.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/multitask-learning",
              "permalink": "/docs/datascience/basics/multitask-learning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/offline-learning",
              "id": "datascience/basics/offline-learning",
              "title": "Off-Policy Learning",
              "description": "Offline Reinforcement Learning",
              "source": "@site/docs/10-datascience/basics/offline-learning.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/offline-learning",
              "permalink": "/docs/datascience/basics/offline-learning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/river",
              "id": "datascience/basics/river",
              "title": "River",
              "description": "River is a Python library for online machine learning. It is the result of a merger between creme and scikit-multiflow. River's ambition is to be the go-to library for doing machine learning on streaming data.",
              "source": "@site/docs/10-datascience/basics/river.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/river",
              "permalink": "/docs/datascience/basics/river",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/basics/scalarization",
              "id": "datascience/basics/scalarization",
              "title": "Scalarization",
              "description": "| Method | Idea | Scalarization | Characteristic |",
              "source": "@site/docs/10-datascience/basics/scalarization.mdx",
              "sourceDirName": "10-datascience/basics",
              "slug": "/datascience/basics/scalarization",
              "permalink": "/docs/datascience/basics/scalarization",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/bayesian-optimization",
              "id": "datascience/bayesian-optimization",
              "title": "Bayesian Optimization",
              "description": "Optimization aims to locate the optimal set of parameters of interest across the whole domain through carefully allocating limited resources. For example, when searching for the car key at home before leaving for work in two minutes, we would naturally start with the most promising place where we would usually put the key. If it is not there, think for a little while about the possible locations and go to the next most promising place. This process iterates until the key is found. In this example, the policy is digesting the available information on previous searches and proposing the following promising location. The environment is the house itself, revealing if the key is placed at the proposed location upon each sampling.",
              "source": "@site/docs/10-datascience/bayesian-optimization.md",
              "sourceDirName": "10-datascience",
              "slug": "/datascience/bayesian-optimization",
              "permalink": "/docs/datascience/bayesian-optimization",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/bias-variance-tradeoff",
              "id": "datascience/bias-variance-tradeoff",
              "title": "Bias-Variance Trade-Off",
              "description": "Bias is a model’s ability to identify general trends and ideas in the dataset, whereas variance is the ability to model data with high precision. Since we think of bias and variance in terms of error, a lower bias or variance is better. The bias-variance relationship is often visualized as a set of dart throws on a bull’s-eye. The ideal set of throws is a cluster of hits all around the center ring, which is low bias (the general “center” of the throws is not shifted off/biased) and low variance (the collection of hits are clustered together rather than far out, indicating consistently good performance).",
              "source": "@site/docs/10-datascience/bias-variance-tradeoff.md",
              "sourceDirName": "10-datascience",
              "slug": "/datascience/bias-variance-tradeoff",
              "permalink": "/docs/datascience/bias-variance-tradeoff",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Splits",
                "permalink": "/docs/datascience/data-splits"
              },
              "next": {
                "title": "Metrics and Evaluation",
                "permalink": "/docs/datascience/metrics-and-evaluation"
              }
            },
            {
              "unversionedId": "datascience/challenges/conversion-rate/README",
              "id": "datascience/challenges/conversion-rate/README",
              "title": "README",
              "description": "https://github.com/Saadorj/DataScienceProjects/tree/master",
              "source": "@site/docs/10-datascience/challenges/conversion-rate/README.md",
              "sourceDirName": "10-datascience/challenges/conversion-rate",
              "slug": "/datascience/challenges/conversion-rate/",
              "permalink": "/docs/datascience/challenges/conversion-rate/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/creditcard-fraud/README",
              "id": "datascience/challenges/creditcard-fraud/README",
              "title": "README",
              "description": "https://github.com/sunjoshi1991/DATA-SCIENCE-CHALLENGES/tree/master",
              "source": "@site/docs/10-datascience/challenges/creditcard-fraud/README.md",
              "sourceDirName": "10-datascience/challenges/creditcard-fraud",
              "slug": "/datascience/challenges/creditcard-fraud/",
              "permalink": "/docs/datascience/challenges/creditcard-fraud/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/employee-retention/README",
              "id": "datascience/challenges/employee-retention/README",
              "title": "README",
              "description": "https://github.com/rebeccak1/employee-retention",
              "source": "@site/docs/10-datascience/challenges/employee-retention/README.md",
              "sourceDirName": "10-datascience/challenges/employee-retention",
              "slug": "/datascience/challenges/employee-retention/",
              "permalink": "/docs/datascience/challenges/employee-retention/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/employee-shuttle-stops",
              "id": "datascience/challenges/employee-shuttle-stops",
              "title": "Optimization of Employee Shuttle Stops",
              "description": "Goal",
              "source": "@site/docs/10-datascience/challenges/employee-shuttle-stops.md",
              "sourceDirName": "10-datascience/challenges",
              "slug": "/datascience/challenges/employee-shuttle-stops",
              "permalink": "/docs/datascience/challenges/employee-shuttle-stops",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/fraud-activity/README",
              "id": "datascience/challenges/fraud-activity/README",
              "title": "Fraud Detection",
              "description": "https://github.com/jkvalentine/Fraud_Detection/tree/master",
              "source": "@site/docs/10-datascience/challenges/fraud-activity/README.md",
              "sourceDirName": "10-datascience/challenges/fraud-activity",
              "slug": "/datascience/challenges/fraud-activity/",
              "permalink": "/docs/datascience/challenges/fraud-activity/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/funnel-analysis/README",
              "id": "datascience/challenges/funnel-analysis/README",
              "title": "README",
              "description": "https://github.com/araj2/Funnel-Analysis/tree/master",
              "source": "@site/docs/10-datascience/challenges/funnel-analysis/README.md",
              "sourceDirName": "10-datascience/challenges/funnel-analysis",
              "slug": "/datascience/challenges/funnel-analysis/",
              "permalink": "/docs/datascience/challenges/funnel-analysis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/loan-grant/README",
              "id": "datascience/challenges/loan-grant/README",
              "title": "README",
              "description": "https://github.com/pawachaitanya/Loan-Granting/tree/master",
              "source": "@site/docs/10-datascience/challenges/loan-grant/README.md",
              "sourceDirName": "10-datascience/challenges/loan-grant",
              "slug": "/datascience/challenges/loan-grant/",
              "permalink": "/docs/datascience/challenges/loan-grant/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/marketing-email-campaign/README",
              "id": "datascience/challenges/marketing-email-campaign/README",
              "title": "README",
              "description": "https://github.com/carlssonnp/Optimizing-Email-Marketing/tree/master",
              "source": "@site/docs/10-datascience/challenges/marketing-email-campaign/README.md",
              "sourceDirName": "10-datascience/challenges/marketing-email-campaign",
              "slug": "/datascience/challenges/marketing-email-campaign/",
              "permalink": "/docs/datascience/challenges/marketing-email-campaign/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/price-test/README",
              "id": "datascience/challenges/price-test/README",
              "title": "README",
              "description": "https://www.kaggle.com/code/ffxiaozhi/data-science-take-home-challenges-pricing-test",
              "source": "@site/docs/10-datascience/challenges/price-test/README.md",
              "sourceDirName": "10-datascience/challenges/price-test",
              "slug": "/datascience/challenges/price-test/",
              "permalink": "/docs/datascience/challenges/price-test/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/README",
              "id": "datascience/challenges/README",
              "title": "Challenges",
              "description": "1. User Referral Program",
              "source": "@site/docs/10-datascience/challenges/README.md",
              "sourceDirName": "10-datascience/challenges",
              "slug": "/datascience/challenges/",
              "permalink": "/docs/datascience/challenges/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/translate-ab-test/README",
              "id": "datascience/challenges/translate-ab-test/README",
              "title": "README",
              "description": "https://github.com/commit-live-students/feature-engineering-for-translation-test-dataset/tree/master",
              "source": "@site/docs/10-datascience/challenges/translate-ab-test/README.md",
              "sourceDirName": "10-datascience/challenges/translate-ab-test",
              "slug": "/datascience/challenges/translate-ab-test/",
              "permalink": "/docs/datascience/challenges/translate-ab-test/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/Ultimate-data-science-take-home-challenge-sample/README",
              "id": "datascience/challenges/Ultimate-data-science-take-home-challenge-sample/README",
              "title": "Ultimate Data Science Take Home Challenge Sample",
              "description": "A practice challenge for the DS interview process",
              "source": "@site/docs/10-datascience/challenges/Ultimate-data-science-take-home-challenge-sample/README.md",
              "sourceDirName": "10-datascience/challenges/Ultimate-data-science-take-home-challenge-sample",
              "slug": "/datascience/challenges/Ultimate-data-science-take-home-challenge-sample/",
              "permalink": "/docs/datascience/challenges/Ultimate-data-science-take-home-challenge-sample/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/user-referral-program",
              "id": "datascience/challenges/user-referral-program",
              "title": "User Referral Program",
              "description": "Goal",
              "source": "@site/docs/10-datascience/challenges/user-referral-program.md",
              "sourceDirName": "10-datascience/challenges",
              "slug": "/datascience/challenges/user-referral-program",
              "permalink": "/docs/datascience/challenges/user-referral-program",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/challenges/video-sharing-analysis",
              "id": "datascience/challenges/video-sharing-analysis",
              "title": "Video Sharing Analysis",
              "description": "Goal",
              "source": "@site/docs/10-datascience/challenges/video-sharing-analysis.md",
              "sourceDirName": "10-datascience/challenges",
              "slug": "/datascience/challenges/video-sharing-analysis",
              "permalink": "/docs/datascience/challenges/video-sharing-analysis",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/computer-vision/lab-agri-setallite-image-segmentation/README",
              "id": "datascience/computer-vision/lab-agri-setallite-image-segmentation/README",
              "title": "Agricultural Satellite Image Segmentation",
              "description": "",
              "source": "@site/docs/10-datascience/computer-vision/lab-agri-setallite-image-segmentation/README.md",
              "sourceDirName": "10-datascience/computer-vision/lab-agri-setallite-image-segmentation",
              "slug": "/datascience/computer-vision/lab-agri-setallite-image-segmentation/",
              "permalink": "/docs/datascience/computer-vision/lab-agri-setallite-image-segmentation/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/computer-vision/lab-image-analytics-tensorflow/README",
              "id": "datascience/computer-vision/lab-image-analytics-tensorflow/README",
              "title": "Image Analytics with Tensorflow",
              "description": "",
              "source": "@site/docs/10-datascience/computer-vision/lab-image-analytics-tensorflow/README.md",
              "sourceDirName": "10-datascience/computer-vision/lab-image-analytics-tensorflow",
              "slug": "/datascience/computer-vision/lab-image-analytics-tensorflow/",
              "permalink": "/docs/datascience/computer-vision/lab-image-analytics-tensorflow/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/computer-vision/README",
              "id": "datascience/computer-vision/README",
              "title": "Computer Vision",
              "description": "Categories",
              "source": "@site/docs/10-datascience/computer-vision/README.md",
              "sourceDirName": "10-datascience/computer-vision",
              "slug": "/datascience/computer-vision/",
              "permalink": "/docs/datascience/computer-vision/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/data-encoding",
              "id": "datascience/data-encoding",
              "title": "Data Encoding",
              "description": "Discrete Data",
              "source": "@site/docs/10-datascience/data-encoding.md",
              "sourceDirName": "10-datascience",
              "slug": "/datascience/data-encoding",
              "permalink": "/docs/datascience/data-encoding",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Preparation",
                "permalink": "/docs/datascience/data-preparation"
              },
              "next": {
                "title": "Feature Selection",
                "permalink": "/docs/datascience/feature-selection"
              }
            },
            {
              "unversionedId": "datascience/data-preparation",
              "id": "datascience/data-preparation",
              "title": "Data Preparation",
              "description": "Roughly, we can identify three primary components of data preprocessing the goal of data encoding is to make raw data both readable and “true to its natural characteristics”; the goal of feature extraction is to identify abstracted or more relevant features from within the data space; the goal of feature selection is to identify if and which features are not relevant to the predictive process and can be removed. Generally, data encoding takes precedence over the latter two components because data must be readable and representative of itself before we can attempt to extract features from it or select which features are relevant.",
              "source": "@site/docs/10-datascience/data-preparation.md",
              "sourceDirName": "10-datascience",
              "slug": "/datascience/data-preparation",
              "permalink": "/docs/datascience/data-preparation",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Metrics and Evaluation",
                "permalink": "/docs/datascience/metrics-and-evaluation"
              },
              "next": {
                "title": "Data Encoding",
                "permalink": "/docs/datascience/data-encoding"
              }
            },
            {
              "unversionedId": "datascience/data-splits",
              "id": "datascience/data-splits",
              "title": "Data Splits",
              "description": "Training and Validation sets",
              "source": "@site/docs/10-datascience/data-splits.md",
              "sourceDirName": "10-datascience",
              "slug": "/datascience/data-splits",
              "permalink": "/docs/datascience/data-splits",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Model Deployment",
                "permalink": "/docs/foundations/basics/deployment"
              },
              "next": {
                "title": "Bias-Variance Trade-Off",
                "permalink": "/docs/datascience/bias-variance-tradeoff"
              }
            },
            {
              "unversionedId": "datascience/deep-learning/deep-learning-basics",
              "id": "datascience/deep-learning/deep-learning-basics",
              "title": "Deep Learning Basics",
              "description": "What is Deep Learning?",
              "source": "@site/docs/10-datascience/deep-learning/deep-learning-basics.md",
              "sourceDirName": "10-datascience/deep-learning",
              "slug": "/datascience/deep-learning/deep-learning-basics",
              "permalink": "/docs/datascience/deep-learning/deep-learning-basics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Prophet",
                "permalink": "/docs/datascience/timeseries/prophet"
              },
              "next": {
                "title": "The Rosenblatt Perceptron",
                "permalink": "/docs/datascience/deep-learning/perceptron"
              }
            },
            {
              "unversionedId": "datascience/deep-learning/perceptron",
              "id": "datascience/deep-learning/perceptron",
              "title": "The Rosenblatt Perceptron",
              "description": "The perceptron is an artificial neuron, that is, a model of a biological neuron.",
              "source": "@site/docs/10-datascience/deep-learning/perceptron.md",
              "sourceDirName": "10-datascience/deep-learning",
              "slug": "/datascience/deep-learning/perceptron",
              "permalink": "/docs/datascience/deep-learning/perceptron",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Deep Learning Basics",
                "permalink": "/docs/datascience/deep-learning/deep-learning-basics"
              },
              "next": {
                "title": "MLOps",
                "permalink": "/docs/mlops/"
              }
            },
            {
              "unversionedId": "datascience/feature-selection",
              "id": "datascience/feature-selection",
              "title": "Feature Selection",
              "description": "Feature selection refers to the process of filtering out or removing features from a dataset. There are two main reasons to perform feature selection: removing redundant (very similar information content) features and filtering out irrelevant (information content not valuable w.r.t. the target) features that may worsen model performance. The difference between feature extraction and feature selection lies in that selection reduces the number of features while extraction creates new features or modifies existing ones. A universal approach to feature selection usually consists of obtaining a measure of “usefulness” for each feature and then eliminating those that do not meet a threshold. Note that no matter which method for feature selection is used, the best result will likely come from trial and error since the optimal techniques and tools vary for datasets.",
              "source": "@site/docs/10-datascience/feature-selection.md",
              "sourceDirName": "10-datascience",
              "slug": "/datascience/feature-selection",
              "permalink": "/docs/datascience/feature-selection",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Encoding",
                "permalink": "/docs/datascience/data-encoding"
              },
              "next": {
                "title": "Linear Regression",
                "permalink": "/docs/datascience/algorithms/linear-regression"
              }
            },
            {
              "unversionedId": "datascience/metrics-and-evaluation",
              "id": "datascience/metrics-and-evaluation",
              "title": "Metrics and Evaluation",
              "description": "In general terms, metrics are tools to set standards and evaluate the performance of models. In the field of machine learning and data science, obtaining a functional model is far from enough. We need to develop methods and assessment metrics to determine how well models perform on tasks that are given. Metrics used in machine learning are formulas and equations that provide specific quantitative measurements as to how well the developed methods perform on the data provided. Evaluation refers to the process of distinguishing between the better and the worse models by comparing metrics.",
              "source": "@site/docs/10-datascience/metrics-and-evaluation.md",
              "sourceDirName": "10-datascience",
              "slug": "/datascience/metrics-and-evaluation",
              "permalink": "/docs/datascience/metrics-and-evaluation",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Bias-Variance Trade-Off",
                "permalink": "/docs/datascience/bias-variance-tradeoff"
              },
              "next": {
                "title": "Data Preparation",
                "permalink": "/docs/datascience/data-preparation"
              }
            },
            {
              "unversionedId": "datascience/nlp/lab-basic-text-handlng-python/index",
              "id": "datascience/nlp/lab-basic-text-handlng-python/index",
              "title": "Lab: Basic Text Handling with Python",
              "description": "Notebook",
              "source": "@site/docs/10-datascience/nlp/lab-basic-text-handlng-python/index.md",
              "sourceDirName": "10-datascience/nlp/lab-basic-text-handlng-python",
              "slug": "/datascience/nlp/lab-basic-text-handlng-python/",
              "permalink": "/docs/datascience/nlp/lab-basic-text-handlng-python/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: ETL process and reading/writing CSV, JSON and XML files in pandas",
                "permalink": "/docs/foundations/language/python/lab-etl-csv-json-xml/"
              },
              "next": {
                "title": "Explore Further",
                "permalink": "/docs/foundations/language/python/links"
              }
            },
            {
              "unversionedId": "datascience/nlp/lab-pdf-wordcloud-mail/README",
              "id": "datascience/nlp/lab-pdf-wordcloud-mail/README",
              "title": "PDF to Wordcloud via Email",
              "description": "Receive a pdf via outlook mail and send back the wordcloud of that pdf in the reply",
              "source": "@site/docs/10-datascience/nlp/lab-pdf-wordcloud-mail/README.md",
              "sourceDirName": "10-datascience/nlp/lab-pdf-wordcloud-mail",
              "slug": "/datascience/nlp/lab-pdf-wordcloud-mail/",
              "permalink": "/docs/datascience/nlp/lab-pdf-wordcloud-mail/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/nlp/README",
              "id": "datascience/nlp/README",
              "title": "Natural Language Processing (NLP)",
              "description": "Text Classification",
              "source": "@site/docs/10-datascience/nlp/README.md",
              "sourceDirName": "10-datascience/nlp",
              "slug": "/datascience/nlp/",
              "permalink": "/docs/datascience/nlp/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/nlp/text-analysis",
              "id": "datascience/nlp/text-analysis",
              "title": "Text Analysis",
              "description": "Rapid text analysis can save lives. Let’s consider a real-world incident when US soldiers stormed a terrorist compound. In the compound, they discovered a computer containing terabytes of archived data. The data included documents, text messages, and emails pertaining to terrorist activities. The documents were too numerous to be read by any single human being. Fortunately, the soldiers were equipped with special software that could perform very fast text analysis. The software allowed the soldiers to process all of the text data without even having to leave the compound. The onsite analysis immediately revealed an active terrorist plot in a nearby neighborhood. The soldiers instantly responded to the plot and prevented a terrorist attack.",
              "source": "@site/docs/10-datascience/nlp/text-analysis.md",
              "sourceDirName": "10-datascience/nlp",
              "slug": "/datascience/nlp/text-analysis",
              "permalink": "/docs/datascience/nlp/text-analysis",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/nlp/text-cleaning",
              "id": "datascience/nlp/text-cleaning",
              "title": "Text Cleaning",
              "description": "",
              "source": "@site/docs/10-datascience/nlp/text-cleaning.md",
              "sourceDirName": "10-datascience/nlp",
              "slug": "/datascience/nlp/text-cleaning",
              "permalink": "/docs/datascience/nlp/text-cleaning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/nlp/text-processing",
              "id": "datascience/nlp/text-processing",
              "title": "Text Processing",
              "description": "Tokenization",
              "source": "@site/docs/10-datascience/nlp/text-processing.md",
              "sourceDirName": "10-datascience/nlp",
              "slug": "/datascience/nlp/text-processing",
              "permalink": "/docs/datascience/nlp/text-processing",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/nlp/text-style-transfer",
              "id": "datascience/nlp/text-style-transfer",
              "title": "Text Style Transfer",
              "description": "How to adapt the text to different situations, audiences and purposes by making some changes? The style of the text usually includes many aspects such as morphology, grammar, emotion, complexity, fluency, tense, tone and so on.",
              "source": "@site/docs/10-datascience/nlp/text-style-transfer.md",
              "sourceDirName": "10-datascience/nlp",
              "slug": "/datascience/nlp/text-style-transfer",
              "permalink": "/docs/datascience/nlp/text-style-transfer",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/nlp/word2vec",
              "id": "datascience/nlp/word2vec",
              "title": "Lab 162 - Word2vec",
              "description": "Word2vec",
              "source": "@site/docs/10-datascience/nlp/word2vec.md",
              "sourceDirName": "10-datascience/nlp",
              "slug": "/datascience/nlp/word2vec",
              "permalink": "/docs/datascience/nlp/word2vec",
              "draft": false,
              "tags": [
                {
                  "label": "nlp",
                  "permalink": "/docs/tags/nlp"
                }
              ],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "sidebarPosition": 162,
              "frontMatter": {
                "title": "Lab 162 - Word2vec",
                "description": "Word2vec",
                "tags": [
                  "nlp"
                ],
                "sidebar_position": 162
              }
            },
            {
              "unversionedId": "datascience/recsys/amazon-personalize",
              "id": "datascience/recsys/amazon-personalize",
              "title": "Amazon Personalize",
              "description": "Amazon Personalize is a machine learning service that makes it easy for developers to create individualized recommendations for customers using their applications. With Amazon Personalize, you provide an activity stream from your application – clicks, page views, signups, purchases, and so forth – as well as an inventory of the items you want to recommend, such as articles, products, videos, or music. You can also choose to provide Amazon Personalize with additional demographic information from your users such as age, or geographic location. Amazon Personalize will process and examine the data, identify what is meaningful, select the right algorithms, and train and optimize a personalization model that is customized for your data. All data analyzed by Amazon Personalize is kept private and secure, and only used for your customized recommendations. You can start serving personalized recommendations via a simple API call. You pay only for what you use, and there are no minimum fees and no upfront commitments.",
              "source": "@site/docs/10-datascience/recsys/amazon-personalize.md",
              "sourceDirName": "10-datascience/recsys",
              "slug": "/datascience/recsys/amazon-personalize",
              "permalink": "/docs/datascience/recsys/amazon-personalize",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/lab-graph-models/README",
              "id": "datascience/recsys/lab-graph-models/README",
              "title": "Graph RecSys Models",
              "description": "General",
              "source": "@site/docs/10-datascience/recsys/lab-graph-models/README.md",
              "sourceDirName": "10-datascience/recsys/lab-graph-models",
              "slug": "/datascience/recsys/lab-graph-models/",
              "permalink": "/docs/datascience/recsys/lab-graph-models/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/lab-movielens-nmf-pytorch/README",
              "id": "datascience/recsys/lab-movielens-nmf-pytorch/README",
              "title": "Neural Matrix Factorization from scratch in PyTorch",
              "description": "Building a Neural Matrix Factorization model from scratch in PyTorch on MovieLens-1M dataset.",
              "source": "@site/docs/10-datascience/recsys/lab-movielens-nmf-pytorch/README.md",
              "sourceDirName": "10-datascience/recsys/lab-movielens-nmf-pytorch",
              "slug": "/datascience/recsys/lab-movielens-nmf-pytorch/",
              "permalink": "/docs/datascience/recsys/lab-movielens-nmf-pytorch/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/lab-recsys-amazon-personalize/README",
              "id": "datascience/recsys/lab-recsys-amazon-personalize/README",
              "title": "Recsys Personalize Getting Started",
              "description": "| Description | Notebook |",
              "source": "@site/docs/10-datascience/recsys/lab-recsys-amazon-personalize/README.md",
              "sourceDirName": "10-datascience/recsys/lab-recsys-amazon-personalize",
              "slug": "/datascience/recsys/lab-recsys-amazon-personalize/",
              "permalink": "/docs/datascience/recsys/lab-recsys-amazon-personalize/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/lab-recsys-evaluation/README",
              "id": "datascience/recsys/lab-recsys-evaluation/README",
              "title": "Recommender System Evaluation",
              "description": "| Description | Notebook |",
              "source": "@site/docs/10-datascience/recsys/lab-recsys-evaluation/README.md",
              "sourceDirName": "10-datascience/recsys/lab-recsys-evaluation",
              "slug": "/datascience/recsys/lab-recsys-evaluation/",
              "permalink": "/docs/datascience/recsys/lab-recsys-evaluation/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/lab-recsys-matrix-factorizations/README",
              "id": "datascience/recsys/lab-recsys-matrix-factorizations/README",
              "title": "RecSys Matrix Factorizations",
              "description": "Neural Matrix Factorization (NMF)",
              "source": "@site/docs/10-datascience/recsys/lab-recsys-matrix-factorizations/README.md",
              "sourceDirName": "10-datascience/recsys/lab-recsys-matrix-factorizations",
              "slug": "/datascience/recsys/lab-recsys-matrix-factorizations/",
              "permalink": "/docs/datascience/recsys/lab-recsys-matrix-factorizations/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/lab-recsys-tourism/README",
              "id": "datascience/recsys/lab-recsys-tourism/README",
              "title": "Travel Recommendation System",
              "description": "TravelBuddy is a startup working on building am AI-based recommendation system that will recommend travel products (e.g. hotels, destination places, restaurants) to its users. You are hired as an AI developer that will handle the end-to-end development and maintenance of this AI system.",
              "source": "@site/docs/10-datascience/recsys/lab-recsys-tourism/README.md",
              "sourceDirName": "10-datascience/recsys/lab-recsys-tourism",
              "slug": "/datascience/recsys/lab-recsys-tourism/",
              "permalink": "/docs/datascience/recsys/lab-recsys-tourism/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/lab-retail-product-recommend-word2vec/README",
              "id": "datascience/recsys/lab-retail-product-recommend-word2vec/README",
              "title": "Retail Product Recommendations using word2vec",
              "description": "Creating a system that automatically recommends a certain number of products to the consumers on an E-commerce website based on the past purchase behavior of the consumers.",
              "source": "@site/docs/10-datascience/recsys/lab-retail-product-recommend-word2vec/README.md",
              "sourceDirName": "10-datascience/recsys/lab-retail-product-recommend-word2vec",
              "slug": "/datascience/recsys/lab-retail-product-recommend-word2vec/",
              "permalink": "/docs/datascience/recsys/lab-retail-product-recommend-word2vec/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/lab-similar-shirt-image-recommender/README",
              "id": "datascience/recsys/lab-similar-shirt-image-recommender/README",
              "title": "Similar Shirt Image Recommender",
              "description": "Recommender system using Deep Learning for an online e-commerce store",
              "source": "@site/docs/10-datascience/recsys/lab-similar-shirt-image-recommender/README.md",
              "sourceDirName": "10-datascience/recsys/lab-similar-shirt-image-recommender",
              "slug": "/datascience/recsys/lab-similar-shirt-image-recommender/",
              "permalink": "/docs/datascience/recsys/lab-similar-shirt-image-recommender/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/most-prominent-architectures",
              "id": "datascience/recsys/most-prominent-architectures",
              "title": "Most Prominent Architectures",
              "description": "The Netflix three tier",
              "source": "@site/docs/10-datascience/recsys/most-prominent-architectures.md",
              "sourceDirName": "10-datascience/recsys",
              "slug": "/datascience/recsys/most-prominent-architectures",
              "permalink": "/docs/datascience/recsys/most-prominent-architectures",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/movielens-mf-node2vec-graph-embeddings/README",
              "id": "datascience/recsys/movielens-mf-node2vec-graph-embeddings/README",
              "title": "Recommender System with Node2vec Graph Embeddings",
              "description": "Building a movie recommender system that will learn user-item representation using graph embedding and comparing performance with other methods like matrix factorization",
              "source": "@site/docs/10-datascience/recsys/movielens-mf-node2vec-graph-embeddings/README.md",
              "sourceDirName": "10-datascience/recsys/movielens-mf-node2vec-graph-embeddings",
              "slug": "/datascience/recsys/movielens-mf-node2vec-graph-embeddings/",
              "permalink": "/docs/datascience/recsys/movielens-mf-node2vec-graph-embeddings/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/recsys/README",
              "id": "datascience/recsys/README",
              "title": "Recommender Systems",
              "description": "Models",
              "source": "@site/docs/10-datascience/recsys/README.md",
              "sourceDirName": "10-datascience/recsys",
              "slug": "/datascience/recsys/",
              "permalink": "/docs/datascience/recsys/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/regression/README",
              "id": "datascience/regression/README",
              "title": "Regression",
              "description": "Sklearn Regression Model",
              "source": "@site/docs/10-datascience/regression/README.md",
              "sourceDirName": "10-datascience/regression",
              "slug": "/datascience/regression/",
              "permalink": "/docs/datascience/regression/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/reinforcement-learning/bias-&-fairness",
              "id": "datascience/reinforcement-learning/bias-&-fairness",
              "title": "Bias & Fairness",
              "description": "It can’t be denied that there is bias all around us. A bias is a prejudice against a person or group of people, including, but not limited to their gender, race, and beliefs. Many of these biases arise from emergent behavior in social interactions, events in history, and cultural and political views around the world. These biases affect the data that we collect. Because AI algorithms work with this data, it is an inherent problem that the machine will “learn” these biases. From a technical perspective, we can engineer the system perfectly, but at the end of the day, humans interact with these systems, and it’s our responsibility to minimize bias and prejudice as much as possible. The algorithms we use are only as good as the data provided to them. Understanding the data and the context in which it is being used is the first step in battling bias, and this understanding will help you build better solutions—because you will be well versed in the problem space. Providing balanced data with as little bias as possible should result in better solutions.",
              "source": "@site/docs/10-datascience/reinforcement-learning/bias-&-fairness.md",
              "sourceDirName": "10-datascience/reinforcement-learning",
              "slug": "/datascience/reinforcement-learning/bias-&-fairness",
              "permalink": "/docs/datascience/reinforcement-learning/bias-&-fairness",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/reinforcement-learning/causal-inference",
              "id": "datascience/reinforcement-learning/causal-inference",
              "title": "Causal Inference",
              "description": "Typical recommender systems frame the recommendation task as either a distance learning problem between pairs of products, or between pairs of users and products, or as a next item prediction problem. However, a recommender system should not only attempt to model organic user behavior but influence it. This is where causal techniques help, potentially via simple modifications of standard matrix factorization methods.",
              "source": "@site/docs/10-datascience/reinforcement-learning/causal-inference.md",
              "sourceDirName": "10-datascience/reinforcement-learning",
              "slug": "/datascience/reinforcement-learning/causal-inference",
              "permalink": "/docs/datascience/reinforcement-learning/causal-inference",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/reinforcement-learning/README",
              "id": "datascience/reinforcement-learning/README",
              "title": "Experimentation",
              "description": "Common Engineering Workflow",
              "source": "@site/docs/10-datascience/reinforcement-learning/README.md",
              "sourceDirName": "10-datascience/reinforcement-learning",
              "slug": "/datascience/reinforcement-learning/",
              "permalink": "/docs/datascience/reinforcement-learning/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/sagemaker/README",
              "id": "datascience/sagemaker/README",
              "title": "Amazon Sagemaker",
              "description": "Amazon SageMaker helps data scientists and developers to prepare, build, train, and deploy machine learning models quickly by bringing together a broad set of purpose-built capabilities. In this demo, learn about how SageMaker can accelerate machine learning development by way of an example where we build the perfect musical playlist tailored to a user's tastes.",
              "source": "@site/docs/10-datascience/sagemaker/README.md",
              "sourceDirName": "10-datascience/sagemaker",
              "slug": "/datascience/sagemaker/",
              "permalink": "/docs/datascience/sagemaker/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "datascience/timeseries/prophet",
              "id": "datascience/timeseries/prophet",
              "title": "Prophet",
              "description": "In 2017, Facebook (now Meta) released its Prophet software as open source. This powerful tool was developed by Facebook engineers because its analysts were overwhelmed with the number of business forecasts demanded by managers. The developers of Prophet wanted to simultaneously solve two problems: 1 - completely automatic forecasting techniques are too brittle and inflexible to handle additional knowledge, and 2 - analysts who are consistently able to produce high-quality forecasts are rare and require extensive expertise. Prophet successfully solved both of these problems.",
              "source": "@site/docs/10-datascience/timeseries/prophet.md",
              "sourceDirName": "10-datascience/timeseries",
              "slug": "/datascience/timeseries/prophet",
              "permalink": "/docs/datascience/timeseries/prophet",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Gradient Boosting",
                "permalink": "/docs/datascience/algorithms/gradient-boosting"
              },
              "next": {
                "title": "Deep Learning Basics",
                "permalink": "/docs/datascience/deep-learning/deep-learning-basics"
              }
            },
            {
              "unversionedId": "devops/containers/lab-assignment-etl-docker/README",
              "id": "devops/containers/lab-assignment-etl-docker/README",
              "title": "ETL Docker",
              "description": "Objective",
              "source": "@site/docs/07-devops/containers/lab-assignment-etl-docker/README.md",
              "sourceDirName": "07-devops/containers/lab-assignment-etl-docker",
              "slug": "/devops/containers/lab-assignment-etl-docker/",
              "permalink": "/docs/devops/containers/lab-assignment-etl-docker/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "devops/containers/lab-deploy-simple-docker-ecs/README",
              "id": "devops/containers/lab-deploy-simple-docker-ecs/README",
              "title": "Deploy Docker in ECS",
              "description": "Create a Docker image",
              "source": "@site/docs/07-devops/containers/lab-deploy-simple-docker-ecs/README.md",
              "sourceDirName": "07-devops/containers/lab-deploy-simple-docker-ecs",
              "slug": "/devops/containers/lab-deploy-simple-docker-ecs/",
              "permalink": "/docs/devops/containers/lab-deploy-simple-docker-ecs/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "devops/containers/lab-kubernetes-kubia-app/README",
              "id": "devops/containers/lab-kubernetes-kubia-app/README",
              "title": "Deploying a NodeJS app in Kubernetes",
              "description": "NodeJS App",
              "source": "@site/docs/07-devops/containers/lab-kubernetes-kubia-app/README.md",
              "sourceDirName": "07-devops/containers/lab-kubernetes-kubia-app",
              "slug": "/devops/containers/lab-kubernetes-kubia-app/",
              "permalink": "/docs/devops/containers/lab-kubernetes-kubia-app/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "devops/containers/README",
              "id": "devops/containers/README",
              "title": "Containers",
              "description": "Docker",
              "source": "@site/docs/07-devops/containers/README.md",
              "sourceDirName": "07-devops/containers",
              "slug": "/devops/containers/",
              "permalink": "/docs/devops/containers/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "DevOps",
                "permalink": "/docs/devops/"
              },
              "next": {
                "title": "Infra as Code (IaC)",
                "permalink": "/docs/devops/iac/"
              }
            },
            {
              "unversionedId": "devops/fastapi/lab-fastapi-applications/README",
              "id": "devops/fastapi/lab-fastapi-applications/README",
              "title": "README",
              "description": "Download by running command sh download.sh",
              "source": "@site/docs/07-devops/fastapi/lab-fastapi-applications/README.md",
              "sourceDirName": "07-devops/fastapi/lab-fastapi-applications",
              "slug": "/devops/fastapi/lab-fastapi-applications/",
              "permalink": "/docs/devops/fastapi/lab-fastapi-applications/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "devops/fastapi/project-railway-api/README",
              "id": "devops/fastapi/project-railway-api/README",
              "title": "Railway API",
              "description": "Data Model",
              "source": "@site/docs/07-devops/fastapi/project-railway-api/README.md",
              "sourceDirName": "07-devops/fastapi/project-railway-api",
              "slug": "/devops/fastapi/project-railway-api/",
              "permalink": "/docs/devops/fastapi/project-railway-api/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "devops/fastapi/README",
              "id": "devops/fastapi/README",
              "title": "FastAPI",
              "description": "Labs",
              "source": "@site/docs/07-devops/fastapi/README.md",
              "sourceDirName": "07-devops/fastapi",
              "slug": "/devops/fastapi/",
              "permalink": "/docs/devops/fastapi/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "devops/iac/README",
              "id": "devops/iac/README",
              "title": "Infra as Code (IaC)",
              "description": "Amazon Cloudformation",
              "source": "@site/docs/07-devops/iac/README.md",
              "sourceDirName": "07-devops/iac",
              "slug": "/devops/iac/",
              "permalink": "/docs/devops/iac/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Containers",
                "permalink": "/docs/devops/containers/"
              },
              "next": {
                "title": "Mathematics",
                "permalink": "/docs/mathematics/"
              }
            },
            {
              "unversionedId": "devops/README",
              "id": "devops/README",
              "title": "DevOps",
              "description": "Infra-as-Code (IaC)",
              "source": "@site/docs/07-devops/README.md",
              "sourceDirName": "07-devops",
              "slug": "/devops/",
              "permalink": "/docs/devops/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Streamlit",
                "permalink": "/docs/visualization/streamlit/"
              },
              "next": {
                "title": "Containers",
                "permalink": "/docs/devops/containers/"
              }
            },
            {
              "unversionedId": "extraction/api/lab-hackernews-git-api/README",
              "id": "extraction/api/lab-hackernews-git-api/README",
              "title": "API HackerNews Github",
              "description": "GitHub API",
              "source": "@site/docs/05-extraction/api/lab-hackernews-git-api/README.md",
              "sourceDirName": "05-extraction/api/lab-hackernews-git-api",
              "slug": "/extraction/api/lab-hackernews-git-api/",
              "permalink": "/docs/extraction/api/lab-hackernews-git-api/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "extraction/api/lab-scoota/README",
              "id": "extraction/api/lab-scoota/README",
              "title": "Extract data from multiple sources and load into database",
              "description": "You are working in a startup developing an e-scooter-sharing system called Scoota. It aspires to operate in the most populous cities all around the world. In each city, your company will have hundreds of e-scooters parked in the streets and allow users to rent them by the minute.",
              "source": "@site/docs/05-extraction/api/lab-scoota/README.md",
              "sourceDirName": "05-extraction/api/lab-scoota",
              "slug": "/extraction/api/lab-scoota/",
              "permalink": "/docs/extraction/api/lab-scoota/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "extraction/api/README",
              "id": "extraction/api/README",
              "title": "Data Extraction from APIs",
              "description": "What is an API?",
              "source": "@site/docs/05-extraction/api/README.md",
              "sourceDirName": "05-extraction/api",
              "slug": "/extraction/api/",
              "permalink": "/docs/extraction/api/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Create a Data Model for Online Shopping Carts",
                "permalink": "/docs/data-modeling/lab-cassandra-shopping-cart-data-model/"
              },
              "next": {
                "title": "Lab: Faker",
                "permalink": "/docs/extraction/faker/lab-generate-data-with-faker/"
              }
            },
            {
              "unversionedId": "extraction/faker/lab-generate-data-with-faker/README",
              "id": "extraction/faker/lab-generate-data-with-faker/README",
              "title": "Lab: Faker",
              "description": "Extract synthetic data using Faker library in python",
              "source": "@site/docs/05-extraction/faker/lab-generate-data-with-faker/README.md",
              "sourceDirName": "05-extraction/faker/lab-generate-data-with-faker",
              "slug": "/extraction/faker/lab-generate-data-with-faker/",
              "permalink": "/docs/extraction/faker/lab-generate-data-with-faker/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Extraction from APIs",
                "permalink": "/docs/extraction/api/"
              },
              "next": {
                "title": "Airflow",
                "permalink": "/docs/orchestration/airflow/"
              }
            },
            {
              "unversionedId": "extraction/README",
              "id": "extraction/README",
              "title": "Data Extraction",
              "description": "Airbyte and Fivetran",
              "source": "@site/docs/05-extraction/README.md",
              "sourceDirName": "05-extraction",
              "slug": "/extraction/",
              "permalink": "/docs/extraction/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "extraction/webscraping/lab-finance-extract-load/README",
              "id": "extraction/webscraping/lab-finance-extract-load/README",
              "title": "Financial Data Extraction and Storage",
              "description": "For this lab, you will assume the role of data engineer working for an international financial analysis company. Your company tracks stock prices, commodities, forex rates, inflation rates.  Your job is to extract financial data from various sources like websites, APIs and files provided by various financial analysis firms. After you collect the data, you extract the data of interest to your company and transform it based on the requirements given to you. Once the transformation is complete you load that data into a database.",
              "source": "@site/docs/05-extraction/webscraping/lab-finance-extract-load/README.md",
              "sourceDirName": "05-extraction/webscraping/lab-finance-extract-load",
              "slug": "/extraction/webscraping/lab-finance-extract-load/",
              "permalink": "/docs/extraction/webscraping/lab-finance-extract-load/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "extraction/webscraping/README",
              "id": "extraction/webscraping/README",
              "title": "Web Scraping",
              "description": "Labs",
              "source": "@site/docs/05-extraction/webscraping/README.md",
              "sourceDirName": "05-extraction/webscraping",
              "slug": "/extraction/webscraping/",
              "permalink": "/docs/extraction/webscraping/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/basics/batch-data-processing",
              "id": "foundations/basics/batch-data-processing",
              "title": "Batch Data Processing",
              "description": "Data processing involves taking source data which has been ingested into your data platform and cleansing it, combining it, and modeling it for downstream use. Historically the most popular way to transform data has been with the SQL language and data engineers have built data transformation pipelines using SQL often with the help of ETL/ELT tools. But recently many folks have also begun adopting the DataFrame API in languages like Python/Spark for this task. For the most part a data engineer can accomplish the same data transformations with either approach, and deciding between the two is mostly a matter of preference and particular use cases. That being said, there are use cases where a particular data transform can't be expressed in SQL and a different approach is needed. The most popular approach for these use cases is Python/Spark along with a DataFrame API.",
              "source": "@site/docs/01-foundations/basics/batch-data-processing.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/batch-data-processing",
              "permalink": "/docs/foundations/basics/batch-data-processing",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Quality",
                "permalink": "/docs/foundations/basics/data-quality"
              },
              "next": {
                "title": "Stream and Unified Data Processing",
                "permalink": "/docs/foundations/basics/stream-data-processing"
              }
            },
            {
              "unversionedId": "foundations/basics/batch-vs-incremental",
              "id": "foundations/basics/batch-vs-incremental",
              "title": "Batch vs Incremental",
              "description": "The idea behind incremental processing is quite simple. Incremental processing extends the semantics of processing streaming data to batch processing pipelines by processing only new data each run and then incrementally updating the new results. This unlocks great cost savings due to much shorter batch pipelines as well as data freshness speedups due to being able to run them much more frequently as well.",
              "source": "@site/docs/01-foundations/basics/batch-vs-incremental.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/batch-vs-incremental",
              "permalink": "/docs/foundations/basics/batch-vs-incremental",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Big Data",
                "permalink": "/docs/foundations/basics/big-data"
              },
              "next": {
                "title": "Data Contract",
                "permalink": "/docs/foundations/basics/data-contract"
              }
            },
            {
              "unversionedId": "foundations/basics/big-data",
              "id": "foundations/basics/big-data",
              "title": "Big Data",
              "description": "Six Vs of big data",
              "source": "@site/docs/01-foundations/basics/big-data.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/big-data",
              "permalink": "/docs/foundations/basics/big-data",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL vs NoSQL",
                "permalink": "/docs/foundations/basics/sql-vs-nosql"
              },
              "next": {
                "title": "Batch vs Incremental",
                "permalink": "/docs/foundations/basics/batch-vs-incremental"
              }
            },
            {
              "unversionedId": "foundations/basics/data-contract",
              "id": "foundations/basics/data-contract",
              "title": "Data Contract",
              "description": "Example",
              "source": "@site/docs/01-foundations/basics/data-contract.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/data-contract",
              "permalink": "/docs/foundations/basics/data-contract",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Batch vs Incremental",
                "permalink": "/docs/foundations/basics/batch-vs-incremental"
              },
              "next": {
                "title": "Data Governance",
                "permalink": "/docs/foundations/basics/data-governance"
              }
            },
            {
              "unversionedId": "foundations/basics/data-governance",
              "id": "foundations/basics/data-governance",
              "title": "Data Governance",
              "description": "What is Data Governance?",
              "source": "@site/docs/01-foundations/basics/data-governance.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/data-governance",
              "permalink": "/docs/foundations/basics/data-governance",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Contract",
                "permalink": "/docs/foundations/basics/data-contract"
              },
              "next": {
                "title": "Data Management",
                "permalink": "/docs/foundations/basics/data-management"
              }
            },
            {
              "unversionedId": "foundations/basics/data-management",
              "id": "foundations/basics/data-management",
              "title": "Data Management",
              "description": "Importance of data management",
              "source": "@site/docs/01-foundations/basics/data-management.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/data-management",
              "permalink": "/docs/foundations/basics/data-management",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Governance",
                "permalink": "/docs/foundations/basics/data-governance"
              },
              "next": {
                "title": "Data Quality",
                "permalink": "/docs/foundations/basics/data-quality"
              }
            },
            {
              "unversionedId": "foundations/basics/data-pipelines",
              "id": "foundations/basics/data-pipelines",
              "title": "Data Pipelines",
              "description": "img",
              "source": "@site/docs/01-foundations/basics/data-pipelines.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/data-pipelines",
              "permalink": "/docs/foundations/basics/data-pipelines",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Basics",
                "permalink": "/docs/foundations/basics/de-basics"
              },
              "next": {
                "title": "OLTP vs OLAP",
                "permalink": "/docs/foundations/basics/oltp-vs-olap"
              }
            },
            {
              "unversionedId": "foundations/basics/data-quality",
              "id": "foundations/basics/data-quality",
              "title": "Data Quality",
              "description": "Do your product dashboards look funky? Are your quarterly reports stale? Is the data set you're using broken or just plain wrong? Have you ever been about to sign off after a long day running queries or building data pipelines only to get pinged by your head of marketing that “the data is missing” from a critical report? What about a frantic email from your CTO about “duplicate data” in a business intelligence dashboard? Or a memo from your CEO, the same one who is so bullish on data, about a confusing or inaccurate number in his latest board deck? If any of these situations hit home for you, you’re not alone. These problems affect almost every team, yet they're usually addressed on an ad hoc basis and in a reactive manner.",
              "source": "@site/docs/01-foundations/basics/data-quality.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/data-quality",
              "permalink": "/docs/foundations/basics/data-quality",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Management",
                "permalink": "/docs/foundations/basics/data-management"
              },
              "next": {
                "title": "Batch Data Processing",
                "permalink": "/docs/foundations/basics/batch-data-processing"
              }
            },
            {
              "unversionedId": "foundations/basics/data-storages",
              "id": "foundations/basics/data-storages",
              "title": "Data Storages",
              "description": "| Architecture          | Total cost of solution                                                                                                                                                  | Flexibility of scenarios                                                                                                                                                                      | Complexity of development                                                                                                                                                     | Maturity of ecosystem                                                                                                                                                                         | Organizational maturity required                                                                                                                                                            |",
              "source": "@site/docs/01-foundations/basics/data-storages.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/data-storages",
              "permalink": "/docs/foundations/basics/data-storages",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "OLTP vs OLAP",
                "permalink": "/docs/foundations/basics/oltp-vs-olap"
              },
              "next": {
                "title": "SQL vs NoSQL",
                "permalink": "/docs/foundations/basics/sql-vs-nosql"
              }
            },
            {
              "unversionedId": "foundations/basics/de-basics",
              "id": "foundations/basics/de-basics",
              "title": "Basics",
              "description": "What is Data Engineering?",
              "source": "@site/docs/01-foundations/basics/de-basics.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/de-basics",
              "permalink": "/docs/foundations/basics/de-basics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Engineering",
                "permalink": "/docs/category/data-engineering"
              },
              "next": {
                "title": "Data Pipelines",
                "permalink": "/docs/foundations/basics/data-pipelines"
              }
            },
            {
              "unversionedId": "foundations/basics/deployment",
              "id": "foundations/basics/deployment",
              "title": "Model Deployment",
              "description": "Prototype vs. Production",
              "source": "@site/docs/01-foundations/basics/deployment.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/deployment",
              "permalink": "/docs/foundations/basics/deployment",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Use Cases",
                "permalink": "/docs/foundations/basics/use-cases"
              },
              "next": {
                "title": "Data Splits",
                "permalink": "/docs/datascience/data-splits"
              }
            },
            {
              "unversionedId": "foundations/basics/extras",
              "id": "foundations/basics/extras",
              "title": "Extras",
              "description": "Unified Approach",
              "source": "@site/docs/01-foundations/basics/extras.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/extras",
              "permalink": "/docs/foundations/basics/extras",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/basics/hadoop-basics",
              "id": "foundations/basics/hadoop-basics",
              "title": "Hadoop Basics",
              "description": "Apache Hadoop is an open source framework that is used to efficiently store and process large datasets ranging in size from gigabytes to petabytes of data. Instead of using one large computer to store and process the data, Hadoop allows clustering multiple computers to analyze massive datasets in parallel more quickly.",
              "source": "@site/docs/01-foundations/basics/hadoop-basics.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/hadoop-basics",
              "permalink": "/docs/foundations/basics/hadoop-basics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Origin of Spark",
                "permalink": "/docs/foundations/basics/spark-origin"
              },
              "next": {
                "title": "Map Reduce",
                "permalink": "/docs/foundations/basics/map-reduce"
              }
            },
            {
              "unversionedId": "foundations/basics/hadoop-vs-spark",
              "id": "foundations/basics/hadoop-vs-spark",
              "title": "Hadoop vs Spark",
              "description": "",
              "source": "@site/docs/01-foundations/basics/hadoop-vs-spark.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/hadoop-vs-spark",
              "permalink": "/docs/foundations/basics/hadoop-vs-spark",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Map Reduce",
                "permalink": "/docs/foundations/basics/map-reduce"
              },
              "next": {
                "title": "Interpreting a Spark DAG",
                "permalink": "/docs/foundations/basics/spark-dag"
              }
            },
            {
              "unversionedId": "foundations/basics/map-reduce",
              "id": "foundations/basics/map-reduce",
              "title": "Map Reduce",
              "description": "Knowing that answering the how question is what is important to understanding big data, the first question we need to answer is how does it actually store the data? What makes it different from non-big data storage?",
              "source": "@site/docs/01-foundations/basics/map-reduce.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/map-reduce",
              "permalink": "/docs/foundations/basics/map-reduce",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Hadoop Basics",
                "permalink": "/docs/foundations/basics/hadoop-basics"
              },
              "next": {
                "title": "Hadoop vs Spark",
                "permalink": "/docs/foundations/basics/hadoop-vs-spark"
              }
            },
            {
              "unversionedId": "foundations/basics/model-optimization",
              "id": "foundations/basics/model-optimization",
              "title": "Model Optimization",
              "description": "Keras Model Pruning",
              "source": "@site/docs/01-foundations/basics/model-optimization.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/model-optimization",
              "permalink": "/docs/foundations/basics/model-optimization",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/basics/most-common-interview-questions-set1",
              "id": "foundations/basics/most-common-interview-questions-set1",
              "title": "25 Most Common Interview Questions",
              "description": "25 Most Common Interview Questions",
              "source": "@site/docs/01-foundations/basics/most-common-interview-questions-set1.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/25-most-common-interview-questions",
              "permalink": "/docs/foundations/basics/25-most-common-interview-questions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {
                "title": "25 Most Common Interview Questions",
                "description": "25 Most Common Interview Questions",
                "slug": "25-most-common-interview-questions"
              },
              "sidebar": "docs",
              "previous": {
                "title": "Orchestration",
                "permalink": "/docs/orchestration/"
              },
              "next": {
                "title": "50 Most Common Interview Questions",
                "permalink": "/docs/foundations/basics/50-most-common-interview-questions"
              }
            },
            {
              "unversionedId": "foundations/basics/most-common-interview-questions-set2",
              "id": "foundations/basics/most-common-interview-questions-set2",
              "title": "50 Most Common Interview Questions",
              "description": "50 Most Common Interview Questions",
              "source": "@site/docs/01-foundations/basics/most-common-interview-questions-set2.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/50-most-common-interview-questions",
              "permalink": "/docs/foundations/basics/50-most-common-interview-questions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {
                "title": "50 Most Common Interview Questions",
                "description": "50 Most Common Interview Questions",
                "slug": "50-most-common-interview-questions"
              },
              "sidebar": "docs",
              "previous": {
                "title": "25 Most Common Interview Questions",
                "permalink": "/docs/foundations/basics/25-most-common-interview-questions"
              },
              "next": {
                "title": "50 Most Asked Data Engineer Interview Questions and Answers in 2023",
                "permalink": "/docs/foundations/basics/50-most-common-interview-questions-2023"
              }
            },
            {
              "unversionedId": "foundations/basics/most-common-interview-questions-set3",
              "id": "foundations/basics/most-common-interview-questions-set3",
              "title": "50 Most Asked Data Engineer Interview Questions and Answers in 2023",
              "description": "50 Most Asked Data Engineer Interview Questions and Answers in 2023",
              "source": "@site/docs/01-foundations/basics/most-common-interview-questions-set3.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/50-most-common-interview-questions-2023",
              "permalink": "/docs/foundations/basics/50-most-common-interview-questions-2023",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {
                "title": "50 Most Asked Data Engineer Interview Questions and Answers in 2023",
                "description": "50 Most Asked Data Engineer Interview Questions and Answers in 2023",
                "slug": "50-most-common-interview-questions-2023"
              },
              "sidebar": "docs",
              "previous": {
                "title": "50 Most Common Interview Questions",
                "permalink": "/docs/foundations/basics/50-most-common-interview-questions"
              },
              "next": {
                "title": "Spark and Hadoop",
                "permalink": "/docs/category/spark-and-hadoop"
              }
            },
            {
              "unversionedId": "foundations/basics/oltp-vs-olap",
              "id": "foundations/basics/oltp-vs-olap",
              "title": "OLTP vs OLAP",
              "description": "Transactional databases (OLTP)",
              "source": "@site/docs/01-foundations/basics/oltp-vs-olap.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/oltp-vs-olap",
              "permalink": "/docs/foundations/basics/oltp-vs-olap",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Pipelines",
                "permalink": "/docs/foundations/basics/data-pipelines"
              },
              "next": {
                "title": "Data Storages",
                "permalink": "/docs/foundations/basics/data-storages"
              }
            },
            {
              "unversionedId": "foundations/basics/origin",
              "id": "foundations/basics/origin",
              "title": "The data science origin story",
              "description": "There's a saying in the data science community that's been around for a while, and it goes: \"A data scientist is better than any computer scientist at statistics, and better than any statistician at computer programming.\" This encapsulates the general skills of most data scientists, as well as the history of the field.",
              "source": "@site/docs/01-foundations/basics/origin.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/origin",
              "permalink": "/docs/foundations/basics/origin",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Sampling",
                "permalink": "/docs/mathematics/statistics/sampling"
              },
              "next": {
                "title": "Use Cases",
                "permalink": "/docs/foundations/basics/use-cases"
              }
            },
            {
              "unversionedId": "foundations/basics/outliers-handling",
              "id": "foundations/basics/outliers-handling",
              "title": "Outliers Handling",
              "description": "Remove categorical outliers",
              "source": "@site/docs/01-foundations/basics/outliers-handling.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/outliers-handling",
              "permalink": "/docs/foundations/basics/outliers-handling",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/basics/rdd",
              "id": "foundations/basics/rdd",
              "title": "Spark RDDs",
              "description": "An RDD (Resilient Distributed Dataset) is the primary data structure in Spark. It is a distributed collection of data that can be processed in parallel. RDDs are immutable, meaning that once an RDD is created, it cannot be modified. Instead, any transformations applied to an RDD will return a new RDD.",
              "source": "@site/docs/01-foundations/basics/rdd.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/rdd",
              "permalink": "/docs/foundations/basics/rdd",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Interpreting a Spark DAG",
                "permalink": "/docs/foundations/basics/spark-dag"
              },
              "next": {
                "title": "Quiz: Spark basics",
                "permalink": "/docs/foundations/basics/spark-quiz"
              }
            },
            {
              "unversionedId": "foundations/basics/spark-basics",
              "id": "foundations/basics/spark-basics",
              "title": "Apache Spark Basics",
              "description": "What is Apache Spark?",
              "source": "@site/docs/01-foundations/basics/spark-basics.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/spark-basics",
              "permalink": "/docs/foundations/basics/spark-basics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Spark and Hadoop",
                "permalink": "/docs/category/spark-and-hadoop"
              },
              "next": {
                "title": "Origin of Spark",
                "permalink": "/docs/foundations/basics/spark-origin"
              }
            },
            {
              "unversionedId": "foundations/basics/spark-dag",
              "id": "foundations/basics/spark-dag",
              "title": "Interpreting a Spark DAG",
              "description": "A DAG is just a regular graph with nodes and edges but with no cycles or loops. In order to understand a Spark DAG, we first have to understand where a DAG comes into the picture during the execution of a Spark job.",
              "source": "@site/docs/01-foundations/basics/spark-dag.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/spark-dag",
              "permalink": "/docs/foundations/basics/spark-dag",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Hadoop vs Spark",
                "permalink": "/docs/foundations/basics/hadoop-vs-spark"
              },
              "next": {
                "title": "Spark RDDs",
                "permalink": "/docs/foundations/basics/rdd"
              }
            },
            {
              "unversionedId": "foundations/basics/spark-origin",
              "id": "foundations/basics/spark-origin",
              "title": "Origin of Spark",
              "description": "Big Data and Distributed Computing at Google",
              "source": "@site/docs/01-foundations/basics/spark-origin.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/spark-origin",
              "permalink": "/docs/foundations/basics/spark-origin",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache Spark Basics",
                "permalink": "/docs/foundations/basics/spark-basics"
              },
              "next": {
                "title": "Hadoop Basics",
                "permalink": "/docs/foundations/basics/hadoop-basics"
              }
            },
            {
              "unversionedId": "foundations/basics/spark-quiz",
              "id": "foundations/basics/spark-quiz",
              "title": "Quiz: Spark basics",
              "description": "Below are a few questions that should come handy in the first go :",
              "source": "@site/docs/01-foundations/basics/spark-quiz.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/spark-quiz",
              "permalink": "/docs/foundations/basics/spark-quiz",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Spark RDDs",
                "permalink": "/docs/foundations/basics/rdd"
              },
              "next": {
                "title": "Developer Essentials",
                "permalink": "/docs/category/developer-essentials"
              }
            },
            {
              "unversionedId": "foundations/basics/sql-vs-nosql",
              "id": "foundations/basics/sql-vs-nosql",
              "title": "SQL vs NoSQL",
              "description": "As you design large systems ( or even smaller ones), you need to decide the inflow-processing and outflow of data coming- and getting processed in the system.",
              "source": "@site/docs/01-foundations/basics/sql-vs-nosql.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/sql-vs-nosql",
              "permalink": "/docs/foundations/basics/sql-vs-nosql",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Storages",
                "permalink": "/docs/foundations/basics/data-storages"
              },
              "next": {
                "title": "Big Data",
                "permalink": "/docs/foundations/basics/big-data"
              }
            },
            {
              "unversionedId": "foundations/basics/stream-data-processing",
              "id": "foundations/basics/stream-data-processing",
              "title": "Stream and Unified Data Processing",
              "description": "What is an event stream?",
              "source": "@site/docs/01-foundations/basics/stream-data-processing.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/stream-data-processing",
              "permalink": "/docs/foundations/basics/stream-data-processing",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Batch Data Processing",
                "permalink": "/docs/foundations/basics/batch-data-processing"
              },
              "next": {
                "title": "Orchestration",
                "permalink": "/docs/orchestration/"
              }
            },
            {
              "unversionedId": "foundations/basics/use-cases",
              "id": "foundations/basics/use-cases",
              "title": "Use Cases",
              "description": "Some of the many uses of machine learning across industries:",
              "source": "@site/docs/01-foundations/basics/use-cases.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/use-cases",
              "permalink": "/docs/foundations/basics/use-cases",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "The data science origin story",
                "permalink": "/docs/foundations/basics/origin"
              },
              "next": {
                "title": "Model Deployment",
                "permalink": "/docs/foundations/basics/deployment"
              }
            },
            {
              "unversionedId": "foundations/basics/vector-search",
              "id": "foundations/basics/vector-search",
              "title": "Vector Search",
              "description": "Faiss",
              "source": "@site/docs/01-foundations/basics/vector-search.md",
              "sourceDirName": "01-foundations/basics",
              "slug": "/foundations/basics/vector-search",
              "permalink": "/docs/foundations/basics/vector-search",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/cloud/aws-commands",
              "id": "foundations/cloud/aws-commands",
              "title": "AWS Commands",
              "description": "",
              "source": "@site/docs/01-foundations/cloud/aws-commands.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/aws-commands",
              "permalink": "/docs/foundations/cloud/aws-commands",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "AWS Container Services",
                "permalink": "/docs/foundations/cloud/aws-containers"
              },
              "next": {
                "title": "Lab: AWS Account Setup",
                "permalink": "/docs/foundations/cloud/lab-aws-setup/"
              }
            },
            {
              "unversionedId": "foundations/cloud/aws-containers",
              "id": "foundations/cloud/aws-containers",
              "title": "AWS Container Services",
              "description": "1. Containers on AWS Overview: ECS | EKS | Fargate | ECR",
              "source": "@site/docs/01-foundations/cloud/aws-containers.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/aws-containers",
              "permalink": "/docs/foundations/cloud/aws-containers",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Secrets Manager",
                "permalink": "/docs/foundations/cloud/secrets-manager"
              },
              "next": {
                "title": "AWS Commands",
                "permalink": "/docs/foundations/cloud/aws-commands"
              }
            },
            {
              "unversionedId": "foundations/cloud/azure-basics",
              "id": "foundations/cloud/azure-basics",
              "title": "Azure Basics",
              "description": "Learning Path",
              "source": "@site/docs/01-foundations/cloud/azure-basics.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/azure-basics",
              "permalink": "/docs/foundations/cloud/azure-basics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure",
                "permalink": "/docs/category/azure"
              },
              "next": {
                "title": "Azure Data Ingestion",
                "permalink": "/docs/foundations/cloud/azure-data-ingestion"
              }
            },
            {
              "unversionedId": "foundations/cloud/azure-batch-processing",
              "id": "foundations/cloud/azure-batch-processing",
              "title": "Azure Batch Processing",
              "description": "Here is a useful table reproduced from Azure that can help you decide on the technologies to use for your batch scenarios:",
              "source": "@site/docs/01-foundations/cloud/azure-batch-processing.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/azure-batch-processing",
              "permalink": "/docs/foundations/cloud/azure-batch-processing",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure Data Ingestion",
                "permalink": "/docs/foundations/cloud/azure-data-ingestion"
              },
              "next": {
                "title": "Azure Full-stack Solutions",
                "permalink": "/docs/foundations/cloud/azure-fullstack-solutions"
              }
            },
            {
              "unversionedId": "foundations/cloud/azure-data-ingestion",
              "id": "foundations/cloud/azure-data-ingestion",
              "title": "Azure Data Ingestion",
              "description": "This is the process of getting all the raw data into the data lake. Data from various sources lands in the raw zone of the data lake. Based on where the data is coming from, such as on-premise systems, other cloud systems, and so on, we could use different ingestion tools. Let's look at some of the options available in Azure:",
              "source": "@site/docs/01-foundations/cloud/azure-data-ingestion.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/azure-data-ingestion",
              "permalink": "/docs/foundations/cloud/azure-data-ingestion",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure Basics",
                "permalink": "/docs/foundations/cloud/azure-basics"
              },
              "next": {
                "title": "Azure Batch Processing",
                "permalink": "/docs/foundations/cloud/azure-batch-processing"
              }
            },
            {
              "unversionedId": "foundations/cloud/azure-fullstack-solutions",
              "id": "foundations/cloud/azure-fullstack-solutions",
              "title": "Azure Full-stack Solutions",
              "description": "Modern Azure Data Architecture Platform",
              "source": "@site/docs/01-foundations/cloud/azure-fullstack-solutions.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/azure-fullstack-solutions",
              "permalink": "/docs/foundations/cloud/azure-fullstack-solutions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure Batch Processing",
                "permalink": "/docs/foundations/cloud/azure-batch-processing"
              },
              "next": {
                "title": "SQL Basics",
                "permalink": "/docs/foundations/language/sql/sql-basics"
              }
            },
            {
              "unversionedId": "foundations/cloud/cloud-computing",
              "id": "foundations/cloud/cloud-computing",
              "title": "Cloud Computing",
              "description": "What is Cloud Computing?",
              "source": "@site/docs/01-foundations/cloud/cloud-computing.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/cloud-computing",
              "permalink": "/docs/foundations/cloud/cloud-computing",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Databricks Case Studies",
                "permalink": "/docs/system-design/databricks-case-studies"
              },
              "next": {
                "title": "AWS",
                "permalink": "/docs/category/aws"
              }
            },
            {
              "unversionedId": "foundations/cloud/dms",
              "id": "foundations/cloud/dms",
              "title": "DMS",
              "description": "AWS Database Migration Service (AWS DMS) helps you migrate databases to AWS quickly and securely. The source database remains fully operational during the migration, minimizing downtime to applications that rely on the database. The AWS Database Migration Service can migrate your data to and from the most widely used commercial and open-source databases.",
              "source": "@site/docs/01-foundations/cloud/dms.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/dms",
              "permalink": "/docs/foundations/cloud/dms",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "S3",
                "permalink": "/docs/foundations/cloud/s3"
              },
              "next": {
                "title": "Secrets Manager",
                "permalink": "/docs/foundations/cloud/secrets-manager"
              }
            },
            {
              "unversionedId": "foundations/cloud/ec2",
              "id": "foundations/cloud/ec2",
              "title": "EC2",
              "description": "The foundational service that provides compute resources for customers to build their applications on AWS is called Amazon EC2. Amazon EC2 provides customers with a choice of 500+ instance types. Customers can then tailor the right combination of instance types for their business applications.",
              "source": "@site/docs/01-foundations/cloud/ec2.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/ec2",
              "permalink": "/docs/foundations/cloud/ec2",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "AWS",
                "permalink": "/docs/category/aws"
              },
              "next": {
                "title": "IAM",
                "permalink": "/docs/foundations/cloud/iam"
              }
            },
            {
              "unversionedId": "foundations/cloud/gcp-basics",
              "id": "foundations/cloud/gcp-basics",
              "title": "GCP Basics",
              "description": "There are a lot of services in GCP. The services are not only limited to data and analytics. They also cover other areas such as application development, machine learning, networks, source repositories, and many more. As a data engineer working on GCP, you will face situations when you need to decide which services you need to use for your organization.",
              "source": "@site/docs/01-foundations/cloud/gcp-basics.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/gcp-basics",
              "permalink": "/docs/foundations/cloud/gcp-basics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "GCP",
                "permalink": "/docs/category/gcp"
              },
              "next": {
                "title": "GCP Setup",
                "permalink": "/docs/foundations/cloud/gcp-setup"
              }
            },
            {
              "unversionedId": "foundations/cloud/gcp-setup",
              "id": "foundations/cloud/gcp-setup",
              "title": "GCP Setup",
              "description": "To set up GCP, please follow the steps below:",
              "source": "@site/docs/01-foundations/cloud/gcp-setup.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/gcp-setup",
              "permalink": "/docs/foundations/cloud/gcp-setup",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "GCP Basics",
                "permalink": "/docs/foundations/cloud/gcp-basics"
              },
              "next": {
                "title": "Azure",
                "permalink": "/docs/category/azure"
              }
            },
            {
              "unversionedId": "foundations/cloud/glue",
              "id": "foundations/cloud/glue",
              "title": "Glue",
              "description": "AWS Glue is a serverless data integration service that makes it easy to discover, prepare, and combine data for analytics, machine learning, and application development. AWS Glue provides all the capabilities needed for data integration so that you can start analyzing your data and put it to use in minutes instead of months.",
              "source": "@site/docs/01-foundations/cloud/glue.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/glue",
              "permalink": "/docs/foundations/cloud/glue",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "IAM",
                "permalink": "/docs/foundations/cloud/iam"
              },
              "next": {
                "title": "RDS",
                "permalink": "/docs/foundations/cloud/rds"
              }
            },
            {
              "unversionedId": "foundations/cloud/iam",
              "id": "foundations/cloud/iam",
              "title": "IAM",
              "description": "Securely manage identities and access to AWS services and resources",
              "source": "@site/docs/01-foundations/cloud/iam.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/iam",
              "permalink": "/docs/foundations/cloud/iam",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "EC2",
                "permalink": "/docs/foundations/cloud/ec2"
              },
              "next": {
                "title": "Glue",
                "permalink": "/docs/foundations/cloud/glue"
              }
            },
            {
              "unversionedId": "foundations/cloud/lab-aws-secrets-manager/README",
              "id": "foundations/cloud/lab-aws-secrets-manager/README",
              "title": "Lab: AWS Secrets Manager",
              "description": "Objective",
              "source": "@site/docs/01-foundations/cloud/lab-aws-secrets-manager/README.md",
              "sourceDirName": "01-foundations/cloud/lab-aws-secrets-manager",
              "slug": "/foundations/cloud/lab-aws-secrets-manager/",
              "permalink": "/docs/foundations/cloud/lab-aws-secrets-manager/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Create IAM Role and Policy",
                "permalink": "/docs/foundations/cloud/lab-create-iam-policy-role/"
              },
              "next": {
                "title": "Lab: Create AWS VPC",
                "permalink": "/docs/foundations/cloud/lab-create-your-first-vpc/"
              }
            },
            {
              "unversionedId": "foundations/cloud/lab-aws-setup/README",
              "id": "foundations/cloud/lab-aws-setup/README",
              "title": "Lab: AWS Account Setup",
              "description": "Create AWS Account",
              "source": "@site/docs/01-foundations/cloud/lab-aws-setup/README.md",
              "sourceDirName": "01-foundations/cloud/lab-aws-setup",
              "slug": "/foundations/cloud/lab-aws-setup/",
              "permalink": "/docs/foundations/cloud/lab-aws-setup/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "AWS Commands",
                "permalink": "/docs/foundations/cloud/aws-commands"
              },
              "next": {
                "title": "Lab: Create IAM Role and Policy",
                "permalink": "/docs/foundations/cloud/lab-create-iam-policy-role/"
              }
            },
            {
              "unversionedId": "foundations/cloud/lab-create-iam-policy-role/README",
              "id": "foundations/cloud/lab-create-iam-policy-role/README",
              "title": "Lab: Create IAM Role and Policy",
              "description": "In this lab, we will learn about AWS IAM service. We will perform the following activities:",
              "source": "@site/docs/01-foundations/cloud/lab-create-iam-policy-role/README.md",
              "sourceDirName": "01-foundations/cloud/lab-create-iam-policy-role",
              "slug": "/foundations/cloud/lab-create-iam-policy-role/",
              "permalink": "/docs/foundations/cloud/lab-create-iam-policy-role/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: AWS Account Setup",
                "permalink": "/docs/foundations/cloud/lab-aws-setup/"
              },
              "next": {
                "title": "Lab: AWS Secrets Manager",
                "permalink": "/docs/foundations/cloud/lab-aws-secrets-manager/"
              }
            },
            {
              "unversionedId": "foundations/cloud/lab-create-your-first-ec2-instance-linux/README",
              "id": "foundations/cloud/lab-create-your-first-ec2-instance-linux/README",
              "title": "Lab: Create AWS EC2 instance",
              "description": "Description",
              "source": "@site/docs/01-foundations/cloud/lab-create-your-first-ec2-instance-linux/README.md",
              "sourceDirName": "01-foundations/cloud/lab-create-your-first-ec2-instance-linux",
              "slug": "/foundations/cloud/lab-create-your-first-ec2-instance-linux/",
              "permalink": "/docs/foundations/cloud/lab-create-your-first-ec2-instance-linux/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Create AWS VPC",
                "permalink": "/docs/foundations/cloud/lab-create-your-first-vpc/"
              },
              "next": {
                "title": "GCP",
                "permalink": "/docs/category/gcp"
              }
            },
            {
              "unversionedId": "foundations/cloud/lab-create-your-first-vpc/README",
              "id": "foundations/cloud/lab-create-your-first-vpc/README",
              "title": "Lab: Create AWS VPC",
              "description": "Description",
              "source": "@site/docs/01-foundations/cloud/lab-create-your-first-vpc/README.md",
              "sourceDirName": "01-foundations/cloud/lab-create-your-first-vpc",
              "slug": "/foundations/cloud/lab-create-your-first-vpc/",
              "permalink": "/docs/foundations/cloud/lab-create-your-first-vpc/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: AWS Secrets Manager",
                "permalink": "/docs/foundations/cloud/lab-aws-secrets-manager/"
              },
              "next": {
                "title": "Lab: Create AWS EC2 instance",
                "permalink": "/docs/foundations/cloud/lab-create-your-first-ec2-instance-linux/"
              }
            },
            {
              "unversionedId": "foundations/cloud/rds",
              "id": "foundations/cloud/rds",
              "title": "RDS",
              "description": "RDS stands for Relational Database Services",
              "source": "@site/docs/01-foundations/cloud/rds.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/rds",
              "permalink": "/docs/foundations/cloud/rds",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Glue",
                "permalink": "/docs/foundations/cloud/glue"
              },
              "next": {
                "title": "S3",
                "permalink": "/docs/foundations/cloud/s3"
              }
            },
            {
              "unversionedId": "foundations/cloud/s3",
              "id": "foundations/cloud/s3",
              "title": "S3",
              "description": "Amazon S3 is one of the most commonly used cloud data storage services for web applications, and high-performance compute use cases. It is Amazon's object storage service providing virtually unlimited data storage. Some of the advantages of using Amazon S3 include very high scalability, durability, data availability, security, and performance. Amazon S3 can be used for a variety of cloud-native applications, ranging from simple data storage to very large data lakes to web hosting and high-performance applications, such as training very advanced and compute-intensive ML models. Amazon S3 offers several classes of storage options with differences in terms of data access, resiliency, archival needs, and cost. We can choose the storage class that best suits our use case and business needs. There is also an option for cost saving when the access pattern is unknown or changes over time (S3 Intelligent-Tiering).",
              "source": "@site/docs/01-foundations/cloud/s3.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/s3",
              "permalink": "/docs/foundations/cloud/s3",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "RDS",
                "permalink": "/docs/foundations/cloud/rds"
              },
              "next": {
                "title": "DMS",
                "permalink": "/docs/foundations/cloud/dms"
              }
            },
            {
              "unversionedId": "foundations/cloud/secrets-manager",
              "id": "foundations/cloud/secrets-manager",
              "title": "Secrets Manager",
              "description": "AWS Secrets Management Service",
              "source": "@site/docs/01-foundations/cloud/secrets-manager.md",
              "sourceDirName": "01-foundations/cloud",
              "slug": "/foundations/cloud/secrets-manager",
              "permalink": "/docs/foundations/cloud/secrets-manager",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "DMS",
                "permalink": "/docs/foundations/cloud/dms"
              },
              "next": {
                "title": "AWS Container Services",
                "permalink": "/docs/foundations/cloud/aws-containers"
              }
            },
            {
              "unversionedId": "foundations/developer/install-anaconda",
              "id": "foundations/developer/install-anaconda",
              "title": "Install Anaconda",
              "description": "1. Download the file from https://www.anaconda.com/products/distribution and install it",
              "source": "@site/docs/01-foundations/developer/install-anaconda.md",
              "sourceDirName": "01-foundations/developer",
              "slug": "/foundations/developer/install-anaconda",
              "permalink": "/docs/foundations/developer/install-anaconda",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Developer Essentials",
                "permalink": "/docs/category/developer-essentials"
              },
              "next": {
                "title": "Install Jupyter Notebook",
                "permalink": "/docs/foundations/developer/install-jupyter"
              }
            },
            {
              "unversionedId": "foundations/developer/install-dbeaver",
              "id": "foundations/developer/install-dbeaver",
              "title": "Install DBeaver",
              "description": "Go to https://dbeaver.io/download to download DBeaver.",
              "source": "@site/docs/01-foundations/developer/install-dbeaver.md",
              "sourceDirName": "01-foundations/developer",
              "slug": "/foundations/developer/install-dbeaver",
              "permalink": "/docs/foundations/developer/install-dbeaver",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Learn Bash Commands",
                "permalink": "/docs/foundations/developer/lab-bash-commands/"
              },
              "next": {
                "title": "System Design",
                "permalink": "/docs/system-design/"
              }
            },
            {
              "unversionedId": "foundations/developer/install-jupyter",
              "id": "foundations/developer/install-jupyter",
              "title": "Install Jupyter Notebook",
              "description": "There are many free options to run jupyter notebooks:",
              "source": "@site/docs/01-foundations/developer/install-jupyter.md",
              "sourceDirName": "01-foundations/developer",
              "slug": "/foundations/developer/install-jupyter",
              "permalink": "/docs/foundations/developer/install-jupyter",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Install Anaconda",
                "permalink": "/docs/foundations/developer/install-anaconda"
              },
              "next": {
                "title": "Install VS Code",
                "permalink": "/docs/foundations/developer/install-vscode"
              }
            },
            {
              "unversionedId": "foundations/developer/install-vscode",
              "id": "foundations/developer/install-vscode",
              "title": "Install VS Code",
              "description": "1. Follow this guide to install VS code in your system. Alternatively, go to https://code.visualstudio.com/download and download the VS Code",
              "source": "@site/docs/01-foundations/developer/install-vscode.md",
              "sourceDirName": "01-foundations/developer",
              "slug": "/foundations/developer/install-vscode",
              "permalink": "/docs/foundations/developer/install-vscode",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Install Jupyter Notebook",
                "permalink": "/docs/foundations/developer/install-jupyter"
              },
              "next": {
                "title": "Lab: Explore VS Code features",
                "permalink": "/docs/foundations/developer/lab-explore-vscode-features"
              }
            },
            {
              "unversionedId": "foundations/developer/lab-bash-commands/index",
              "id": "foundations/developer/lab-bash-commands/index",
              "title": "Lab: Learn Bash Commands",
              "description": "- pwd: Display the current directory",
              "source": "@site/docs/01-foundations/developer/lab-bash-commands/index.md",
              "sourceDirName": "01-foundations/developer/lab-bash-commands",
              "slug": "/foundations/developer/lab-bash-commands/",
              "permalink": "/docs/foundations/developer/lab-bash-commands/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Learn git commands",
                "permalink": "/docs/foundations/developer/lab-learn-git-commands"
              },
              "next": {
                "title": "Install DBeaver",
                "permalink": "/docs/foundations/developer/install-dbeaver"
              }
            },
            {
              "unversionedId": "foundations/developer/lab-explore-vscode-features",
              "id": "foundations/developer/lab-explore-vscode-features",
              "title": "Lab: Explore VS Code features",
              "description": "In this lab, we will explore the following features:",
              "source": "@site/docs/01-foundations/developer/lab-explore-vscode-features.md",
              "sourceDirName": "01-foundations/developer",
              "slug": "/foundations/developer/lab-explore-vscode-features",
              "permalink": "/docs/foundations/developer/lab-explore-vscode-features",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Install VS Code",
                "permalink": "/docs/foundations/developer/install-vscode"
              },
              "next": {
                "title": "Setup Git",
                "permalink": "/docs/foundations/developer/setup-git"
              }
            },
            {
              "unversionedId": "foundations/developer/lab-learn-git-commands",
              "id": "foundations/developer/lab-learn-git-commands",
              "title": "Lab: Learn git commands",
              "description": "Objective",
              "source": "@site/docs/01-foundations/developer/lab-learn-git-commands.md",
              "sourceDirName": "01-foundations/developer",
              "slug": "/foundations/developer/lab-learn-git-commands",
              "permalink": "/docs/foundations/developer/lab-learn-git-commands",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Setup Git",
                "permalink": "/docs/foundations/developer/setup-git"
              },
              "next": {
                "title": "Lab: Learn Bash Commands",
                "permalink": "/docs/foundations/developer/lab-bash-commands/"
              }
            },
            {
              "unversionedId": "foundations/developer/setup-git",
              "id": "foundations/developer/setup-git",
              "title": "Setup Git",
              "description": "One of the major problems with coding is to keep track of changes. It is also almost impossible to maintain a program you have multiple versions of. Another is the topic of collaboration and documentation. Which is super Important. Let’s say you work on a Spark application and your colleges need to make changes while you are on holiday. Without some code management they are in huge trouble: Where is the code? What have you changed last? Where is the documentation? How do we mark what we have changed? But if you put your code on GitHub your colleges can find your code. They can understand it through your documentation (please also have in-line comments) Developers can pull your code, make a new branch and do the changes. After your holiday you can inspect what they have done and merge it with your original code. and you end up having only one application.",
              "source": "@site/docs/01-foundations/developer/setup-git.md",
              "sourceDirName": "01-foundations/developer",
              "slug": "/foundations/developer/setup-git",
              "permalink": "/docs/foundations/developer/setup-git",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Explore VS Code features",
                "permalink": "/docs/foundations/developer/lab-explore-vscode-features"
              },
              "next": {
                "title": "Lab: Learn git commands",
                "permalink": "/docs/foundations/developer/lab-learn-git-commands"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/broadcasting",
              "id": "foundations/language/pyspark/broadcasting",
              "title": "Broadcasting",
              "description": "Broadcasting is the process of sending a read-only variable to the worker nodes, rather than sending a copy of the variable to each worker node. This can greatly improve the performance of Spark jobs by reducing the amount of data that needs to be sent over the network.",
              "source": "@site/docs/01-foundations/language/pyspark/broadcasting.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/broadcasting",
              "permalink": "/docs/foundations/language/pyspark/broadcasting",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "UDFs",
                "permalink": "/docs/foundations/language/pyspark/udf"
              },
              "next": {
                "title": "cheat-sheet",
                "permalink": "/docs/foundations/language/pyspark/cheat-sheet"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/caching",
              "id": "foundations/language/pyspark/caching",
              "title": "Caching",
              "description": "What is Caching?",
              "source": "@site/docs/01-foundations/language/pyspark/caching.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/caching",
              "permalink": "/docs/foundations/language/pyspark/caching",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lazy Processing",
                "permalink": "/docs/foundations/language/pyspark/lazy-processing"
              },
              "next": {
                "title": "UDFs",
                "permalink": "/docs/foundations/language/pyspark/udf"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/cheat-sheet",
              "id": "foundations/language/pyspark/cheat-sheet",
              "title": "cheat-sheet",
              "description": "PySpark Cheat Sheet",
              "source": "@site/docs/01-foundations/language/pyspark/cheat-sheet.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/cheat-sheet",
              "permalink": "/docs/foundations/language/pyspark/cheat-sheet",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Broadcasting",
                "permalink": "/docs/foundations/language/pyspark/broadcasting"
              },
              "next": {
                "title": "Spark Execution Plan",
                "permalink": "/docs/foundations/language/pyspark/execution-plan"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/dataframe",
              "id": "foundations/language/pyspark/dataframe",
              "title": "PySpark DataFrame",
              "description": "Creating a DataFrame in PySpark",
              "source": "@site/docs/01-foundations/language/pyspark/dataframe.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/dataframe",
              "permalink": "/docs/foundations/language/pyspark/dataframe",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Installing Spark",
                "permalink": "/docs/foundations/language/pyspark/install"
              },
              "next": {
                "title": "Methods, Operations and Functions",
                "permalink": "/docs/foundations/language/pyspark/methods-operations"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/execution-plan",
              "id": "foundations/language/pyspark/execution-plan",
              "title": "Spark Execution Plan",
              "description": "Spark uses a query optimizer known as Catalyst to optimize the execution plan of Spark jobs. The execution plan is a representation of the physical execution of a query and it can be used to understand how Spark is processing data.",
              "source": "@site/docs/01-foundations/language/pyspark/execution-plan.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/execution-plan",
              "permalink": "/docs/foundations/language/pyspark/execution-plan",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "cheat-sheet",
                "permalink": "/docs/foundations/language/pyspark/cheat-sheet"
              },
              "next": {
                "title": "PySpark vs Pandas",
                "permalink": "/docs/foundations/language/pyspark/pyspark-vs-pandas"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/install",
              "id": "foundations/language/pyspark/install",
              "title": "Installing Spark",
              "description": "To get started with PySpark, you will need to have the Spark software installed on your machine. You can download the latest version of Spark from the Apache Spark website. Once you have Spark installed, you can start using it to process data.",
              "source": "@site/docs/01-foundations/language/pyspark/install.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/install",
              "permalink": "/docs/foundations/language/pyspark/install",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Explore Further",
                "permalink": "/docs/foundations/language/python/links"
              },
              "next": {
                "title": "PySpark DataFrame",
                "permalink": "/docs/foundations/language/pyspark/dataframe"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-bcg/README",
              "id": "foundations/language/pyspark/lab-bcg/README",
              "title": "Lab: BCG Case Study",
              "description": "Dataset",
              "source": "@site/docs/01-foundations/language/pyspark/lab-bcg/README.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-bcg",
              "slug": "/foundations/language/pyspark/lab-bcg/",
              "permalink": "/docs/foundations/language/pyspark/lab-bcg/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Understanding Spark Query Execution",
                "permalink": "/docs/foundations/language/pyspark/lab-understand-spark-query-execution/"
              },
              "next": {
                "title": "Lab: S3 Postgres Scala",
                "permalink": "/docs/processing/databricks/lab-databricks-scala-postgres-s3/"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-calculating-partitions/README",
              "id": "foundations/language/pyspark/lab-calculating-partitions/README",
              "title": "Calculating Spark Partitions",
              "description": "nbviewer",
              "source": "@site/docs/01-foundations/language/pyspark/lab-calculating-partitions/README.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-calculating-partitions",
              "slug": "/foundations/language/pyspark/lab-calculating-partitions/",
              "permalink": "/docs/foundations/language/pyspark/lab-calculating-partitions/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: S3 Postgres Scala",
                "permalink": "/docs/processing/databricks/lab-databricks-scala-postgres-s3/"
              },
              "next": {
                "title": "Getting Started with Scala",
                "permalink": "/docs/foundations/language/scala/lab-scala-getting-started/"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-pyspark-basics/index",
              "id": "foundations/language/pyspark/lab-pyspark-basics/index",
              "title": "Lab: Pyspark Basics",
              "description": "In this lab, we will use the power of PySpark to perform various activities in databricks environment.",
              "source": "@site/docs/01-foundations/language/pyspark/lab-pyspark-basics/index.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-pyspark-basics",
              "slug": "/foundations/language/pyspark/lab-pyspark-basics/",
              "permalink": "/docs/foundations/language/pyspark/lab-pyspark-basics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "PySpark vs Pandas",
                "permalink": "/docs/foundations/language/pyspark/pyspark-vs-pandas"
              },
              "next": {
                "title": "Lab: Connect AWS to PySpark and build an ETL pipeline",
                "permalink": "/docs/processing/databricks/lab-databricks-pyspark-s3/"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-pyspark-nyctaxi/README",
              "id": "foundations/language/pyspark/lab-pyspark-nyctaxi/README",
              "title": "Pyspark NYC Taxi",
              "description": "",
              "source": "@site/docs/01-foundations/language/pyspark/lab-pyspark-nyctaxi/README.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-pyspark-nyctaxi",
              "slug": "/foundations/language/pyspark/lab-pyspark-nyctaxi/",
              "permalink": "/docs/foundations/language/pyspark/lab-pyspark-nyctaxi/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-spark-optimizations-2/README",
              "id": "foundations/language/pyspark/lab-spark-optimizations-2/README",
              "title": "Lab: Spark Optimizations",
              "description": "Performance tuning in Apache Spark plays an instrumental role in running efficient big data workloads. More often than not, the optimization techniques employed to prevent the shuffling and skewing of data drastically improve performance. In this lab, we will learn about the Spark optimization techniques directly related to Spark Core that help prevent the shuffling and skewing of data.",
              "source": "@site/docs/01-foundations/language/pyspark/lab-spark-optimizations-2/README.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-spark-optimizations-2",
              "slug": "/foundations/language/pyspark/lab-spark-optimizations-2/",
              "permalink": "/docs/foundations/language/pyspark/lab-spark-optimizations-2/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Connect AWS to PySpark and build an ETL pipeline",
                "permalink": "/docs/processing/databricks/lab-databricks-pyspark-s3/"
              },
              "next": {
                "title": "Lab: Spark Optimizations for Analytics Workloads",
                "permalink": "/docs/foundations/language/pyspark/lab-spark-optimizations/"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-spark-optimizations/README",
              "id": "foundations/language/pyspark/lab-spark-optimizations/README",
              "title": "Lab: Spark Optimizations for Analytics Workloads",
              "description": "Optimizations in Apache Spark play a crucial role while building big data solutions. Knowledge and experience in tuning Spark-based workloads help organizations save costs and time while running these workloads on the cloud. In this lab, we will learn about various optimization techniques concerning Spark DataFrames and big data analytics in general. We will learn about the limitations of the collect() method and inferSchema when reading data. This will be followed by an overview of the best practices for working with CSV files, Parquet files, Pandas projects, and Koalas projects. Also, we will learn about some powerful optimization techniques, such as column predicate pushdown, column pruning, and partitioning strategies.",
              "source": "@site/docs/01-foundations/language/pyspark/lab-spark-optimizations/README.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-spark-optimizations",
              "slug": "/foundations/language/pyspark/lab-spark-optimizations/",
              "permalink": "/docs/foundations/language/pyspark/lab-spark-optimizations/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Spark Optimizations",
                "permalink": "/docs/foundations/language/pyspark/lab-spark-optimizations-2/"
              },
              "next": {
                "title": "Lab: Uber Data Analysis in Pyspark",
                "permalink": "/docs/foundations/language/pyspark/lab-uber-analysis/"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-sql-to-pyspark/README",
              "id": "foundations/language/pyspark/lab-sql-to-pyspark/README",
              "title": "SQL to PySpark Code Conversion",
              "description": "Output:",
              "source": "@site/docs/01-foundations/language/pyspark/lab-sql-to-pyspark/README.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-sql-to-pyspark",
              "slug": "/foundations/language/pyspark/lab-sql-to-pyspark/",
              "permalink": "/docs/foundations/language/pyspark/lab-sql-to-pyspark/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-uber-analysis/README",
              "id": "foundations/language/pyspark/lab-uber-analysis/README",
              "title": "Lab: Uber Data Analysis in Pyspark",
              "description": "This lab can be used as a take-home assignment to learn Pyspark and Data Engineering.",
              "source": "@site/docs/01-foundations/language/pyspark/lab-uber-analysis/README.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-uber-analysis",
              "slug": "/foundations/language/pyspark/lab-uber-analysis/",
              "permalink": "/docs/foundations/language/pyspark/lab-uber-analysis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Spark Optimizations for Analytics Workloads",
                "permalink": "/docs/foundations/language/pyspark/lab-spark-optimizations/"
              },
              "next": {
                "title": "Lab: Understanding Spark Query Execution",
                "permalink": "/docs/foundations/language/pyspark/lab-understand-spark-query-execution/"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/lab-understand-spark-query-execution/README",
              "id": "foundations/language/pyspark/lab-understand-spark-query-execution/README",
              "title": "Lab: Understanding Spark Query Execution",
              "description": "To write efficient Spark applications, we need to have some understanding of how Spark executes queries. Having a good understanding of how Spark executes a given query helps big data developers/engineers work efficiently with large volumes of data.",
              "source": "@site/docs/01-foundations/language/pyspark/lab-understand-spark-query-execution/README.md",
              "sourceDirName": "01-foundations/language/pyspark/lab-understand-spark-query-execution",
              "slug": "/foundations/language/pyspark/lab-understand-spark-query-execution/",
              "permalink": "/docs/foundations/language/pyspark/lab-understand-spark-query-execution/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Uber Data Analysis in Pyspark",
                "permalink": "/docs/foundations/language/pyspark/lab-uber-analysis/"
              },
              "next": {
                "title": "Lab: BCG Case Study",
                "permalink": "/docs/foundations/language/pyspark/lab-bcg/"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/lazy-processing",
              "id": "foundations/language/pyspark/lazy-processing",
              "title": "Lazy Processing",
              "description": "PySpark uses a concept called lazy processing, which means that operations on DataFrames and RDDs are not executed immediately, but rather are recorded in a lineage. The actual execution of the operations is delayed until an action is called. This allows Spark to optimize the execution plan by analyzing the entire lineage of operations, rather than executing each operation individually.",
              "source": "@site/docs/01-foundations/language/pyspark/lazy-processing.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/lazy-processing",
              "permalink": "/docs/foundations/language/pyspark/lazy-processing",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Partitioning",
                "permalink": "/docs/foundations/language/pyspark/partitioning"
              },
              "next": {
                "title": "Caching",
                "permalink": "/docs/foundations/language/pyspark/caching"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/methods-operations",
              "id": "foundations/language/pyspark/methods-operations",
              "title": "Methods, Operations and Functions",
              "description": "PySpark provides a variety of methods to work with data, some of the most commonly used are:",
              "source": "@site/docs/01-foundations/language/pyspark/methods-operations.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/methods-operations",
              "permalink": "/docs/foundations/language/pyspark/methods-operations",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "PySpark DataFrame",
                "permalink": "/docs/foundations/language/pyspark/dataframe"
              },
              "next": {
                "title": "Partitioning",
                "permalink": "/docs/foundations/language/pyspark/partitioning"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/partitioning",
              "id": "foundations/language/pyspark/partitioning",
              "title": "Partitioning",
              "description": "A partition in spark is a logical chunk of data mapped to a single node in a cluster. Partitions are basic units of parallelism. Each partition is processed by a single task slot. In a multicore system, total slots for tasks will be num of executors x number of cores. Hence the number of partitions decides the task parallelism.",
              "source": "@site/docs/01-foundations/language/pyspark/partitioning.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/partitioning",
              "permalink": "/docs/foundations/language/pyspark/partitioning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Methods, Operations and Functions",
                "permalink": "/docs/foundations/language/pyspark/methods-operations"
              },
              "next": {
                "title": "Lazy Processing",
                "permalink": "/docs/foundations/language/pyspark/lazy-processing"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/pyspark-vs-pandas",
              "id": "foundations/language/pyspark/pyspark-vs-pandas",
              "title": "PySpark vs Pandas",
              "description": "Spark DataFrames were inspired by pandas, which also provides an abstraction on top of the data called a DataFrame. pandas is a widely adopted library for data manipulation and analytics. Many developers use it to extrapolate data using Python.",
              "source": "@site/docs/01-foundations/language/pyspark/pyspark-vs-pandas.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/pyspark-vs-pandas",
              "permalink": "/docs/foundations/language/pyspark/pyspark-vs-pandas",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Spark Execution Plan",
                "permalink": "/docs/foundations/language/pyspark/execution-plan"
              },
              "next": {
                "title": "Lab: Pyspark Basics",
                "permalink": "/docs/foundations/language/pyspark/lab-pyspark-basics/"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/udf",
              "id": "foundations/language/pyspark/udf",
              "title": "UDFs",
              "description": "In PySpark, UDF stands for User-Defined Function, which is a feature that allows users to define their own functions and apply them to Spark data frames or RDDs.",
              "source": "@site/docs/01-foundations/language/pyspark/udf.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/udf",
              "permalink": "/docs/foundations/language/pyspark/udf",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Caching",
                "permalink": "/docs/foundations/language/pyspark/caching"
              },
              "next": {
                "title": "Broadcasting",
                "permalink": "/docs/foundations/language/pyspark/broadcasting"
              }
            },
            {
              "unversionedId": "foundations/language/pyspark/window-functions",
              "id": "foundations/language/pyspark/window-functions",
              "title": "Window Functions",
              "description": "",
              "source": "@site/docs/01-foundations/language/pyspark/window-functions.md",
              "sourceDirName": "01-foundations/language/pyspark",
              "slug": "/foundations/language/pyspark/window-functions",
              "permalink": "/docs/foundations/language/pyspark/window-functions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/python/introduction-to-python",
              "id": "foundations/language/python/introduction-to-python",
              "title": "Introduction to Python",
              "description": "A strong understanding of Python syntax, data types, operators, and control structures is essential. Data engineering using Python only gets better, and here is a list of points if you are beginning to think otherwise.",
              "source": "@site/docs/01-foundations/language/python/introduction-to-python.md",
              "sourceDirName": "01-foundations/language/python",
              "slug": "/foundations/language/python/introduction-to-python",
              "permalink": "/docs/foundations/language/python/introduction-to-python",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Explore Further",
                "permalink": "/docs/foundations/language/sql/links"
              },
              "next": {
                "title": "Lab: Interesting Python Syntaxes",
                "permalink": "/docs/foundations/language/python/python-syntax-sugars"
              }
            },
            {
              "unversionedId": "foundations/language/python/lab-etl-csv-json-xml/index",
              "id": "foundations/language/python/lab-etl-csv-json-xml/index",
              "title": "Lab: ETL process and reading/writing CSV, JSON and XML files in pandas",
              "description": "",
              "source": "@site/docs/01-foundations/language/python/lab-etl-csv-json-xml/index.md",
              "sourceDirName": "01-foundations/language/python/lab-etl-csv-json-xml",
              "slug": "/foundations/language/python/lab-etl-csv-json-xml/",
              "permalink": "/docs/foundations/language/python/lab-etl-csv-json-xml/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Interesting Python Syntaxes",
                "permalink": "/docs/foundations/language/python/python-syntax-sugars"
              },
              "next": {
                "title": "Lab: Basic Text Handling with Python",
                "permalink": "/docs/datascience/nlp/lab-basic-text-handlng-python/"
              }
            },
            {
              "unversionedId": "foundations/language/python/links",
              "id": "foundations/language/python/links",
              "title": "Explore Further",
              "description": "1. https://scrimba.com/learn/python",
              "source": "@site/docs/01-foundations/language/python/links.md",
              "sourceDirName": "01-foundations/language/python",
              "slug": "/foundations/language/python/links",
              "permalink": "/docs/foundations/language/python/links",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Basic Text Handling with Python",
                "permalink": "/docs/datascience/nlp/lab-basic-text-handlng-python/"
              },
              "next": {
                "title": "Installing Spark",
                "permalink": "/docs/foundations/language/pyspark/install"
              }
            },
            {
              "unversionedId": "foundations/language/python/packaging/docs/README",
              "id": "foundations/language/python/packaging/docs/README",
              "title": "Home",
              "description": "Standards - AI/ML boilerplates and snippets",
              "source": "@site/docs/01-foundations/language/python/packaging/docs/README.md",
              "sourceDirName": "01-foundations/language/python/packaging/docs",
              "slug": "/foundations/language/python/packaging/docs/",
              "permalink": "/docs/foundations/language/python/packaging/docs/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {
                "layout": "default",
                "title": "Home",
                "nav_order": 1,
                "description": "Standards - AI/ML boilerplates and snippets",
                "permalink": "/"
              }
            },
            {
              "unversionedId": "foundations/language/python/python-snippets",
              "id": "foundations/language/python/python-snippets",
              "title": "Python code",
              "description": "Generating a hash for given string",
              "source": "@site/docs/01-foundations/language/python/python-snippets.md",
              "sourceDirName": "01-foundations/language/python",
              "slug": "/foundations/language/python/python-snippets",
              "permalink": "/docs/foundations/language/python/python-snippets",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/python/python-syntax-sugars",
              "id": "foundations/language/python/python-syntax-sugars",
              "title": "Lab: Interesting Python Syntaxes",
              "description": "Sweet Python Syntax Sugar for Improving Your Coding Experience by Yang Zhou",
              "source": "@site/docs/01-foundations/language/python/python-syntax-sugars.md",
              "sourceDirName": "01-foundations/language/python",
              "slug": "/foundations/language/python/python-syntax-sugars",
              "permalink": "/docs/foundations/language/python/python-syntax-sugars",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Introduction to Python",
                "permalink": "/docs/foundations/language/python/introduction-to-python"
              },
              "next": {
                "title": "Lab: ETL process and reading/writing CSV, JSON and XML files in pandas",
                "permalink": "/docs/foundations/language/python/lab-etl-csv-json-xml/"
              }
            },
            {
              "unversionedId": "foundations/language/python/README",
              "id": "foundations/language/python/README",
              "title": "Python",
              "description": "Concepts",
              "source": "@site/docs/01-foundations/language/python/README.md",
              "sourceDirName": "01-foundations/language/python",
              "slug": "/foundations/language/python/",
              "permalink": "/docs/foundations/language/python/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/scala/lab-scala-getting-started/README",
              "id": "foundations/language/scala/lab-scala-getting-started/README",
              "title": "Getting Started with Scala",
              "description": "Why Scala?",
              "source": "@site/docs/01-foundations/language/scala/lab-scala-getting-started/README.md",
              "sourceDirName": "01-foundations/language/scala/lab-scala-getting-started",
              "slug": "/foundations/language/scala/lab-scala-getting-started/",
              "permalink": "/docs/foundations/language/scala/lab-scala-getting-started/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Calculating Spark Partitions",
                "permalink": "/docs/foundations/language/pyspark/lab-calculating-partitions/"
              },
              "next": {
                "title": "Serialization",
                "permalink": "/docs/storage/serialization"
              }
            },
            {
              "unversionedId": "foundations/language/scala/README",
              "id": "foundations/language/scala/README",
              "title": "Scala",
              "description": "- Expressive",
              "source": "@site/docs/01-foundations/language/scala/README.md",
              "sourceDirName": "01-foundations/language/scala",
              "slug": "/foundations/language/scala/",
              "permalink": "/docs/foundations/language/scala/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/aggregate-functions",
              "id": "foundations/language/sql/aggregate-functions",
              "title": "SQL Aggregate Functions",
              "description": "| Aggregate function                                                  | Description                                                            |",
              "source": "@site/docs/01-foundations/language/sql/aggregate-functions.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/aggregate-functions",
              "permalink": "/docs/foundations/language/sql/aggregate-functions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Cursor",
                "permalink": "/docs/foundations/language/sql/cursor"
              },
              "next": {
                "title": "SQL String Functions",
                "permalink": "/docs/foundations/language/sql/string-functions"
              }
            },
            {
              "unversionedId": "foundations/language/sql/challenges/assignment1/README",
              "id": "foundations/language/sql/challenges/assignment1/README",
              "title": "Lab - SQL Assignment",
              "description": "Activity",
              "source": "@site/docs/01-foundations/language/sql/challenges/assignment1/README.md",
              "sourceDirName": "01-foundations/language/sql/challenges/assignment1",
              "slug": "/foundations/language/sql/challenges/assignment1/",
              "permalink": "/docs/foundations/language/sql/challenges/assignment1/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/challenges/assignment1/solution",
              "id": "foundations/language/sql/challenges/assignment1/solution",
              "title": "solution",
              "description": "Solution",
              "source": "@site/docs/01-foundations/language/sql/challenges/assignment1/solution.md",
              "sourceDirName": "01-foundations/language/sql/challenges/assignment1",
              "slug": "/foundations/language/sql/challenges/assignment1/solution",
              "permalink": "/docs/foundations/language/sql/challenges/assignment1/solution",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/challenges/assignment2/README",
              "id": "foundations/language/sql/challenges/assignment2/README",
              "title": "SQL Assignment",
              "description": "Learning goals",
              "source": "@site/docs/01-foundations/language/sql/challenges/assignment2/README.md",
              "sourceDirName": "01-foundations/language/sql/challenges/assignment2",
              "slug": "/foundations/language/sql/challenges/assignment2/",
              "permalink": "/docs/foundations/language/sql/challenges/assignment2/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/challenges/assignment3/README",
              "id": "foundations/language/sql/challenges/assignment3/README",
              "title": "SQL Assignment",
              "description": "Part 1: Deforestation Exploration",
              "source": "@site/docs/01-foundations/language/sql/challenges/assignment3/README.md",
              "sourceDirName": "01-foundations/language/sql/challenges/assignment3",
              "slug": "/foundations/language/sql/challenges/assignment3/",
              "permalink": "/docs/foundations/language/sql/challenges/assignment3/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/challenges/assignment4/README",
              "id": "foundations/language/sql/challenges/assignment4/README",
              "title": "SQL Assignment",
              "description": "",
              "source": "@site/docs/01-foundations/language/sql/challenges/assignment4/README.md",
              "sourceDirName": "01-foundations/language/sql/challenges/assignment4",
              "slug": "/foundations/language/sql/challenges/assignment4/",
              "permalink": "/docs/foundations/language/sql/challenges/assignment4/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/challenges/assignment5/index",
              "id": "foundations/language/sql/challenges/assignment5/index",
              "title": "Challenge - Danny's Diner",
              "description": "Danny seriously loves Japanese food so in the beginning of 2021, he decides to embark upon a risky venture and opens up a cute little restaurant that sells his 3 favourite foods: sushi, curry and ramen.",
              "source": "@site/docs/01-foundations/language/sql/challenges/assignment5/index.md",
              "sourceDirName": "01-foundations/language/sql/challenges/assignment5",
              "slug": "/foundations/language/sql/challenges/assignment5/",
              "permalink": "/docs/foundations/language/sql/challenges/assignment5/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Challenge - Employee Analytics",
                "permalink": "/docs/foundations/language/sql/challenges/employee"
              },
              "next": {
                "title": "Explore Further",
                "permalink": "/docs/foundations/language/sql/links"
              }
            },
            {
              "unversionedId": "foundations/language/sql/challenges/assignment6/README",
              "id": "foundations/language/sql/challenges/assignment6/README",
              "title": "SQL Pizza Runner Assignment",
              "description": "Did you know that over 115 million kilograms of pizza is consumed daily worldwide??? (Well according to Wikipedia anyway…)",
              "source": "@site/docs/01-foundations/language/sql/challenges/assignment6/README.md",
              "sourceDirName": "01-foundations/language/sql/challenges/assignment6",
              "slug": "/foundations/language/sql/challenges/assignment6/",
              "permalink": "/docs/foundations/language/sql/challenges/assignment6/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/challenges/assignment7/README",
              "id": "foundations/language/sql/challenges/assignment7/README",
              "title": "Patients SQL Assignment",
              "description": "Queries",
              "source": "@site/docs/01-foundations/language/sql/challenges/assignment7/README.md",
              "sourceDirName": "01-foundations/language/sql/challenges/assignment7",
              "slug": "/foundations/language/sql/challenges/assignment7/",
              "permalink": "/docs/foundations/language/sql/challenges/assignment7/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/challenges/braintree/index",
              "id": "foundations/language/sql/challenges/braintree/index",
              "title": "Challenge - BrainTree SQL Code Challenge",
              "description": "Instructions",
              "source": "@site/docs/01-foundations/language/sql/challenges/braintree/index.md",
              "sourceDirName": "01-foundations/language/sql/challenges/braintree",
              "slug": "/foundations/language/sql/challenges/braintree/",
              "permalink": "/docs/foundations/language/sql/challenges/braintree/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Challenge - Yammer Advanced Analytics",
                "permalink": "/docs/foundations/language/sql/challenges/yammer/"
              },
              "next": {
                "title": "Challenge - Employee Analytics",
                "permalink": "/docs/foundations/language/sql/challenges/employee"
              }
            },
            {
              "unversionedId": "foundations/language/sql/challenges/employee",
              "id": "foundations/language/sql/challenges/employee",
              "title": "Challenge - Employee Analytics",
              "description": "Small dataset | 6 Questions",
              "source": "@site/docs/01-foundations/language/sql/challenges/employee.md",
              "sourceDirName": "01-foundations/language/sql/challenges",
              "slug": "/foundations/language/sql/challenges/employee",
              "permalink": "/docs/foundations/language/sql/challenges/employee",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Challenge - BrainTree SQL Code Challenge",
                "permalink": "/docs/foundations/language/sql/challenges/braintree/"
              },
              "next": {
                "title": "Challenge - Danny's Diner",
                "permalink": "/docs/foundations/language/sql/challenges/assignment5/"
              }
            },
            {
              "unversionedId": "foundations/language/sql/challenges/yammer/index",
              "id": "foundations/language/sql/challenges/yammer/index",
              "title": "Challenge - Yammer Advanced Analytics",
              "description": "Yammer is a social network for communicating with coworkers. Individuals share documents, updates, and ideas by posting them in groups. Yammer is free to use indefinitely, but companies must pay license fees if they want access to administrative controls, including integration with user management systems like ActiveDirectory.",
              "source": "@site/docs/01-foundations/language/sql/challenges/yammer/index.md",
              "sourceDirName": "01-foundations/language/sql/challenges/yammer",
              "slug": "/foundations/language/sql/challenges/yammer/",
              "permalink": "/docs/foundations/language/sql/challenges/yammer/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: SQLite Basics",
                "permalink": "/docs/foundations/language/sql/lab-sqlite-basics/"
              },
              "next": {
                "title": "Challenge - BrainTree SQL Code Challenge",
                "permalink": "/docs/foundations/language/sql/challenges/braintree/"
              }
            },
            {
              "unversionedId": "foundations/language/sql/commands/and",
              "id": "foundations/language/sql/commands/and",
              "title": "SQL AND",
              "description": "AND is a logical operator in SQL that allows you to select only rows that satisfy two conditions.",
              "source": "@site/docs/01-foundations/language/sql/commands/and.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/and",
              "permalink": "/docs/foundations/language/sql/commands/and",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/between",
              "id": "foundations/language/sql/commands/between",
              "title": "SQL BETWEEN",
              "description": "BETWEEN is a logical operator in SQL that allows you to select only rows that are within a specific range.",
              "source": "@site/docs/01-foundations/language/sql/commands/between.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/between",
              "permalink": "/docs/foundations/language/sql/commands/between",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/case",
              "id": "foundations/language/sql/commands/case",
              "title": "SQL CASE",
              "description": "The CASE statement is SQL's way of handling if/then logic. The CASE statement is followed by at least one pair of WHEN and THEN statements—SQL's equivalent of IF/THEN in Excel. Because of this pairing, you might be tempted to call this SQL CASE WHEN, but CASE is the accepted term.",
              "source": "@site/docs/01-foundations/language/sql/commands/case.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/case",
              "permalink": "/docs/foundations/language/sql/commands/case",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/distinct",
              "id": "foundations/language/sql/commands/distinct",
              "title": "SQL DISTINCT",
              "description": "You'll occasionally want to look at only the unique values in a particular column. You can do this using SELECT DISTINCT syntax.",
              "source": "@site/docs/01-foundations/language/sql/commands/distinct.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/distinct",
              "permalink": "/docs/foundations/language/sql/commands/distinct",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/groupby",
              "id": "foundations/language/sql/commands/groupby",
              "title": "SQL GROUP BY",
              "description": "SQL aggregate function like COUNT, AVG, and SUM have something in common: they all aggregate across the entire table. But what if you want to aggregate only part of a table? For example, you might want to count the number of entries for each year.",
              "source": "@site/docs/01-foundations/language/sql/commands/groupby.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/groupby",
              "permalink": "/docs/foundations/language/sql/commands/groupby",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/having",
              "id": "foundations/language/sql/commands/having",
              "title": "SQL HAVING",
              "description": "You'll often encounter datasets where GROUP BY isn't enough to get what you're looking for. Let's say that it's not enough just to know aggregated stats by month. After all, there are a lot of months in this dataset. Instead, you might want to find every month during which AAPL stock worked its way over $400/share. The WHERE clause won't work for this because it doesn't allow you to filter on aggregate columns—that's where the HAVING clause comes in.",
              "source": "@site/docs/01-foundations/language/sql/commands/having.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/having",
              "permalink": "/docs/foundations/language/sql/commands/having",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/in",
              "id": "foundations/language/sql/commands/in",
              "title": "SQL IN",
              "description": "IN is a logical operator in SQL that allows you to specify a list of values that you'd like to include in the results.",
              "source": "@site/docs/01-foundations/language/sql/commands/in.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/in",
              "permalink": "/docs/foundations/language/sql/commands/in",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/index",
              "id": "foundations/language/sql/commands/index",
              "title": "Commands",
              "description": "",
              "source": "@site/docs/01-foundations/language/sql/commands/index.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/",
              "permalink": "/docs/foundations/language/sql/commands/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Query",
                "permalink": "/docs/foundations/language/sql/sql-query"
              },
              "next": {
                "title": "CTE (Common Table Expressions)",
                "permalink": "/docs/foundations/language/sql/cte"
              }
            },
            {
              "unversionedId": "foundations/language/sql/commands/isnull",
              "id": "foundations/language/sql/commands/isnull",
              "title": "SQL IS NULL",
              "description": "IS NULL is a logical operator in SQL that allows you to exclude rows with missing data from your results.",
              "source": "@site/docs/01-foundations/language/sql/commands/isnull.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/isnull",
              "permalink": "/docs/foundations/language/sql/commands/isnull",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/like",
              "id": "foundations/language/sql/commands/like",
              "title": "SQL LIKE",
              "description": "LIKE is a logical operator in SQL that allows you to match on similar values rather than exact ones.",
              "source": "@site/docs/01-foundations/language/sql/commands/like.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/like",
              "permalink": "/docs/foundations/language/sql/commands/like",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/limit",
              "id": "foundations/language/sql/commands/limit",
              "title": "SQL LIMIT",
              "description": "As you might expect, the limit restricts how many rows the SQL query returns.",
              "source": "@site/docs/01-foundations/language/sql/commands/limit.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/limit",
              "permalink": "/docs/foundations/language/sql/commands/limit",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/not",
              "id": "foundations/language/sql/commands/not",
              "title": "SQL NOT",
              "description": "NOT is a logical operator in SQL that you can put before any conditional statement to select rows for which that statement is false.",
              "source": "@site/docs/01-foundations/language/sql/commands/not.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/not",
              "permalink": "/docs/foundations/language/sql/commands/not",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/or",
              "id": "foundations/language/sql/commands/or",
              "title": "SQL OR",
              "description": "OR is a logical operator in SQL that allows you to select rows that satisfy either of two conditions. It works the same way as AND, which selects the rows that satisfy both of two conditions.",
              "source": "@site/docs/01-foundations/language/sql/commands/or.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/or",
              "permalink": "/docs/foundations/language/sql/commands/or",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/orderby",
              "id": "foundations/language/sql/commands/orderby",
              "title": "SQL ORDER BY",
              "description": "The ORDER BY clause allows you to reorder your results based on the data in one or more columns.",
              "source": "@site/docs/01-foundations/language/sql/commands/orderby.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/orderby",
              "permalink": "/docs/foundations/language/sql/commands/orderby",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/select",
              "id": "foundations/language/sql/commands/select",
              "title": "SQL SELECT",
              "description": "There are two required ingredients in any SQL query: SELECT and FROM---and they have to be in that order. SELECT indicates which columns you'd like to view, and FROM identifies the table that they live in.",
              "source": "@site/docs/01-foundations/language/sql/commands/select.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/select",
              "permalink": "/docs/foundations/language/sql/commands/select",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/union",
              "id": "foundations/language/sql/commands/union",
              "title": "SQL UNION",
              "description": "SQL joins allow you to combine two datasets side-by-side, but UNION allows you to stack one dataset on top of the other. Put differently, UNION allows you to write two separate SELECT statements, and to have the results of one statement display in the same table as the results from the other statement.",
              "source": "@site/docs/01-foundations/language/sql/commands/union.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/union",
              "permalink": "/docs/foundations/language/sql/commands/union",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/commands/where",
              "id": "foundations/language/sql/commands/where",
              "title": "SQL WHERE",
              "description": "Once you know how to view some data using SELECT and FROM, the next step is filtering the data using the WHERE clause.",
              "source": "@site/docs/01-foundations/language/sql/commands/where.md",
              "sourceDirName": "01-foundations/language/sql/commands",
              "slug": "/foundations/language/sql/commands/where",
              "permalink": "/docs/foundations/language/sql/commands/where",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/comments",
              "id": "foundations/language/sql/comments",
              "title": "Comments",
              "description": "You can \"comment out\" pieces of code by adding combinations of characters. In other words, you can specify parts of your query that will not actually be treated like SQL code. It can be helpful to include comments that explain your thinking so that you can easily remember what you intended to do if you ever want to revisit your work. Commenting can also be useful if you want to test variations on your query while keeping all of your code intact.",
              "source": "@site/docs/01-foundations/language/sql/comments.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/comments",
              "permalink": "/docs/foundations/language/sql/comments",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Joins",
                "permalink": "/docs/foundations/language/sql/joins"
              },
              "next": {
                "title": "Cursor",
                "permalink": "/docs/foundations/language/sql/cursor"
              }
            },
            {
              "unversionedId": "foundations/language/sql/comparison-operators",
              "id": "foundations/language/sql/comparison-operators",
              "title": "SQL Comparison Operators",
              "description": "Comparison operators on numerical data",
              "source": "@site/docs/01-foundations/language/sql/comparison-operators.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/comparison-operators",
              "permalink": "/docs/foundations/language/sql/comparison-operators",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Indexes",
                "permalink": "/docs/foundations/language/sql/indexes"
              },
              "next": {
                "title": "SQL Logical Operators",
                "permalink": "/docs/foundations/language/sql/logical-operators"
              }
            },
            {
              "unversionedId": "foundations/language/sql/cte",
              "id": "foundations/language/sql/cte",
              "title": "CTE (Common Table Expressions)",
              "description": "A common table expression is a named temporary result set that exists only within the execution scope of a single SQL statement e.g.,SELECT, INSERT, UPDATE, or DELETE.",
              "source": "@site/docs/01-foundations/language/sql/cte.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/cte",
              "permalink": "/docs/foundations/language/sql/cte",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Commands",
                "permalink": "/docs/foundations/language/sql/commands/"
              },
              "next": {
                "title": "Subquery",
                "permalink": "/docs/foundations/language/sql/subquery"
              }
            },
            {
              "unversionedId": "foundations/language/sql/cursor",
              "id": "foundations/language/sql/cursor",
              "title": "Cursor",
              "description": "To handle a result set inside a stored procedure, you use a cursor. A cursor allows you to iterate a set of rows returned by a query and process each row individually.",
              "source": "@site/docs/01-foundations/language/sql/cursor.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/cursor",
              "permalink": "/docs/foundations/language/sql/cursor",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Comments",
                "permalink": "/docs/foundations/language/sql/comments"
              },
              "next": {
                "title": "SQL Aggregate Functions",
                "permalink": "/docs/foundations/language/sql/aggregate-functions"
              }
            },
            {
              "unversionedId": "foundations/language/sql/date-functions",
              "id": "foundations/language/sql/date-functions",
              "title": "SQL Date Functions",
              "description": "Assuming you've got some dates properly stored as a date or time data type, you can do some pretty powerful things. Maybe you'd like to calculate a field of dates a week after an existing field. Or maybe you'd like to create a field that indicates how many days apart the values in two other date fields are. These are trivially simple, but it's important to keep in mind that the data type of your results will depend on exactly what you are doing to the dates.",
              "source": "@site/docs/01-foundations/language/sql/date-functions.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/date-functions",
              "permalink": "/docs/foundations/language/sql/date-functions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL String Functions",
                "permalink": "/docs/foundations/language/sql/string-functions"
              },
              "next": {
                "title": "Window Functions",
                "permalink": "/docs/foundations/language/sql/window-functions"
              }
            },
            {
              "unversionedId": "foundations/language/sql/indexes",
              "id": "foundations/language/sql/indexes",
              "title": "Indexes",
              "description": "An index is created by a table or view to define a field that can be used to optimize queries.",
              "source": "@site/docs/01-foundations/language/sql/indexes.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/indexes",
              "permalink": "/docs/foundations/language/sql/indexes",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Triggers",
                "permalink": "/docs/foundations/language/sql/triggers"
              },
              "next": {
                "title": "SQL Comparison Operators",
                "permalink": "/docs/foundations/language/sql/comparison-operators"
              }
            },
            {
              "unversionedId": "foundations/language/sql/joins",
              "id": "foundations/language/sql/joins",
              "title": "SQL Joins",
              "description": "It might be helpful to refer to this JOIN visualization by Patrik Spathon.",
              "source": "@site/docs/01-foundations/language/sql/joins.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/joins",
              "permalink": "/docs/foundations/language/sql/joins",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Logical Operators",
                "permalink": "/docs/foundations/language/sql/logical-operators"
              },
              "next": {
                "title": "Comments",
                "permalink": "/docs/foundations/language/sql/comments"
              }
            },
            {
              "unversionedId": "foundations/language/sql/lab-basic-to-advanced/index",
              "id": "foundations/language/sql/lab-basic-to-advanced/index",
              "title": "Lab: SQL Basics to Advanced Primer",
              "description": "Notebooks",
              "source": "@site/docs/01-foundations/language/sql/lab-basic-to-advanced/index.md",
              "sourceDirName": "01-foundations/language/sql/lab-basic-to-advanced",
              "slug": "/foundations/language/sql/lab-basic-to-advanced/",
              "permalink": "/docs/foundations/language/sql/lab-basic-to-advanced/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Data Ingestion to MySQL",
                "permalink": "/docs/foundations/language/sql/lab-mysql-data-ingestion/"
              },
              "next": {
                "title": "Lab: Postgres SQL basics to advanced",
                "permalink": "/docs/foundations/language/sql/lab-postgres-queries/"
              }
            },
            {
              "unversionedId": "foundations/language/sql/lab-mysql-data-ingestion/index",
              "id": "foundations/language/sql/lab-mysql-data-ingestion/index",
              "title": "Lab: Data Ingestion to MySQL",
              "description": "Process Flow",
              "source": "@site/docs/01-foundations/language/sql/lab-mysql-data-ingestion/index.md",
              "sourceDirName": "01-foundations/language/sql/lab-mysql-data-ingestion",
              "slug": "/foundations/language/sql/lab-mysql-data-ingestion/",
              "permalink": "/docs/foundations/language/sql/lab-mysql-data-ingestion/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Joins",
                "permalink": "/docs/foundations/language/sql/joins"
              },
              "next": {
                "title": "Lab: SQL Basics to Advanced Primer",
                "permalink": "/docs/foundations/language/sql/lab-basic-to-advanced/"
              }
            },
            {
              "unversionedId": "foundations/language/sql/lab-postgres-queries/index",
              "id": "foundations/language/sql/lab-postgres-queries/index",
              "title": "Lab: Postgres SQL basics to advanced",
              "description": "Notebooks",
              "source": "@site/docs/01-foundations/language/sql/lab-postgres-queries/index.md",
              "sourceDirName": "01-foundations/language/sql/lab-postgres-queries",
              "slug": "/foundations/language/sql/lab-postgres-queries/",
              "permalink": "/docs/foundations/language/sql/lab-postgres-queries/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: SQL Basics to Advanced Primer",
                "permalink": "/docs/foundations/language/sql/lab-basic-to-advanced/"
              },
              "next": {
                "title": "Lab: Postgres Sales",
                "permalink": "/docs/foundations/language/sql/lab-postgres-sales/"
              }
            },
            {
              "unversionedId": "foundations/language/sql/lab-postgres-sales/index",
              "id": "foundations/language/sql/lab-postgres-sales/index",
              "title": "Lab: Postgres Sales",
              "description": "Running Dates, String and Advanced queries in Postgres on Sales data",
              "source": "@site/docs/01-foundations/language/sql/lab-postgres-sales/index.md",
              "sourceDirName": "01-foundations/language/sql/lab-postgres-sales",
              "slug": "/foundations/language/sql/lab-postgres-sales/",
              "permalink": "/docs/foundations/language/sql/lab-postgres-sales/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Postgres SQL basics to advanced",
                "permalink": "/docs/foundations/language/sql/lab-postgres-queries/"
              },
              "next": {
                "title": "Lab: SQLite Basics",
                "permalink": "/docs/foundations/language/sql/lab-sqlite-basics/"
              }
            },
            {
              "unversionedId": "foundations/language/sql/lab-sqlite-basics/index",
              "id": "foundations/language/sql/lab-sqlite-basics/index",
              "title": "Lab: SQLite Basics",
              "description": "Working with Book dataset on SQLite database",
              "source": "@site/docs/01-foundations/language/sql/lab-sqlite-basics/index.md",
              "sourceDirName": "01-foundations/language/sql/lab-sqlite-basics",
              "slug": "/foundations/language/sql/lab-sqlite-basics/",
              "permalink": "/docs/foundations/language/sql/lab-sqlite-basics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Postgres Sales",
                "permalink": "/docs/foundations/language/sql/lab-postgres-sales/"
              },
              "next": {
                "title": "Challenge - Yammer Advanced Analytics",
                "permalink": "/docs/foundations/language/sql/challenges/yammer/"
              }
            },
            {
              "unversionedId": "foundations/language/sql/links",
              "id": "foundations/language/sql/links",
              "title": "Explore Further",
              "description": "1. SQL Cheat Sheet",
              "source": "@site/docs/01-foundations/language/sql/links.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/links",
              "permalink": "/docs/foundations/language/sql/links",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Challenge - Danny's Diner",
                "permalink": "/docs/foundations/language/sql/challenges/assignment5/"
              },
              "next": {
                "title": "Introduction to Python",
                "permalink": "/docs/foundations/language/python/introduction-to-python"
              }
            },
            {
              "unversionedId": "foundations/language/sql/logical-operators",
              "id": "foundations/language/sql/logical-operators",
              "title": "SQL Logical Operators",
              "description": "You'll likely also want to filter data using several conditions---possibly more often than you'll want to filter by only one condition. Logical operators allow you to use multiple comparison operators in one query.",
              "source": "@site/docs/01-foundations/language/sql/logical-operators.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/logical-operators",
              "permalink": "/docs/foundations/language/sql/logical-operators",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Comparison Operators",
                "permalink": "/docs/foundations/language/sql/comparison-operators"
              },
              "next": {
                "title": "SQL Joins",
                "permalink": "/docs/foundations/language/sql/joins"
              }
            },
            {
              "unversionedId": "foundations/language/sql/performance-tuning",
              "id": "foundations/language/sql/performance-tuning",
              "title": "Performance Tuning",
              "description": "SQL tuning is the process of improving SQL queries to accelerate your servers performance. It's general purpose is to reduce the amount of time it takes a user to receive a result after issuing a query, and to reduce the amount of resources used to process a query.",
              "source": "@site/docs/01-foundations/language/sql/performance-tuning.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/performance-tuning",
              "permalink": "/docs/foundations/language/sql/performance-tuning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Window Functions",
                "permalink": "/docs/foundations/language/sql/window-functions"
              },
              "next": {
                "title": "SQL Joins",
                "permalink": "/docs/foundations/language/sql/joins"
              }
            },
            {
              "unversionedId": "foundations/language/sql/sql-basics",
              "id": "foundations/language/sql/sql-basics",
              "title": "SQL Basics",
              "description": "What is SQL?",
              "source": "@site/docs/01-foundations/language/sql/sql-basics.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/sql-basics",
              "permalink": "/docs/foundations/language/sql/sql-basics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure Full-stack Solutions",
                "permalink": "/docs/foundations/cloud/azure-fullstack-solutions"
              },
              "next": {
                "title": "SQL Query",
                "permalink": "/docs/foundations/language/sql/sql-query"
              }
            },
            {
              "unversionedId": "foundations/language/sql/sql-interviews-questions",
              "id": "foundations/language/sql/sql-interviews-questions",
              "title": "SQL Interview Questions",
              "description": "Topics Covered in SQL Interviews for Data Engineers",
              "source": "@site/docs/01-foundations/language/sql/sql-interviews-questions.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/sql-interviews-questions",
              "permalink": "/docs/foundations/language/sql/sql-interviews-questions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "foundations/language/sql/sql-query",
              "id": "foundations/language/sql/sql-query",
              "title": "SQL Query",
              "description": "Execution path of a query",
              "source": "@site/docs/01-foundations/language/sql/sql-query.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/sql-query",
              "permalink": "/docs/foundations/language/sql/sql-query",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Basics",
                "permalink": "/docs/foundations/language/sql/sql-basics"
              },
              "next": {
                "title": "Commands",
                "permalink": "/docs/foundations/language/sql/commands/"
              }
            },
            {
              "unversionedId": "foundations/language/sql/stored-procedures",
              "id": "foundations/language/sql/stored-procedures",
              "title": "Stored Procedures",
              "description": "A stored procedure is a set of SQL statements stored in a database. These statements can request data entry parameters, which are used as variables during execution, and can constitute a data output.",
              "source": "@site/docs/01-foundations/language/sql/stored-procedures.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/stored-procedures",
              "permalink": "/docs/foundations/language/sql/stored-procedures",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Views",
                "permalink": "/docs/foundations/language/sql/views"
              },
              "next": {
                "title": "Triggers",
                "permalink": "/docs/foundations/language/sql/triggers"
              }
            },
            {
              "unversionedId": "foundations/language/sql/string-functions",
              "id": "foundations/language/sql/string-functions",
              "title": "SQL String Functions",
              "description": "| Name                                                                                                    | Description                                                                              |",
              "source": "@site/docs/01-foundations/language/sql/string-functions.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/string-functions",
              "permalink": "/docs/foundations/language/sql/string-functions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Aggregate Functions",
                "permalink": "/docs/foundations/language/sql/aggregate-functions"
              },
              "next": {
                "title": "SQL Date Functions",
                "permalink": "/docs/foundations/language/sql/date-functions"
              }
            },
            {
              "unversionedId": "foundations/language/sql/subquery",
              "id": "foundations/language/sql/subquery",
              "title": "Subquery",
              "description": "Subqueries (also known as inner queries or nested queries) are a tool for performing operations in multiple steps. For example, if you wanted to take the sums of several columns, then average all of those values, you'd need to do each aggregation in a distinct step.",
              "source": "@site/docs/01-foundations/language/sql/subquery.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/subquery",
              "permalink": "/docs/foundations/language/sql/subquery",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "CTE (Common Table Expressions)",
                "permalink": "/docs/foundations/language/sql/cte"
              },
              "next": {
                "title": "Views",
                "permalink": "/docs/foundations/language/sql/views"
              }
            },
            {
              "unversionedId": "foundations/language/sql/triggers",
              "id": "foundations/language/sql/triggers",
              "title": "Triggers",
              "description": "Triggers are a type of stored procedure, configured to call whenever an event occurs. This trigger can be used, for example, to signalize the execution of some statements whenever new data is included in a table, or a record is edited in the table.",
              "source": "@site/docs/01-foundations/language/sql/triggers.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/triggers",
              "permalink": "/docs/foundations/language/sql/triggers",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Stored Procedures",
                "permalink": "/docs/foundations/language/sql/stored-procedures"
              },
              "next": {
                "title": "Indexes",
                "permalink": "/docs/foundations/language/sql/indexes"
              }
            },
            {
              "unversionedId": "foundations/language/sql/views",
              "id": "foundations/language/sql/views",
              "title": "Views",
              "description": "A view can be considered a virtual table because it is composed of rows and columns of data, the results of a SELECT SQL instruction in one or more database tables. Views are great resources for organizing information from different tables to create reports.",
              "source": "@site/docs/01-foundations/language/sql/views.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/views",
              "permalink": "/docs/foundations/language/sql/views",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Subquery",
                "permalink": "/docs/foundations/language/sql/subquery"
              },
              "next": {
                "title": "Stored Procedures",
                "permalink": "/docs/foundations/language/sql/stored-procedures"
              }
            },
            {
              "unversionedId": "foundations/language/sql/window-functions",
              "id": "foundations/language/sql/window-functions",
              "title": "Window Functions",
              "description": "There is no official categorisation of Window Functions but based on the usage, we can briefly categorise them in 3 ways:",
              "source": "@site/docs/01-foundations/language/sql/window-functions.md",
              "sourceDirName": "01-foundations/language/sql",
              "slug": "/foundations/language/sql/window-functions",
              "permalink": "/docs/foundations/language/sql/window-functions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQL Date Functions",
                "permalink": "/docs/foundations/language/sql/date-functions"
              },
              "next": {
                "title": "Performance Tuning",
                "permalink": "/docs/foundations/language/sql/performance-tuning"
              }
            },
            {
              "unversionedId": "interviewprep/algorithm-problems",
              "id": "interviewprep/algorithm-problems",
              "title": "Algorithm Problems",
              "description": "1. https://leetcode.com/problems/two-sum/",
              "source": "@site/docs/interviewprep/algorithm-problems.md",
              "sourceDirName": "interviewprep",
              "slug": "/interviewprep/algorithm-problems",
              "permalink": "/docs/interviewprep/algorithm-problems",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "interviewprep/azure-data-engineering",
              "id": "interviewprep/azure-data-engineering",
              "title": "Azure Data Engineering",
              "description": "Case study - data lake",
              "source": "@site/docs/interviewprep/azure-data-engineering.md",
              "sourceDirName": "interviewprep",
              "slug": "/interviewprep/azure-data-engineering",
              "permalink": "/docs/interviewprep/azure-data-engineering",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "interviewprep/basic-technical-questions",
              "id": "interviewprep/basic-technical-questions",
              "title": "Basic Technical Questions",
              "description": "Interviewers use easy technical questions designed to weed out candidates without the right experience. This question assesses your experience level, comfort with specific tools, and the depth of your domain expertise. Basic technical questions include:",
              "source": "@site/docs/interviewprep/basic-technical-questions.md",
              "sourceDirName": "interviewprep",
              "slug": "/interviewprep/basic-technical-questions",
              "permalink": "/docs/interviewprep/basic-technical-questions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "interviewprep/behavioral-interview-questions",
              "id": "interviewprep/behavioral-interview-questions",
              "title": "Behavioral Interview Questions",
              "description": "Behavioral questions assess soft skills (e.g., communication, leadership, adaptability), your skill level, and how you fit into the company’s data engineering team.",
              "source": "@site/docs/interviewprep/behavioral-interview-questions.md",
              "sourceDirName": "interviewprep",
              "slug": "/interviewprep/behavioral-interview-questions",
              "permalink": "/docs/interviewprep/behavioral-interview-questions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "interviewprep/behavioral-questions",
              "id": "interviewprep/behavioral-questions",
              "title": "Behavioral Questions",
              "description": "Tell me about yourself",
              "source": "@site/docs/interviewprep/behavioral-questions.md",
              "sourceDirName": "interviewprep",
              "slug": "/interviewprep/behavioral-questions",
              "permalink": "/docs/interviewprep/behavioral-questions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "interviewprep/README",
              "id": "interviewprep/README",
              "title": "Interview Preparation",
              "description": "Whether you’re just getting into the data engineer job market or your interview is tomorrow, practice is an essential part of the interview preparation process for a data engineer. Data engineering interview questions assess your data engineering skills and domain expertise. They are based on a company’s tech stack and technology goals, and they test your ability to perform job functions. In an interview for any Engineering role, the interviewer wants to understand if you have good analytical skills, problem-solving ability, communication, work culture and ability to build technical solutions. Specific to Data Engineering, they also want to understand if you have the skills to handle large data and build scalable and robust systems.",
              "source": "@site/docs/interviewprep/README.md",
              "sourceDirName": "interviewprep",
              "slug": "/interviewprep/",
              "permalink": "/docs/interviewprep/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "US Immigration analysis and data pipeline",
                "permalink": "/docs/capstones/us-immigration/"
              },
              "next": {
                "title": "Resume Buildup",
                "permalink": "/docs/interviewprep/resume-buildup"
              }
            },
            {
              "unversionedId": "interviewprep/resume-buildup",
              "id": "interviewprep/resume-buildup",
              "title": "Resume Buildup",
              "description": "Expert Tips to Perfect Your Data Engineer Resume",
              "source": "@site/docs/interviewprep/resume-buildup.md",
              "sourceDirName": "interviewprep",
              "slug": "/interviewprep/resume-buildup",
              "permalink": "/docs/interviewprep/resume-buildup",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Interview Preparation",
                "permalink": "/docs/interviewprep/"
              },
              "next": {
                "title": "Resources",
                "permalink": "/docs/misc/resources"
              }
            },
            {
              "unversionedId": "introduction",
              "id": "introduction",
              "title": "Introduction",
              "description": "Hit the ⭐️ button if you like the repo",
              "source": "@site/docs/introduction.md",
              "sourceDirName": ".",
              "slug": "/introduction",
              "permalink": "/docs/introduction",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "next": {
                "title": "Getting Started",
                "permalink": "/docs/category/getting-started"
              }
            },
            {
              "unversionedId": "mathematics/probability/probability-distributions",
              "id": "mathematics/probability/probability-distributions",
              "title": "Probability Distributions",
              "description": "Random variables are important in analysis. Probability distributions depict the distribution of the values of a random variable. The distributions can help in selecting the right algorithms, and hence plotting the distribution of the data is an important part of the analytical process; this is performed as a part of exploratory data analysis (EDA). The following are some important probability distributions:",
              "source": "@site/docs/mathematics/probability/probability-distributions.md",
              "sourceDirName": "mathematics/probability",
              "slug": "/mathematics/probability/probability-distributions",
              "permalink": "/docs/mathematics/probability/probability-distributions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Mathematics",
                "permalink": "/docs/mathematics/"
              },
              "next": {
                "title": "Rules of Probability",
                "permalink": "/docs/mathematics/probability/rules-of-probability"
              }
            },
            {
              "unversionedId": "mathematics/probability/README",
              "id": "mathematics/probability/README",
              "title": "Probability",
              "description": "Concepts",
              "source": "@site/docs/mathematics/probability/README.md",
              "sourceDirName": "mathematics/probability",
              "slug": "/mathematics/probability/",
              "permalink": "/docs/mathematics/probability/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "mathematics/probability/rules-of-probability",
              "id": "mathematics/probability/rules-of-probability",
              "title": "Rules of Probability",
              "description": "Probability of Mutually Exclusive Events",
              "source": "@site/docs/mathematics/probability/rules-of-probability.md",
              "sourceDirName": "mathematics/probability",
              "slug": "/mathematics/probability/rules-of-probability",
              "permalink": "/docs/mathematics/probability/rules-of-probability",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Probability Distributions",
                "permalink": "/docs/mathematics/probability/probability-distributions"
              },
              "next": {
                "title": "Sampling",
                "permalink": "/docs/mathematics/statistics/sampling"
              }
            },
            {
              "unversionedId": "mathematics/README",
              "id": "mathematics/README",
              "title": "Mathematics",
              "description": "For data science, 4 topics are important:",
              "source": "@site/docs/mathematics/README.md",
              "sourceDirName": "mathematics",
              "slug": "/mathematics/",
              "permalink": "/docs/mathematics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Infra as Code (IaC)",
                "permalink": "/docs/devops/iac/"
              },
              "next": {
                "title": "Probability Distributions",
                "permalink": "/docs/mathematics/probability/probability-distributions"
              }
            },
            {
              "unversionedId": "mathematics/statistics/README",
              "id": "mathematics/statistics/README",
              "title": "Statistics",
              "description": "Concepts",
              "source": "@site/docs/mathematics/statistics/README.md",
              "sourceDirName": "mathematics/statistics",
              "slug": "/mathematics/statistics/",
              "permalink": "/docs/mathematics/statistics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "mathematics/statistics/sampling",
              "id": "mathematics/statistics/sampling",
              "title": "Sampling",
              "description": "- Random sampling: This is the most common probability sampling technique as every single sample is selected randomly from the population data set. This gives an opportunity for each record in the data set an equal chance (probability) to be chosen to be a part of the sample. For example, the HR department wants to conduct a social event. Therefore, it wants to select 50 people out of 300. To provide an equal opportunity to everyone, HR picks the names randomly from a jar containing all the names of employees.",
              "source": "@site/docs/mathematics/statistics/sampling.md",
              "sourceDirName": "mathematics/statistics",
              "slug": "/mathematics/statistics/sampling",
              "permalink": "/docs/mathematics/statistics/sampling",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Rules of Probability",
                "permalink": "/docs/mathematics/probability/rules-of-probability"
              },
              "next": {
                "title": "The data science origin story",
                "permalink": "/docs/foundations/basics/origin"
              }
            },
            {
              "unversionedId": "misc/explore-further",
              "id": "misc/explore-further",
              "title": "Explore Further",
              "description": "Basic Concepts",
              "source": "@site/docs/misc/explore-further.md",
              "sourceDirName": "misc",
              "slug": "/misc/explore-further",
              "permalink": "/docs/misc/explore-further",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "misc/extras",
              "id": "misc/extras",
              "title": "Extras",
              "description": "Data, analytics and AI maturity curve",
              "source": "@site/docs/misc/extras.md",
              "sourceDirName": "misc",
              "slug": "/misc/extras",
              "permalink": "/docs/misc/extras",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Resources",
                "permalink": "/docs/misc/resources"
              }
            },
            {
              "unversionedId": "misc/pending-topics",
              "id": "misc/pending-topics",
              "title": "Pending Topics",
              "description": "- Programming",
              "source": "@site/docs/misc/pending-topics.md",
              "sourceDirName": "misc",
              "slug": "/misc/pending-topics",
              "permalink": "/docs/misc/pending-topics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "misc/readme_archive",
              "id": "misc/readme_archive",
              "title": "Data Engineering Intensive Training Program",
              "description": "Hit the ⭐️ button if you like the repo.",
              "source": "@site/docs/misc/readme_archive.md",
              "sourceDirName": "misc",
              "slug": "/misc/readme_archive",
              "permalink": "/docs/misc/readme_archive",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "misc/resources",
              "id": "misc/resources",
              "title": "Resources",
              "description": "Courses",
              "source": "@site/docs/misc/resources.md",
              "sourceDirName": "misc",
              "slug": "/misc/resources",
              "permalink": "/docs/misc/resources",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Resume Buildup",
                "permalink": "/docs/interviewprep/resume-buildup"
              },
              "next": {
                "title": "Extras",
                "permalink": "/docs/misc/extras"
              }
            },
            {
              "unversionedId": "mlops/code-snippets",
              "id": "mlops/code-snippets",
              "title": "MLOps Code Snippets",
              "description": "1. Dask-ML-Parallelize model training:",
              "source": "@site/docs/17-mlops/code-snippets.md",
              "sourceDirName": "17-mlops",
              "slug": "/mlops/code-snippets",
              "permalink": "/docs/mlops/code-snippets",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "MLOps",
                "permalink": "/docs/mlops/"
              },
              "next": {
                "title": "MLflow",
                "permalink": "/docs/mlops/mlflow/"
              }
            },
            {
              "unversionedId": "mlops/ml-lab-tracking/README",
              "id": "mlops/ml-lab-tracking/README",
              "title": "Experiments Tracking, Model Management, and Dataset Versioning",
              "description": "Training DL models is an iterative process that consumes a lot of time and resources. Therefore, keeping track of all experiments and consistently organizing them can prevent us from wasting our time on unnecessary operations such as training similar models repeatedly on the same set of data. In other words, having well-documented records of all model architectures and their hyperparameter sets, as well as the version of data used during experiments, can help us derive the right conclusion from the experiments, which naturally leads to the project being successful.",
              "source": "@site/docs/17-mlops/ml-lab-tracking/README.md",
              "sourceDirName": "17-mlops/ml-lab-tracking",
              "slug": "/mlops/ml-lab-tracking/",
              "permalink": "/docs/mlops/ml-lab-tracking/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "mlops/mlflow/README",
              "id": "mlops/mlflow/README",
              "title": "MLflow",
              "description": "MLflow is a platform that makes it simpler to manage the entire machine learning lifecycle. It enables you to track your experiments and their results, deploy and manage your models, and package your machine learning code in a reusable, reproducible format. It provides a central model registry that supports versioning and annotating, as well as model serving capabilities. It does that by redefining experimentation logs and module structure.",
              "source": "@site/docs/17-mlops/mlflow/README.md",
              "sourceDirName": "17-mlops/mlflow",
              "slug": "/mlops/mlflow/",
              "permalink": "/docs/mlops/mlflow/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "MLOps Code Snippets",
                "permalink": "/docs/mlops/code-snippets"
              },
              "next": {
                "title": "Case Studies",
                "permalink": "/docs/category/case-studies"
              }
            },
            {
              "unversionedId": "mlops/README",
              "id": "mlops/README",
              "title": "MLOps",
              "description": "The boom in AI has seen a rising demand for better AI infrastructure — both in the compute hardware layer and AI framework optimizations that make optimal use of accelerated compute. Unfortunately, organizations often overlook the critical importance of a middle tier: infrastructure software that standardizes the ML life cycle, adding a common platform for teams of data scientists and researchers to standardize their approach and eliminate distracting DevOps work. This process of building the ML life cycle is increasingly known as MLOps, with end-to-end platforms being built to automate and standardize repeatable manual processes. Although dozens of MLOps platforms exist, adopting one can be confusing and cumbersome. What should be considered when employing MLOps? What are the core pillars to MLOps, and which features are most critical?",
              "source": "@site/docs/17-mlops/README.md",
              "sourceDirName": "17-mlops",
              "slug": "/mlops/",
              "permalink": "/docs/mlops/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "The Rosenblatt Perceptron",
                "permalink": "/docs/datascience/deep-learning/perceptron"
              },
              "next": {
                "title": "MLOps Code Snippets",
                "permalink": "/docs/mlops/code-snippets"
              }
            },
            {
              "unversionedId": "orchestration/airflow/github-nft/README",
              "id": "orchestration/airflow/github-nft/README",
              "title": "Github NFT Pipeline",
              "description": "Objective",
              "source": "@site/docs/06-orchestration/airflow/github-nft/README.md",
              "sourceDirName": "06-orchestration/airflow/github-nft",
              "slug": "/orchestration/airflow/github-nft/",
              "permalink": "/docs/orchestration/airflow/github-nft/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/lab-airflow-conn-py/README",
              "id": "orchestration/airflow/lab-airflow-conn-py/README",
              "title": "Airflow connection using Python",
              "description": "Set Airflow connection using Python",
              "source": "@site/docs/06-orchestration/airflow/lab-airflow-conn-py/README.md",
              "sourceDirName": "06-orchestration/airflow/lab-airflow-conn-py",
              "slug": "/orchestration/airflow/lab-airflow-conn-py/",
              "permalink": "/docs/orchestration/airflow/lab-airflow-conn-py/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/lab-airflow-email-notifications/README",
              "id": "orchestration/airflow/lab-airflow-email-notifications/README",
              "title": "Airflow Email Notifications",
              "description": "1. Create AWS SES Identity with Email here.",
              "source": "@site/docs/06-orchestration/airflow/lab-airflow-email-notifications/README.md",
              "sourceDirName": "06-orchestration/airflow/lab-airflow-email-notifications",
              "slug": "/orchestration/airflow/lab-airflow-email-notifications/",
              "permalink": "/docs/orchestration/airflow/lab-airflow-email-notifications/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/lab-airflow-getting-started/README",
              "id": "orchestration/airflow/lab-airflow-getting-started/README",
              "title": "Getting Started with Airflow",
              "description": "In this lab, we will learn the followings:",
              "source": "@site/docs/06-orchestration/airflow/lab-airflow-getting-started/README.md",
              "sourceDirName": "06-orchestration/airflow/lab-airflow-getting-started",
              "slug": "/orchestration/airflow/lab-airflow-getting-started/",
              "permalink": "/docs/orchestration/airflow/lab-airflow-getting-started/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/lab-bike-sharing-service-pipeline/README",
              "id": "orchestration/airflow/lab-bike-sharing-service-pipeline/README",
              "title": "Bike Sharing Service Data Pipeline",
              "description": "This lab will be divided into five different DAG levels. Each DAG level will have specific learning objectives, as follows:",
              "source": "@site/docs/06-orchestration/airflow/lab-bike-sharing-service-pipeline/README.md",
              "sourceDirName": "06-orchestration/airflow/lab-bike-sharing-service-pipeline",
              "slug": "/orchestration/airflow/lab-bike-sharing-service-pipeline/",
              "permalink": "/docs/orchestration/airflow/lab-bike-sharing-service-pipeline/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/lab-forex-etl/README",
              "id": "orchestration/airflow/lab-forex-etl/README",
              "title": "Airflow Forex ETL",
              "description": "The ETL process will extract data from fixer.io API, transform it, and load it to a PostgreSQL database. This project aims to have an automated process that constantly feeds the PostgreSQL database with data.",
              "source": "@site/docs/06-orchestration/airflow/lab-forex-etl/README.md",
              "sourceDirName": "06-orchestration/airflow/lab-forex-etl",
              "slug": "/orchestration/airflow/lab-forex-etl/",
              "permalink": "/docs/orchestration/airflow/lab-forex-etl/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/lab-imdb-spark-etl/README",
              "id": "orchestration/airflow/lab-imdb-spark-etl/README",
              "title": "IMDB data procesing and Airflow pipeline",
              "description": "Objective",
              "source": "@site/docs/06-orchestration/airflow/lab-imdb-spark-etl/README.md",
              "sourceDirName": "06-orchestration/airflow/lab-imdb-spark-etl",
              "slug": "/orchestration/airflow/lab-imdb-spark-etl/",
              "permalink": "/docs/orchestration/airflow/lab-imdb-spark-etl/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/lab-tolldata/README",
              "id": "orchestration/airflow/lab-tolldata/README",
              "title": "Creating ETL Data Pipelines using Apache Airflow",
              "description": "Objective",
              "source": "@site/docs/06-orchestration/airflow/lab-tolldata/README.md",
              "sourceDirName": "06-orchestration/airflow/lab-tolldata",
              "slug": "/orchestration/airflow/lab-tolldata/",
              "permalink": "/docs/orchestration/airflow/lab-tolldata/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/labdev-spotify/README",
              "id": "orchestration/airflow/labdev-spotify/README",
              "title": "Spotify-Data-Engineering-and-Analysis",
              "description": "Data Engineering and Analysis using Spotify API to get statistical insights about played music",
              "source": "@site/docs/06-orchestration/airflow/labdev-spotify/README.md",
              "sourceDirName": "06-orchestration/airflow/labdev-spotify",
              "slug": "/orchestration/airflow/labdev-spotify/",
              "permalink": "/docs/orchestration/airflow/labdev-spotify/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/airflow/README",
              "id": "orchestration/airflow/README",
              "title": "Airflow",
              "description": "Apache Airflow is an open source tool for programmatically authoring, scheduling, and monitoring data pipelines. It has over 9 million downloads per month and an active OSS community. Airflow allows data practitioners to define their data pipelines as Python code in a highly extensible and infinitely scalable way.",
              "source": "@site/docs/06-orchestration/airflow/README.md",
              "sourceDirName": "06-orchestration/airflow",
              "slug": "/orchestration/airflow/",
              "permalink": "/docs/orchestration/airflow/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Faker",
                "permalink": "/docs/extraction/faker/lab-generate-data-with-faker/"
              },
              "next": {
                "title": "Azure Data Factory",
                "permalink": "/docs/orchestration/azure-data-factory/"
              }
            },
            {
              "unversionedId": "orchestration/azure-data-factory/lab-adf-incremental-loading/README",
              "id": "orchestration/azure-data-factory/lab-adf-incremental-loading/README",
              "title": "Lab: Incremental Data Loading in Azure Data Factory",
              "description": "There are different ways in which we can design incremental loading using ADF. Based on the type of data source, we can have different techniques to implement incremental loading. Some of them are listed here:",
              "source": "@site/docs/06-orchestration/azure-data-factory/lab-adf-incremental-loading/README.md",
              "sourceDirName": "06-orchestration/azure-data-factory/lab-adf-incremental-loading",
              "slug": "/orchestration/azure-data-factory/lab-adf-incremental-loading/",
              "permalink": "/docs/orchestration/azure-data-factory/lab-adf-incremental-loading/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure Data Factory",
                "permalink": "/docs/orchestration/azure-data-factory/"
              },
              "next": {
                "title": "Lab: Azure Data Factory and Synapse Analytics",
                "permalink": "/docs/orchestration/azure-data-factory/lab-batch-processing-solution/"
              }
            },
            {
              "unversionedId": "orchestration/azure-data-factory/lab-batch-processing-solution/README",
              "id": "orchestration/azure-data-factory/lab-batch-processing-solution/README",
              "title": "Lab: Azure Data Factory and Synapse Analytics",
              "description": "Developing batch processing solutions by using Data Factory, Data Lake, Spark, Azure Synapse Pipelines, PolyBase, and Azure Databricks",
              "source": "@site/docs/06-orchestration/azure-data-factory/lab-batch-processing-solution/README.md",
              "sourceDirName": "06-orchestration/azure-data-factory/lab-batch-processing-solution",
              "slug": "/orchestration/azure-data-factory/lab-batch-processing-solution/",
              "permalink": "/docs/orchestration/azure-data-factory/lab-batch-processing-solution/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Incremental Data Loading in Azure Data Factory",
                "permalink": "/docs/orchestration/azure-data-factory/lab-adf-incremental-loading/"
              },
              "next": {
                "title": "Lab: Building Data Ingestion Pipelines Using Azure Data Factory",
                "permalink": "/docs/orchestration/azure-data-factory/lab-data-ingestion-pipeline/"
              }
            },
            {
              "unversionedId": "orchestration/azure-data-factory/lab-data-ingestion-pipeline/README",
              "id": "orchestration/azure-data-factory/lab-data-ingestion-pipeline/README",
              "title": "Lab: Building Data Ingestion Pipelines Using Azure Data Factory",
              "description": "Azure Data Factory is the bread and butter for a data engineer and understanding its fundamentals is extremely essential in building efficient pipelines. By the end of the lab, you will know how to provision a data factory account, copy data from an Azure SQL database to a data lake using copy activity, use control flow activities, move data from SQL Server to a data lake, and choose options to trigger a data factory pipeline.",
              "source": "@site/docs/06-orchestration/azure-data-factory/lab-data-ingestion-pipeline/README.md",
              "sourceDirName": "06-orchestration/azure-data-factory/lab-data-ingestion-pipeline",
              "slug": "/orchestration/azure-data-factory/lab-data-ingestion-pipeline/",
              "permalink": "/docs/orchestration/azure-data-factory/lab-data-ingestion-pipeline/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Azure Data Factory and Synapse Analytics",
                "permalink": "/docs/orchestration/azure-data-factory/lab-batch-processing-solution/"
              },
              "next": {
                "title": "Cloud Data Fusion",
                "permalink": "/docs/orchestration/datafusion/"
              }
            },
            {
              "unversionedId": "orchestration/azure-data-factory/README",
              "id": "orchestration/azure-data-factory/README",
              "title": "Azure Data Factory",
              "description": "Azure Data Factory is the data orchestration service in Azure. Using Azure Data Factory, you can build pipelines that are capable of reading data from multiple sources, transforming the data, and loading the data into data stores to be consumed by reporting applications such as Power BI. Azure Data Factory much like SQL Server Integration Services (SSIS) in an on-premises world, provides a code-free UI for developing, managing, and maintaining data engineering pipelines.",
              "source": "@site/docs/06-orchestration/azure-data-factory/README.md",
              "sourceDirName": "06-orchestration/azure-data-factory",
              "slug": "/orchestration/azure-data-factory/",
              "permalink": "/docs/orchestration/azure-data-factory/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Airflow",
                "permalink": "/docs/orchestration/airflow/"
              },
              "next": {
                "title": "Lab: Incremental Data Loading in Azure Data Factory",
                "permalink": "/docs/orchestration/azure-data-factory/lab-adf-incremental-loading/"
              }
            },
            {
              "unversionedId": "orchestration/datafusion/lab-datafusion-pipeline/README",
              "id": "orchestration/datafusion/lab-datafusion-pipeline/README",
              "title": "Lab: Building and Executing a Pipeline Graph with Data Fusion",
              "description": "Objective",
              "source": "@site/docs/06-orchestration/datafusion/lab-datafusion-pipeline/README.md",
              "sourceDirName": "06-orchestration/datafusion/lab-datafusion-pipeline",
              "slug": "/orchestration/datafusion/lab-datafusion-pipeline/",
              "permalink": "/docs/orchestration/datafusion/lab-datafusion-pipeline/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Cloud Data Fusion",
                "permalink": "/docs/orchestration/datafusion/"
              },
              "next": {
                "title": "Lab: Step Function Athena SNS",
                "permalink": "/docs/orchestration/stepfunctions/lab-stepfunction-athena-sns/"
              }
            },
            {
              "unversionedId": "orchestration/datafusion/README",
              "id": "orchestration/datafusion/README",
              "title": "Cloud Data Fusion",
              "description": "Watch this video//youtu.be/ySMexrnxfSg",
              "source": "@site/docs/06-orchestration/datafusion/README.md",
              "sourceDirName": "06-orchestration/datafusion",
              "slug": "/orchestration/datafusion/",
              "permalink": "/docs/orchestration/datafusion/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Building Data Ingestion Pipelines Using Azure Data Factory",
                "permalink": "/docs/orchestration/azure-data-factory/lab-data-ingestion-pipeline/"
              },
              "next": {
                "title": "Lab: Building and Executing a Pipeline Graph with Data Fusion",
                "permalink": "/docs/orchestration/datafusion/lab-datafusion-pipeline/"
              }
            },
            {
              "unversionedId": "orchestration/modern-data-stack/lab-analyse-stacks/README",
              "id": "orchestration/modern-data-stack/lab-analyse-stacks/README",
              "title": "Analyze and Compare the Modern Data Stacks",
              "description": "1. Go to https://www.moderndatastack.xyz/stacks and select any 5 MDS (Modern Data Stacks).",
              "source": "@site/docs/06-orchestration/modern-data-stack/lab-analyse-stacks/README.md",
              "sourceDirName": "06-orchestration/modern-data-stack/lab-analyse-stacks",
              "slug": "/orchestration/modern-data-stack/lab-analyse-stacks/",
              "permalink": "/docs/orchestration/modern-data-stack/lab-analyse-stacks/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/modern-data-stack/lab-metaflow-snowflake/README",
              "id": "orchestration/modern-data-stack/lab-metaflow-snowflake/README",
              "title": "Sequential Recommendation with the Modern Data Stack",
              "description": "As a use case, we pick a popular RecSys challenge, session-based recommendation",
              "source": "@site/docs/06-orchestration/modern-data-stack/lab-metaflow-snowflake/README.md",
              "sourceDirName": "06-orchestration/modern-data-stack/lab-metaflow-snowflake",
              "slug": "/orchestration/modern-data-stack/lab-metaflow-snowflake/",
              "permalink": "/docs/orchestration/modern-data-stack/lab-metaflow-snowflake/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/modern-data-stack/lab-terraform-gcp/README",
              "id": "orchestration/modern-data-stack/lab-terraform-gcp/README",
              "title": "Build a modern data stack",
              "description": "In this lab, we will use Terraform to deploy a modern data stack on Google Cloud (GCP).",
              "source": "@site/docs/06-orchestration/modern-data-stack/lab-terraform-gcp/README.md",
              "sourceDirName": "06-orchestration/modern-data-stack/lab-terraform-gcp",
              "slug": "/orchestration/modern-data-stack/lab-terraform-gcp/",
              "permalink": "/docs/orchestration/modern-data-stack/lab-terraform-gcp/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/modern-data-stack/README",
              "id": "orchestration/modern-data-stack/README",
              "title": "Modern Data Stack (MDS)",
              "description": "Big Data Systems with Modern Data Stack",
              "source": "@site/docs/06-orchestration/modern-data-stack/README.md",
              "sourceDirName": "06-orchestration/modern-data-stack",
              "slug": "/orchestration/modern-data-stack/",
              "permalink": "/docs/orchestration/modern-data-stack/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/nifi/README",
              "id": "orchestration/nifi/README",
              "title": "NiFi",
              "description": "Apache NiFi is a framework for building data engineering pipelines, and it utilizes DAGs. Apache NiFi was built by the National Security Agency and is used at several federal agencies. Apache NiFi is easier to set up and is useful for new data engineers. The GUI is excellent and while you can use Jython, Clojure, Scala, or Groovy to write processors, you can accomplish a lot with a simple configuration of existing processors.",
              "source": "@site/docs/06-orchestration/nifi/README.md",
              "sourceDirName": "06-orchestration/nifi",
              "slug": "/orchestration/nifi/",
              "permalink": "/docs/orchestration/nifi/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/prefect/lab-prefect-streaming/README",
              "id": "orchestration/prefect/lab-prefect-streaming/README",
              "title": "prefect-streaming",
              "description": "Example project demonstrating deployment patterns for real-time streaming workflows",
              "source": "@site/docs/06-orchestration/prefect/lab-prefect-streaming/README.md",
              "sourceDirName": "06-orchestration/prefect/lab-prefect-streaming",
              "slug": "/orchestration/prefect/lab-prefect-streaming/",
              "permalink": "/docs/orchestration/prefect/lab-prefect-streaming/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/prefect/README",
              "id": "orchestration/prefect/README",
              "title": "Prefect",
              "description": "Labs",
              "source": "@site/docs/06-orchestration/prefect/README.md",
              "sourceDirName": "06-orchestration/prefect",
              "slug": "/orchestration/prefect/",
              "permalink": "/docs/orchestration/prefect/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "orchestration/README",
              "id": "orchestration/README",
              "title": "Orchestration",
              "description": "Workflow orchestration tools are software platforms that help organizations manage and automate complex business processes across different systems and teams. These tools allow businesses to define, schedule, monitor, and manage workflows, which can help streamline operations, reduce errors, and increase productivity.",
              "source": "@site/docs/06-orchestration/README.md",
              "sourceDirName": "06-orchestration",
              "slug": "/orchestration/",
              "permalink": "/docs/orchestration/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Stream and Unified Data Processing",
                "permalink": "/docs/foundations/basics/stream-data-processing"
              },
              "next": {
                "title": "25 Most Common Interview Questions",
                "permalink": "/docs/foundations/basics/25-most-common-interview-questions"
              }
            },
            {
              "unversionedId": "orchestration/stepfunctions/lab-stepfunction-athena-sns/README",
              "id": "orchestration/stepfunctions/lab-stepfunction-athena-sns/README",
              "title": "Lab: Step Function Athena SNS",
              "description": "Objective: Execute multiple queries (Amazon Athena, Amazon SNS)",
              "source": "@site/docs/06-orchestration/stepfunctions/lab-stepfunction-athena-sns/README.md",
              "sourceDirName": "06-orchestration/stepfunctions/lab-stepfunction-athena-sns",
              "slug": "/orchestration/stepfunctions/lab-stepfunction-athena-sns/",
              "permalink": "/docs/orchestration/stepfunctions/lab-stepfunction-athena-sns/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Building and Executing a Pipeline Graph with Data Fusion",
                "permalink": "/docs/orchestration/datafusion/lab-datafusion-pipeline/"
              },
              "next": {
                "title": "Lab: Step Function Ecommerce SQL",
                "permalink": "/docs/orchestration/stepfunctions/lab-stepfunction-ecomm-sqs/"
              }
            },
            {
              "unversionedId": "orchestration/stepfunctions/lab-stepfunction-ecomm-sqs/README",
              "id": "orchestration/stepfunctions/lab-stepfunction-ecomm-sqs/README",
              "title": "Lab: Step Function Ecommerce SQL",
              "description": "Objective: Orchestrate Queue-based Microservices",
              "source": "@site/docs/06-orchestration/stepfunctions/lab-stepfunction-ecomm-sqs/README.md",
              "sourceDirName": "06-orchestration/stepfunctions/lab-stepfunction-ecomm-sqs",
              "slug": "/orchestration/stepfunctions/lab-stepfunction-ecomm-sqs/",
              "permalink": "/docs/orchestration/stepfunctions/lab-stepfunction-ecomm-sqs/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Step Function Athena SNS",
                "permalink": "/docs/orchestration/stepfunctions/lab-stepfunction-athena-sns/"
              },
              "next": {
                "title": "Flask",
                "permalink": "/docs/visualization/flask/"
              }
            },
            {
              "unversionedId": "orchestration/stepfunctions/README",
              "id": "orchestration/stepfunctions/README",
              "title": "Step Functions",
              "description": "Labs",
              "source": "@site/docs/06-orchestration/stepfunctions/README.md",
              "sourceDirName": "06-orchestration/stepfunctions",
              "slug": "/orchestration/stepfunctions/",
              "permalink": "/docs/orchestration/stepfunctions/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/apache-beam",
              "id": "processing/apache-beam",
              "title": "Apache Beam",
              "description": "What is apache beam?",
              "source": "@site/docs/03-processing/apache-beam.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/apache-beam",
              "permalink": "/docs/processing/apache-beam",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Real-Time Clickstream Anomaly Detection with Kinesis",
                "permalink": "/docs/processing/lab-kinesis-clickstream-anomaly/"
              },
              "next": {
                "title": "Lab: Apache Beam Getting Started",
                "permalink": "/docs/processing/lab-getting-started-with-beam/"
              }
            },
            {
              "unversionedId": "processing/apache-druid",
              "id": "processing/apache-druid",
              "title": "Druid",
              "description": "One database that meets all the criteria for real-time analytics application is Apache Druid. It enables subsecond performance at scale, provides high concurrency at the best value, and easily ingests and combines real-time streaming data and historical batch data. It is a high-performance, real-time analytics database that is flexible, efficient, and resilient.",
              "source": "@site/docs/03-processing/apache-druid.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/apache-druid",
              "permalink": "/docs/processing/apache-druid",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/apache-flink",
              "id": "processing/apache-flink",
              "title": "Apache Flink",
              "description": "Apache Flink is a widely used data processing engine for scalable streaming ETL, analytics, and event-driven applications. It provides precise time and state management with fault tolerance. Flink can process bounded stream (batch) and unbounded stream (stream) with a unified API or application. After data is processed with Apache Flink, downstream applications can access the curated data with a unified data catalog. With unified metadata, both data processing and data consuming applications can access the tables using the same metadata.",
              "source": "@site/docs/03-processing/apache-flink.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/apache-flink",
              "permalink": "/docs/processing/apache-flink",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Project: Building an event-driven IKEA app with Kafka",
                "permalink": "/docs/processing/project-kafka-ikea/"
              },
              "next": {
                "title": "Lab: Real-time Taxi Price Model based Prediction using Flink",
                "permalink": "/docs/processing/lab-flink-taxi-pricing/"
              }
            },
            {
              "unversionedId": "processing/apache-kafka",
              "id": "processing/apache-kafka",
              "title": "Apache Kafka",
              "description": "What is Apache Kafka?",
              "source": "@site/docs/03-processing/apache-kafka.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/apache-kafka",
              "permalink": "/docs/processing/apache-kafka",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Streaming Data Processing - Streaming Data Pipelines",
                "permalink": "/docs/processing/lab-gcp-pubsub-processing"
              },
              "next": {
                "title": "Lab: Getting started with Kafka and CLI",
                "permalink": "/docs/processing/lab-kafka-cli/"
              }
            },
            {
              "unversionedId": "processing/aws-emr",
              "id": "processing/aws-emr",
              "title": "Amazon EMR",
              "description": "EMR Serverless",
              "source": "@site/docs/03-processing/aws-emr.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/aws-emr",
              "permalink": "/docs/processing/aws-emr",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Project: Data Pipeline with Databricks PySpark and Superset",
                "permalink": "/docs/processing/databricks/project-databricks-superset/"
              },
              "next": {
                "title": "Lab: EMR Serverless",
                "permalink": "/docs/processing/lab-emr-serverless/"
              }
            },
            {
              "unversionedId": "processing/aws-kinesis",
              "id": "processing/aws-kinesis",
              "title": "Amazon Kinesis",
              "description": "Easily collect, process, and analyze video and data streams in real time",
              "source": "@site/docs/03-processing/aws-kinesis.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/aws-kinesis",
              "permalink": "/docs/processing/aws-kinesis",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Lambda CSV to Parquet",
                "permalink": "/docs/processing/lab-lambda-csv-parquet/"
              },
              "next": {
                "title": "Lab: Real Time Apache Log Analytics with Kinesis",
                "permalink": "/docs/processing/lab-kinesis-apache-logs/"
              }
            },
            {
              "unversionedId": "processing/aws-lambda",
              "id": "processing/aws-lambda",
              "title": "AWS Lambda Function",
              "description": "Lambda Function",
              "source": "@site/docs/03-processing/aws-lambda.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/aws-lambda",
              "permalink": "/docs/processing/aws-lambda",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: CSV to Parquet Transformation with Glue Studio",
                "permalink": "/docs/processing/lab-csv-to-parquet-conversion/"
              },
              "next": {
                "title": "Snippets related to Lambda function",
                "permalink": "/docs/processing/aws-lambda-snippets"
              }
            },
            {
              "unversionedId": "processing/aws-lambda-snippets",
              "id": "processing/aws-lambda-snippets",
              "title": "Snippets related to Lambda function",
              "description": "Create a CloudFormation template for creating a Lambda function that writes to an S3 bucket",
              "source": "@site/docs/03-processing/aws-lambda-snippets.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/aws-lambda-snippets",
              "permalink": "/docs/processing/aws-lambda-snippets",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "AWS Lambda Function",
                "permalink": "/docs/processing/aws-lambda"
              },
              "next": {
                "title": "Lab: Lambda CSV to Parquet",
                "permalink": "/docs/processing/lab-lambda-csv-parquet/"
              }
            },
            {
              "unversionedId": "processing/azure-synapse-analytics",
              "id": "processing/azure-synapse-analytics",
              "title": "Azure Synapse Analytics",
              "description": "Azure Synapse Analytics workspaces generation 2, formally released in December 2020, is the industry-leading big data solution for processing and consolidating data of business value. Azure Synapse Analytics has three important components:",
              "source": "@site/docs/03-processing/azure-synapse-analytics.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/azure-synapse-analytics",
              "permalink": "/docs/processing/azure-synapse-analytics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Simple Data Pipeline with HDInsight",
                "permalink": "/docs/processing/lab-azure-hdinsight-simple-data-processing/"
              },
              "next": {
                "title": "Lab: Transforming Data Using Azure Synapse Dataflows",
                "permalink": "/docs/processing/lab-azure-synapse-dataflows/"
              }
            },
            {
              "unversionedId": "processing/databricks/boston-crime-analysis/README",
              "id": "processing/databricks/boston-crime-analysis/README",
              "title": "Boston Crime Analysis",
              "description": "Perform data cleansing, transformation and load 300,000+ records in a PySpark dataframe using PySpark and process the resultant data to CSV, reducing data redundancy by 15% and improving data accuracy by 90%",
              "source": "@site/docs/03-processing/databricks/boston-crime-analysis/README.md",
              "sourceDirName": "03-processing/databricks/boston-crime-analysis",
              "slug": "/processing/databricks/boston-crime-analysis/",
              "permalink": "/docs/processing/databricks/boston-crime-analysis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/databricks/lab-cybersecurity-databricks/README",
              "id": "processing/databricks/lab-cybersecurity-databricks/README",
              "title": "Lab: Cybersecurity Databricks",
              "description": "Objective",
              "source": "@site/docs/03-processing/databricks/lab-cybersecurity-databricks/README.md",
              "sourceDirName": "03-processing/databricks/lab-cybersecurity-databricks",
              "slug": "/processing/databricks/lab-cybersecurity-databricks/",
              "permalink": "/docs/processing/databricks/lab-cybersecurity-databricks/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Databricks",
                "permalink": "/docs/processing/databricks/"
              },
              "next": {
                "title": "Lab: Databricks Clickstream Analysis",
                "permalink": "/docs/processing/databricks/lab-databricks-clickstream/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-data-processing-azure-dbr/README",
              "id": "processing/databricks/lab-data-processing-azure-dbr/README",
              "title": "Lab: Processing Data Using Azure Databricks",
              "description": "Files",
              "source": "@site/docs/03-processing/databricks/lab-data-processing-azure-dbr/README.md",
              "sourceDirName": "03-processing/databricks/lab-data-processing-azure-dbr",
              "slug": "/processing/databricks/lab-data-processing-azure-dbr/",
              "permalink": "/docs/processing/databricks/lab-data-processing-azure-dbr/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Real-Time Point-of-Sale Analytics With the Data Lakehouse",
                "permalink": "/docs/processing/databricks/lab-retail-pos-databricks/"
              },
              "next": {
                "title": "Project: Data Engineering with Databricks",
                "permalink": "/docs/processing/databricks/project-databricks-de/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-databricks-clickstream/README",
              "id": "processing/databricks/lab-databricks-clickstream/README",
              "title": "Lab: Databricks Clickstream Analysis",
              "description": "Objective",
              "source": "@site/docs/03-processing/databricks/lab-databricks-clickstream/README.md",
              "sourceDirName": "03-processing/databricks/lab-databricks-clickstream",
              "slug": "/processing/databricks/lab-databricks-clickstream/",
              "permalink": "/docs/processing/databricks/lab-databricks-clickstream/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Cybersecurity Databricks",
                "permalink": "/docs/processing/databricks/lab-cybersecurity-databricks/"
              },
              "next": {
                "title": "Lab: Databricks Deltalake",
                "permalink": "/docs/processing/databricks/lab-databricks-deltalake/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-databricks-deltalake/README",
              "id": "processing/databricks/lab-databricks-deltalake/README",
              "title": "Lab: Databricks Deltalake",
              "description": "Objective: Creation of an elementary Data Lakehouse using Databricks and the Delta lake technology",
              "source": "@site/docs/03-processing/databricks/lab-databricks-deltalake/README.md",
              "sourceDirName": "03-processing/databricks/lab-databricks-deltalake",
              "slug": "/processing/databricks/lab-databricks-deltalake/",
              "permalink": "/docs/processing/databricks/lab-databricks-deltalake/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Databricks Clickstream Analysis",
                "permalink": "/docs/processing/databricks/lab-databricks-clickstream/"
              },
              "next": {
                "title": "Lab: Delta Lake Optimizations",
                "permalink": "/docs/processing/databricks/lab-deltalake-optimizations/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-databricks-pyspark-s3/index",
              "id": "processing/databricks/lab-databricks-pyspark-s3/index",
              "title": "Lab: Connect AWS to PySpark and build an ETL pipeline",
              "description": "Github",
              "source": "@site/docs/03-processing/databricks/lab-databricks-pyspark-s3/index.md",
              "sourceDirName": "03-processing/databricks/lab-databricks-pyspark-s3",
              "slug": "/processing/databricks/lab-databricks-pyspark-s3/",
              "permalink": "/docs/processing/databricks/lab-databricks-pyspark-s3/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Pyspark Basics",
                "permalink": "/docs/foundations/language/pyspark/lab-pyspark-basics/"
              },
              "next": {
                "title": "Lab: Spark Optimizations",
                "permalink": "/docs/foundations/language/pyspark/lab-spark-optimizations-2/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-databricks-scala-postgres-s3/README",
              "id": "processing/databricks/lab-databricks-scala-postgres-s3/README",
              "title": "Lab: S3 Postgres Scala",
              "description": "Objective",
              "source": "@site/docs/03-processing/databricks/lab-databricks-scala-postgres-s3/README.md",
              "sourceDirName": "03-processing/databricks/lab-databricks-scala-postgres-s3",
              "slug": "/processing/databricks/lab-databricks-scala-postgres-s3/",
              "permalink": "/docs/processing/databricks/lab-databricks-scala-postgres-s3/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: BCG Case Study",
                "permalink": "/docs/foundations/language/pyspark/lab-bcg/"
              },
              "next": {
                "title": "Calculating Spark Partitions",
                "permalink": "/docs/foundations/language/pyspark/lab-calculating-partitions/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-deltalake-optimizations/README",
              "id": "processing/databricks/lab-deltalake-optimizations/README",
              "title": "Lab: Delta Lake Optimizations",
              "description": "In this lab, we will learn about various Delta Lake optimizations that help us build a more performant Lakehouse.",
              "source": "@site/docs/03-processing/databricks/lab-deltalake-optimizations/README.md",
              "sourceDirName": "03-processing/databricks/lab-deltalake-optimizations",
              "slug": "/processing/databricks/lab-deltalake-optimizations/",
              "permalink": "/docs/processing/databricks/lab-deltalake-optimizations/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Databricks Deltalake",
                "permalink": "/docs/processing/databricks/lab-databricks-deltalake/"
              },
              "next": {
                "title": "Lab: dlt vs dbt",
                "permalink": "/docs/processing/databricks/lab-dlt-dbt/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-dlt-dbt/README",
              "id": "processing/databricks/lab-dlt-dbt/README",
              "title": "Lab: dlt vs dbt",
              "description": "Objective",
              "source": "@site/docs/03-processing/databricks/lab-dlt-dbt/README.md",
              "sourceDirName": "03-processing/databricks/lab-dlt-dbt",
              "slug": "/processing/databricks/lab-dlt-dbt/",
              "permalink": "/docs/processing/databricks/lab-dlt-dbt/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Delta Lake Optimizations",
                "permalink": "/docs/processing/databricks/lab-deltalake-optimizations/"
              },
              "next": {
                "title": "Lab: Healthcare Lakehouse",
                "permalink": "/docs/processing/databricks/lab-healthcare-databricks/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-healthcare-databricks/README",
              "id": "processing/databricks/lab-healthcare-databricks/README",
              "title": "Lab: Healthcare Lakehouse",
              "description": "Unlocking the Power of Health Data With a Modern Data Lakehouse",
              "source": "@site/docs/03-processing/databricks/lab-healthcare-databricks/README.md",
              "sourceDirName": "03-processing/databricks/lab-healthcare-databricks",
              "slug": "/processing/databricks/lab-healthcare-databricks/",
              "permalink": "/docs/processing/databricks/lab-healthcare-databricks/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: dlt vs dbt",
                "permalink": "/docs/processing/databricks/lab-dlt-dbt/"
              },
              "next": {
                "title": "Lab: Real-time Health Tracking and Monitoring System",
                "permalink": "/docs/processing/databricks/lab-iot-health-tracker/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-iot-health-tracker/README",
              "id": "processing/databricks/lab-iot-health-tracker/README",
              "title": "Lab: Real-time Health Tracking and Monitoring System",
              "description": "What you'll build",
              "source": "@site/docs/03-processing/databricks/lab-iot-health-tracker/README.md",
              "sourceDirName": "03-processing/databricks/lab-iot-health-tracker",
              "slug": "/processing/databricks/lab-iot-health-tracker/",
              "permalink": "/docs/processing/databricks/lab-iot-health-tracker/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Healthcare Lakehouse",
                "permalink": "/docs/processing/databricks/lab-healthcare-databricks/"
              },
              "next": {
                "title": "Lab: Simplifying Data Engineering and Analytics with Delta",
                "permalink": "/docs/processing/databricks/lab-loan-application/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-loan-application/README",
              "id": "processing/databricks/lab-loan-application/README",
              "title": "Lab: Simplifying Data Engineering and Analytics with Delta",
              "description": "Objective",
              "source": "@site/docs/03-processing/databricks/lab-loan-application/README.md",
              "sourceDirName": "03-processing/databricks/lab-loan-application",
              "slug": "/processing/databricks/lab-loan-application/",
              "permalink": "/docs/processing/databricks/lab-loan-application/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Real-time Health Tracking and Monitoring System",
                "permalink": "/docs/processing/databricks/lab-iot-health-tracker/"
              },
              "next": {
                "title": "Lab: Real-Time Point-of-Sale Analytics With the Data Lakehouse",
                "permalink": "/docs/processing/databricks/lab-retail-pos-databricks/"
              }
            },
            {
              "unversionedId": "processing/databricks/lab-pyspark-itversity/README",
              "id": "processing/databricks/lab-pyspark-itversity/README",
              "title": "Pyspark Itversity - Hadoop and Spark Hands-on Practical Exercises",
              "description": "References",
              "source": "@site/docs/03-processing/databricks/lab-pyspark-itversity/README.md",
              "sourceDirName": "03-processing/databricks/lab-pyspark-itversity",
              "slug": "/processing/databricks/lab-pyspark-itversity/",
              "permalink": "/docs/processing/databricks/lab-pyspark-itversity/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/databricks/lab-retail-pos-databricks/README",
              "id": "processing/databricks/lab-retail-pos-databricks/README",
              "title": "Lab: Real-Time Point-of-Sale Analytics With the Data Lakehouse",
              "description": "Introduction",
              "source": "@site/docs/03-processing/databricks/lab-retail-pos-databricks/README.md",
              "sourceDirName": "03-processing/databricks/lab-retail-pos-databricks",
              "slug": "/processing/databricks/lab-retail-pos-databricks/",
              "permalink": "/docs/processing/databricks/lab-retail-pos-databricks/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Simplifying Data Engineering and Analytics with Delta",
                "permalink": "/docs/processing/databricks/lab-loan-application/"
              },
              "next": {
                "title": "Lab: Processing Data Using Azure Databricks",
                "permalink": "/docs/processing/databricks/lab-data-processing-azure-dbr/"
              }
            },
            {
              "unversionedId": "processing/databricks/project-advancedbricks/README",
              "id": "processing/databricks/project-advancedbricks/README",
              "title": "Project: AdvancedBricks",
              "description": "Advanced Data Engineering with Databricks",
              "source": "@site/docs/03-processing/databricks/project-advancedbricks/README.md",
              "sourceDirName": "03-processing/databricks/project-advancedbricks",
              "slug": "/processing/databricks/project-advancedbricks/",
              "permalink": "/docs/processing/databricks/project-advancedbricks/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Project: Data Engineer Learner Path with Databricks",
                "permalink": "/docs/processing/databricks/project-learnerbricks/"
              },
              "next": {
                "title": "Project: BedBricks",
                "permalink": "/docs/processing/databricks/project-bedbricks/"
              }
            },
            {
              "unversionedId": "processing/databricks/project-bedbricks/README",
              "id": "processing/databricks/project-bedbricks/README",
              "title": "Project: BedBricks",
              "description": "Databricks PySpark Ecommerce Data Processing Case Study",
              "source": "@site/docs/03-processing/databricks/project-bedbricks/README.md",
              "sourceDirName": "03-processing/databricks/project-bedbricks",
              "slug": "/processing/databricks/project-bedbricks/",
              "permalink": "/docs/processing/databricks/project-bedbricks/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Project: AdvancedBricks",
                "permalink": "/docs/processing/databricks/project-advancedbricks/"
              },
              "next": {
                "title": "Project: Data Pipeline with Databricks PySpark and Superset",
                "permalink": "/docs/processing/databricks/project-databricks-superset/"
              }
            },
            {
              "unversionedId": "processing/databricks/project-databricks-de/README",
              "id": "processing/databricks/project-databricks-de/README",
              "title": "Project: Data Engineering with Databricks",
              "description": "Github",
              "source": "@site/docs/03-processing/databricks/project-databricks-de/README.md",
              "sourceDirName": "03-processing/databricks/project-databricks-de",
              "slug": "/processing/databricks/project-databricks-de/",
              "permalink": "/docs/processing/databricks/project-databricks-de/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Processing Data Using Azure Databricks",
                "permalink": "/docs/processing/databricks/lab-data-processing-azure-dbr/"
              },
              "next": {
                "title": "Project: Data Engineer Learner Path with Databricks",
                "permalink": "/docs/processing/databricks/project-learnerbricks/"
              }
            },
            {
              "unversionedId": "processing/databricks/project-databricks-superset/README",
              "id": "processing/databricks/project-databricks-superset/README",
              "title": "Project: Data Pipeline with Databricks PySpark and Superset",
              "description": "Put on your data engineer hat! In this project, you’ll build a modern, cloud-based, three-layer data Lakehouse. First, you’ll set up your workspace on the Databricks platform, leveraging important Databricks features, before pushing the data into the first two layers of the data lake. Next, using Apache Spark, you’ll build the third layer, used to serve insights to different end-users. Then, you’ll use Delta Lake to turn your existing data lake into a Lakehouse. Finally, you’ll deliver an infrastructure that allows your end-users to perform specific queries, using Apache Superset, and build dashboards on top of the existing data. When you’re done with the projects in this series, you’ll have a complete big data pipeline for a cloud-based data lake—and you’ll understand why the three-layer architecture is so popular.",
              "source": "@site/docs/03-processing/databricks/project-databricks-superset/README.md",
              "sourceDirName": "03-processing/databricks/project-databricks-superset",
              "slug": "/processing/databricks/project-databricks-superset/",
              "permalink": "/docs/processing/databricks/project-databricks-superset/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Project: BedBricks",
                "permalink": "/docs/processing/databricks/project-bedbricks/"
              },
              "next": {
                "title": "Amazon EMR",
                "permalink": "/docs/processing/aws-emr"
              }
            },
            {
              "unversionedId": "processing/databricks/project-learnerbricks/README",
              "id": "processing/databricks/project-learnerbricks/README",
              "title": "Project: Data Engineer Learner Path with Databricks",
              "description": "The Data Engineering with Databricks (DEWD) course is designed to prepare students for the Databricks Certified Associate Data Engineer certification exam. The content for this course consists of the Associate-level modules of the Data Engineer Learning Path, and can be delivered as an instructor-led training (ILT) or self-paced (SP) course.",
              "source": "@site/docs/03-processing/databricks/project-learnerbricks/README.md",
              "sourceDirName": "03-processing/databricks/project-learnerbricks",
              "slug": "/processing/databricks/project-learnerbricks/",
              "permalink": "/docs/processing/databricks/project-learnerbricks/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Project: Data Engineering with Databricks",
                "permalink": "/docs/processing/databricks/project-databricks-de/"
              },
              "next": {
                "title": "Project: AdvancedBricks",
                "permalink": "/docs/processing/databricks/project-advancedbricks/"
              }
            },
            {
              "unversionedId": "processing/databricks/README",
              "id": "processing/databricks/README",
              "title": "Databricks",
              "description": "Databricks is a platform that enables enterprises to quickly build their Data Lakehouse infrastructure and enable all data personas – data engineers, data scientists, and business intelligence personnel – in their organization to extract and deliver insights from the data. The platform provides a curated experience for each data persona, enabling them to execute their daily workflows. The foundational technologies that enable these experiences are open source – Apache Spark, Delta lake, MLflow, and more.",
              "source": "@site/docs/03-processing/databricks/README.md",
              "sourceDirName": "03-processing/databricks",
              "slug": "/processing/databricks/",
              "permalink": "/docs/processing/databricks/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Messflix (hypothetical)",
                "permalink": "/docs/storage/casestudy-messflix-hypothetical"
              },
              "next": {
                "title": "Lab: Cybersecurity Databricks",
                "permalink": "/docs/processing/databricks/lab-cybersecurity-databricks/"
              }
            },
            {
              "unversionedId": "processing/databricks/setup",
              "id": "processing/databricks/setup",
              "title": "Setup Databricks",
              "description": "Watch and follow this video.",
              "source": "@site/docs/03-processing/databricks/setup.md",
              "sourceDirName": "03-processing/databricks",
              "slug": "/processing/databricks/setup",
              "permalink": "/docs/processing/databricks/setup",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/dbt",
              "id": "processing/dbt",
              "title": "dbt",
              "description": "Transform your data in warehouse",
              "source": "@site/docs/03-processing/dbt.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/dbt",
              "permalink": "/docs/processing/dbt",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Flink Kafka Source",
                "permalink": "/docs/processing/lab-flink-kafka-source/"
              },
              "next": {
                "title": "Lab: Building an ELT pipeline for a cab service company using dbt and Postgres",
                "permalink": "/docs/processing/lab-dbt-nyctaxi/"
              }
            },
            {
              "unversionedId": "processing/gcp-dataproc",
              "id": "processing/gcp-dataproc",
              "title": "Dataproc",
              "description": "Running Hadoop on Dataproc",
              "source": "@site/docs/03-processing/gcp-dataproc.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/gcp-dataproc",
              "permalink": "/docs/processing/gcp-dataproc",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Ray AIR Basics",
                "permalink": "/docs/processing/lab-ray-air-basics/"
              },
              "next": {
                "title": "Lab: Running Apache Spark jobs on Cloud Dataproc",
                "permalink": "/docs/processing/lab-gcp-dataproc/"
              }
            },
            {
              "unversionedId": "processing/gcp-pubsub",
              "id": "processing/gcp-pubsub",
              "title": "Pub/Sub",
              "description": "Introduction to Pub/Sub",
              "source": "@site/docs/03-processing/gcp-pubsub.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/gcp-pubsub",
              "permalink": "/docs/processing/gcp-pubsub",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: GCP Dataprep",
                "permalink": "/docs/processing/lab-gcp-dataprep"
              },
              "next": {
                "title": "Lab: Streaming Data Processing - Publish Streaming Data into PubSub",
                "permalink": "/docs/processing/lab-gcp-pubsub"
              }
            },
            {
              "unversionedId": "processing/lab-azure-hdinsight-simple-data-processing/README",
              "id": "processing/lab-azure-hdinsight-simple-data-processing/README",
              "title": "Lab: Simple Data Pipeline with HDInsight",
              "description": "Pre-requisites",
              "source": "@site/docs/03-processing/lab-azure-hdinsight-simple-data-processing/README.md",
              "sourceDirName": "03-processing/lab-azure-hdinsight-simple-data-processing",
              "slug": "/processing/lab-azure-hdinsight-simple-data-processing/",
              "permalink": "/docs/processing/lab-azure-hdinsight-simple-data-processing/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Running Apache Spark jobs on Cloud Dataproc",
                "permalink": "/docs/processing/lab-gcp-dataproc/"
              },
              "next": {
                "title": "Azure Synapse Analytics",
                "permalink": "/docs/processing/azure-synapse-analytics"
              }
            },
            {
              "unversionedId": "processing/lab-azure-synapse-data-processing/README",
              "id": "processing/lab-azure-synapse-data-processing/README",
              "title": "Lab: Processing Data Using Azure Synapse Analytics",
              "description": "This lab covers exploring data using Synapse Serverless SQL pool, processing data using Synapse Spark Pools, Working with Synapse Lake database, and integrating Synapse Analytics with Power BI",
              "source": "@site/docs/03-processing/lab-azure-synapse-data-processing/README.md",
              "sourceDirName": "03-processing/lab-azure-synapse-data-processing",
              "slug": "/processing/lab-azure-synapse-data-processing/",
              "permalink": "/docs/processing/lab-azure-synapse-data-processing/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Transforming Data Using Azure Synapse Dataflows",
                "permalink": "/docs/processing/lab-azure-synapse-dataflows/"
              },
              "next": {
                "title": "Lab: Implementing the Serving Layer Star Schema",
                "permalink": "/docs/processing/lab-azure-synapse-implementing-star-schema/"
              }
            },
            {
              "unversionedId": "processing/lab-azure-synapse-dataflows/README",
              "id": "processing/lab-azure-synapse-dataflows/README",
              "title": "Lab: Transforming Data Using Azure Synapse Dataflows",
              "description": "This lab focuses on performing transformations using Synapse Dataflows, optimizing data flows using partitioning, and managing dynamic source schema changes using schema drifting",
              "source": "@site/docs/03-processing/lab-azure-synapse-dataflows/README.md",
              "sourceDirName": "03-processing/lab-azure-synapse-dataflows",
              "slug": "/processing/lab-azure-synapse-dataflows/",
              "permalink": "/docs/processing/lab-azure-synapse-dataflows/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure Synapse Analytics",
                "permalink": "/docs/processing/azure-synapse-analytics"
              },
              "next": {
                "title": "Lab: Processing Data Using Azure Synapse Analytics",
                "permalink": "/docs/processing/lab-azure-synapse-data-processing/"
              }
            },
            {
              "unversionedId": "processing/lab-azure-synapse-implementing-star-schema/README",
              "id": "processing/lab-azure-synapse-implementing-star-schema/README",
              "title": "Lab: Implementing the Serving Layer Star Schema",
              "description": "In this lab, we will learn about implementing the serving layer, which involves implementing star schemas, techniques to read and write different data formats, sharing data between services such as SQL and Spark, and more. Once you complete this lab, you should be able to understand the differences between a Synapse dedicated SQL pool versus traditional SQL systems for implementing the Star schema, the various ways of accessing Parquet data using technologies such as Spark and SQL, and the details involved in storing metadata across services. All this knowledge should help you build a practical and maintainable serving layer in a data lake.",
              "source": "@site/docs/03-processing/lab-azure-synapse-implementing-star-schema/README.md",
              "sourceDirName": "03-processing/lab-azure-synapse-implementing-star-schema",
              "slug": "/processing/lab-azure-synapse-implementing-star-schema/",
              "permalink": "/docs/processing/lab-azure-synapse-implementing-star-schema/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Processing Data Using Azure Synapse Analytics",
                "permalink": "/docs/processing/lab-azure-synapse-data-processing/"
              },
              "next": {
                "title": "Lab: GCP Dataprep",
                "permalink": "/docs/processing/lab-gcp-dataprep"
              }
            },
            {
              "unversionedId": "processing/lab-confluent-kafka-faker/README",
              "id": "processing/lab-confluent-kafka-faker/README",
              "title": "Lab: Kafka and CDC",
              "description": "Real-time CDC-enabled Extract and Load Pipeline with Kafka on Cloud",
              "source": "@site/docs/03-processing/lab-confluent-kafka-faker/README.md",
              "sourceDirName": "03-processing/lab-confluent-kafka-faker",
              "slug": "/processing/lab-confluent-kafka-faker/",
              "permalink": "/docs/processing/lab-confluent-kafka-faker/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Confluent Kafka with Python",
                "permalink": "/docs/processing/lab-confluent-python/"
              },
              "next": {
                "title": "Lab: Real-time fraud detection by applying filter in Kafka topic",
                "permalink": "/docs/processing/lab-kafka-fraud-detection/"
              }
            },
            {
              "unversionedId": "processing/lab-confluent-python/README",
              "id": "processing/lab-confluent-python/README",
              "title": "Lab: Confluent Kafka with Python",
              "description": "Produce messages to and consume messages from a Kafka cluster using Confluent Python Client for Apache Kafka.",
              "source": "@site/docs/03-processing/lab-confluent-python/README.md",
              "sourceDirName": "03-processing/lab-confluent-python",
              "slug": "/processing/lab-confluent-python/",
              "permalink": "/docs/processing/lab-confluent-python/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Getting started with Kafka and Python",
                "permalink": "/docs/processing/lab-kafka-python/"
              },
              "next": {
                "title": "Lab: Kafka and CDC",
                "permalink": "/docs/processing/lab-confluent-kafka-faker/"
              }
            },
            {
              "unversionedId": "processing/lab-csv-to-parquet-conversion/README",
              "id": "processing/lab-csv-to-parquet-conversion/README",
              "title": "Lab: CSV to Parquet Transformation with Glue Studio",
              "description": "Task: Process raw (CSV or JSON) data from the Landing S3 bucket and save it into another S3 bucket in a Columnar format with partitioning",
              "source": "@site/docs/03-processing/lab-csv-to-parquet-conversion/README.md",
              "sourceDirName": "03-processing/lab-csv-to-parquet-conversion",
              "slug": "/processing/lab-csv-to-parquet-conversion/",
              "permalink": "/docs/processing/lab-csv-to-parquet-conversion/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Tickets ETL with Glue Studio",
                "permalink": "/docs/processing/lab-glue-studio-tickets/"
              },
              "next": {
                "title": "AWS Lambda Function",
                "permalink": "/docs/processing/aws-lambda"
              }
            },
            {
              "unversionedId": "processing/lab-dataflow-bigquery-etl",
              "id": "processing/lab-dataflow-bigquery-etl",
              "title": "Lab: ETL Processing on Google Cloud Using Dataflow and BigQuery",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-dataflow-bigquery-etl.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-dataflow-bigquery-etl",
              "permalink": "/docs/processing/lab-dataflow-bigquery-etl",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: GCP Serverless Dataflow",
                "permalink": "/docs/processing/lab-gcp-serverless-dataflow"
              },
              "next": {
                "title": "Ray",
                "permalink": "/docs/processing/ray"
              }
            },
            {
              "unversionedId": "processing/lab-dbt-jaffle-shop/models/docs",
              "id": "processing/lab-dbt-jaffle-shop/models/docs",
              "title": "docs",
              "description": "{% docs orders_status %}",
              "source": "@site/docs/03-processing/lab-dbt-jaffle-shop/models/docs.md",
              "sourceDirName": "03-processing/lab-dbt-jaffle-shop/models",
              "slug": "/processing/lab-dbt-jaffle-shop/models/docs",
              "permalink": "/docs/processing/lab-dbt-jaffle-shop/models/docs",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/lab-dbt-jaffle-shop/models/overview",
              "id": "processing/lab-dbt-jaffle-shop/models/overview",
              "title": "overview",
              "description": "{% docs overview %}",
              "source": "@site/docs/03-processing/lab-dbt-jaffle-shop/models/overview.md",
              "sourceDirName": "03-processing/lab-dbt-jaffle-shop/models",
              "slug": "/processing/lab-dbt-jaffle-shop/models/overview",
              "permalink": "/docs/processing/lab-dbt-jaffle-shop/models/overview",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/lab-dbt-jaffle-shop/README",
              "id": "processing/lab-dbt-jaffle-shop/README",
              "title": "Lab: dbt Postgres on Jaffle Shop data",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-dbt-jaffle-shop/README.md",
              "sourceDirName": "03-processing/lab-dbt-jaffle-shop",
              "slug": "/processing/lab-dbt-jaffle-shop/",
              "permalink": "/docs/processing/lab-dbt-jaffle-shop/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Building an ELT pipeline for a cab service company using dbt and Postgres",
                "permalink": "/docs/processing/lab-dbt-nyctaxi/"
              },
              "next": {
                "title": "Lab: dbt Snowflake on Knoema data",
                "permalink": "/docs/processing/lab-dbt-knoema/"
              }
            },
            {
              "unversionedId": "processing/lab-dbt-knoema/README",
              "id": "processing/lab-dbt-knoema/README",
              "title": "Lab: dbt Snowflake on Knoema data",
              "description": "In this lab, we are going to analyze historical trading performance of a company that has trading desks spread across different regions. As inputs, we are going to leverage datasets available in Knoema Economy Data Atlas that is available in Snowflake Data Marketplace, plus few manual uploads.",
              "source": "@site/docs/03-processing/lab-dbt-knoema/README.md",
              "sourceDirName": "03-processing/lab-dbt-knoema",
              "slug": "/processing/lab-dbt-knoema/",
              "permalink": "/docs/processing/lab-dbt-knoema/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: dbt Postgres on Jaffle Shop data",
                "permalink": "/docs/processing/lab-dbt-jaffle-shop/"
              },
              "next": {
                "title": "Lab: dbt Postgres on Olist Retail data",
                "permalink": "/docs/processing/lab-dbt-olist/"
              }
            },
            {
              "unversionedId": "processing/lab-dbt-nyctaxi-lookup/README",
              "id": "processing/lab-dbt-nyctaxi-lookup/README",
              "title": "NYC Taxi Analtics and ELT Pipeline with dbt and Postgres",
              "description": "Lineage Graph",
              "source": "@site/docs/03-processing/lab-dbt-nyctaxi-lookup/README.md",
              "sourceDirName": "03-processing/lab-dbt-nyctaxi-lookup",
              "slug": "/processing/lab-dbt-nyctaxi-lookup/",
              "permalink": "/docs/processing/lab-dbt-nyctaxi-lookup/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/lab-dbt-nyctaxi/README",
              "id": "processing/lab-dbt-nyctaxi/README",
              "title": "Lab: Building an ELT pipeline for a cab service company using dbt and Postgres",
              "description": "Architecture",
              "source": "@site/docs/03-processing/lab-dbt-nyctaxi/README.md",
              "sourceDirName": "03-processing/lab-dbt-nyctaxi",
              "slug": "/processing/lab-dbt-nyctaxi/",
              "permalink": "/docs/processing/lab-dbt-nyctaxi/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "dbt",
                "permalink": "/docs/processing/dbt"
              },
              "next": {
                "title": "Lab: dbt Postgres on Jaffle Shop data",
                "permalink": "/docs/processing/lab-dbt-jaffle-shop/"
              }
            },
            {
              "unversionedId": "processing/lab-dbt-olist/models/staging/olist/stg_ecommerce",
              "id": "processing/lab-dbt-olist/models/staging/olist/stg_ecommerce",
              "title": "stg_ecommerce",
              "description": "{% docs segment_info %}",
              "source": "@site/docs/03-processing/lab-dbt-olist/models/staging/olist/stg_ecommerce.md",
              "sourceDirName": "03-processing/lab-dbt-olist/models/staging/olist",
              "slug": "/processing/lab-dbt-olist/models/staging/olist/stg_ecommerce",
              "permalink": "/docs/processing/lab-dbt-olist/models/staging/olist/stg_ecommerce",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/lab-dbt-olist/README",
              "id": "processing/lab-dbt-olist/README",
              "title": "Lab: dbt Postgres on Olist Retail data",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-dbt-olist/README.md",
              "sourceDirName": "03-processing/lab-dbt-olist",
              "slug": "/processing/lab-dbt-olist/",
              "permalink": "/docs/processing/lab-dbt-olist/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: dbt Snowflake on Knoema data",
                "permalink": "/docs/processing/lab-dbt-knoema/"
              },
              "next": {
                "title": "Lab: dbt BigQuery on Stack Exchange data",
                "permalink": "/docs/processing/lab-dbt-stackexchnge/"
              }
            },
            {
              "unversionedId": "processing/lab-dbt-stackexchnge/README",
              "id": "processing/lab-dbt-stackexchnge/README",
              "title": "Lab: dbt BigQuery on Stack Exchange data",
              "description": "Extract, Load and Transform the Stack Exchange data using dbt and google bigquery warehouse.",
              "source": "@site/docs/03-processing/lab-dbt-stackexchnge/README.md",
              "sourceDirName": "03-processing/lab-dbt-stackexchnge",
              "slug": "/processing/lab-dbt-stackexchnge/",
              "permalink": "/docs/processing/lab-dbt-stackexchnge/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: dbt Postgres on Olist Retail data",
                "permalink": "/docs/processing/lab-dbt-olist/"
              },
              "next": {
                "title": "Lab: Building an ELT Pipeline with dbt and Amazon Redshift on TICKIT data",
                "permalink": "/docs/processing/lab-dbt-tickit/"
              }
            },
            {
              "unversionedId": "processing/lab-dbt-tickit/README",
              "id": "processing/lab-dbt-tickit/README",
              "title": "Lab: Building an ELT Pipeline with dbt and Amazon Redshift on TICKIT data",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-dbt-tickit/README.md",
              "sourceDirName": "03-processing/lab-dbt-tickit",
              "slug": "/processing/lab-dbt-tickit/",
              "permalink": "/docs/processing/lab-dbt-tickit/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: dbt BigQuery on Stack Exchange data",
                "permalink": "/docs/processing/lab-dbt-stackexchnge/"
              },
              "next": {
                "title": "Lab: dbt Snowflake on TPCH data",
                "permalink": "/docs/processing/lab-dbt-tpch/"
              }
            },
            {
              "unversionedId": "processing/lab-dbt-tpch/README",
              "id": "processing/lab-dbt-tpch/README",
              "title": "Lab: dbt Snowflake on TPCH data",
              "description": "Accelerating Data Teams with Snowflake and dbt Cloud Hands On Lab",
              "source": "@site/docs/03-processing/lab-dbt-tpch/README.md",
              "sourceDirName": "03-processing/lab-dbt-tpch",
              "slug": "/processing/lab-dbt-tpch/",
              "permalink": "/docs/processing/lab-dbt-tpch/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Building an ELT Pipeline with dbt and Amazon Redshift on TICKIT data",
                "permalink": "/docs/processing/lab-dbt-tickit/"
              },
              "next": {
                "title": "Snowpark",
                "permalink": "/docs/processing/snowpark"
              }
            },
            {
              "unversionedId": "processing/lab-emr-serverless/README",
              "id": "processing/lab-emr-serverless/README",
              "title": "Lab: EMR Serverless",
              "description": "Creating and submitting Word count Spark Job in EMR Serverless",
              "source": "@site/docs/03-processing/lab-emr-serverless/README.md",
              "sourceDirName": "03-processing/lab-emr-serverless",
              "slug": "/processing/lab-emr-serverless/",
              "permalink": "/docs/processing/lab-emr-serverless/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Amazon EMR",
                "permalink": "/docs/processing/aws-emr"
              },
              "next": {
                "title": "Lab: Glue ETL",
                "permalink": "/docs/processing/lab-glue-advanced/"
              }
            },
            {
              "unversionedId": "processing/lab-flink-kafka-sink/README",
              "id": "processing/lab-flink-kafka-sink/README",
              "title": "Lab: Flink Kafka Sink",
              "description": "Files",
              "source": "@site/docs/03-processing/lab-flink-kafka-sink/README.md",
              "sourceDirName": "03-processing/lab-flink-kafka-sink",
              "slug": "/processing/lab-flink-kafka-sink/",
              "permalink": "/docs/processing/lab-flink-kafka-sink/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Real-time Twitter Stream Wordcount using Flink",
                "permalink": "/docs/processing/lab-flink-twitter-stream-processing/"
              },
              "next": {
                "title": "Lab: Flink Kafka Source",
                "permalink": "/docs/processing/lab-flink-kafka-source/"
              }
            },
            {
              "unversionedId": "processing/lab-flink-kafka-source/README",
              "id": "processing/lab-flink-kafka-source/README",
              "title": "Lab: Flink Kafka Source",
              "description": "Files",
              "source": "@site/docs/03-processing/lab-flink-kafka-source/README.md",
              "sourceDirName": "03-processing/lab-flink-kafka-source",
              "slug": "/processing/lab-flink-kafka-source/",
              "permalink": "/docs/processing/lab-flink-kafka-source/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Flink Kafka Sink",
                "permalink": "/docs/processing/lab-flink-kafka-sink/"
              },
              "next": {
                "title": "dbt",
                "permalink": "/docs/processing/dbt"
              }
            },
            {
              "unversionedId": "processing/lab-flink-taxi-pricing/README",
              "id": "processing/lab-flink-taxi-pricing/README",
              "title": "Lab: Real-time Taxi Price Model based Prediction using Flink",
              "description": "Files",
              "source": "@site/docs/03-processing/lab-flink-taxi-pricing/README.md",
              "sourceDirName": "03-processing/lab-flink-taxi-pricing",
              "slug": "/processing/lab-flink-taxi-pricing/",
              "permalink": "/docs/processing/lab-flink-taxi-pricing/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache Flink",
                "permalink": "/docs/processing/apache-flink"
              },
              "next": {
                "title": "Lab: Real-time Twitter Stream Wordcount using Flink",
                "permalink": "/docs/processing/lab-flink-twitter-stream-processing/"
              }
            },
            {
              "unversionedId": "processing/lab-flink-twitter-stream-processing/README",
              "id": "processing/lab-flink-twitter-stream-processing/README",
              "title": "Lab: Real-time Twitter Stream Wordcount using Flink",
              "description": "Files",
              "source": "@site/docs/03-processing/lab-flink-twitter-stream-processing/README.md",
              "sourceDirName": "03-processing/lab-flink-twitter-stream-processing",
              "slug": "/processing/lab-flink-twitter-stream-processing/",
              "permalink": "/docs/processing/lab-flink-twitter-stream-processing/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Real-time Taxi Price Model based Prediction using Flink",
                "permalink": "/docs/processing/lab-flink-taxi-pricing/"
              },
              "next": {
                "title": "Lab: Flink Kafka Sink",
                "permalink": "/docs/processing/lab-flink-kafka-sink/"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-beam-mapreduce/README",
              "id": "processing/lab-gcp-beam-mapreduce/README",
              "title": "Lab: MapReduce in Beam using Python",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-gcp-beam-mapreduce/README.md",
              "sourceDirName": "03-processing/lab-gcp-beam-mapreduce",
              "slug": "/processing/lab-gcp-beam-mapreduce/",
              "permalink": "/docs/processing/lab-gcp-beam-mapreduce/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Apache Beam Getting Started",
                "permalink": "/docs/processing/lab-getting-started-with-beam/"
              },
              "next": {
                "title": "Lab: GCP Dataflow Pipeline - A Simple Dataflow Pipeline (Python)",
                "permalink": "/docs/processing/lab-gcp-dataflow-pipeline"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-dataflow-batch-pipeline",
              "id": "processing/lab-gcp-dataflow-batch-pipeline",
              "title": "Lab: GCP Dataflow Batch Pipeline",
              "description": "Objective: Serverless Data Processing with Dataflow - Batch Analytics Pipelines with Cloud Dataflow (Python)",
              "source": "@site/docs/03-processing/lab-gcp-dataflow-batch-pipeline.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-gcp-dataflow-batch-pipeline",
              "permalink": "/docs/processing/lab-gcp-dataflow-batch-pipeline",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: GCP Dataflow Pipeline - A Simple Dataflow Pipeline (Python)",
                "permalink": "/docs/processing/lab-gcp-dataflow-pipeline"
              },
              "next": {
                "title": "Lab: GCP Dataflow Size Inputs",
                "permalink": "/docs/processing/lab-gcp-dataflow-side-inputs"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-dataflow-pipeline",
              "id": "processing/lab-gcp-dataflow-pipeline",
              "title": "Lab: GCP Dataflow Pipeline - A Simple Dataflow Pipeline (Python)",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-gcp-dataflow-pipeline.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-gcp-dataflow-pipeline",
              "permalink": "/docs/processing/lab-gcp-dataflow-pipeline",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: MapReduce in Beam using Python",
                "permalink": "/docs/processing/lab-gcp-beam-mapreduce/"
              },
              "next": {
                "title": "Lab: GCP Dataflow Batch Pipeline",
                "permalink": "/docs/processing/lab-gcp-dataflow-batch-pipeline"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-dataflow-side-inputs",
              "id": "processing/lab-gcp-dataflow-side-inputs",
              "title": "Lab: GCP Dataflow Size Inputs",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-gcp-dataflow-side-inputs.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-gcp-dataflow-side-inputs",
              "permalink": "/docs/processing/lab-gcp-dataflow-side-inputs",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: GCP Dataflow Batch Pipeline",
                "permalink": "/docs/processing/lab-gcp-dataflow-batch-pipeline"
              },
              "next": {
                "title": "GCP Dataflow Streaming Pipeline",
                "permalink": "/docs/processing/lab-gcp-dataflow-stream-pipeline"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-dataflow-stream-pipeline",
              "id": "processing/lab-gcp-dataflow-stream-pipeline",
              "title": "GCP Dataflow Streaming Pipeline",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-gcp-dataflow-stream-pipeline.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-gcp-dataflow-stream-pipeline",
              "permalink": "/docs/processing/lab-gcp-dataflow-stream-pipeline",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: GCP Dataflow Size Inputs",
                "permalink": "/docs/processing/lab-gcp-dataflow-side-inputs"
              },
              "next": {
                "title": "Lab: GCP Serverless Dataflow",
                "permalink": "/docs/processing/lab-gcp-serverless-dataflow"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-dataprep",
              "id": "processing/lab-gcp-dataprep",
              "title": "Lab: GCP Dataprep",
              "description": "Creating a Data Transformation Pipeline with Cloud Dataprep",
              "source": "@site/docs/03-processing/lab-gcp-dataprep.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-gcp-dataprep",
              "permalink": "/docs/processing/lab-gcp-dataprep",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Implementing the Serving Layer Star Schema",
                "permalink": "/docs/processing/lab-azure-synapse-implementing-star-schema/"
              },
              "next": {
                "title": "Pub/Sub",
                "permalink": "/docs/processing/gcp-pubsub"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-dataproc/README",
              "id": "processing/lab-gcp-dataproc/README",
              "title": "Lab: Running Apache Spark jobs on Cloud Dataproc",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-gcp-dataproc/README.md",
              "sourceDirName": "03-processing/lab-gcp-dataproc",
              "slug": "/processing/lab-gcp-dataproc/",
              "permalink": "/docs/processing/lab-gcp-dataproc/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Dataproc",
                "permalink": "/docs/processing/gcp-dataproc"
              },
              "next": {
                "title": "Lab: Simple Data Pipeline with HDInsight",
                "permalink": "/docs/processing/lab-azure-hdinsight-simple-data-processing/"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-pubsub",
              "id": "processing/lab-gcp-pubsub",
              "title": "Lab: Streaming Data Processing - Publish Streaming Data into PubSub",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-gcp-pubsub.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-gcp-pubsub",
              "permalink": "/docs/processing/lab-gcp-pubsub",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Pub/Sub",
                "permalink": "/docs/processing/gcp-pubsub"
              },
              "next": {
                "title": "Lab: Streaming Data Processing - Streaming Data Pipelines",
                "permalink": "/docs/processing/lab-gcp-pubsub-processing"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-pubsub-processing",
              "id": "processing/lab-gcp-pubsub-processing",
              "title": "Lab: Streaming Data Processing - Streaming Data Pipelines",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-gcp-pubsub-processing.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-gcp-pubsub-processing",
              "permalink": "/docs/processing/lab-gcp-pubsub-processing",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Streaming Data Processing - Publish Streaming Data into PubSub",
                "permalink": "/docs/processing/lab-gcp-pubsub"
              },
              "next": {
                "title": "Apache Kafka",
                "permalink": "/docs/processing/apache-kafka"
              }
            },
            {
              "unversionedId": "processing/lab-gcp-serverless-dataflow",
              "id": "processing/lab-gcp-serverless-dataflow",
              "title": "Lab: GCP Serverless Dataflow",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-gcp-serverless-dataflow.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/lab-gcp-serverless-dataflow",
              "permalink": "/docs/processing/lab-gcp-serverless-dataflow",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "GCP Dataflow Streaming Pipeline",
                "permalink": "/docs/processing/lab-gcp-dataflow-stream-pipeline"
              },
              "next": {
                "title": "Lab: ETL Processing on Google Cloud Using Dataflow and BigQuery",
                "permalink": "/docs/processing/lab-dataflow-bigquery-etl"
              }
            },
            {
              "unversionedId": "processing/lab-getting-started-with-beam/README",
              "id": "processing/lab-getting-started-with-beam/README",
              "title": "Lab: Apache Beam Getting Started",
              "description": "Pipeline 1 - Simple Ingest Data Pipeline",
              "source": "@site/docs/03-processing/lab-getting-started-with-beam/README.md",
              "sourceDirName": "03-processing/lab-getting-started-with-beam",
              "slug": "/processing/lab-getting-started-with-beam/",
              "permalink": "/docs/processing/lab-getting-started-with-beam/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache Beam",
                "permalink": "/docs/processing/apache-beam"
              },
              "next": {
                "title": "Lab: MapReduce in Beam using Python",
                "permalink": "/docs/processing/lab-gcp-beam-mapreduce/"
              }
            },
            {
              "unversionedId": "processing/lab-glue-advanced/README",
              "id": "processing/lab-glue-advanced/README",
              "title": "Lab: Glue ETL",
              "description": "Advanced Data Engineering and Data Processing with AWS Glue Jobs",
              "source": "@site/docs/03-processing/lab-glue-advanced/README.md",
              "sourceDirName": "03-processing/lab-glue-advanced",
              "slug": "/processing/lab-glue-advanced/",
              "permalink": "/docs/processing/lab-glue-advanced/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: EMR Serverless",
                "permalink": "/docs/processing/lab-emr-serverless/"
              },
              "next": {
                "title": "Lab: Glue ETL and CDC UPSERT",
                "permalink": "/docs/processing/lab-glue-deltalake-cdc-upsert/"
              }
            },
            {
              "unversionedId": "processing/lab-glue-deltalake-cdc-upsert/README",
              "id": "processing/lab-glue-deltalake-cdc-upsert/README",
              "title": "Lab: Glue ETL and CDC UPSERT",
              "description": "Handle UPSERT data operations using open-source Delta Lake and AWS Glue",
              "source": "@site/docs/03-processing/lab-glue-deltalake-cdc-upsert/README.md",
              "sourceDirName": "03-processing/lab-glue-deltalake-cdc-upsert",
              "slug": "/processing/lab-glue-deltalake-cdc-upsert/",
              "permalink": "/docs/processing/lab-glue-deltalake-cdc-upsert/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Glue ETL",
                "permalink": "/docs/processing/lab-glue-advanced/"
              },
              "next": {
                "title": "Lab: Glue Studio Custom Transforms",
                "permalink": "/docs/processing/lab-glue-studio-custom-transforms/"
              }
            },
            {
              "unversionedId": "processing/lab-glue-studio-custom-transforms/README",
              "id": "processing/lab-glue-studio-custom-transforms/README",
              "title": "Lab: Glue Studio Custom Transforms",
              "description": "Objective: Create your own reusable visual transforms for AWS Glue Studio",
              "source": "@site/docs/03-processing/lab-glue-studio-custom-transforms/README.md",
              "sourceDirName": "03-processing/lab-glue-studio-custom-transforms",
              "slug": "/processing/lab-glue-studio-custom-transforms/",
              "permalink": "/docs/processing/lab-glue-studio-custom-transforms/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Glue ETL and CDC UPSERT",
                "permalink": "/docs/processing/lab-glue-deltalake-cdc-upsert/"
              },
              "next": {
                "title": "Lab: Tickets ETL with Glue Studio",
                "permalink": "/docs/processing/lab-glue-studio-tickets/"
              }
            },
            {
              "unversionedId": "processing/lab-glue-studio-tickets/README",
              "id": "processing/lab-glue-studio-tickets/README",
              "title": "Lab: Tickets ETL with Glue Studio",
              "description": "You can use AWS Glue Studio to create jobs that extract structured or semi-structured data from a data source, perform a transformation of that data, and save the result set in a data target.",
              "source": "@site/docs/03-processing/lab-glue-studio-tickets/README.md",
              "sourceDirName": "03-processing/lab-glue-studio-tickets",
              "slug": "/processing/lab-glue-studio-tickets/",
              "permalink": "/docs/processing/lab-glue-studio-tickets/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Glue Studio Custom Transforms",
                "permalink": "/docs/processing/lab-glue-studio-custom-transforms/"
              },
              "next": {
                "title": "Lab: CSV to Parquet Transformation with Glue Studio",
                "permalink": "/docs/processing/lab-csv-to-parquet-conversion/"
              }
            },
            {
              "unversionedId": "processing/lab-kafka-cli/README",
              "id": "processing/lab-kafka-cli/README",
              "title": "Lab: Getting started with Kafka and CLI",
              "description": "Notebook",
              "source": "@site/docs/03-processing/lab-kafka-cli/README.md",
              "sourceDirName": "03-processing/lab-kafka-cli",
              "slug": "/processing/lab-kafka-cli/",
              "permalink": "/docs/processing/lab-kafka-cli/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache Kafka",
                "permalink": "/docs/processing/apache-kafka"
              },
              "next": {
                "title": "Lab: Getting started with Kafka and Python",
                "permalink": "/docs/processing/lab-kafka-python/"
              }
            },
            {
              "unversionedId": "processing/lab-kafka-fraud-detection/README",
              "id": "processing/lab-kafka-fraud-detection/README",
              "title": "Lab: Real-time fraud detection by applying filter in Kafka topic",
              "description": "In this lab, we will generate some transactions out of which some would be fraudulent and then at the consumer end, we will check if the transaction is legit or fraud.",
              "source": "@site/docs/03-processing/lab-kafka-fraud-detection/README.md",
              "sourceDirName": "03-processing/lab-kafka-fraud-detection",
              "slug": "/processing/lab-kafka-fraud-detection/",
              "permalink": "/docs/processing/lab-kafka-fraud-detection/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Kafka and CDC",
                "permalink": "/docs/processing/lab-confluent-kafka-faker/"
              },
              "next": {
                "title": "Kafka Streams for NYC Taxi data",
                "permalink": "/docs/processing/lab-kafka-nyctaxi/"
              }
            },
            {
              "unversionedId": "processing/lab-kafka-nyctaxi/assets/README",
              "id": "processing/lab-kafka-nyctaxi/assets/README",
              "title": "Kafka with Docker Compose",
              "description": "- zookeeper: a centralized service for maintaining configuration info. Kafka uses it for maintaining metadata knowledge such as topic partitions, etc. Zookeeper is being phased out as a dependency, but for easier deployment we will use it in the lesson.",
              "source": "@site/docs/03-processing/lab-kafka-nyctaxi/assets/README.md",
              "sourceDirName": "03-processing/lab-kafka-nyctaxi/assets",
              "slug": "/processing/lab-kafka-nyctaxi/assets/",
              "permalink": "/docs/processing/lab-kafka-nyctaxi/assets/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/lab-kafka-nyctaxi/README",
              "id": "processing/lab-kafka-nyctaxi/README",
              "title": "Kafka Streams for NYC Taxi data",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-kafka-nyctaxi/README.md",
              "sourceDirName": "03-processing/lab-kafka-nyctaxi",
              "slug": "/processing/lab-kafka-nyctaxi/",
              "permalink": "/docs/processing/lab-kafka-nyctaxi/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Real-time fraud detection by applying filter in Kafka topic",
                "permalink": "/docs/processing/lab-kafka-fraud-detection/"
              },
              "next": {
                "title": "Lab: Kafka on Cloud with Amazon ECS and Container Orchestration",
                "permalink": "/docs/processing/lab-kafka-python-ecs/"
              }
            },
            {
              "unversionedId": "processing/lab-kafka-python-ecs/README",
              "id": "processing/lab-kafka-python-ecs/README",
              "title": "Lab: Kafka on Cloud with Amazon ECS and Container Orchestration",
              "description": "Notebooks",
              "source": "@site/docs/03-processing/lab-kafka-python-ecs/README.md",
              "sourceDirName": "03-processing/lab-kafka-python-ecs",
              "slug": "/processing/lab-kafka-python-ecs/",
              "permalink": "/docs/processing/lab-kafka-python-ecs/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Kafka Streams for NYC Taxi data",
                "permalink": "/docs/processing/lab-kafka-nyctaxi/"
              },
              "next": {
                "title": "Lab: Realtime Streaming analytics with Apache Kafka and Spark Streaming",
                "permalink": "/docs/processing/lab-kafka-spark-streaming/"
              }
            },
            {
              "unversionedId": "processing/lab-kafka-python/README",
              "id": "processing/lab-kafka-python/README",
              "title": "Lab: Getting started with Kafka and Python",
              "description": "Files",
              "source": "@site/docs/03-processing/lab-kafka-python/README.md",
              "sourceDirName": "03-processing/lab-kafka-python",
              "slug": "/processing/lab-kafka-python/",
              "permalink": "/docs/processing/lab-kafka-python/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Getting started with Kafka and CLI",
                "permalink": "/docs/processing/lab-kafka-cli/"
              },
              "next": {
                "title": "Lab: Confluent Kafka with Python",
                "permalink": "/docs/processing/lab-confluent-python/"
              }
            },
            {
              "unversionedId": "processing/lab-kafka-spark-streaming/README",
              "id": "processing/lab-kafka-spark-streaming/README",
              "title": "Lab: Realtime Streaming analytics with Apache Kafka and Spark Streaming",
              "description": "Activity 1",
              "source": "@site/docs/03-processing/lab-kafka-spark-streaming/README.md",
              "sourceDirName": "03-processing/lab-kafka-spark-streaming",
              "slug": "/processing/lab-kafka-spark-streaming/",
              "permalink": "/docs/processing/lab-kafka-spark-streaming/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Kafka on Cloud with Amazon ECS and Container Orchestration",
                "permalink": "/docs/processing/lab-kafka-python-ecs/"
              },
              "next": {
                "title": "Lab: Stock Market Kafka Real Time",
                "permalink": "/docs/processing/lab-kafka-stock-market/"
              }
            },
            {
              "unversionedId": "processing/lab-kafka-stock-market/README",
              "id": "processing/lab-kafka-stock-market/README",
              "title": "Lab: Stock Market Kafka Real Time",
              "description": "Problem Statement",
              "source": "@site/docs/03-processing/lab-kafka-stock-market/README.md",
              "sourceDirName": "03-processing/lab-kafka-stock-market",
              "slug": "/processing/lab-kafka-stock-market/",
              "permalink": "/docs/processing/lab-kafka-stock-market/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Realtime Streaming analytics with Apache Kafka and Spark Streaming",
                "permalink": "/docs/processing/lab-kafka-spark-streaming/"
              },
              "next": {
                "title": "Lab: Data Streaming Pipeline with Kafka for livetolldata",
                "permalink": "/docs/processing/lab-kafka-toll-analysis/"
              }
            },
            {
              "unversionedId": "processing/lab-kafka-toll-analysis/README",
              "id": "processing/lab-kafka-toll-analysis/README",
              "title": "Lab: Data Streaming Pipeline with Kafka for livetolldata",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-kafka-toll-analysis/README.md",
              "sourceDirName": "03-processing/lab-kafka-toll-analysis",
              "slug": "/processing/lab-kafka-toll-analysis/",
              "permalink": "/docs/processing/lab-kafka-toll-analysis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Stock Market Kafka Real Time",
                "permalink": "/docs/processing/lab-kafka-stock-market/"
              },
              "next": {
                "title": "Project: Building an event-driven IKEA app with Kafka",
                "permalink": "/docs/processing/project-kafka-ikea/"
              }
            },
            {
              "unversionedId": "processing/lab-kinesis-apache-logs/README",
              "id": "processing/lab-kinesis-apache-logs/README",
              "title": "Lab: Real Time Apache Log Analytics with Kinesis",
              "description": "Objective",
              "source": "@site/docs/03-processing/lab-kinesis-apache-logs/README.md",
              "sourceDirName": "03-processing/lab-kinesis-apache-logs",
              "slug": "/processing/lab-kinesis-apache-logs/",
              "permalink": "/docs/processing/lab-kinesis-apache-logs/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Amazon Kinesis",
                "permalink": "/docs/processing/aws-kinesis"
              },
              "next": {
                "title": "Lab: Real-Time Clickstream Anomaly Detection with Kinesis",
                "permalink": "/docs/processing/lab-kinesis-clickstream-anomaly/"
              }
            },
            {
              "unversionedId": "processing/lab-kinesis-clickstream-anomaly/README",
              "id": "processing/lab-kinesis-clickstream-anomaly/README",
              "title": "Lab: Real-Time Clickstream Anomaly Detection with Kinesis",
              "description": "Architecture",
              "source": "@site/docs/03-processing/lab-kinesis-clickstream-anomaly/README.md",
              "sourceDirName": "03-processing/lab-kinesis-clickstream-anomaly",
              "slug": "/processing/lab-kinesis-clickstream-anomaly/",
              "permalink": "/docs/processing/lab-kinesis-clickstream-anomaly/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Real Time Apache Log Analytics with Kinesis",
                "permalink": "/docs/processing/lab-kinesis-apache-logs/"
              },
              "next": {
                "title": "Apache Beam",
                "permalink": "/docs/processing/apache-beam"
              }
            },
            {
              "unversionedId": "processing/lab-lambda-csv-parquet/README",
              "id": "processing/lab-lambda-csv-parquet/README",
              "title": "Lab: Lambda CSV to Parquet",
              "description": "Create an S3 bucket and IAM user with user-defined policy. Create Lambda layer and lambda function and add the layer to the function. Add S3 trigger for auto-transformation from csv to parquet and query with Glue.",
              "source": "@site/docs/03-processing/lab-lambda-csv-parquet/README.md",
              "sourceDirName": "03-processing/lab-lambda-csv-parquet",
              "slug": "/processing/lab-lambda-csv-parquet/",
              "permalink": "/docs/processing/lab-lambda-csv-parquet/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Snippets related to Lambda function",
                "permalink": "/docs/processing/aws-lambda-snippets"
              },
              "next": {
                "title": "Amazon Kinesis",
                "permalink": "/docs/processing/aws-kinesis"
              }
            },
            {
              "unversionedId": "processing/lab-ray-air-basics/README",
              "id": "processing/lab-ray-air-basics/README",
              "title": "Lab: Ray AIR Basics",
              "description": "In this lab, we are learning all 4 high-level APIs of Ray AIR with some examples.",
              "source": "@site/docs/03-processing/lab-ray-air-basics/README.md",
              "sourceDirName": "03-processing/lab-ray-air-basics",
              "slug": "/processing/lab-ray-air-basics/",
              "permalink": "/docs/processing/lab-ray-air-basics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Ray Core Basics",
                "permalink": "/docs/processing/lab-ray-core-basics/"
              },
              "next": {
                "title": "Dataproc",
                "permalink": "/docs/processing/gcp-dataproc"
              }
            },
            {
              "unversionedId": "processing/lab-ray-core-basics/README",
              "id": "processing/lab-ray-core-basics/README",
              "title": "Lab: Ray Core Basics",
              "description": "- Recipe 1: Your first Ray API example",
              "source": "@site/docs/03-processing/lab-ray-core-basics/README.md",
              "sourceDirName": "03-processing/lab-ray-core-basics",
              "slug": "/processing/lab-ray-core-basics/",
              "permalink": "/docs/processing/lab-ray-core-basics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Ray",
                "permalink": "/docs/processing/ray"
              },
              "next": {
                "title": "Lab: Ray AIR Basics",
                "permalink": "/docs/processing/lab-ray-air-basics/"
              }
            },
            {
              "unversionedId": "processing/lab-snowpark-churnpark/README",
              "id": "processing/lab-snowpark-churnpark/README",
              "title": "Lab: Churn Analytics Demo with dbt Snowpark Python models",
              "description": "PPT//docs.google.com/presentation/d/1IJSeE96bze7DECuDYqsTVv6FaOcNcJ5tTiCWKEkuQQ/edit#slide=id.g158d486fe9e2_12",
              "source": "@site/docs/03-processing/lab-snowpark-churnpark/README.md",
              "sourceDirName": "03-processing/lab-snowpark-churnpark",
              "slug": "/processing/lab-snowpark-churnpark/",
              "permalink": "/docs/processing/lab-snowpark-churnpark/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Snowpark",
                "permalink": "/docs/processing/snowpark"
              },
              "next": {
                "title": "Lab: Modeling with dbt and Snowpark",
                "permalink": "/docs/processing/lab-snowpark-dbtsnowpy/"
              }
            },
            {
              "unversionedId": "processing/lab-snowpark-dbtsnowpy/README",
              "id": "processing/lab-snowpark-dbtsnowpy/README",
              "title": "Lab: Modeling with dbt and Snowpark",
              "description": "Files",
              "source": "@site/docs/03-processing/lab-snowpark-dbtsnowpy/README.md",
              "sourceDirName": "03-processing/lab-snowpark-dbtsnowpy",
              "slug": "/processing/lab-snowpark-dbtsnowpy/",
              "permalink": "/docs/processing/lab-snowpark-dbtsnowpy/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Churn Analytics Demo with dbt Snowpark Python models",
                "permalink": "/docs/processing/lab-snowpark-churnpark/"
              },
              "next": {
                "title": "Lab: FIFA prediction model with dbt and Snowpark",
                "permalink": "/docs/processing/lab-snowpark-fifapark/"
              }
            },
            {
              "unversionedId": "processing/lab-snowpark-fifapark/README",
              "id": "processing/lab-snowpark-fifapark/README",
              "title": "Lab: FIFA prediction model with dbt and Snowpark",
              "description": "Files",
              "source": "@site/docs/03-processing/lab-snowpark-fifapark/README.md",
              "sourceDirName": "03-processing/lab-snowpark-fifapark",
              "slug": "/processing/lab-snowpark-fifapark/",
              "permalink": "/docs/processing/lab-snowpark-fifapark/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Modeling with dbt and Snowpark",
                "permalink": "/docs/processing/lab-snowpark-dbtsnowpy/"
              },
              "next": {
                "title": "Lab: Jaffle Shop Modeling with Snowpark",
                "permalink": "/docs/processing/lab-snowpark-jafflepark/"
              }
            },
            {
              "unversionedId": "processing/lab-snowpark-jafflepark/models/docs",
              "id": "processing/lab-snowpark-jafflepark/models/docs",
              "title": "docs",
              "description": "{% docs orders_status %}",
              "source": "@site/docs/03-processing/lab-snowpark-jafflepark/models/docs.md",
              "sourceDirName": "03-processing/lab-snowpark-jafflepark/models",
              "slug": "/processing/lab-snowpark-jafflepark/models/docs",
              "permalink": "/docs/processing/lab-snowpark-jafflepark/models/docs",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "processing/lab-snowpark-jafflepark/README",
              "id": "processing/lab-snowpark-jafflepark/README",
              "title": "Lab: Jaffle Shop Modeling with Snowpark",
              "description": "Files",
              "source": "@site/docs/03-processing/lab-snowpark-jafflepark/README.md",
              "sourceDirName": "03-processing/lab-snowpark-jafflepark",
              "slug": "/processing/lab-snowpark-jafflepark/",
              "permalink": "/docs/processing/lab-snowpark-jafflepark/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: FIFA prediction model with dbt and Snowpark",
                "permalink": "/docs/processing/lab-snowpark-fifapark/"
              },
              "next": {
                "title": "Lab: Knoema Regression Model with Snowpark",
                "permalink": "/docs/processing/lab-snowpark-knoema-regression/"
              }
            },
            {
              "unversionedId": "processing/lab-snowpark-knoema-regression/README",
              "id": "processing/lab-snowpark-knoema-regression/README",
              "title": "Lab: Knoema Regression Model with Snowpark",
              "description": "We are interested in the US Inflation data, so we will use this query to explore the data for the application: What is the US inflation over time?",
              "source": "@site/docs/03-processing/lab-snowpark-knoema-regression/README.md",
              "sourceDirName": "03-processing/lab-snowpark-knoema-regression",
              "slug": "/processing/lab-snowpark-knoema-regression/",
              "permalink": "/docs/processing/lab-snowpark-knoema-regression/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Jaffle Shop Modeling with Snowpark",
                "permalink": "/docs/processing/lab-snowpark-jafflepark/"
              },
              "next": {
                "title": "Data Modeling",
                "permalink": "/docs/category/data-modeling"
              }
            },
            {
              "unversionedId": "processing/project-kafka-ikea/README",
              "id": "processing/project-kafka-ikea/README",
              "title": "Project: Building an event-driven IKEA app with Kafka",
              "description": "This app is designed to break down the event driven architecture for modern apps",
              "source": "@site/docs/03-processing/project-kafka-ikea/README.md",
              "sourceDirName": "03-processing/project-kafka-ikea",
              "slug": "/processing/project-kafka-ikea/",
              "permalink": "/docs/processing/project-kafka-ikea/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Data Streaming Pipeline with Kafka for livetolldata",
                "permalink": "/docs/processing/lab-kafka-toll-analysis/"
              },
              "next": {
                "title": "Apache Flink",
                "permalink": "/docs/processing/apache-flink"
              }
            },
            {
              "unversionedId": "processing/ray",
              "id": "processing/ray",
              "title": "Ray",
              "description": "What is Ray?",
              "source": "@site/docs/03-processing/ray.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/ray",
              "permalink": "/docs/processing/ray",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: ETL Processing on Google Cloud Using Dataflow and BigQuery",
                "permalink": "/docs/processing/lab-dataflow-bigquery-etl"
              },
              "next": {
                "title": "Lab: Ray Core Basics",
                "permalink": "/docs/processing/lab-ray-core-basics/"
              }
            },
            {
              "unversionedId": "processing/snowpark",
              "id": "processing/snowpark",
              "title": "Snowpark",
              "description": "What is Snowpark",
              "source": "@site/docs/03-processing/snowpark.md",
              "sourceDirName": "03-processing",
              "slug": "/processing/snowpark",
              "permalink": "/docs/processing/snowpark",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: dbt Snowflake on TPCH data",
                "permalink": "/docs/processing/lab-dbt-tpch/"
              },
              "next": {
                "title": "Lab: Churn Analytics Demo with dbt Snowpark Python models",
                "permalink": "/docs/processing/lab-snowpark-churnpark/"
              }
            },
            {
              "unversionedId": "storage/apache-couchdb",
              "id": "storage/apache-couchdb",
              "title": "Apache CouchDB",
              "description": "Apache CouchDB is an open source NoSQL document database that collects and stores data in JSON-based document formats. Unlike relational databases, CouchDB uses a schema-free data model, which simplifies record management across various computing devices, mobile phones, and web browsers.",
              "source": "@site/docs/02-storage/apache-couchdb.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/apache-couchdb",
              "permalink": "/docs/storage/apache-couchdb",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "DynamoDB",
                "permalink": "/docs/storage/aws-dynamodb"
              },
              "next": {
                "title": "MongoDB",
                "permalink": "/docs/storage/mongodb"
              }
            },
            {
              "unversionedId": "storage/apache-hudi",
              "id": "storage/apache-hudi",
              "title": "Apache Hudi",
              "description": "Bring transactions, record-level updates/deletes and change streams to data lakes",
              "source": "@site/docs/02-storage/apache-hudi.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/apache-hudi",
              "permalink": "/docs/storage/apache-hudi",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Deltalake",
                "permalink": "/docs/storage/deltalake"
              },
              "next": {
                "title": "Apache Iceberg",
                "permalink": "/docs/storage/apache-iceberg"
              }
            },
            {
              "unversionedId": "storage/apache-iceberg",
              "id": "storage/apache-iceberg",
              "title": "Apache Iceberg",
              "description": "The open table format for analytic datasets",
              "source": "@site/docs/02-storage/apache-iceberg.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/apache-iceberg",
              "permalink": "/docs/storage/apache-iceberg",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache Hudi",
                "permalink": "/docs/storage/apache-hudi"
              },
              "next": {
                "title": "Lab: Read Delta Tables stored in Amazon S3 with Python",
                "permalink": "/docs/storage/lab-read-s3-delta-in-python/"
              }
            },
            {
              "unversionedId": "storage/arrow",
              "id": "storage/arrow",
              "title": "Apache Arrow or in-memory serialization",
              "description": "When we introduced serialization as a storage raw ingredient at the beginning of this chapter, we mentioned that software could store data in complex objects scattered in memory and connected by pointers, or more orderly, densely packed structures such as Fortran and C arrays. Generally, densely packed in-memory data structures were limited to simple types (e.g., INT64) or fixed-width data structures (e.g., fixed-width strings). More complex structures (e.g., JSON documents) could not be densely stored in memory and required serialization for storage and transfer between systems.",
              "source": "@site/docs/02-storage/arrow.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/arrow",
              "permalink": "/docs/storage/arrow",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "ORC",
                "permalink": "/docs/storage/orc"
              },
              "next": {
                "title": "Hudi",
                "permalink": "/docs/storage/hudi"
              }
            },
            {
              "unversionedId": "storage/athena",
              "id": "storage/athena",
              "title": "Amazon Athena",
              "description": "Athena is a Serverless Query Service from Amazon based on Presto engine",
              "source": "@site/docs/02-storage/athena.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/athena",
              "permalink": "/docs/storage/athena",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Warehouses",
                "permalink": "/docs/storage/data-warehouses"
              },
              "next": {
                "title": "Project: Athena Federated",
                "permalink": "/docs/storage/project-athena-federated/"
              }
            },
            {
              "unversionedId": "storage/avro",
              "id": "storage/avro",
              "title": "Avro",
              "description": "Avro is a row-oriented data format designed for RPCs and data serialization. Avro encodes data into a binary format, with schema metadata specified in JSON. Avro is popular in the Hadoop ecosystem and is also supported by various cloud data tools.",
              "source": "@site/docs/02-storage/avro.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/avro",
              "permalink": "/docs/storage/avro",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "JSON and JSONL",
                "permalink": "/docs/storage/json"
              },
              "next": {
                "title": "Parquet",
                "permalink": "/docs/storage/parquet"
              }
            },
            {
              "unversionedId": "storage/avro-vs-parquet-vs-orc",
              "id": "storage/avro-vs-parquet-vs-orc",
              "title": "Avro vs Parquet vs ORC",
              "description": "B1752502010",
              "source": "@site/docs/02-storage/avro-vs-parquet-vs-orc.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/avro-vs-parquet-vs-orc",
              "permalink": "/docs/storage/avro-vs-parquet-vs-orc",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Database Storage Engines",
                "permalink": "/docs/storage/database-storage-engines"
              },
              "next": {
                "title": "Parquet vs CSV",
                "permalink": "/docs/storage/parquet-vs-csv"
              }
            },
            {
              "unversionedId": "storage/aws-dynamodb",
              "id": "storage/aws-dynamodb",
              "title": "DynamoDB",
              "description": "Getting Started with DynamoDB",
              "source": "@site/docs/02-storage/aws-dynamodb.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/aws-dynamodb",
              "permalink": "/docs/storage/aws-dynamodb",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "BigTable",
                "permalink": "/docs/storage/gcp-bigtable"
              },
              "next": {
                "title": "Apache CouchDB",
                "permalink": "/docs/storage/apache-couchdb"
              }
            },
            {
              "unversionedId": "storage/azure-datalake",
              "id": "storage/azure-datalake",
              "title": "Azure Data Lakes",
              "description": "Azure Data Lake is a highly scalable and durable object-based cloud storage solution from Microsoft. It is optimized to store large amounts of structured and semi-structured data such as logs, application data, and documents.",
              "source": "@site/docs/02-storage/azure-datalake.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/azure-datalake",
              "permalink": "/docs/storage/azure-datalake",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Why we need Data Lakes?",
                "permalink": "/docs/storage/why-datalakes"
              },
              "next": {
                "title": "Google Cloud Storage (GCS)",
                "permalink": "/docs/storage/gcs"
              }
            },
            {
              "unversionedId": "storage/azure-sql",
              "id": "storage/azure-sql",
              "title": "Azure SQL Databases",
              "description": "Azure SQL Database, a fundamental relational database as a service offered in Azure, acts as a source, destination, or even as an intermediate storage layer in data engineering pipelines. Azure SQL Database can be used to consolidate data coming from several relational data sources and build mini data warehouses or data marts. With the introduction of Hyperscale tier in Azure SQL Database, the capacity of Azure SQL Database has increased leaps and bounds too. Securing Azure SQL Database is also pivotal in protecting access to the database. Having a strong understanding of Azure SQL Database's capabilities and security options is essential for any data engineer.",
              "source": "@site/docs/02-storage/azure-sql.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/azure-sql",
              "permalink": "/docs/storage/azure-sql",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "GCP CloudSQL",
                "permalink": "/docs/storage/gcp-cloudsql"
              },
              "next": {
                "title": "Interview Questions",
                "permalink": "/docs/storage/interview-questions"
              }
            },
            {
              "unversionedId": "storage/bigquery",
              "id": "storage/bigquery",
              "title": "BigQuery",
              "description": "BigQuery is server-less, highly scalable, and cost-effective Data warehouse designed for Google cloud Platform (GCP) to store and query petabytes of data. The query engine is capable of running SQL queries on terabytes of data in a matter of seconds, and petabytes in only minutes. You get this performance without having to manage any infrastructure and without having to create or rebuild indexes.",
              "source": "@site/docs/02-storage/bigquery.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/bigquery",
              "permalink": "/docs/storage/bigquery",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Redshift Spectrum Query Tuning",
                "permalink": "/docs/storage/lab-redshift-spectrum-query-tuning"
              },
              "next": {
                "title": "Snowflake",
                "permalink": "/docs/storage/snowflake"
              }
            },
            {
              "unversionedId": "storage/casestudy-messflix-hypothetical",
              "id": "storage/casestudy-messflix-hypothetical",
              "title": "Messflix (hypothetical)",
              "description": "Messflix, a movie- and TV-show streaming platform, just hit a wall. A data wall. The company has all the data in the world but complains about not even being able to build a proper recommendation system for its movies and shows. The competition seems to be able to get it done; in fact, the competition is famous for being the first movers in a lot of technology sectors.",
              "source": "@site/docs/02-storage/casestudy-messflix-hypothetical.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/casestudy-messflix-hypothetical",
              "permalink": "/docs/storage/casestudy-messflix-hypothetical",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Mesh Basics",
                "permalink": "/docs/storage/data-mesh-basics"
              },
              "next": {
                "title": "Databricks",
                "permalink": "/docs/processing/databricks/"
              }
            },
            {
              "unversionedId": "storage/cassandra",
              "id": "storage/cassandra",
              "title": "Cassandra",
              "description": "Apache Cassandra is an open source, distributed, decentralized, elastically scalable, highly available, fault-tolerant, tuneably consistent, row-oriented database. Cassandra bases its distribution design on Amazon’s Dynamo and its data model on Google’s Bigtable, with a query language similar to SQL. Created at Facebook, it now powers cloud-scale applications across many industries.",
              "source": "@site/docs/02-storage/cassandra.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/cassandra",
              "permalink": "/docs/storage/cassandra",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Links",
                "permalink": "/docs/storage/database-links"
              },
              "next": {
                "title": "BigTable",
                "permalink": "/docs/storage/gcp-bigtable"
              }
            },
            {
              "unversionedId": "storage/code-snippets",
              "id": "storage/code-snippets",
              "title": "Code Snippets",
              "description": "Connect to Redshift using Python",
              "source": "@site/docs/02-storage/code-snippets.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/code-snippets",
              "permalink": "/docs/storage/code-snippets",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/compression",
              "id": "storage/compression",
              "title": "Compression",
              "description": "gzip, bzip2, Snappy",
              "source": "@site/docs/02-storage/compression.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/compression",
              "permalink": "/docs/storage/compression",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/csv",
              "id": "storage/csv",
              "title": "CSV: The nonstandard standard",
              "description": "CSV is a serialization format that data engineers love to hate. The term CSV is essentially a catchall for delimited text, but there is flexibility in conventions of escaping, quote characters, delimiter, and more.",
              "source": "@site/docs/02-storage/csv.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/csv",
              "permalink": "/docs/storage/csv",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Serialization",
                "permalink": "/docs/storage/serialization"
              },
              "next": {
                "title": "XML",
                "permalink": "/docs/storage/xml"
              }
            },
            {
              "unversionedId": "storage/data-lakehouses",
              "id": "storage/data-lakehouses",
              "title": "Data Lakehouses",
              "description": "We have been collecting data for decades. The flat file storages of the 60s led to the data warehouses of the 80s to Massively Parallel Processing (MPP) and NoSQL databases, and eventually to data lakes and now the lakehouses. New paradigms continue to be coined but it would be fair to say that most enterprise organizations have settled on some variation of a data lake and lakehouse:",
              "source": "@site/docs/02-storage/data-lakehouses.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/data-lakehouses",
              "permalink": "/docs/storage/data-lakehouses",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Azure Data Lake - Securing and Monitoring",
                "permalink": "/docs/storage/lab-adl-securing-monitoring-lakes/"
              },
              "next": {
                "title": "Deltalake",
                "permalink": "/docs/storage/deltalake"
              }
            },
            {
              "unversionedId": "storage/data-mesh-basics",
              "id": "storage/data-mesh-basics",
              "title": "Data Mesh Basics",
              "description": "The data mesh is to data as agile is to software engineering, or as microservices are to architecture patterns.",
              "source": "@site/docs/02-storage/data-mesh-basics.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/data-mesh-basics",
              "permalink": "/docs/storage/data-mesh-basics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: SCD in Lakehouse",
                "permalink": "/docs/storage/lab-scd-glue-delta/"
              },
              "next": {
                "title": "Messflix (hypothetical)",
                "permalink": "/docs/storage/casestudy-messflix-hypothetical"
              }
            },
            {
              "unversionedId": "storage/data-warehouses",
              "id": "storage/data-warehouses",
              "title": "Data Warehouses",
              "description": "Enterprises are becoming increasingly data driven, and a key component of any enterprise’s data strategy is a data warehouse—a central repository of integrated data from all across the company. Traditionally, the data warehouse was used by data analysts to create analytical reports. But now it is also increasingly used to populate real-time dashboards, to make ad hoc queries, and to provide decision-making guidance through predictive analytics. Because of these business requirements for advanced analytics and a trend toward cost control, agility, and self-service data access, many organizations are moving to cloud-based data warehouses such as Snowfkake, Amazon Redshift and Google BigQuery.",
              "source": "@site/docs/02-storage/data-warehouses.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/data-warehouses",
              "permalink": "/docs/storage/data-warehouses",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Couchdb Movies Data Migration",
                "permalink": "/docs/storage/lab-couchdb-movies-data-migration/"
              },
              "next": {
                "title": "Amazon Athena",
                "permalink": "/docs/storage/athena"
              }
            },
            {
              "unversionedId": "storage/database-links",
              "id": "storage/database-links",
              "title": "Links",
              "description": "- https://learnsql.com/blog/companies-that-use-postgresql-in-business/",
              "source": "@site/docs/02-storage/database-links.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/database-links",
              "permalink": "/docs/storage/database-links",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: SQLite Edu Hipolabs API",
                "permalink": "/docs/storage/lab-sqlite-hipolabs-api/"
              },
              "next": {
                "title": "Cassandra",
                "permalink": "/docs/storage/cassandra"
              }
            },
            {
              "unversionedId": "storage/database-storage-engines",
              "id": "storage/database-storage-engines",
              "title": "Database Storage Engines",
              "description": "To round out the discussion of serialization, we briefly discuss database storage engines. All databases have an underlying storage engine; many don’t expose their storage engines as a separate abstraction (for example, BigQuery, Snowflake). Some (notably, MySQL) support fully pluggable storage engines. Others (e.g., SQL Server) offer major storage engine configuration options (columnar versus row-based storage) that dramatically affect database behavior.",
              "source": "@site/docs/02-storage/database-storage-engines.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/database-storage-engines",
              "permalink": "/docs/storage/database-storage-engines",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Iceberg",
                "permalink": "/docs/storage/iceberg"
              },
              "next": {
                "title": "Avro vs Parquet vs ORC",
                "permalink": "/docs/storage/avro-vs-parquet-vs-orc"
              }
            },
            {
              "unversionedId": "storage/datalakes",
              "id": "storage/datalakes",
              "title": "Data Lakes",
              "description": "What is a Cloud Data Lake Architecture",
              "source": "@site/docs/02-storage/datalakes.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/datalakes",
              "permalink": "/docs/storage/datalakes",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Links",
                "permalink": "/docs/storage/warehouse-links"
              },
              "next": {
                "title": "Why we need Data Lakes?",
                "permalink": "/docs/storage/why-datalakes"
              }
            },
            {
              "unversionedId": "storage/deltalake",
              "id": "storage/deltalake",
              "title": "Deltalake",
              "description": "An open format storage layer for your lakehouses",
              "source": "@site/docs/02-storage/deltalake.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/deltalake",
              "permalink": "/docs/storage/deltalake",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Lakehouses",
                "permalink": "/docs/storage/data-lakehouses"
              },
              "next": {
                "title": "Apache Hudi",
                "permalink": "/docs/storage/apache-hudi"
              }
            },
            {
              "unversionedId": "storage/duckdb",
              "id": "storage/duckdb",
              "title": "DuckDB",
              "description": "DuckDB is a really interesting project aimed at being a SQLite style database with a focus on OLAP (online analytical processing). OLAP is typically associated with analytics due to its design catering to long running queries over large datasets or aggregations over joins of multiple tables with vast amounts of data. DuckDB is an open source project developed by the non-profit organization, DuckDB Labs based in Amsterdam, Netherlands and takes donations and contracting work around their database.",
              "source": "@site/docs/02-storage/duckdb.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/duckdb",
              "permalink": "/docs/storage/duckdb",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "SQLite",
                "permalink": "/docs/storage/sqlite"
              },
              "next": {
                "title": "GCP CloudSQL",
                "permalink": "/docs/storage/gcp-cloudsql"
              }
            },
            {
              "unversionedId": "storage/gcp-bigtable",
              "id": "storage/gcp-bigtable",
              "title": "BigTable",
              "description": "High-throughput streaming with Cloud Bigtable",
              "source": "@site/docs/02-storage/gcp-bigtable.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/gcp-bigtable",
              "permalink": "/docs/storage/gcp-bigtable",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Cassandra",
                "permalink": "/docs/storage/cassandra"
              },
              "next": {
                "title": "DynamoDB",
                "permalink": "/docs/storage/aws-dynamodb"
              }
            },
            {
              "unversionedId": "storage/gcp-cloudsql",
              "id": "storage/gcp-cloudsql",
              "title": "GCP CloudSQL",
              "description": "CloudSQL is a fully managed relational database service for MySQL, PostgreSQL, and SQL Server with rich extension collections, configuration flags, and developer ecosystems.",
              "source": "@site/docs/02-storage/gcp-cloudsql.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/gcp-cloudsql",
              "permalink": "/docs/storage/gcp-cloudsql",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "DuckDB",
                "permalink": "/docs/storage/duckdb"
              },
              "next": {
                "title": "Azure SQL Databases",
                "permalink": "/docs/storage/azure-sql"
              }
            },
            {
              "unversionedId": "storage/gcs",
              "id": "storage/gcs",
              "title": "Google Cloud Storage (GCS)",
              "description": "Google Cloud Storage (GCS) is object storage. It's a service that is fully managed by GCP, which means we don't need to think about any underlying infrastructure for GCS. For example, we don't need to think about pre-sizing the storage, the network bandwidth, number of nodes, or any other infrastructure-related stuff.",
              "source": "@site/docs/02-storage/gcs.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/gcs",
              "permalink": "/docs/storage/gcs",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure Data Lakes",
                "permalink": "/docs/storage/azure-datalake"
              },
              "next": {
                "title": "Lab: Data Lake on S3",
                "permalink": "/docs/storage/lab-datalake-healthcare-s3-glue-athena/"
              }
            },
            {
              "unversionedId": "storage/hudi",
              "id": "storage/hudi",
              "title": "Hudi",
              "description": "Hudi stands for Hadoop Update Delete Incremental. This table management technology combines multiple serialization techniques to allow columnar database performance for analytics queries while also supporting atomic, transactional updates. A typical Hudi application is a table that is updated from a CDC stream from a transactional application database. The stream is captured into a row-oriented serialization format, while the bulk of the table is retained in a columnar format. A query runs over both columnar and row-oriented files to return results for the current state of the table. Periodically, a repacking process runs that combines the row and columnar files into updated columnar files to maximize query efficiency.",
              "source": "@site/docs/02-storage/hudi.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/hudi",
              "permalink": "/docs/storage/hudi",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache Arrow or in-memory serialization",
                "permalink": "/docs/storage/arrow"
              },
              "next": {
                "title": "Iceberg",
                "permalink": "/docs/storage/iceberg"
              }
            },
            {
              "unversionedId": "storage/iceberg",
              "id": "storage/iceberg",
              "title": "Iceberg",
              "description": "Like Hudi, Iceberg is a table management technology. Iceberg can track all files that make up a table. It can also track files in each table snapshot over time, allowing table time travel in a data lake environment. Iceberg supports schema evolution and can readily manage tables at a petabyte scale.",
              "source": "@site/docs/02-storage/iceberg.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/iceberg",
              "permalink": "/docs/storage/iceberg",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Hudi",
                "permalink": "/docs/storage/hudi"
              },
              "next": {
                "title": "Database Storage Engines",
                "permalink": "/docs/storage/database-storage-engines"
              }
            },
            {
              "unversionedId": "storage/interview-questions",
              "id": "storage/interview-questions",
              "title": "Interview Questions",
              "description": "What is a relational database?",
              "source": "@site/docs/02-storage/interview-questions.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/interview-questions",
              "permalink": "/docs/storage/interview-questions",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Azure SQL Databases",
                "permalink": "/docs/storage/azure-sql"
              },
              "next": {
                "title": "Postgres vs MySQL",
                "permalink": "/docs/storage/postgres-vs-mysql"
              }
            },
            {
              "unversionedId": "storage/json",
              "id": "storage/json",
              "title": "JSON and JSONL",
              "description": "JavaScript Object Notation (JSON) has emerged as the new standard for data exchange over APIs, and it has also become an extremely popular format for data storage. In the context of databases, the popularity of JSON has grown apace with the rise of MongoDB and other document stores. Databases such as Snowflake, BigQuery, and SQL Server also offer extensive native support, facilitating easy data exchange between applications, APIs, and database systems.",
              "source": "@site/docs/02-storage/json.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/json",
              "permalink": "/docs/storage/json",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "XML",
                "permalink": "/docs/storage/xml"
              },
              "next": {
                "title": "Avro",
                "permalink": "/docs/storage/avro"
              }
            },
            {
              "unversionedId": "storage/lab-adl-create-manage-data/README",
              "id": "storage/lab-adl-create-manage-data/README",
              "title": "Lab: Creating and Managing Data in Azure Data Lake",
              "description": "Files",
              "source": "@site/docs/02-storage/lab-adl-create-manage-data/README.md",
              "sourceDirName": "02-storage/lab-adl-create-manage-data",
              "slug": "/storage/lab-adl-create-manage-data/",
              "permalink": "/docs/storage/lab-adl-create-manage-data/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Data Lake on S3",
                "permalink": "/docs/storage/lab-datalake-healthcare-s3-glue-athena/"
              },
              "next": {
                "title": "Lab: Azure Data Lake - Securing and Monitoring",
                "permalink": "/docs/storage/lab-adl-securing-monitoring-lakes/"
              }
            },
            {
              "unversionedId": "storage/lab-adl-securing-monitoring-lakes/README",
              "id": "storage/lab-adl-securing-monitoring-lakes/README",
              "title": "Lab: Azure Data Lake - Securing and Monitoring",
              "description": "Data Lake forms the key storage layer for data engineering pipelines. Security and the monitoring of Data Lake accounts are key aspects of Data Lake maintenance. This lab will focus on configuring security controls such as firewalls, encryption, and creating private links to a Data Lake account. By the end of this lab, you will have learned how to configure a firewall, virtual network, and private link to secure the Data Lake, encrypt Data Lake using Azure Key Vault, and monitor key user actions in Data Lake.",
              "source": "@site/docs/02-storage/lab-adl-securing-monitoring-lakes/README.md",
              "sourceDirName": "02-storage/lab-adl-securing-monitoring-lakes",
              "slug": "/storage/lab-adl-securing-monitoring-lakes/",
              "permalink": "/docs/storage/lab-adl-securing-monitoring-lakes/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Creating and Managing Data in Azure Data Lake",
                "permalink": "/docs/storage/lab-adl-create-manage-data/"
              },
              "next": {
                "title": "Data Lakehouses",
                "permalink": "/docs/storage/data-lakehouses"
              }
            },
            {
              "unversionedId": "storage/lab-amazon-keyspaces/README",
              "id": "storage/lab-amazon-keyspaces/README",
              "title": "Lab: Amazon Keyspaces",
              "description": "Setup",
              "source": "@site/docs/02-storage/lab-amazon-keyspaces/README.md",
              "sourceDirName": "02-storage/lab-amazon-keyspaces",
              "slug": "/storage/lab-amazon-keyspaces/",
              "permalink": "/docs/storage/lab-amazon-keyspaces/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: GCP Streaming Bigtable",
                "permalink": "/docs/storage/lab-gcp-streaming-bigtable/"
              },
              "next": {
                "title": "Lab: Intro to DynamoDB",
                "permalink": "/docs/storage/lab-intro-to-dynamodb/"
              }
            },
            {
              "unversionedId": "storage/lab-aws-rds-service/README",
              "id": "storage/lab-aws-rds-service/README",
              "title": "Lab: AWS RDS Service",
              "description": "1. Create database in RDS DBMS and generate credentials",
              "source": "@site/docs/02-storage/lab-aws-rds-service/README.md",
              "sourceDirName": "02-storage/lab-aws-rds-service",
              "slug": "/storage/lab-aws-rds-service/",
              "permalink": "/docs/storage/lab-aws-rds-service/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Postgres vs MySQL",
                "permalink": "/docs/storage/postgres-vs-mysql"
              },
              "next": {
                "title": "Lab: Data Ingestion to MySQL",
                "permalink": "/docs/storage/lab-mysql-data-ingestion/"
              }
            },
            {
              "unversionedId": "storage/lab-azure-sql-securing-databases/README",
              "id": "storage/lab-azure-sql-securing-databases/README",
              "title": "Lab: Configuring and Securing Azure SQL Database",
              "description": "Azure SQL Database, a fundamental relational database as a service offered in Azure, acts as a source, destination, or even as an intermediate storage layer in data engineering pipelines. Azure SQL Database can be used to consolidate data coming from several relational data sources and build mini data warehouses or data marts. With the introduction of Hyperscale tier in Azure SQL Database, the capacity of Azure SQL Database has increased leaps and bounds too. Securing Azure SQL Database is also pivotal in protecting access to the database. Having a strong understanding of Azure SQL Database's capabilities and security options is essential for any data engineer.",
              "source": "@site/docs/02-storage/lab-azure-sql-securing-databases/README.md",
              "sourceDirName": "02-storage/lab-azure-sql-securing-databases",
              "slug": "/storage/lab-azure-sql-securing-databases/",
              "permalink": "/docs/storage/lab-azure-sql-securing-databases/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Loading Taxi Data into Google Cloud SQL",
                "permalink": "/docs/storage/lab-gcp-cloudsql-nyctaxi/"
              },
              "next": {
                "title": "db2",
                "permalink": "/docs/storage/lab-db2-bookshop-petsale-data-ingestion/"
              }
            },
            {
              "unversionedId": "storage/lab-bigquery-analysis/README",
              "id": "storage/lab-bigquery-analysis/README",
              "title": "BigQuery Analysis",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-bigquery-analysis/README.md",
              "sourceDirName": "02-storage/lab-bigquery-analysis",
              "slug": "/storage/lab-bigquery-analysis/",
              "permalink": "/docs/storage/lab-bigquery-analysis/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-bigquery-commandline/README",
              "id": "storage/lab-bigquery-commandline/README",
              "title": "BigQuery Commandline",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-bigquery-commandline/README.md",
              "sourceDirName": "02-storage/lab-bigquery-commandline",
              "slug": "/storage/lab-bigquery-commandline/",
              "permalink": "/docs/storage/lab-bigquery-commandline/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-bigquery-composer/README",
              "id": "storage/lab-bigquery-composer/README",
              "title": "GCP BigQuery Composer",
              "description": "Cloud Composer - Copying BigQuery Tables Across Different Locations",
              "source": "@site/docs/02-storage/lab-bigquery-composer/README.md",
              "sourceDirName": "02-storage/lab-bigquery-composer",
              "slug": "/storage/lab-bigquery-composer/",
              "permalink": "/docs/storage/lab-bigquery-composer/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-bigquery-data-warehousing/README",
              "id": "storage/lab-bigquery-data-warehousing/README",
              "title": "BigQuery Data Warehousing",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-bigquery-data-warehousing/README.md",
              "sourceDirName": "02-storage/lab-bigquery-data-warehousing",
              "slug": "/storage/lab-bigquery-data-warehousing/",
              "permalink": "/docs/storage/lab-bigquery-data-warehousing/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-bigquery-ml/README",
              "id": "storage/lab-bigquery-ml/README",
              "title": "GCP BigQuery ML",
              "description": "Predict Visitor Purchases with a Classification Model in BigQuery ML",
              "source": "@site/docs/02-storage/lab-bigquery-ml/README.md",
              "sourceDirName": "02-storage/lab-bigquery-ml",
              "slug": "/storage/lab-bigquery-ml/",
              "permalink": "/docs/storage/lab-bigquery-ml/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-bigquery-nyctaxi/README",
              "id": "storage/lab-bigquery-nyctaxi/README",
              "title": "GCP BigQuery NYC Taxi",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-bigquery-nyctaxi/README.md",
              "sourceDirName": "02-storage/lab-bigquery-nyctaxi",
              "slug": "/storage/lab-bigquery-nyctaxi/",
              "permalink": "/docs/storage/lab-bigquery-nyctaxi/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-bigquery-optimization/README",
              "id": "storage/lab-bigquery-optimization/README",
              "title": "BigQuery Optimization",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-bigquery-optimization/README.md",
              "sourceDirName": "02-storage/lab-bigquery-optimization",
              "slug": "/storage/lab-bigquery-optimization/",
              "permalink": "/docs/storage/lab-bigquery-optimization/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-bigquery-query-optimization/README",
              "id": "storage/lab-bigquery-query-optimization/README",
              "title": "GCP Bigquery Query Optimization",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-bigquery-query-optimization/README.md",
              "sourceDirName": "02-storage/lab-bigquery-query-optimization",
              "slug": "/storage/lab-bigquery-query-optimization/",
              "permalink": "/docs/storage/lab-bigquery-query-optimization/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-biqeury-building-warehouse/README",
              "id": "storage/lab-biqeury-building-warehouse/README",
              "title": "Building a BigQuery Data Warehouse",
              "description": "Introduction",
              "source": "@site/docs/02-storage/lab-biqeury-building-warehouse/README.md",
              "sourceDirName": "02-storage/lab-biqeury-building-warehouse",
              "slug": "/storage/lab-biqeury-building-warehouse/",
              "permalink": "/docs/storage/lab-biqeury-building-warehouse/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-couchdb-movies-data-migration/README",
              "id": "storage/lab-couchdb-movies-data-migration/README",
              "title": "Lab: Couchdb Movies Data Migration",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-couchdb-movies-data-migration/README.md",
              "sourceDirName": "02-storage/lab-couchdb-movies-data-migration",
              "slug": "/storage/lab-couchdb-movies-data-migration/",
              "permalink": "/docs/storage/lab-couchdb-movies-data-migration/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: MongoDB Basics",
                "permalink": "/docs/storage/lab-mongodb-basics/"
              },
              "next": {
                "title": "Data Warehouses",
                "permalink": "/docs/storage/data-warehouses"
              }
            },
            {
              "unversionedId": "storage/lab-data-loading-python/README",
              "id": "storage/lab-data-loading-python/README",
              "title": "Lab: Loading Data in Python",
              "description": "In this lab, we will learn how to load various file formats in Python.",
              "source": "@site/docs/02-storage/lab-data-loading-python/README.md",
              "sourceDirName": "02-storage/lab-data-loading-python",
              "slug": "/storage/lab-data-loading-python/",
              "permalink": "/docs/storage/lab-data-loading-python/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Parquet vs CSV",
                "permalink": "/docs/storage/parquet-vs-csv"
              },
              "next": {
                "title": "Lab: JSON Data Processing",
                "permalink": "/docs/storage/lab-processing-json-data/"
              }
            },
            {
              "unversionedId": "storage/lab-datalake-healthcare-s3-glue-athena/README",
              "id": "storage/lab-datalake-healthcare-s3-glue-athena/README",
              "title": "Lab: Data Lake on S3",
              "description": "Process flow",
              "source": "@site/docs/02-storage/lab-datalake-healthcare-s3-glue-athena/README.md",
              "sourceDirName": "02-storage/lab-datalake-healthcare-s3-glue-athena",
              "slug": "/storage/lab-datalake-healthcare-s3-glue-athena/",
              "permalink": "/docs/storage/lab-datalake-healthcare-s3-glue-athena/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Google Cloud Storage (GCS)",
                "permalink": "/docs/storage/gcs"
              },
              "next": {
                "title": "Lab: Creating and Managing Data in Azure Data Lake",
                "permalink": "/docs/storage/lab-adl-create-manage-data/"
              }
            },
            {
              "unversionedId": "storage/lab-db2-bookshop-petsale-data-ingestion/README",
              "id": "storage/lab-db2-bookshop-petsale-data-ingestion/README",
              "title": "db2",
              "description": "db2 BookShop and PetSale Data Ingestion and Stored Procedure",
              "source": "@site/docs/02-storage/lab-db2-bookshop-petsale-data-ingestion/README.md",
              "sourceDirName": "02-storage/lab-db2-bookshop-petsale-data-ingestion",
              "slug": "/storage/lab-db2-bookshop-petsale-data-ingestion/",
              "permalink": "/docs/storage/lab-db2-bookshop-petsale-data-ingestion/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Configuring and Securing Azure SQL Database",
                "permalink": "/docs/storage/lab-azure-sql-securing-databases/"
              },
              "next": {
                "title": "Lab: DuckDB",
                "permalink": "/docs/storage/lab-duckdb-analytics-bank-tpch-nyctaxi/"
              }
            },
            {
              "unversionedId": "storage/lab-duckdb-analytics-bank-tpch-nyctaxi/README",
              "id": "storage/lab-duckdb-analytics-bank-tpch-nyctaxi/README",
              "title": "Lab: DuckDB",
              "description": "OLAP Analytics on bank, TPCH and NYC Taxi datasets using DuckDB",
              "source": "@site/docs/02-storage/lab-duckdb-analytics-bank-tpch-nyctaxi/README.md",
              "sourceDirName": "02-storage/lab-duckdb-analytics-bank-tpch-nyctaxi",
              "slug": "/storage/lab-duckdb-analytics-bank-tpch-nyctaxi/",
              "permalink": "/docs/storage/lab-duckdb-analytics-bank-tpch-nyctaxi/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "db2",
                "permalink": "/docs/storage/lab-db2-bookshop-petsale-data-ingestion/"
              },
              "next": {
                "title": "Lab: SQLite Edu Hipolabs API",
                "permalink": "/docs/storage/lab-sqlite-hipolabs-api/"
              }
            },
            {
              "unversionedId": "storage/lab-gcp-cloudsql-nyctaxi/README",
              "id": "storage/lab-gcp-cloudsql-nyctaxi/README",
              "title": "Lab: Loading Taxi Data into Google Cloud SQL",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-gcp-cloudsql-nyctaxi/README.md",
              "sourceDirName": "02-storage/lab-gcp-cloudsql-nyctaxi",
              "slug": "/storage/lab-gcp-cloudsql-nyctaxi/",
              "permalink": "/docs/storage/lab-gcp-cloudsql-nyctaxi/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Police API",
                "permalink": "/docs/storage/lab-mysql-police-api-etl/"
              },
              "next": {
                "title": "Lab: Configuring and Securing Azure SQL Database",
                "permalink": "/docs/storage/lab-azure-sql-securing-databases/"
              }
            },
            {
              "unversionedId": "storage/lab-gcp-streaming-bigtable/README",
              "id": "storage/lab-gcp-streaming-bigtable/README",
              "title": "Lab: GCP Streaming Bigtable",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-gcp-streaming-bigtable/README.md",
              "sourceDirName": "02-storage/lab-gcp-streaming-bigtable",
              "slug": "/storage/lab-gcp-streaming-bigtable/",
              "permalink": "/docs/storage/lab-gcp-streaming-bigtable/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Getting started with Cassandra",
                "permalink": "/docs/storage/lab-getting-started-with-cassandra/"
              },
              "next": {
                "title": "Lab: Amazon Keyspaces",
                "permalink": "/docs/storage/lab-amazon-keyspaces/"
              }
            },
            {
              "unversionedId": "storage/lab-getting-started-with-cassandra/cassandra-cli",
              "id": "storage/lab-getting-started-with-cassandra/cassandra-cli",
              "title": "Working with Cassandra and CLI",
              "description": "Cassandra and Shell",
              "source": "@site/docs/02-storage/lab-getting-started-with-cassandra/cassandra-cli.md",
              "sourceDirName": "02-storage/lab-getting-started-with-cassandra",
              "slug": "/storage/lab-getting-started-with-cassandra/cassandra-cli",
              "permalink": "/docs/storage/lab-getting-started-with-cassandra/cassandra-cli",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-getting-started-with-cassandra/getting-started",
              "id": "storage/lab-getting-started-with-cassandra/getting-started",
              "title": "Cassandra Getting Started",
              "description": "NoSQL data modeling and analysis with Apache Cassandra",
              "source": "@site/docs/02-storage/lab-getting-started-with-cassandra/getting-started.md",
              "sourceDirName": "02-storage/lab-getting-started-with-cassandra",
              "slug": "/storage/lab-getting-started-with-cassandra/getting-started",
              "permalink": "/docs/storage/lab-getting-started-with-cassandra/getting-started",
              "draft": false,
              "tags": [
                {
                  "label": "cassandra",
                  "permalink": "/docs/tags/cassandra"
                },
                {
                  "label": "cql",
                  "permalink": "/docs/tags/cql"
                },
                {
                  "label": "keyspaces",
                  "permalink": "/docs/tags/keyspaces"
                }
              ],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {
                "title": "Cassandra Getting Started",
                "description": "NoSQL data modeling and analysis with Apache Cassandra",
                "tags": [
                  "cassandra",
                  "cql",
                  "keyspaces"
                ]
              }
            },
            {
              "unversionedId": "storage/lab-getting-started-with-cassandra/README",
              "id": "storage/lab-getting-started-with-cassandra/README",
              "title": "Lab: Getting started with Cassandra",
              "description": "Notebooks",
              "source": "@site/docs/02-storage/lab-getting-started-with-cassandra/README.md",
              "sourceDirName": "02-storage/lab-getting-started-with-cassandra",
              "slug": "/storage/lab-getting-started-with-cassandra/",
              "permalink": "/docs/storage/lab-getting-started-with-cassandra/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "MongoDB",
                "permalink": "/docs/storage/mongodb"
              },
              "next": {
                "title": "Lab: GCP Streaming Bigtable",
                "permalink": "/docs/storage/lab-gcp-streaming-bigtable/"
              }
            },
            {
              "unversionedId": "storage/lab-glue-emr-iceberg-serverless-lakehouse/README",
              "id": "storage/lab-glue-emr-iceberg-serverless-lakehouse/README",
              "title": "Lab: Build an Iceberg Lakehouse",
              "description": "Build a serverless transactional data lake with Apache Iceberg, Amazon EMR Serverless, and Amazon Athena",
              "source": "@site/docs/02-storage/lab-glue-emr-iceberg-serverless-lakehouse/README.md",
              "sourceDirName": "02-storage/lab-glue-emr-iceberg-serverless-lakehouse",
              "slug": "/storage/lab-glue-emr-iceberg-serverless-lakehouse/",
              "permalink": "/docs/storage/lab-glue-emr-iceberg-serverless-lakehouse/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Read Delta Tables stored in Amazon S3 with Python",
                "permalink": "/docs/storage/lab-read-s3-delta-in-python/"
              },
              "next": {
                "title": "Lab: The Easy Ways to Clean Up Production Messes",
                "permalink": "/docs/storage/lab-production-cleaning-deltalake/"
              }
            },
            {
              "unversionedId": "storage/lab-intro-to-dynamodb/README",
              "id": "storage/lab-intro-to-dynamodb/README",
              "title": "Lab: Intro to DynamoDB",
              "description": "Description",
              "source": "@site/docs/02-storage/lab-intro-to-dynamodb/README.md",
              "sourceDirName": "02-storage/lab-intro-to-dynamodb",
              "slug": "/storage/lab-intro-to-dynamodb/",
              "permalink": "/docs/storage/lab-intro-to-dynamodb/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Amazon Keyspaces",
                "permalink": "/docs/storage/lab-amazon-keyspaces/"
              },
              "next": {
                "title": "Lab: MongoDB Basics",
                "permalink": "/docs/storage/lab-mongodb-basics/"
              }
            },
            {
              "unversionedId": "storage/lab-mongodb-basics/README",
              "id": "storage/lab-mongodb-basics/README",
              "title": "Lab: MongoDB Basics",
              "description": "Environment Setup",
              "source": "@site/docs/02-storage/lab-mongodb-basics/README.md",
              "sourceDirName": "02-storage/lab-mongodb-basics",
              "slug": "/storage/lab-mongodb-basics/",
              "permalink": "/docs/storage/lab-mongodb-basics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Intro to DynamoDB",
                "permalink": "/docs/storage/lab-intro-to-dynamodb/"
              },
              "next": {
                "title": "Lab: Couchdb Movies Data Migration",
                "permalink": "/docs/storage/lab-couchdb-movies-data-migration/"
              }
            },
            {
              "unversionedId": "storage/lab-mongodb-pandas/README",
              "id": "storage/lab-mongodb-pandas/README",
              "title": "MongoDB to CSV conversion",
              "description": "Pull a noSQL data from MongoDB and convert into Pandas dataframe",
              "source": "@site/docs/02-storage/lab-mongodb-pandas/README.md",
              "sourceDirName": "02-storage/lab-mongodb-pandas",
              "slug": "/storage/lab-mongodb-pandas/",
              "permalink": "/docs/storage/lab-mongodb-pandas/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-mysql-data-ingestion/README",
              "id": "storage/lab-mysql-data-ingestion/README",
              "title": "Lab: Data Ingestion to MySQL",
              "description": "Process Flow",
              "source": "@site/docs/02-storage/lab-mysql-data-ingestion/README.md",
              "sourceDirName": "02-storage/lab-mysql-data-ingestion",
              "slug": "/storage/lab-mysql-data-ingestion/",
              "permalink": "/docs/storage/lab-mysql-data-ingestion/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: AWS RDS Service",
                "permalink": "/docs/storage/lab-aws-rds-service/"
              },
              "next": {
                "title": "Lab: SQLite Basics",
                "permalink": "/docs/storage/lab-sqlite-basics/"
              }
            },
            {
              "unversionedId": "storage/lab-mysql-police-api-etl/README",
              "id": "storage/lab-mysql-police-api-etl/README",
              "title": "Lab: Police API",
              "description": "Using the Police UK API extracted the data related to street-level crime and outcome data and nearest police stations",
              "source": "@site/docs/02-storage/lab-mysql-police-api-etl/README.md",
              "sourceDirName": "02-storage/lab-mysql-police-api-etl",
              "slug": "/storage/lab-mysql-police-api-etl/",
              "permalink": "/docs/storage/lab-mysql-police-api-etl/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Generate Trips Data using Stored Procedure",
                "permalink": "/docs/storage/lab-postgres-trips-stored-procedure/"
              },
              "next": {
                "title": "Lab: Loading Taxi Data into Google Cloud SQL",
                "permalink": "/docs/storage/lab-gcp-cloudsql-nyctaxi/"
              }
            },
            {
              "unversionedId": "storage/lab-postgres-bash-etl/README",
              "id": "storage/lab-postgres-bash-etl/README",
              "title": "Lab: ETL with bash script",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-postgres-bash-etl/README.md",
              "sourceDirName": "02-storage/lab-postgres-bash-etl",
              "slug": "/storage/lab-postgres-bash-etl/",
              "permalink": "/docs/storage/lab-postgres-bash-etl/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Getting Started with Postgres",
                "permalink": "/docs/storage/lab-postgres-getting-started/"
              },
              "next": {
                "title": "Lab: Postgres Crime Reports",
                "permalink": "/docs/storage/lab-postgres-crime-reports/"
              }
            },
            {
              "unversionedId": "storage/lab-postgres-crime-reports/README",
              "id": "storage/lab-postgres-crime-reports/README",
              "title": "Lab: Postgres Crime Reports",
              "description": "Building a Database for Crime Reports",
              "source": "@site/docs/02-storage/lab-postgres-crime-reports/README.md",
              "sourceDirName": "02-storage/lab-postgres-crime-reports",
              "slug": "/storage/lab-postgres-crime-reports/",
              "permalink": "/docs/storage/lab-postgres-crime-reports/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: ETL with bash script",
                "permalink": "/docs/storage/lab-postgres-bash-etl/"
              },
              "next": {
                "title": "Lab: Generate Trips Data using Stored Procedure",
                "permalink": "/docs/storage/lab-postgres-trips-stored-procedure/"
              }
            },
            {
              "unversionedId": "storage/lab-postgres-getting-started/README",
              "id": "storage/lab-postgres-getting-started/README",
              "title": "Lab: Getting Started with Postgres",
              "description": "Notebooks",
              "source": "@site/docs/02-storage/lab-postgres-getting-started/README.md",
              "sourceDirName": "02-storage/lab-postgres-getting-started",
              "slug": "/storage/lab-postgres-getting-started/",
              "permalink": "/docs/storage/lab-postgres-getting-started/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: SQLite Basics",
                "permalink": "/docs/storage/lab-sqlite-basics/"
              },
              "next": {
                "title": "Lab: ETL with bash script",
                "permalink": "/docs/storage/lab-postgres-bash-etl/"
              }
            },
            {
              "unversionedId": "storage/lab-postgres-trips-stored-procedure/README",
              "id": "storage/lab-postgres-trips-stored-procedure/README",
              "title": "Lab: Generate Trips Data using Stored Procedure",
              "description": "- Step 1 - Connect to the database",
              "source": "@site/docs/02-storage/lab-postgres-trips-stored-procedure/README.md",
              "sourceDirName": "02-storage/lab-postgres-trips-stored-procedure",
              "slug": "/storage/lab-postgres-trips-stored-procedure/",
              "permalink": "/docs/storage/lab-postgres-trips-stored-procedure/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Postgres Crime Reports",
                "permalink": "/docs/storage/lab-postgres-crime-reports/"
              },
              "next": {
                "title": "Lab: Police API",
                "permalink": "/docs/storage/lab-mysql-police-api-etl/"
              }
            },
            {
              "unversionedId": "storage/lab-processing-json-data/README",
              "id": "storage/lab-processing-json-data/README",
              "title": "Lab: JSON Data Processing",
              "description": "In this lab, we will learn how to process JSON data.",
              "source": "@site/docs/02-storage/lab-processing-json-data/README.md",
              "sourceDirName": "02-storage/lab-processing-json-data",
              "slug": "/storage/lab-processing-json-data/",
              "permalink": "/docs/storage/lab-processing-json-data/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Loading Data in Python",
                "permalink": "/docs/storage/lab-data-loading-python/"
              },
              "next": {
                "title": "Postgres",
                "permalink": "/docs/storage/postgres"
              }
            },
            {
              "unversionedId": "storage/lab-production-cleaning-deltalake/README",
              "id": "storage/lab-production-cleaning-deltalake/README",
              "title": "Lab: The Easy Ways to Clean Up Production Messes",
              "description": "When it comes to working with production data, messes are bound to happen. Whether it’s data inconsistency, schema errors, or other issues, cleaning up production messes can be a time-consuming and frustrating process. Fortunately, Delta Lake provides a powerful toolset for handling these types of issues, making it easy to fix production messes quickly and efficiently.",
              "source": "@site/docs/02-storage/lab-production-cleaning-deltalake/README.md",
              "sourceDirName": "02-storage/lab-production-cleaning-deltalake",
              "slug": "/storage/lab-production-cleaning-deltalake/",
              "permalink": "/docs/storage/lab-production-cleaning-deltalake/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Build an Iceberg Lakehouse",
                "permalink": "/docs/storage/lab-glue-emr-iceberg-serverless-lakehouse/"
              },
              "next": {
                "title": "Lab: SCD in Lakehouse",
                "permalink": "/docs/storage/lab-scd-glue-delta/"
              }
            },
            {
              "unversionedId": "storage/lab-read-s3-delta-in-python/README",
              "id": "storage/lab-read-s3-delta-in-python/README",
              "title": "Lab: Read Delta Tables stored in Amazon S3 with Python",
              "description": "",
              "source": "@site/docs/02-storage/lab-read-s3-delta-in-python/README.md",
              "sourceDirName": "02-storage/lab-read-s3-delta-in-python",
              "slug": "/storage/lab-read-s3-delta-in-python/",
              "permalink": "/docs/storage/lab-read-s3-delta-in-python/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache Iceberg",
                "permalink": "/docs/storage/apache-iceberg"
              },
              "next": {
                "title": "Lab: Build an Iceberg Lakehouse",
                "permalink": "/docs/storage/lab-glue-emr-iceberg-serverless-lakehouse/"
              }
            },
            {
              "unversionedId": "storage/lab-redshift-data-loading",
              "id": "storage/lab-redshift-data-loading",
              "title": "Lab: Data Loading into Redshift",
              "description": "Load with COPY command",
              "source": "@site/docs/02-storage/lab-redshift-data-loading.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-redshift-data-loading",
              "permalink": "/docs/storage/lab-redshift-data-loading",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Amazon Redshift",
                "permalink": "/docs/storage/redshift"
              },
              "next": {
                "title": "Lab: Redshift Data Loading and Analysis",
                "permalink": "/docs/storage/lab-redshift-data-loading-analysis"
              }
            },
            {
              "unversionedId": "storage/lab-redshift-data-loading-analysis",
              "id": "storage/lab-redshift-data-loading-analysis",
              "title": "Lab: Redshift Data Loading and Analysis",
              "description": "1. Load csv and json data from S3 into Redshift using COPY command",
              "source": "@site/docs/02-storage/lab-redshift-data-loading-analysis.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-redshift-data-loading-analysis",
              "permalink": "/docs/storage/lab-redshift-data-loading-analysis",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Data Loading into Redshift",
                "permalink": "/docs/storage/lab-redshift-data-loading"
              },
              "next": {
                "title": "Lab: Redshift Table Design and Query Tuning",
                "permalink": "/docs/storage/lab-redshift-table-design-query-tuning"
              }
            },
            {
              "unversionedId": "storage/lab-redshift-immersion/README",
              "id": "storage/lab-redshift-immersion/README",
              "title": "Redshift Advanced",
              "description": "Data Load with Redshift Spectrum",
              "source": "@site/docs/02-storage/lab-redshift-immersion/README.md",
              "sourceDirName": "02-storage/lab-redshift-immersion",
              "slug": "/storage/lab-redshift-immersion/",
              "permalink": "/docs/storage/lab-redshift-immersion/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-redshift-ml/README",
              "id": "storage/lab-redshift-ml/README",
              "title": "Amazon Redshift ML",
              "description": "In this Lab, we will Create, Train and Deploy Multi Layer Perceptron (MLP) models using Amazon Redshift ML.",
              "source": "@site/docs/02-storage/lab-redshift-ml/README.md",
              "sourceDirName": "02-storage/lab-redshift-ml",
              "slug": "/storage/lab-redshift-ml/",
              "permalink": "/docs/storage/lab-redshift-ml/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-redshift-ongoing-load-elt",
              "id": "storage/lab-redshift-ongoing-load-elt",
              "title": "Lab: Redshift Ongoing Load - ELT",
              "description": "This lab demonstrates how you can modernize your ongoing data loads using Stored Procedures, Materialized Views and Pre-defined Functions to transform data within Redshift.",
              "source": "@site/docs/02-storage/lab-redshift-ongoing-load-elt.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-redshift-ongoing-load-elt",
              "permalink": "/docs/storage/lab-redshift-ongoing-load-elt",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Redshift Slowly Changing Dimension",
                "permalink": "/docs/storage/lab-redshift-scd-2"
              },
              "next": {
                "title": "Lab: Redshift Spectrum Query Data Lake",
                "permalink": "/docs/storage/lab-redshift-spectrum-query-datalake"
              }
            },
            {
              "unversionedId": "storage/lab-redshift-scd",
              "id": "storage/lab-redshift-scd",
              "title": "Lab: Implement a slowly changing dimension in Redshift",
              "description": "1. Learn how to create a type 2 dimension table by adding slowly changing tracking columns",
              "source": "@site/docs/02-storage/lab-redshift-scd.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-redshift-scd",
              "permalink": "/docs/storage/lab-redshift-scd",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Redshift Table Design and Query Tuning",
                "permalink": "/docs/storage/lab-redshift-table-design-query-tuning"
              },
              "next": {
                "title": "Lab: Redshift Slowly Changing Dimension",
                "permalink": "/docs/storage/lab-redshift-scd-2"
              }
            },
            {
              "unversionedId": "storage/lab-redshift-scd-2",
              "id": "storage/lab-redshift-scd-2",
              "title": "Lab: Redshift Slowly Changing Dimension",
              "description": "Data loading into a SCD table involves a first-time bulk data loading, referred to as the initial data load. This is followed by continuous or regular data loading, referred to as an incremental data load, to keep the records up to date with changes in the source tables.",
              "source": "@site/docs/02-storage/lab-redshift-scd-2.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-redshift-scd-2",
              "permalink": "/docs/storage/lab-redshift-scd-2",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Implement a slowly changing dimension in Redshift",
                "permalink": "/docs/storage/lab-redshift-scd"
              },
              "next": {
                "title": "Lab: Redshift Ongoing Load - ELT",
                "permalink": "/docs/storage/lab-redshift-ongoing-load-elt"
              }
            },
            {
              "unversionedId": "storage/lab-redshift-spectrum-query-datalake",
              "id": "storage/lab-redshift-spectrum-query-datalake",
              "title": "Lab: Redshift Spectrum Query Data Lake",
              "description": "In this lab, we show you how to query data in your Amazon S3 data lake with Amazon Redshift without loading or moving data. We will also demonstrate how you can leverage views which union data in Redshift Managed storage with data in S3. You can query structured and semi-structured data from files in Amazon S3 without having to copy or move data into Amazon Redshift tables.",
              "source": "@site/docs/02-storage/lab-redshift-spectrum-query-datalake.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-redshift-spectrum-query-datalake",
              "permalink": "/docs/storage/lab-redshift-spectrum-query-datalake",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Redshift Ongoing Load - ELT",
                "permalink": "/docs/storage/lab-redshift-ongoing-load-elt"
              },
              "next": {
                "title": "Lab: Redshift Spectrum Query Tuning",
                "permalink": "/docs/storage/lab-redshift-spectrum-query-tuning"
              }
            },
            {
              "unversionedId": "storage/lab-redshift-spectrum-query-tuning",
              "id": "storage/lab-redshift-spectrum-query-tuning",
              "title": "Lab: Redshift Spectrum Query Tuning",
              "description": "In this lab, we show you how to diagnose your Redshift Spectrum query performance and optimize performance by leveraging partitions, optimizing storage, and predicate pushdown.",
              "source": "@site/docs/02-storage/lab-redshift-spectrum-query-tuning.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-redshift-spectrum-query-tuning",
              "permalink": "/docs/storage/lab-redshift-spectrum-query-tuning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Redshift Spectrum Query Data Lake",
                "permalink": "/docs/storage/lab-redshift-spectrum-query-datalake"
              },
              "next": {
                "title": "BigQuery",
                "permalink": "/docs/storage/bigquery"
              }
            },
            {
              "unversionedId": "storage/lab-redshift-table-design-query-tuning",
              "id": "storage/lab-redshift-table-design-query-tuning",
              "title": "Lab: Redshift Table Design and Query Tuning",
              "description": "1. Setting distribution and sort keys",
              "source": "@site/docs/02-storage/lab-redshift-table-design-query-tuning.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-redshift-table-design-query-tuning",
              "permalink": "/docs/storage/lab-redshift-table-design-query-tuning",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Redshift Data Loading and Analysis",
                "permalink": "/docs/storage/lab-redshift-data-loading-analysis"
              },
              "next": {
                "title": "Lab: Implement a slowly changing dimension in Redshift",
                "permalink": "/docs/storage/lab-redshift-scd"
              }
            },
            {
              "unversionedId": "storage/lab-scd-glue-delta/README",
              "id": "storage/lab-scd-glue-delta/README",
              "title": "Lab: SCD in Lakehouse",
              "description": "Implement slowly changing dimensions in a data lake using AWS Glue and Delta",
              "source": "@site/docs/02-storage/lab-scd-glue-delta/README.md",
              "sourceDirName": "02-storage/lab-scd-glue-delta",
              "slug": "/storage/lab-scd-glue-delta/",
              "permalink": "/docs/storage/lab-scd-glue-delta/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: The Easy Ways to Clean Up Production Messes",
                "permalink": "/docs/storage/lab-production-cleaning-deltalake/"
              },
              "next": {
                "title": "Data Mesh Basics",
                "permalink": "/docs/storage/data-mesh-basics"
              }
            },
            {
              "unversionedId": "storage/lab-snowflake-getting-started/README",
              "id": "storage/lab-snowflake-getting-started/README",
              "title": "Snowflake Getting Started",
              "description": "Connect to Snowflake using Python",
              "source": "@site/docs/02-storage/lab-snowflake-getting-started/README.md",
              "sourceDirName": "02-storage/lab-snowflake-getting-started",
              "slug": "/storage/lab-snowflake-getting-started/",
              "permalink": "/docs/storage/lab-snowflake-getting-started/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-snowflake-snowsql/README",
              "id": "storage/lab-snowflake-snowsql/README",
              "title": "Snowflake SnowSQL",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-snowflake-snowsql/README.md",
              "sourceDirName": "02-storage/lab-snowflake-snowsql",
              "slug": "/storage/lab-snowflake-snowsql/",
              "permalink": "/docs/storage/lab-snowflake-snowsql/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-snowpark-churn/README",
              "id": "storage/lab-snowpark-churn/README",
              "title": "Snowpark Churn",
              "description": "Links",
              "source": "@site/docs/02-storage/lab-snowpark-churn/README.md",
              "sourceDirName": "02-storage/lab-snowpark-churn",
              "slug": "/storage/lab-snowpark-churn/",
              "permalink": "/docs/storage/lab-snowpark-churn/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/lab-sqlite-basics/README",
              "id": "storage/lab-sqlite-basics/README",
              "title": "Lab: SQLite Basics",
              "description": "The following entity-relationship- (ER) diagram for the books database shows the database’s tables and the relationships among them:",
              "source": "@site/docs/02-storage/lab-sqlite-basics/README.md",
              "sourceDirName": "02-storage/lab-sqlite-basics",
              "slug": "/storage/lab-sqlite-basics/",
              "permalink": "/docs/storage/lab-sqlite-basics/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Data Ingestion to MySQL",
                "permalink": "/docs/storage/lab-mysql-data-ingestion/"
              },
              "next": {
                "title": "Lab: Getting Started with Postgres",
                "permalink": "/docs/storage/lab-postgres-getting-started/"
              }
            },
            {
              "unversionedId": "storage/lab-sqlite-hipolabs-api/README",
              "id": "storage/lab-sqlite-hipolabs-api/README",
              "title": "Lab: SQLite Edu Hipolabs API",
              "description": "Objective",
              "source": "@site/docs/02-storage/lab-sqlite-hipolabs-api/README.md",
              "sourceDirName": "02-storage/lab-sqlite-hipolabs-api",
              "slug": "/storage/lab-sqlite-hipolabs-api/",
              "permalink": "/docs/storage/lab-sqlite-hipolabs-api/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: DuckDB",
                "permalink": "/docs/storage/lab-duckdb-analytics-bank-tpch-nyctaxi/"
              },
              "next": {
                "title": "Links",
                "permalink": "/docs/storage/database-links"
              }
            },
            {
              "unversionedId": "storage/lab-zero-to-snowflake",
              "id": "storage/lab-zero-to-snowflake",
              "title": "Getting Started with Snowflake - Zero to Snowflake",
              "description": "Follow this:",
              "source": "@site/docs/02-storage/lab-zero-to-snowflake.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/lab-zero-to-snowflake",
              "permalink": "/docs/storage/lab-zero-to-snowflake",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "storage/mongodb",
              "id": "storage/mongodb",
              "title": "MongoDB",
              "description": "",
              "source": "@site/docs/02-storage/mongodb.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/mongodb",
              "permalink": "/docs/storage/mongodb",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache CouchDB",
                "permalink": "/docs/storage/apache-couchdb"
              },
              "next": {
                "title": "Lab: Getting started with Cassandra",
                "permalink": "/docs/storage/lab-getting-started-with-cassandra/"
              }
            },
            {
              "unversionedId": "storage/mysql",
              "id": "storage/mysql",
              "title": "MySQL",
              "description": "",
              "source": "@site/docs/02-storage/mysql.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/mysql",
              "permalink": "/docs/storage/mysql",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Postgres",
                "permalink": "/docs/storage/postgres"
              },
              "next": {
                "title": "SQLite",
                "permalink": "/docs/storage/sqlite"
              }
            },
            {
              "unversionedId": "storage/orc",
              "id": "storage/orc",
              "title": "ORC",
              "description": "Optimized Row Columnar (ORC) is a columnar storage format similar to Parquet. ORC was very popular for use with Apache Hive; while still widely used, we generally see it much less than Apache Parquet, and it enjoys somewhat less support in modern cloud ecosystem tools. For example, Snowflake and BigQuery support Parquet file import and export; while they can read from ORC files, neither tool can export to ORC.",
              "source": "@site/docs/02-storage/orc.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/orc",
              "permalink": "/docs/storage/orc",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Parquet",
                "permalink": "/docs/storage/parquet"
              },
              "next": {
                "title": "Apache Arrow or in-memory serialization",
                "permalink": "/docs/storage/arrow"
              }
            },
            {
              "unversionedId": "storage/parquet",
              "id": "storage/parquet",
              "title": "Parquet",
              "description": "Parquet stores data in a columnar format and is designed to realize excellent read and write performance in a data lake environment. Parquet solves a few problems that frequently bedevil data engineers. Parquet-encoded data builds in schema information and natively supports nested data, unlike CSV. Furthermore, Parquet is portable; while databases such as BigQuery and Snowflake serialize data in proprietary columnar formats and offer excellent query performance on data stored internally, a huge performance hit occurs when interoperating with external tools. Data must be deserialized, reserialized into an exchangeable format, and exported to use data lake tools such as Spark and Presto. Parquet files in a data lake may be a superior option to proprietary cloud data warehouses in a polyglot tool environment.",
              "source": "@site/docs/02-storage/parquet.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/parquet",
              "permalink": "/docs/storage/parquet",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Avro",
                "permalink": "/docs/storage/avro"
              },
              "next": {
                "title": "ORC",
                "permalink": "/docs/storage/orc"
              }
            },
            {
              "unversionedId": "storage/parquet-vs-csv",
              "id": "storage/parquet-vs-csv",
              "title": "Parquet vs CSV",
              "description": "While CSV is simple and the most widely used data format (Excel, Google Sheets), there are several distinct advantages for Parquet, including:",
              "source": "@site/docs/02-storage/parquet-vs-csv.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/parquet-vs-csv",
              "permalink": "/docs/storage/parquet-vs-csv",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Avro vs Parquet vs ORC",
                "permalink": "/docs/storage/avro-vs-parquet-vs-orc"
              },
              "next": {
                "title": "Lab: Loading Data in Python",
                "permalink": "/docs/storage/lab-data-loading-python/"
              }
            },
            {
              "unversionedId": "storage/postgres",
              "id": "storage/postgres",
              "title": "Postgres",
              "description": "Picking the right database management system is a difficult task due to the vast number of options on the market. Depending on the business model, you can pick a commercial database or an open source database with commercial support. In addition to this, there are several technical and non-technical factors to assess. When it comes to picking a relational database management system, PostgreSQL stands at the top for several reasons. The PostgreSQL slogan, \"The world's most advanced open source database,\" emphasizes the sophistication of its features and the high degree of community confidence.",
              "source": "@site/docs/02-storage/postgres.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/postgres",
              "permalink": "/docs/storage/postgres",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: JSON Data Processing",
                "permalink": "/docs/storage/lab-processing-json-data/"
              },
              "next": {
                "title": "MySQL",
                "permalink": "/docs/storage/mysql"
              }
            },
            {
              "unversionedId": "storage/postgres-vs-mysql",
              "id": "storage/postgres-vs-mysql",
              "title": "Postgres vs MySQL",
              "description": "When it comes to choosing a relational database management system (RDBMS), two popular options are PostgreSQL and MySQL. Both have been around for decades and have proven to be highly reliable, secure, and scalable. However, they have different strengths and weaknesses that make one more suitable for certain use cases than the other.",
              "source": "@site/docs/02-storage/postgres-vs-mysql.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/postgres-vs-mysql",
              "permalink": "/docs/storage/postgres-vs-mysql",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Interview Questions",
                "permalink": "/docs/storage/interview-questions"
              },
              "next": {
                "title": "Lab: AWS RDS Service",
                "permalink": "/docs/storage/lab-aws-rds-service/"
              }
            },
            {
              "unversionedId": "storage/project-athena-federated/README",
              "id": "storage/project-athena-federated/README",
              "title": "Project: Athena Federated",
              "description": "Building Federated Query System using Amazon Athena",
              "source": "@site/docs/02-storage/project-athena-federated/README.md",
              "sourceDirName": "02-storage/project-athena-federated",
              "slug": "/storage/project-athena-federated/",
              "permalink": "/docs/storage/project-athena-federated/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Amazon Athena",
                "permalink": "/docs/storage/athena"
              },
              "next": {
                "title": "Amazon Redshift",
                "permalink": "/docs/storage/redshift"
              }
            },
            {
              "unversionedId": "storage/redshift",
              "id": "storage/redshift",
              "title": "Amazon Redshift",
              "description": "Amazon Redshift is a data warehousing service optimized for online analytical processing (OLAP) applications. You can start with just a few hundred gigabytes (GB) of data and scale to a petabyte (PB) or more. Designing your database for analytical processing lets you take full advantage of Amazon Redshift's columnar architecture.",
              "source": "@site/docs/02-storage/redshift.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/redshift",
              "permalink": "/docs/storage/redshift",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Project: Athena Federated",
                "permalink": "/docs/storage/project-athena-federated/"
              },
              "next": {
                "title": "Lab: Data Loading into Redshift",
                "permalink": "/docs/storage/lab-redshift-data-loading"
              }
            },
            {
              "unversionedId": "storage/serialization",
              "id": "storage/serialization",
              "title": "Serialization",
              "description": "Many serialization algorithms and formats are available to data engineers. While the abundance of options is a significant source of pain in data engineering, they are also a massive opportunity for performance improvements. We’ve sometimes seen job performance improve by a factor of 100 simply by switching from CSV to Parquet serialization. As data moves through a pipeline, engineers will also manage reserialization—conversion from one format to another. Sometimes data engineers have no choice but to accept data in an ancient, nasty form; they must design processes to deserialize this format and handle exceptions, and then clean up and convert data for consistent, fast downstream processing and consumption.",
              "source": "@site/docs/02-storage/serialization.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/serialization",
              "permalink": "/docs/storage/serialization",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Getting Started with Scala",
                "permalink": "/docs/foundations/language/scala/lab-scala-getting-started/"
              },
              "next": {
                "title": "CSV: The nonstandard standard",
                "permalink": "/docs/storage/csv"
              }
            },
            {
              "unversionedId": "storage/snowflake",
              "id": "storage/snowflake",
              "title": "Snowflake",
              "description": "Snowflake is the Data Cloud that enables you to build data-intensive applications without operational burden, so you can focus on data and analytics instead of infrastructure management.",
              "source": "@site/docs/02-storage/snowflake.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/snowflake",
              "permalink": "/docs/storage/snowflake",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "BigQuery",
                "permalink": "/docs/storage/bigquery"
              },
              "next": {
                "title": "Links",
                "permalink": "/docs/storage/warehouse-links"
              }
            },
            {
              "unversionedId": "storage/sqlite",
              "id": "storage/sqlite",
              "title": "SQLite",
              "description": "SQLite is a C-language library that implements a small, fast, self-contained, high-reliability, full-featured, SQL database engine. SQLite is the most used database engine in the world.",
              "source": "@site/docs/02-storage/sqlite.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/sqlite",
              "permalink": "/docs/storage/sqlite",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "MySQL",
                "permalink": "/docs/storage/mysql"
              },
              "next": {
                "title": "DuckDB",
                "permalink": "/docs/storage/duckdb"
              }
            },
            {
              "unversionedId": "storage/warehouse-links",
              "id": "storage/warehouse-links",
              "title": "Links",
              "description": "1. Accelerate Application Development with Real Time Streams in Amazon Redshift",
              "source": "@site/docs/02-storage/warehouse-links.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/warehouse-links",
              "permalink": "/docs/storage/warehouse-links",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Snowflake",
                "permalink": "/docs/storage/snowflake"
              },
              "next": {
                "title": "Data Lakes",
                "permalink": "/docs/storage/datalakes"
              }
            },
            {
              "unversionedId": "storage/why-datalakes",
              "id": "storage/why-datalakes",
              "title": "Why we need Data Lakes?",
              "description": "Before the cloud data lake architecture",
              "source": "@site/docs/02-storage/why-datalakes.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/why-datalakes",
              "permalink": "/docs/storage/why-datalakes",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Data Lakes",
                "permalink": "/docs/storage/datalakes"
              },
              "next": {
                "title": "Azure Data Lakes",
                "permalink": "/docs/storage/azure-datalake"
              }
            },
            {
              "unversionedId": "storage/xml",
              "id": "storage/xml",
              "title": "XML",
              "description": "Extensible Markup Language (XML) was popular when HTML and the internet were new, but it is now viewed as legacy; it is generally slow to deserialize and serialize for data engineering applications. XML is another standard that data engineers are often forced to interact with as they exchange data with legacy systems and software. JSON has largely replaced XML for plain-text object serialization.",
              "source": "@site/docs/02-storage/xml.md",
              "sourceDirName": "02-storage",
              "slug": "/storage/xml",
              "permalink": "/docs/storage/xml",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "CSV: The nonstandard standard",
                "permalink": "/docs/storage/csv"
              },
              "next": {
                "title": "JSON and JSONL",
                "permalink": "/docs/storage/json"
              }
            },
            {
              "unversionedId": "system-design/databricks-case-studies",
              "id": "system-design/databricks-case-studies",
              "title": "Databricks Case Studies",
              "description": "Data teams across the world are using Databricks to solve the toughest data problems. Every Databricks success story brings a unique set of challenges and new learning for architects and data professionals. Databricks can be used as a transformation layer, a real-time streaming engine, or a solution for machine learning and advanced analytics. In this note, we will look at several real-world case study examples and learn how Databricks is used to help drive innovation across various industries around the world.",
              "source": "@site/docs/system-design/databricks-case-studies.md",
              "sourceDirName": "system-design",
              "slug": "/system-design/databricks-case-studies",
              "permalink": "/docs/system-design/databricks-case-studies",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "System Design Examples",
                "permalink": "/docs/system-design/examples"
              },
              "next": {
                "title": "Cloud Computing",
                "permalink": "/docs/foundations/cloud/cloud-computing"
              }
            },
            {
              "unversionedId": "system-design/examples",
              "id": "system-design/examples",
              "title": "System Design Examples",
              "description": "BookMyShow",
              "source": "@site/docs/system-design/examples.md",
              "sourceDirName": "system-design",
              "slug": "/system-design/examples",
              "permalink": "/docs/system-design/examples",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "System Design",
                "permalink": "/docs/system-design/"
              },
              "next": {
                "title": "Databricks Case Studies",
                "permalink": "/docs/system-design/databricks-case-studies"
              }
            },
            {
              "unversionedId": "system-design/README",
              "id": "system-design/README",
              "title": "System Design",
              "description": "Design the architecture, components and interfaces for big data systems",
              "source": "@site/docs/system-design/README.md",
              "sourceDirName": "system-design",
              "slug": "/system-design/",
              "permalink": "/docs/system-design/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Install DBeaver",
                "permalink": "/docs/foundations/developer/install-dbeaver"
              },
              "next": {
                "title": "System Design Examples",
                "permalink": "/docs/system-design/examples"
              }
            },
            {
              "unversionedId": "visualization/flask/README",
              "id": "visualization/flask/README",
              "title": "Flask",
              "description": "Shazam API Song Analytics",
              "source": "@site/docs/08-visualization/flask/README.md",
              "sourceDirName": "08-visualization/flask",
              "slug": "/visualization/flask/",
              "permalink": "/docs/visualization/flask/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Step Function Ecommerce SQL",
                "permalink": "/docs/orchestration/stepfunctions/lab-stepfunction-ecomm-sqs/"
              },
              "next": {
                "title": "Lab: Streaming Analytics and Dashboards",
                "permalink": "/docs/visualization/looker-studio/lab-gcp-streaming-analytics"
              }
            },
            {
              "unversionedId": "visualization/looker-studio/lab-gcp-streaming-analytics",
              "id": "visualization/looker-studio/lab-gcp-streaming-analytics",
              "title": "Lab: Streaming Analytics and Dashboards",
              "description": "Objective",
              "source": "@site/docs/08-visualization/looker-studio/lab-gcp-streaming-analytics.md",
              "sourceDirName": "08-visualization/looker-studio",
              "slug": "/visualization/looker-studio/lab-gcp-streaming-analytics",
              "permalink": "/docs/visualization/looker-studio/lab-gcp-streaming-analytics",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Flask",
                "permalink": "/docs/visualization/flask/"
              },
              "next": {
                "title": "Apache Superset - Preset",
                "permalink": "/docs/visualization/preset/"
              }
            },
            {
              "unversionedId": "visualization/looker-studio/README",
              "id": "visualization/looker-studio/README",
              "title": "Looker Studio",
              "description": "Labs",
              "source": "@site/docs/08-visualization/looker-studio/README.md",
              "sourceDirName": "08-visualization/looker-studio",
              "slug": "/visualization/looker-studio/",
              "permalink": "/docs/visualization/looker-studio/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "visualization/preset/README",
              "id": "visualization/preset/README",
              "title": "Apache Superset - Preset",
              "description": "Setup Preset",
              "source": "@site/docs/08-visualization/preset/README.md",
              "sourceDirName": "08-visualization/preset",
              "slug": "/visualization/preset/",
              "permalink": "/docs/visualization/preset/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Lab: Streaming Analytics and Dashboards",
                "permalink": "/docs/visualization/looker-studio/lab-gcp-streaming-analytics"
              },
              "next": {
                "title": "Streamlit",
                "permalink": "/docs/visualization/streamlit/"
              }
            },
            {
              "unversionedId": "visualization/README",
              "id": "visualization/README",
              "title": "Visualization",
              "description": "Steps",
              "source": "@site/docs/08-visualization/README.md",
              "sourceDirName": "08-visualization",
              "slug": "/visualization/",
              "permalink": "/docs/visualization/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {}
            },
            {
              "unversionedId": "visualization/streamlit/README",
              "id": "visualization/streamlit/README",
              "title": "Streamlit",
              "description": "Amazon Fashion Recommender",
              "source": "@site/docs/08-visualization/streamlit/README.md",
              "sourceDirName": "08-visualization/streamlit",
              "slug": "/visualization/streamlit/",
              "permalink": "/docs/visualization/streamlit/",
              "draft": false,
              "tags": [],
              "version": "current",
              "lastUpdatedBy": "Author",
              "lastUpdatedAt": 1539502055,
              "formattedLastUpdatedAt": "Oct 14, 2018",
              "frontMatter": {},
              "sidebar": "docs",
              "previous": {
                "title": "Apache Superset - Preset",
                "permalink": "/docs/visualization/preset/"
              },
              "next": {
                "title": "DevOps",
                "permalink": "/docs/devops/"
              }
            }
          ],
          "drafts": [],
          "sidebars": {
            "docs": [
              {
                "type": "doc",
                "id": "introduction"
              },
              {
                "type": "category",
                "label": "Getting Started",
                "link": {
                  "type": "generated-index",
                  "slug": "/category/getting-started",
                  "permalink": "/docs/category/getting-started"
                },
                "items": [
                  {
                    "type": "category",
                    "label": "Data Engineering",
                    "link": {
                      "type": "generated-index",
                      "slug": "/category/data-engineering",
                      "permalink": "/docs/category/data-engineering"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/basics/de-basics"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/data-pipelines"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/oltp-vs-olap"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/data-storages"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/sql-vs-nosql"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/big-data"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/batch-vs-incremental"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/data-contract"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/data-governance"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/data-management"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/data-quality"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/batch-data-processing"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/stream-data-processing"
                      },
                      {
                        "type": "doc",
                        "id": "orchestration/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/most-common-interview-questions-set1"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/most-common-interview-questions-set2"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/most-common-interview-questions-set3"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Spark and Hadoop",
                    "link": {
                      "type": "generated-index",
                      "slug": "/category/spark-and-hadoop",
                      "permalink": "/docs/category/spark-and-hadoop"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/basics/spark-basics"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/spark-origin"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/hadoop-basics"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/map-reduce"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/hadoop-vs-spark"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/spark-dag"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/rdd"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/spark-quiz"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Developer Essentials",
                    "link": {
                      "type": "generated-index",
                      "slug": "/category/developer-essentials",
                      "permalink": "/docs/category/developer-essentials"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/developer/install-anaconda"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/developer/install-jupyter"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/developer/install-vscode"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/developer/lab-explore-vscode-features"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/developer/setup-git"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/developer/lab-learn-git-commands"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/developer/lab-bash-commands/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/developer/install-dbeaver"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "System Design",
                    "link": {
                      "type": "doc",
                      "id": "system-design/README"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "system-design/examples"
                      },
                      {
                        "type": "doc",
                        "id": "system-design/databricks-case-studies"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Cloud Computing",
                "link": {
                  "type": "doc",
                  "id": "foundations/cloud/cloud-computing"
                },
                "items": [
                  {
                    "type": "category",
                    "label": "AWS",
                    "link": {
                      "type": "generated-index",
                      "slug": "/category/aws",
                      "permalink": "/docs/category/aws"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/cloud/ec2"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/iam"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/glue"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/rds"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/s3"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/dms"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/secrets-manager"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/aws-containers"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/aws-commands"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/lab-aws-setup/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/lab-create-iam-policy-role/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/lab-aws-secrets-manager/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/lab-create-your-first-vpc/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/lab-create-your-first-ec2-instance-linux/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "GCP",
                    "link": {
                      "type": "generated-index",
                      "slug": "/category/gcp",
                      "permalink": "/docs/category/gcp"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/cloud/gcp-basics"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/gcp-setup"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Azure",
                    "link": {
                      "type": "generated-index",
                      "slug": "/category/azure",
                      "permalink": "/docs/category/azure"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/cloud/azure-basics"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/azure-data-ingestion"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/azure-batch-processing"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/cloud/azure-fullstack-solutions"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Programming",
                "items": [
                  {
                    "type": "category",
                    "label": "SQL",
                    "link": {
                      "type": "doc",
                      "id": "foundations/language/sql/sql-basics"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/sql-query"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/commands/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/cte"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/subquery"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/views"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/stored-procedures"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/triggers"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/indexes"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/comparison-operators"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/logical-operators"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/joins"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/comments"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/cursor"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/aggregate-functions"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/string-functions"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/date-functions"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/window-functions"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/performance-tuning"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/joins"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/lab-mysql-data-ingestion/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/lab-basic-to-advanced/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/lab-postgres-queries/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/lab-postgres-sales/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/lab-sqlite-basics/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/challenges/yammer/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/challenges/braintree/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/challenges/employee"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/challenges/assignment5/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/sql/links"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Python",
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/language/python/introduction-to-python"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/python/python-syntax-sugars"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/python/lab-etl-csv-json-xml/index"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/nlp/lab-basic-text-handlng-python/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/python/links"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "PySpark",
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/install"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/dataframe"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/methods-operations"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/partitioning"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/lazy-processing"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/caching"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/udf"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/broadcasting"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/cheat-sheet"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/execution-plan"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/pyspark-vs-pandas"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/lab-pyspark-basics/index"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-databricks-pyspark-s3/index"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/lab-spark-optimizations-2/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/lab-spark-optimizations/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/lab-uber-analysis/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/lab-understand-spark-query-execution/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/lab-bcg/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-databricks-scala-postgres-s3/README"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/language/pyspark/lab-calculating-partitions/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Spark Scala",
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/language/scala/lab-scala-getting-started/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Data Storage",
                "items": [
                  {
                    "type": "category",
                    "label": "Flat Files",
                    "items": [
                      {
                        "type": "doc",
                        "id": "storage/serialization"
                      },
                      {
                        "type": "doc",
                        "id": "storage/csv"
                      },
                      {
                        "type": "doc",
                        "id": "storage/xml"
                      },
                      {
                        "type": "doc",
                        "id": "storage/json"
                      },
                      {
                        "type": "doc",
                        "id": "storage/avro"
                      },
                      {
                        "type": "doc",
                        "id": "storage/parquet"
                      },
                      {
                        "type": "doc",
                        "id": "storage/orc"
                      },
                      {
                        "type": "doc",
                        "id": "storage/arrow"
                      },
                      {
                        "type": "doc",
                        "id": "storage/hudi"
                      },
                      {
                        "type": "doc",
                        "id": "storage/iceberg"
                      },
                      {
                        "type": "doc",
                        "id": "storage/database-storage-engines"
                      },
                      {
                        "type": "doc",
                        "id": "storage/avro-vs-parquet-vs-orc"
                      },
                      {
                        "type": "doc",
                        "id": "storage/parquet-vs-csv"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-data-loading-python/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-processing-json-data/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Databases",
                    "items": [
                      {
                        "type": "doc",
                        "id": "storage/postgres"
                      },
                      {
                        "type": "doc",
                        "id": "storage/mysql"
                      },
                      {
                        "type": "doc",
                        "id": "storage/sqlite"
                      },
                      {
                        "type": "doc",
                        "id": "storage/duckdb"
                      },
                      {
                        "type": "doc",
                        "id": "storage/gcp-cloudsql"
                      },
                      {
                        "type": "doc",
                        "id": "storage/azure-sql"
                      },
                      {
                        "type": "doc",
                        "id": "storage/interview-questions"
                      },
                      {
                        "type": "doc",
                        "id": "storage/postgres-vs-mysql"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-aws-rds-service/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-mysql-data-ingestion/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-sqlite-basics/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-postgres-getting-started/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-postgres-bash-etl/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-postgres-crime-reports/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-postgres-trips-stored-procedure/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-mysql-police-api-etl/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-gcp-cloudsql-nyctaxi/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-azure-sql-securing-databases/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-db2-bookshop-petsale-data-ingestion/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-duckdb-analytics-bank-tpch-nyctaxi/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-sqlite-hipolabs-api/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/database-links"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "NoSQL Databases",
                    "items": [
                      {
                        "type": "doc",
                        "id": "storage/cassandra"
                      },
                      {
                        "type": "doc",
                        "id": "storage/gcp-bigtable"
                      },
                      {
                        "type": "doc",
                        "id": "storage/aws-dynamodb"
                      },
                      {
                        "type": "doc",
                        "id": "storage/apache-couchdb"
                      },
                      {
                        "type": "doc",
                        "id": "storage/mongodb"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-getting-started-with-cassandra/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-gcp-streaming-bigtable/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-amazon-keyspaces/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-intro-to-dynamodb/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-mongodb-basics/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-couchdb-movies-data-migration/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Warehouses",
                    "items": [
                      {
                        "type": "doc",
                        "id": "storage/data-warehouses"
                      },
                      {
                        "type": "doc",
                        "id": "storage/athena"
                      },
                      {
                        "type": "doc",
                        "id": "storage/project-athena-federated/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/redshift"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-redshift-data-loading"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-redshift-data-loading-analysis"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-redshift-table-design-query-tuning"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-redshift-scd"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-redshift-scd-2"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-redshift-ongoing-load-elt"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-redshift-spectrum-query-datalake"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-redshift-spectrum-query-tuning"
                      },
                      {
                        "type": "doc",
                        "id": "storage/bigquery"
                      },
                      {
                        "type": "doc",
                        "id": "storage/snowflake"
                      },
                      {
                        "type": "doc",
                        "id": "storage/warehouse-links"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Data Lakes",
                    "items": [
                      {
                        "type": "doc",
                        "id": "storage/datalakes"
                      },
                      {
                        "type": "doc",
                        "id": "storage/why-datalakes"
                      },
                      {
                        "type": "doc",
                        "id": "storage/azure-datalake"
                      },
                      {
                        "type": "doc",
                        "id": "storage/gcs"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-datalake-healthcare-s3-glue-athena/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-adl-create-manage-data/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-adl-securing-monitoring-lakes/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Lakehouses",
                    "items": [
                      {
                        "type": "doc",
                        "id": "storage/data-lakehouses"
                      },
                      {
                        "type": "doc",
                        "id": "storage/deltalake"
                      },
                      {
                        "type": "doc",
                        "id": "storage/apache-hudi"
                      },
                      {
                        "type": "doc",
                        "id": "storage/apache-iceberg"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-read-s3-delta-in-python/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-glue-emr-iceberg-serverless-lakehouse/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-production-cleaning-deltalake/README"
                      },
                      {
                        "type": "doc",
                        "id": "storage/lab-scd-glue-delta/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Data Meshes",
                    "items": [
                      {
                        "type": "doc",
                        "id": "storage/data-mesh-basics"
                      },
                      {
                        "type": "doc",
                        "id": "storage/casestudy-messflix-hypothetical"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Data Processing",
                "items": [
                  {
                    "type": "category",
                    "label": "Databricks",
                    "link": {
                      "type": "doc",
                      "id": "processing/databricks/README"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-cybersecurity-databricks/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-databricks-clickstream/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-databricks-deltalake/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-deltalake-optimizations/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-dlt-dbt/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-healthcare-databricks/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-iot-health-tracker/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-loan-application/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-retail-pos-databricks/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/lab-data-processing-azure-dbr/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/project-databricks-de/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/project-learnerbricks/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/project-advancedbricks/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/project-bedbricks/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/databricks/project-databricks-superset/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "AWS EMR",
                    "link": {
                      "type": "doc",
                      "id": "processing/aws-emr"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-emr-serverless/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "AWS Glue Studio",
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-glue-advanced/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-glue-deltalake-cdc-upsert/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-glue-studio-custom-transforms/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-glue-studio-tickets/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-csv-to-parquet-conversion/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "AWS Lambda Function",
                    "link": {
                      "type": "doc",
                      "id": "processing/aws-lambda"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/aws-lambda-snippets"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-lambda-csv-parquet/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Amazon Kinesis",
                    "link": {
                      "type": "doc",
                      "id": "processing/aws-kinesis"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-kinesis-apache-logs/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-kinesis-clickstream-anomaly/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Apache Beam",
                    "link": {
                      "type": "doc",
                      "id": "processing/apache-beam"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-getting-started-with-beam/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-beam-mapreduce/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "GCP Dataflow",
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-dataflow-pipeline"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-dataflow-batch-pipeline"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-dataflow-side-inputs"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-dataflow-stream-pipeline"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-serverless-dataflow"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-dataflow-bigquery-etl"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Ray",
                    "link": {
                      "type": "doc",
                      "id": "processing/ray"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-ray-core-basics/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-ray-air-basics/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "GCP Dataproc",
                    "link": {
                      "type": "doc",
                      "id": "processing/gcp-dataproc"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-dataproc/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Azure HDInsight",
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-azure-hdinsight-simple-data-processing/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Azure Synapse Analytics",
                    "link": {
                      "type": "doc",
                      "id": "processing/azure-synapse-analytics"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-azure-synapse-dataflows/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-azure-synapse-data-processing/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-azure-synapse-implementing-star-schema/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "GCP Dataprep",
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-dataprep"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "GCP PubSub",
                    "link": {
                      "type": "doc",
                      "id": "processing/gcp-pubsub"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-pubsub"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-gcp-pubsub-processing"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Apache Kafka",
                    "link": {
                      "type": "doc",
                      "id": "processing/apache-kafka"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-kafka-cli/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-kafka-python/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-confluent-python/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-confluent-kafka-faker/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-kafka-fraud-detection/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-kafka-nyctaxi/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-kafka-python-ecs/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-kafka-spark-streaming/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-kafka-stock-market/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-kafka-toll-analysis/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/project-kafka-ikea/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Apache Flink",
                    "link": {
                      "type": "doc",
                      "id": "processing/apache-flink"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-flink-taxi-pricing/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-flink-twitter-stream-processing/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-flink-kafka-sink/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-flink-kafka-source/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "dbt",
                    "link": {
                      "type": "doc",
                      "id": "processing/dbt"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-dbt-nyctaxi/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-dbt-jaffle-shop/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-dbt-knoema/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-dbt-olist/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-dbt-stackexchnge/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-dbt-tickit/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-dbt-tpch/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Snowpark",
                    "link": {
                      "type": "doc",
                      "id": "processing/snowpark"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "processing/lab-snowpark-churnpark/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-snowpark-dbtsnowpy/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-snowpark-fifapark/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-snowpark-jafflepark/README"
                      },
                      {
                        "type": "doc",
                        "id": "processing/lab-snowpark-knoema-regression/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Data Modeling",
                "link": {
                  "type": "generated-index",
                  "slug": "/category/data-modeling",
                  "permalink": "/docs/category/data-modeling"
                },
                "items": [
                  {
                    "type": "category",
                    "label": "SQL Data Modeling",
                    "link": {
                      "type": "doc",
                      "id": "data-modeling/sql-data-modeling"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "data-modeling/inmon-vs-kimball"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/data-modeling-stages"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/3nf-data-modeling"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/dimensional-modeling"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/data-vault-modeling"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/data-modeling-steps"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/designing-scd"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/designing-incremental-loading"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/data-warehousing"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/normalization-vs-denormalization"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/cap-theorem"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/quiz"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-airbnb-postgres-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-cars-mysql-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-dvd-rental-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-google-playstore-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-inegi-snowflake-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-mysql-northwind-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-mysql-retail-store-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-postgres-busrapid-transit/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-postgres-elt-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-postgres-ewallet-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-postgres-housing-cdc-scd/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-snowflake-creditdebit-datamodel/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-sparkify-data-model-postgres/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "NoSQL Data Modeling",
                    "link": {
                      "type": "doc",
                      "id": "data-modeling/nosql-data-modeling"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-cassandra-digital-music-library/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-cassandra-email-data-model/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-cassandra-hotel-reservations/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-cassandra-investment-data-model/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-cassandra-sensor-data-model/README"
                      },
                      {
                        "type": "doc",
                        "id": "data-modeling/lab-cassandra-shopping-cart-data-model/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Data Extraction",
                "items": [
                  {
                    "type": "category",
                    "label": "API",
                    "items": [
                      {
                        "type": "doc",
                        "id": "extraction/api/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Faker",
                    "items": [
                      {
                        "type": "doc",
                        "id": "extraction/faker/lab-generate-data-with-faker/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Data Pipelines",
                "items": [
                  {
                    "type": "category",
                    "label": "Airflow",
                    "items": [
                      {
                        "type": "doc",
                        "id": "orchestration/airflow/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Azure Data Factory",
                    "link": {
                      "type": "doc",
                      "id": "orchestration/azure-data-factory/README"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "orchestration/azure-data-factory/lab-adf-incremental-loading/README"
                      },
                      {
                        "type": "doc",
                        "id": "orchestration/azure-data-factory/lab-batch-processing-solution/README"
                      },
                      {
                        "type": "doc",
                        "id": "orchestration/azure-data-factory/lab-data-ingestion-pipeline/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "GCP Cloud DataFusion",
                    "link": {
                      "type": "doc",
                      "id": "orchestration/datafusion/README"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "orchestration/datafusion/lab-datafusion-pipeline/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "AWS Step Functions",
                    "items": [
                      {
                        "type": "doc",
                        "id": "orchestration/stepfunctions/lab-stepfunction-athena-sns/README"
                      },
                      {
                        "type": "doc",
                        "id": "orchestration/stepfunctions/lab-stepfunction-ecomm-sqs/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Data Visualization",
                "items": [
                  {
                    "type": "category",
                    "label": "Flask",
                    "items": [
                      {
                        "type": "doc",
                        "id": "visualization/flask/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Looker Studio",
                    "items": [
                      {
                        "type": "doc",
                        "id": "visualization/looker-studio/lab-gcp-streaming-analytics"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Apache Superset",
                    "items": [
                      {
                        "type": "doc",
                        "id": "visualization/preset/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Streamlit",
                    "items": [
                      {
                        "type": "doc",
                        "id": "visualization/streamlit/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "DevOps",
                "items": [
                  {
                    "type": "category",
                    "label": "Basics",
                    "items": [
                      {
                        "type": "doc",
                        "id": "devops/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Containers",
                    "items": [
                      {
                        "type": "doc",
                        "id": "devops/containers/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Infra as Code",
                    "items": [
                      {
                        "type": "doc",
                        "id": "devops/iac/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Mathematics",
                "link": {
                  "type": "doc",
                  "id": "mathematics/README"
                },
                "items": [
                  {
                    "type": "category",
                    "label": "Probability",
                    "items": [
                      {
                        "type": "doc",
                        "id": "mathematics/probability/probability-distributions"
                      },
                      {
                        "type": "doc",
                        "id": "mathematics/probability/rules-of-probability"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Statistics",
                    "items": [
                      {
                        "type": "doc",
                        "id": "mathematics/statistics/sampling"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Data Science",
                "items": [
                  {
                    "type": "category",
                    "label": "Basics",
                    "items": [
                      {
                        "type": "doc",
                        "id": "foundations/basics/origin"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/use-cases"
                      },
                      {
                        "type": "doc",
                        "id": "foundations/basics/deployment"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/data-splits"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/bias-variance-tradeoff"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/metrics-and-evaluation"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/data-preparation"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/data-encoding"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/feature-selection"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Algorithms",
                    "items": [
                      {
                        "type": "doc",
                        "id": "datascience/algorithms/linear-regression"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/algorithms/logistic-regression"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/algorithms/decision-trees"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/algorithms/random-forest"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/algorithms/knn"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/algorithms/gradient-boosting"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Time-Series Forecasting",
                    "items": [
                      {
                        "type": "doc",
                        "id": "datascience/timeseries/prophet"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Deep Learning",
                    "items": [
                      {
                        "type": "doc",
                        "id": "datascience/deep-learning/deep-learning-basics"
                      },
                      {
                        "type": "doc",
                        "id": "datascience/deep-learning/perceptron"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "MLOps",
                    "items": [
                      {
                        "type": "doc",
                        "id": "mlops/README"
                      },
                      {
                        "type": "doc",
                        "id": "mlops/code-snippets"
                      },
                      {
                        "type": "doc",
                        "id": "mlops/mlflow/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Extras",
                "items": [
                  {
                    "type": "category",
                    "label": "Case Studies",
                    "link": {
                      "type": "generated-index",
                      "slug": "/category/case-studies",
                      "permalink": "/docs/category/case-studies"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "casestudies/99group"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/airbnb"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/amazon"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/bookingdotcom"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/expedia"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/fair"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/harmony"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/helpshift"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/hometogo"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/intuit"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/linkedin"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/myntra"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/outfit7"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/panoramic"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/plexure"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/spotify"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/starbucks"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/trivago"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/twilio"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/twitter"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/uber"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/video-stream"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/webshoes"
                      },
                      {
                        "type": "doc",
                        "id": "casestudies/woot"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "category",
                    "label": "Capstones",
                    "link": {
                      "type": "generated-index",
                      "slug": "/category/capstones",
                      "permalink": "/docs/category/capstones"
                    },
                    "items": [
                      {
                        "type": "doc",
                        "id": "capstones/ServerlessStreamingApp/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/acled/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/citibike-trip-histories/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/city-pollution/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/city-traffic-drone/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/climate/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/cloudmaze/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/dbt-redshift/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/digitalskola/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/disaster-response/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/funflix/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/hmc/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/kinesis-flink-beam/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/kinesis-flink-etl/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/kortex/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/lufthansa/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/movie-sentiment/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/multi-touch-attribution/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/recofront/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/reddit/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/redshield/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/robust-data-pipeline/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/smartcity/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/sparkify/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/spotify/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/twitter-sentiment-glue/README"
                      },
                      {
                        "type": "doc",
                        "id": "capstones/us-immigration/README"
                      }
                    ],
                    "collapsed": true,
                    "collapsible": true
                  },
                  {
                    "type": "doc",
                    "id": "interviewprep/README"
                  },
                  {
                    "type": "doc",
                    "id": "interviewprep/resume-buildup"
                  },
                  {
                    "type": "doc",
                    "id": "misc/resources"
                  },
                  {
                    "type": "doc",
                    "id": "misc/extras"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              }
            ]
          }
        }
      ]
    }
  },
  "docusaurus-plugin-content-blog": {
    "default": {
      "blogSidebarTitle": "Recent posts",
      "blogPosts": [
        {
          "id": "/2022/12/24/ab-mab-tests",
          "metadata": {
            "permalink": "/blog/2022/12/24/ab-mab-tests",
            "source": "@site/blog/2022-12-24-ab-mab-tests.mdx",
            "title": "A/B and Multi-Armed Bandit Tests",
            "description": "Lab 1: Simple T-test",
            "date": "2022-12-24T00:00:00.000Z",
            "formattedDate": "December 24, 2022",
            "tags": [
              {
                "label": "mab",
                "permalink": "/blog/tags/mab"
              },
              {
                "label": "ab",
                "permalink": "/blog/tags/ab"
              }
            ],
            "readingTime": 0.775,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "A/B and Multi-Armed Bandit Tests",
              "authors": [
                "sparsh"
              ],
              "tags": [
                "mab",
                "ab"
              ]
            },
            "nextItem": {
              "title": "SQL Server to Snowflake Schema Conversion",
              "permalink": "/blog/2022/12/13/sql-to-snowflake-schema-conversion"
            }
          },
          "content": "## Lab 1: Simple T-test\n\n- Simple T-test to compare 2 samples of ad-conversions\n\n## Lab 2: A/B test\n\n- AB test and plots with explanations to understand the basics\n- A/B testing step-by-step guide in Python\n\n## Lab 3: Multi-Armed Bandit (MAB) test\n\n- Testing out different bandit methods for effective online testing methods\n- Multi-armed Bandit for Banner Ad and 4 Exploration Strategies\n- How to build Multi-Armed Bandit Product Recommender\n- Solving Multi-armed Bandit Problems\n\n## Solution\n\n1. [AB test and plots with explanations to understand the basics](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2021-06-27-ab-test-in-five-simple-steps.ipynb)\n2. [Simple T-test to compare 2 samples of ad-conversions](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2021-06-27-ad-conversion-simple-ab-testing.ipynb)\n3. [Testing out different bandit methods for effective online testing methods](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2021-06-19-methods-for-effective-online-testing.ipynb)\n4. [A/B testing step-by-step guide in Python](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2021-06-28-step-by-step-ab-testing-guide.ipynb)\n5. [AB Testing With Python](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2021-06-28-udacity-abtest-python.ipynb)\n6. [Multi-armed Bandit for Banner Ad and 4 Exploration Strategies](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2021-07-02-ads-selection-using-bandits.ipynb)\n7. [How to build Multi-Armed Bandit Product Recommender](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2021-07-27-mab-product.ipynb)\n8. [Multi-Armed Bandits](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2022-01-14-mab.ipynb)\n9. [Multi-armed Bandit for Banner Ad](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2022-01-18-mab.ipynb)\n10. [Solving Multi-armed Bandit Problems](https://nbviewer.org/github/sparsh-ai/notebooks/blob/main/2022-01-20-mab.ipynb)"
        },
        {
          "id": "/2022/12/13/sql-to-snowflake-schema-conversion",
          "metadata": {
            "permalink": "/blog/2022/12/13/sql-to-snowflake-schema-conversion",
            "source": "@site/blog/2022-12-13-sql-to-snowflake-schema-conversion.mdx",
            "title": "SQL Server to Snowflake Schema Conversion",
            "description": "Last week, I was asked to migrate one view from the On-premises MS SQL Server to Snowflake. My first approach is to directly copy paste the DDL (Data Definition Language) and as I predicted, it didn't work. But my goal here was to follow TDD (Test Driven Development) - I ran the first version of DDL and Snowflake told me what the error is, I corrected the error and repeated the cycle 6-8 times until the code ran successfully without error and that's how I did the migration.",
            "date": "2022-12-13T00:00:00.000Z",
            "formattedDate": "December 13, 2022",
            "tags": [
              {
                "label": "snowflake",
                "permalink": "/blog/tags/snowflake"
              }
            ],
            "readingTime": 1.235,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "SQL Server to Snowflake Schema Conversion",
              "authors": [
                "sparsh"
              ],
              "tags": [
                "snowflake"
              ]
            },
            "prevItem": {
              "title": "A/B and Multi-Armed Bandit Tests",
              "permalink": "/blog/2022/12/24/ab-mab-tests"
            },
            "nextItem": {
              "title": "The Complete Python Course (2022)",
              "permalink": "/blog/2022/12/12/the-complete-python-course-2022"
            }
          },
          "content": "Last week, I was asked to migrate one view from the On-premises MS SQL Server to Snowflake. My first approach is to directly copy paste the DDL (Data Definition Language) and as I predicted, it didn't work. But my goal here was to follow TDD (Test Driven Development) - I ran the first version of DDL and Snowflake told me what the error is, I corrected the error and repeated the cycle 6-8 times until the code ran successfully without error and that's how I did the migration. \n\nCouple of points that I noted down as conversion rules are:\n\n1. Use `LISTAGG` for `STUFF` - you need to left join the tables with LISTAGG for each STUFF statement\n2. Remove `[]` brackets\n3. Use `IFNULL` for `ISNULL`\n4. `CONCAT` works better for appending strings compare to `+`\n5. Use `MONTHNAME` for `DATENAME(month,<>)`, same applies for other date cases\n6. `CONVERT` doesn't work, you would need to write custom logic for it (sorry, no direct keyword here!)\n\nI am sure there are more rules we can list out here, but in my view, these were the only rules I needed to apply to migrate my view. If I got another opportunity to migrate some more views and find some new rules, I will definitely update this list.\n\nIf you already know some rules which are not here, you can mail me at sprsag@gmail.com or directly message in the Recohut's slack channel.\n\nThanks for your attention, see you soon!"
        },
        {
          "id": "/2022/12/12/the-complete-python-course-2022",
          "metadata": {
            "permalink": "/blog/2022/12/12/the-complete-python-course-2022",
            "source": "@site/blog/2022-12-12-the-complete-python-course-2022.mdx",
            "title": "The Complete Python Course (2022)",
            "description": "Python is a powerful object-oriented programming language used in many development areas and is considered a perfect language for scripting. Python is a cross-platform programming language that allows you to code faster with lesser code writing required.",
            "date": "2022-12-12T00:00:00.000Z",
            "formattedDate": "December 12, 2022",
            "tags": [
              {
                "label": "python",
                "permalink": "/blog/tags/python"
              },
              {
                "label": "course",
                "permalink": "/blog/tags/course"
              },
              {
                "label": "packtpublishing",
                "permalink": "/blog/tags/packtpublishing"
              }
            ],
            "readingTime": 2.17,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "The Complete Python Course (2022)",
              "authors": [
                "sparsh"
              ],
              "tags": [
                "python",
                "course",
                "packtpublishing"
              ]
            },
            "prevItem": {
              "title": "SQL Server to Snowflake Schema Conversion",
              "permalink": "/blog/2022/12/13/sql-to-snowflake-schema-conversion"
            },
            "nextItem": {
              "title": "Opening our Bootcamp material",
              "permalink": "/blog/2022/11/16/opening-material"
            }
          },
          "content": "![](https://learning.oreilly.com/covers/urn:orm:video:9781837636778/400w/)\n\nPython is a powerful object-oriented programming language used in many development areas and is considered a perfect language for scripting. Python is a cross-platform programming language that allows you to code faster with lesser code writing required.\n\nThe course begins with a complete introduction to the capabilities and features of Python and how to set up the language on your computer along with PyCharm IDE. You will learn about multiple programming-paradigms (object-oriented, functional, and imperative). You will explore the concepts of an interpreted language that is dynamically typed and cross-platform. The course advances to explain the concepts of OOP: variables, user input, statements, functions, classes, and objects. You will learn about functions, tuples, dictionaries, and lists in Python. You will also explore various operator modules including math, statistics, and random modules. You will work on practical examples to understand the concepts of Python programming well.\n\nUpon completion, you will master advanced-level programming skillsets of Python and execute codes successfully. You will be able to complete your quest for learning to program using Python. Using the various built-in Python modules, you will grasp a must-know skill for data science and interpretation.\n\n## What You Will Learn\n\n- Learn multiple programming paradigms (OOPs and functional programs)\n- Learn variables, classes, objects, tuples, strings, and operators\n- Use dynamically typed interpreted language for lesser coding lines\n- Create lists, loops, functions, tokens, sets, and dictionaries\n- Understand cross-platform, dynamic, interpreted, and intuitive coding\n- Use random, math, and statistical operators to handle data\n\n## Audience\n\nThis course is designed for beginners in programming and those who want to master Python programming skills. Intermediate-level Python programmers who want to enhance their Python Programming Skills and students and Engineers who wish to learn Python as part of their academics. This course would also benefit professional programmers who want to switch to Python Programming from alternative coding platforms.\n\nThe course only requires the learners to have basic computer knowledge to gain from this course, and no other learning prerequisites are required.\n\n## About The Author\n\nAmit Diwan: Studyopedia was founded by Amit Diwan in 2018 after working for Tutorialspoint , IIT, IASRI, Sitepoint, DU, and C# Corner. Studyopedia sells courses on Udemy, Tutorialspoint, Geeksforgeeks, and Skillshare, providing video courses to master various technologies and programming languages, databases, frameworks, Python, data science, machine learning, Java, Android, C/C++, HTML5, Bootstrap, JavaScript, jQuery, PHP, CSS, WordPress, Drupal, Joomla, Magento, osCommerce, OpenCart, PrestaShop, and other disciplines. Studyopedia delivers high-quality video courses to millions of students and professionals enrolled through their website on multiple programming languages and technologies.\n\n## Resources\n\n1. [Video](https://learning.oreilly.com/videos/the-complete-python/9781837636778)\n2. [Code](https://github.com/PacktPublishing/The-Complete-Python-Course-2022-)"
        },
        {
          "id": "/2022/11/16/opening-material",
          "metadata": {
            "permalink": "/blog/2022/11/16/opening-material",
            "source": "@site/blog/2022-11-16-opening-material.md",
            "title": "Opening our Bootcamp material",
            "description": "For short period of time, to help laid off job seekers, We have decided to open source our data engineering bootcamp material. It's the same website we use for students",
            "date": "2022-11-16T00:00:00.000Z",
            "formattedDate": "November 16, 2022",
            "tags": [
              {
                "label": "docusaurus",
                "permalink": "/blog/tags/docusaurus"
              },
              {
                "label": "recohut",
                "permalink": "/blog/tags/recohut"
              },
              {
                "label": "dataengineering",
                "permalink": "/blog/tags/dataengineering"
              }
            ],
            "readingTime": 0.495,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Opening our Bootcamp material",
              "authors": "sparsh",
              "tags": [
                "docusaurus",
                "recohut",
                "dataengineering",
                "dataengineering"
              ]
            },
            "prevItem": {
              "title": "The Complete Python Course (2022)",
              "permalink": "/blog/2022/12/12/the-complete-python-course-2022"
            },
            "nextItem": {
              "title": "Clinical Decision Making",
              "permalink": "/blog/2021/10/01/clinical-decision-making"
            }
          },
          "content": "For short period of time, to help laid off job seekers, We have decided to open source our data engineering bootcamp material. It's the same website we use for students\n\nCheck it out here - https://datacamp.recohut.in/\n\n:::tip\nCurious how we build this docs website with minimum effort and tech behind it?\n\nIts based on library @docusaurus which is react based static site generator \n\nIt even has a site wide elastic search built in. \n\n(Try Searching it on website, I am sure you will be impressed)\n:::\n\nTag and send your `data engineers` / `data analyst` / `data scientist` friends."
        },
        {
          "id": "/2021/10/01/clinical-decision-making",
          "metadata": {
            "permalink": "/blog/2021/10/01/clinical-decision-making",
            "source": "@site/blog/2021-10-01-clinical-decision-making.mdx",
            "title": "Clinical Decision Making",
            "description": "Health insurance can be complicated—especially when it comes to prior authorization (also referred to as pre-approval, pre-authorization, and pre-certification). The manual labor involved in obtaining prior authorizations (PAs) is a well-recognized burden among providers. Up to 46% of PA requests are still submitted by fax, and 60% require a telephone call, according to America’s Health Insurance Plans (AHIP). A 2018 survey by the American Medical Association (AMA) found that doctors and their staff spend an average of 2 days a week completing PAs. In addition to eating up time that physicians could spend with patients, PAs also contribute to burnout.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "classification",
                "permalink": "/blog/tags/classification"
              },
              {
                "label": "healthcare",
                "permalink": "/blog/tags/healthcare"
              }
            ],
            "readingTime": 1.46,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Clinical Decision Making",
              "authors": "sparsh",
              "tags": [
                "classification",
                "healthcare"
              ]
            },
            "prevItem": {
              "title": "Opening our Bootcamp material",
              "permalink": "/blog/2022/11/16/opening-material"
            },
            "nextItem": {
              "title": "Detectron 2",
              "permalink": "/blog/2021/10/01/detectron-2"
            }
          },
          "content": "Health insurance can be complicated—especially when it comes to prior authorization (also referred to as pre-approval, pre-authorization, and pre-certification). The manual labor involved in obtaining prior authorizations (PAs) is a well-recognized burden among providers. Up to 46% of PA requests are still submitted by fax, and 60% require a telephone call, according to America’s Health Insurance Plans (AHIP). A 2018 survey by the American Medical Association (AMA) found that doctors and their staff spend an average of 2 days a week completing PAs. In addition to eating up time that physicians could spend with patients, PAs also contribute to burnout.\n\nThe objective was to identify the patterns from data to create clinical decision making in Pre-Auth and improve the accuracy in a clinical decision based on historical data analysis. \n\nTwo use cases were identified. Use Case 1 - *Supervised Learning Model - to aid clinicians in UM decision making. Tasks -* Ingest Pre-authorization data from Mongo DB into the analytical environment, Exploratory Data Analysis and Feature Engineering, Train supervised analytical models, model validation and model selection, Create a web service to be plugged into the case processing flow to call the model, and Display the recommendation from the model on UI on the authorization review screen. Use Case 2 - *Unsupervised Learning Model - to generate insights from the pre-authorization data. Tasks -* Ingest Pre-authorization data from Mongo DB into the analytical environment, Cluster analysis, univariate and multivariate analysis, and Generate insights and display insights on the dashboard.\n\nFinal Deliverables - Model re-training (batch mode), validation and deployment code (python scripts) with Unix command line support, Documentation - PPT, Recorded video, Technical document, Flask API backend system, HTML/PHP Web App frontend UI integration, and Plotly Dash Supervised/Unsupervised learning and insights generation dashboard."
        },
        {
          "id": "/2021/10/01/detectron-2",
          "metadata": {
            "permalink": "/blog/2021/10/01/detectron-2",
            "source": "@site/blog/2021-10-01-detectron-2.mdx",
            "title": "Detectron 2",
            "description": "/img/content-blog-raw-blog-detectron-2-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "tool",
                "permalink": "/blog/tags/tool"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 6.13,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Detectron 2",
              "authors": "sparsh",
              "tags": [
                "tool",
                "vision"
              ]
            },
            "prevItem": {
              "title": "Clinical Decision Making",
              "permalink": "/blog/2021/10/01/clinical-decision-making"
            },
            "nextItem": {
              "title": "Distributed Training of Recommender Systems",
              "permalink": "/blog/2021/10/01/distributed-training-of-recommender-systems"
            }
          },
          "content": "![/img/content-blog-raw-blog-detectron-2-untitled.png](/img/content-blog-raw-blog-detectron-2-untitled.png)\n\n# Introduction\n\nDetectron 2 is a next-generation open-source object detection system from Facebook AI Research. With the repo you can use and train the various state-of-the-art models for detection tasks such as bounding-box detection, instance and semantic segmentation, and person keypoint detection.\n\nThe following is the directory tree of detectron 2:\n\n```\ndetectron2\n├─checkpoint  <- checkpointer and model catalog handlers\n├─config      <- default configs and handlers\n├─data        <- dataset handlers and data loaders\n├─engine      <- predictor and trainer engines\n├─evaluation  <- evaluator for each dataset\n├─export      <- converter of detectron2 models to caffe2 (ONNX)\n├─layers      <- custom layers e.g. deformable conv.\n├─model_zoo   <- pre-trained model links and handler\n├─modeling   \n│  ├─meta_arch <- meta architecture e.g. R-CNN, RetinaNet\n│  ├─backbone  <- backbone network e.g. ResNet, FPN\n│  ├─proposal_generator <- region proposal network\n│  └─roi_heads <- head networks for pooled ROIs e.g. box, mask heads\n├─solver       <- optimizer and scheduler builders\n├─structures   <- structure classes e.g. Boxes, Instances, etc\n└─utils        <- utility modules e.g. visualizer, logger, etc\n```\n\n# Installation\n\n```python\n%%time\n!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html;\n!pip install cython pyyaml==5.1;\n!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI';\n!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html;\n\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\n```\n\n# Inference on pre-trained models\n\n![Original image](/img/content-blog-raw-blog-detectron-2-untitled-1.png)\n\nOriginal image\n\n![Object detection with Faster-RCNN-101](/img/content-blog-raw-blog-detectron-2-untitled-2.png)\n\nObject detection with Faster-RCNN-101\n\n![Instance segmentation with Mask-RCNN-50](/img/content-blog-raw-blog-detectron-2-untitled-3.png)\n\nInstance segmentation with Mask-RCNN-50\n\n![Keypoint estimation with Keypoint-RCNN-50](/img/content-blog-raw-blog-detectron-2-untitled-4.png)\n\nKeypoint estimation with Keypoint-RCNN-50\n\n![Panoptic segmentation with Panoptic-FPN-101](/img/content-blog-raw-blog-detectron-2-untitled-5.png)\n\nPanoptic segmentation with Panoptic-FPN-101\n\n![Default Mask R-CNN (top) vs. Mask R-CNN with PointRend (bottom) comparison](/img/content-blog-raw-blog-detectron-2-untitled-6.png)\n\nDefault Mask R-CNN (top) vs. Mask R-CNN with PointRend (bottom) comparison\n\n# Fine-tuning Balloons Dataset\n\n### Load the data\n\n```\n# download, decompress the data\n!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n!unzip balloon_dataset.zip > /dev/null\n```\n\n### Convert dataset into Detectron2's standard format\n\n```\nfrom detectron2.structures import BoxMode\n# write a function that loads the dataset into detectron2's standard format\ndef get_balloon_dicts(img_dir):\n    json_file = os.path.join(img_dir, \"via_region_data.json\")\n    with open(json_file) as f:\n        imgs_anns = json.load(f)\n\n    dataset_dicts = []\n    for _, v in imgs_anns.items():\n        record = {}\n        \n        filename = os.path.join(img_dir, v[\"filename\"])\n        height, width = cv2.imread(filename).shape[:2]\n        \n        record[\"file_name\"] = filename\n        record[\"height\"] = height\n        record[\"width\"] = width\n      \n        annos = v[\"regions\"]\n        objs = []\n        for _, anno in annos.items():\n            assert not anno[\"region_attributes\"]\n            anno = anno[\"shape_attributes\"]\n            px = anno[\"all_points_x\"]\n            py = anno[\"all_points_y\"]\n            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n            poly = list(itertools.chain.from_iterable(poly))\n\n            obj = {\n                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n                \"bbox_mode\": BoxMode.XYXY_ABS,\n                \"segmentation\": [poly],\n                \"category_id\": 0,\n                \"iscrowd\": 0\n            }\n            objs.append(obj)\n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfor d in [\"train\", \"val\"]:\n    DatasetCatalog.register(\"balloon/\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n    MetadataCatalog.get(\"balloon/\" + d).set(thing_classes=[\"balloon\"])\nballoon_metadata = MetadataCatalog.get(\"balloon/train\")\n```\n\n### Model configuration and training\n\n```\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"balloon/train\",)\ncfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.00025\ncfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough, but you can certainly train longer\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()\n```\n\n### Inference and Visualization\n\n```\nfrom detectron2.utils.visualizer import ColorMode\n\n# load weights\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n# Set training data-set path\ncfg.DATASETS.TEST = (\"balloon/val\", )\n# Create predictor (model for inference)\npredictor = DefaultPredictor(cfg)\n\ndataset_dicts = get_balloon_dicts(\"balloon/val\")\nfor d in random.sample(dataset_dicts, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=balloon_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    cv2_imshow(v.get_image()[:, :, ::-1])\n```\n\n![/img/content-blog-raw-blog-detectron-2-untitled-7.png](/img/content-blog-raw-blog-detectron-2-untitled-7.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-8.png](/img/content-blog-raw-blog-detectron-2-untitled-8.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-9.png](/img/content-blog-raw-blog-detectron-2-untitled-9.png)\n\n# Fine-tuning Chip Dataset\n\n### Load the data\n\n```\n#get the dataset\n!pip install -q kaggle\n!pip install -q kaggle-cli\nos.environ['KAGGLE_USERNAME'] = \"sparshag\" \nos.environ['KAGGLE_KEY'] = \"1b1f894d1fa6febe9676681b44ad807b\"\n!kaggle datasets download -d tannergi/microcontroller-detection\n!unzip microcontroller-detection.zip\n```\n\n### Convert dataset into Detectron2's standard format\n\n```\n# Registering the dataset\nfrom detectron2.structures import BoxMode\ndef get_microcontroller_dicts(csv_file, img_dir):\n    df = pd.read_csv(csv_file)\n    df['filename'] = df['filename'].map(lambda x: img_dir+x)\n\n    classes = ['Raspberry_Pi_3', 'Arduino_Nano', 'ESP8266', 'Heltec_ESP32_Lora']\n\n    df['class_int'] = df['class'].map(lambda x: classes.index(x))\n\n    dataset_dicts = []\n    for filename in df['filename'].unique().tolist():\n        record = {}\n        \n        height, width = cv2.imread(filename).shape[:2]\n        \n        record[\"file_name\"] = filename\n        record[\"height\"] = height\n        record[\"width\"] = width\n\n        objs = []\n        for index, row in df[(df['filename']==filename)].iterrows():\n          obj= {\n              'bbox': [row['xmin'], row['ymin'], row['xmax'], row['ymax']],\n              'bbox_mode': BoxMode.XYXY_ABS,\n              'category_id': row['class_int'],\n              \"iscrowd\": 0\n          }\n          objs.append(obj)\n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts\n\nclasses = ['Raspberry_Pi_3', 'Arduino_Nano', 'ESP8266', 'Heltec_ESP32_Lora']\nfor d in [\"train\", \"test\"]:\n  DatasetCatalog.register('microcontroller/' + d, lambda d=d: get_microcontroller_dicts('Microcontroller Detection/' + d + '_labels.csv', 'Microcontroller Detection/' + d+'/'))\n  MetadataCatalog.get('microcontroller/' + d).set(thing_classes=classes)\nmicrocontroller_metadata = MetadataCatalog.get('microcontroller/train')\n```\n\n### Model configuration and training\n\n```\n# Train the model\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = ('microcontroller/train',)\ncfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.MAX_ITER = 1000\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()\n```\n\n![/img/content-blog-raw-blog-detectron-2-untitled-10.png](/img/content-blog-raw-blog-detectron-2-untitled-10.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-11.png](/img/content-blog-raw-blog-detectron-2-untitled-11.png)\n\n### Inference and Visualization\n\n```\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\ncfg.DATASETS.TEST = ('microcontroller/test', )\npredictor = DefaultPredictor(cfg)\n\ndf_test = pd.read_csv('Microcontroller Detection/test_labels.csv')\n\ndataset_dicts = DatasetCatalog.get('microcontroller/test')\nfor d in random.sample(dataset_dicts, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1], \n                   metadata=microcontroller_metadata, \n                   scale=0.8\n                   )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    cv2_imshow(v.get_image()[:, :, ::-1])\n```\n\n### Real-time Webcam inference\n\n```\nfrom IPython.display import display, Javascript\nfrom google.colab.output import eval_js\nfrom base64 import b64decode\n\ndef take_photo(filename='photo.jpg', quality=0.8):\n  js = Javascript('''\n    async function takePhoto(quality) {\n      const div = document.createElement('div');\n      const capture = document.createElement('button');\n      capture.textContent = 'Capture';\n      div.appendChild(capture);\n\n      const video = document.createElement('video');\n      video.style.display = 'block';\n      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n      document.body.appendChild(div);\n      div.appendChild(video);\n      video.srcObject = stream;\n      await video.play();\n\n      // Resize the output to fit the video element.\n      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n      // Wait for Capture to be clicked.\n      await new Promise((resolve) => capture.onclick = resolve);\n\n      const canvas = document.createElement('canvas');\n      canvas.width = video.videoWidth;\n      canvas.height = video.videoHeight;\n      canvas.getContext('2d').drawImage(video, 0, 0);\n      stream.getVideoTracks()[0].stop();\n      div.remove();\n      return canvas.toDataURL('image/jpeg', quality);\n    }\n    ''')\n  display(js)\n  data = eval_js('takePhoto({})'.format(quality))\n  binary = b64decode(data.split(',')[1])\n  with open(filename, 'wb') as f:\n    f.write(binary)\n  return filename\n\nfrom IPython.display import Image\ntry:\n  filename = take_photo()\n  print('Saved to {}'.format(filename))\n  \n  # Show the image which was just taken.\n  display(Image(filename))\nexcept Exception as err:\n  # Errors will be thrown if the user does not have a webcam or if they do not\n  # grant the page permission to access it.\n  print(str(err))\n```\n\n```\nmodel_path = '/content/output/model_final.pth'\nconfig_path= model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n\n# Create config\ncfg = get_cfg()\ncfg.merge_from_file(config_path)\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1\ncfg.MODEL.WEIGHTS = model_path\n\npredictor = DefaultPredictor(cfg)\n\nim = cv2.imread('photo.jpg')\noutputs = predictor(im)\n\nv = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\nv = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\ncv2_imshow(v.get_image()[:, :, ::-1])\n```\n\n# Fine-tuning on Face dataset\n\nThe process is same. Here is the output.\n\n![/img/content-blog-raw-blog-detectron-2-untitled-12.png](/img/content-blog-raw-blog-detectron-2-untitled-12.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-13.png](/img/content-blog-raw-blog-detectron-2-untitled-13.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-14.png](/img/content-blog-raw-blog-detectron-2-untitled-14.png)\n\n### Behind the scenes\n\n![/img/content-blog-raw-blog-detectron-2-untitled-15.png](/img/content-blog-raw-blog-detectron-2-untitled-15.png)\n\n### References\n\n- [How to embed Detectron2 in your computer vision project - blogpost](https://medium.com/deepvisionguru/how-to-embed-detectron2-in-your-computer-vision-project-817f29149461)\n- [Detectron2 Train a Instance Segmentation Model by Gilbert Tanner](https://gilberttanner.com/blog/detectron2-train-a-instance-segmentation-model)\n- [How to train Detectron2 with Custom COCO Datasets - DLology](https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/)\n- [Character Recognition and Segmentation For Custom Data Using Detectron2 - blogpost](https://towardsdatascience.com/character-recognition-and-segmentation-for-custom-data-using-detectron2-599de82b393c)\n- [Training models with Panoptic Segmentation in Detectron2](https://www.celantur.com/blog/panoptic-segmentation-in-detectron2/)\n- [Image segmentation using Detectron2 - Kaggle](https://www.kaggle.com/lewisgmorris/image-segmentation-using-detectron2)\n- [A Beginner’s Guide To Object Detection And Computer Vision With Facebook’s Detectron2](https://towardsdatascience.com/a-beginners-guide-to-object-detection-and-computer-vision-with-facebook-s-detectron2-700b6273390e)\n- [Face Detection on Custom Dataset with Detectron2 and PyTorch using Python](https://www.curiousily.com/posts/face-detection-on-custom-dataset-with-detectron2-in-python/)\n- [My Experiment Notion](https://www.notion.so/Detectron-2-d31ac9c14a8d4d9888882df14a4e0eee)\n- [Official Colab](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5)\n- [Official Slide](https://research.fb.com/wp-content/uploads/2019/12/4.-detectron2.pdf)\n- [Official Git](https://github.com/facebookresearch/detectron2)"
        },
        {
          "id": "/2021/10/01/distributed-training-of-recommender-systems",
          "metadata": {
            "permalink": "/blog/2021/10/01/distributed-training-of-recommender-systems",
            "source": "@site/blog/2021-10-01-distributed-training-of-recommender-systems.mdx",
            "title": "Distributed Training of Recommender Systems",
            "description": "The usage and importance of recommender systems are increasing at a fast pace. And deep learning is gaining traction as the preferred choice for model architecture. Giants like Google and Facebook are already using recommenders to earn billions of dollars.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "distributed",
                "permalink": "/blog/tags/distributed"
              },
              {
                "label": "recsys",
                "permalink": "/blog/tags/recsys"
              }
            ],
            "readingTime": 5.85,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Distributed Training of Recommender Systems",
              "authors": "sparsh",
              "tags": [
                "distributed",
                "recsys"
              ]
            },
            "prevItem": {
              "title": "Detectron 2",
              "permalink": "/blog/2021/10/01/detectron-2"
            },
            "nextItem": {
              "title": "Document Recommendation",
              "permalink": "/blog/2021/10/01/document-recommendation"
            }
          },
          "content": "The usage and importance of recommender systems are increasing at a fast pace. And deep learning is gaining traction as the preferred choice for model architecture. Giants like Google and Facebook are already using recommenders to earn billions of dollars.\n\nRecently, Facebook shared its approach to maintain its 12 trillion parameter recommender. Building these large systems is challenging because it requires huge computation and memory resources. And we will soon enter into 100 trillion range. And SMEs will not be left behind due to open-source environment of software architectures and the decreasing cost of hardware, especially on the cloud infrastructure.\n\nAs per one estimate, a model with 100 trillion parameters would require at least 200TB just to store the model, even at 16-bit floating-point accuracy. So we need architectures that can support efficient and distributed training of recommendation models.\n\n***Memory-intensive vs Computation-intensive***: The increasing parameter comes mostly from the embedding layer which maps each entrance of an ID type feature (such as an user ID and a session ID) into a fixed length low-dimensional embedding vector. Consider the billion scale of entrances for the ID type features in a production recommender system and the wide utilization of feature crosses, the embedding layer usually domains the parameter space, which makes this component extremely **memory-intensive**. On the other hand, these low-dimensional embedding vectors are concatenated with diversified Non-ID type features (e.g., image, audio, video, social network, etc.) to feed a group of increasingly sophisticated neural networks (e.g., convolution, LSTM, multi-head attention) for prediction(s). Furthermore, in practice, multiple objectives can also be combined and optimized simultaneously for multiple tasks. These mechanisms make the rest neural network increasingly **computation-intensive**.\n\n![An example of a recommender models with 100+ trillions of parameter in the embedding layer and 50+ TFLOP computation in the neural network.](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled.png)\n\nAn example of a recommender models with 100+ trillions of parameter in the embedding layer and 50+ TFLOP computation in the neural network.\n\n[Alibaba's XDL](https://github.com/alibaba/x-deeplearning), [Baidu's PaddleRec](https://github.com/PaddlePaddle/PaddleRec), and [Kwai's Persia](https://github.com/persiaml/persia) are some open-source frameworks for this large-scale distributed training of recommender systems.\n\n<aside>\n📌 ***Synchronous vs Asynchronous Algorithms***: Synchronous algorithms always use the up-to-date gradient to update the model to ensure the model accuracy. However, the overhead of communications for synchronous algorithms starts to become too expensive to scale out the training procedure, causing inefficiency in running time. While asynchronous algorithm have better hardware efficiency, it often leads to a “significant” loss in model accuracy at this scale—for production recommender systems (e.g., Baidu’s search engine). Recall that even 0.1% drop of accuracy would lead to a noticeable loss in revenue.\n\n</aside>\n\n### Parameter Server Framework\n\nExisting distributed systems for deep learning based recommender models are usually built on top of the parameter server (PS) framework, where one can add elastic distributed storage to hold the increasingly large amount of parameters of the embedding layer. On the other hand, the computation workload does not scale linearly with the increasing parameter scale of the embedding layer—in fact, with an efficient implementation, a lookup operation over a larger embedding table would introduce almost no additional computations.\n\n![Left: deep learning based recommender model training workflow over a heterogeneous cluster. Right: Gantt charts to compare fully synchronous, fully asynchronous, raw hybrid and optimized hybrid modes of distributed training of the deep learning recommender model. [Source](https://arxiv.org/pdf/2111.05897v1.pdf).](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-1.png)\n\nLeft: deep learning based recommender model training workflow over a heterogeneous cluster. Right: Gantt charts to compare fully synchronous, fully asynchronous, raw hybrid and optimized hybrid modes of distributed training of the deep learning recommender model. [Source](https://arxiv.org/pdf/2111.05897v1.pdf).\n\n### PERSIA\n\n**PERSIA** (**P**arallel r**E**commendation t**R**aining **S**ystem with hybr**I**d **A**cceleration) is a PyTorch-based system for training deep learning recommendation models on commodity hardware. It supports models containing more than 100 trillion parameters.\n\nIt uses a hybrid training algorithm to tackle the embedding layer and dense neural network modules differently—the embedding layer is trained in an asynchronous fashion to improve the throughput of training samples, while the rest neural network is trained in a synchronous fashion to preserve the statistical efficiency.\n\nIt also uses a distributed system to manage the hybrid computation resources (CPUs and GPUs) to optimize the co-existence of asynchronicity and synchronicity in the training algorithm.\n\n![Untitled](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-2.png)\n\n![Untitled](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-3.png)\n\nPersia includes a data loader module, a embedding PS (Parameter Server) module, a group of embedding workers over CPU nodes, and a group of NN workers over GPU instances. Each module can be dynamically scaled for different model scales and desired training throughput:\n\n- A data loader that fetches training data from distributed storages such as Hadoop, Kafka, etc;\n- A embedding parameter server (embedding PS for short) manages the storage and update of the parameters in the embedding layer $\\mathrm{w}^{emb}$;\n- A group of embedding workers that runs Algorithm 1 for getting the embedding parameters from the embedding PS; aggregating embedding vectors (potentially) and putting embedding gradients back to embedding PS;\n- A group of NN workers that runs the forward-/backward- propagation of the neural network $\\mathrm{NN_{w^{nn}}(·)}$.\n\n![The architecture of Persia.](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-4.png)\n\nThe architecture of Persia.\n\nLogically, the training procedure is conducted by Persia in a data dispatching based paradigm as below:\n\n1. The data loader will dispatch the ID type feature $\\mathrm{x^{ID}}$ to an embedding worker—the embedding worker will generate an unique sample ID 𝜉 for this sample, buffer this sample ID with the ID type feature $\\mathrm{x_\\xi^{ID}}$ locally, and returns this ID 𝜉 back the data loader; the data loader will associate this sample’s Non-ID type features and labels with this unique ID.\n2. Next, the data loader will dispatch the Non-ID type feature and label(s) $\\mathrm{(x_\\xi^{NID},y_\\xi)}$ to a NN worker.\n3. Once a NN worker receives this incomplete training sample, it will issue a request to pull the ID type features’ $\\mathrm{(x_\\xi^{ID})}$ embedding $\\mathrm{w_\\xi^{emb}}$ from some embedding worker according to the sample ID 𝜉—this would trigger the forward propagation in Algorithm 1, where the embedding worker will use the buffered ID type feature $\\mathrm{x_\\xi^{ID}}$ to get the corresponding $\\mathrm{w_\\xi^{emb}}$ from the embedding PS.\n4. Then the embedding worker performs some potential aggregation of original embedding vectors. When this computation finishes, the aggregated embedding vector $\\mathrm{w_\\xi^{emb}}$ will be transmitted to the NN worker that issues the pull request.\n5. Once the NN worker gets a group of complete inputs for the dense module, it will create a mini-batch and conduct the training computation of the NN according to Algorithm 2. Note that the parameter of the NN always locates in the device RAM of the NN worker, where the NN workers synchronize the gradients by the AllReduce Paradigm.\n6. When the iteration of Algorithm 2 is finished, the NN worker will send the gradients of the embedding ($\\mathrm{F_\\xi^{emb'}}$) back to the embedding worker (also along with the sample ID 𝜉).\n7. The embedding worker will query the buffered ID type feature $\\mathrm{x_\\xi^{ID}}$ according to the sample ID 𝜉; compute gradients $\\mathrm{F_\\xi^{emb'}}$ of the embedding parameters and send the gradients to the embedding PS, so that the embedding PS can finally compute the updates according the embedding parameter’s gradients by its SGD optimizer and update the embedding parameters."
        },
        {
          "id": "/2021/10/01/document-recommendation",
          "metadata": {
            "permalink": "/blog/2021/10/01/document-recommendation",
            "source": "@site/blog/2021-10-01-document-recommendation.mdx",
            "title": "Document Recommendation",
            "description": "/img/content-blog-raw-blog-document-recommendation-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              }
            ],
            "readingTime": 1.285,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Document Recommendation",
              "authors": "sparsh",
              "tags": [
                "nlp",
                "similarity"
              ]
            },
            "prevItem": {
              "title": "Distributed Training of Recommender Systems",
              "permalink": "/blog/2021/10/01/distributed-training-of-recommender-systems"
            },
            "nextItem": {
              "title": "Fake Voice Detection",
              "permalink": "/blog/2021/10/01/fake-voice-detection"
            }
          },
          "content": "![/img/content-blog-raw-blog-document-recommendation-untitled.png](/img/content-blog-raw-blog-document-recommendation-untitled.png)\n\n## **Introduction**\n\n### Business objective\n\nFor the given user query, recommend relevant documents (BRM_ifam)\n\n### Technical objective\n\n1-to-N mapping of given input text\n\n## **Proposed Framework 1 — Hybrid Recommender System**\n\n- Text → Vector (Universal Sentence Embedding with TF Hub)\n- Vector → Content-based Filtering Recommendation\n- Index → Interaction Matrix\n- Interaction Matrix → Collaborative Filtering Recommendation\n- Collaborative + Content-based → Hybrid Recommendation\n- Evaluation: Area-under-curve\n\n## **Proposed Framework 2 — Content-based Recommender System**\n\n1. Find A most similar user → Cosine similarity\n2. For each user in A, find TopK Most Similar Items → Map Argsort\n3. For each item Find TopL Most Similar Items → Cosine similarity\n4. Display\n5. Implement an evaluation metric\n6. Evaluate\n\n## **Results and Discussion**\n\n- build.py → this script will take the training data as input and save all the required files in the same working directory\n- recommend.py → this script will take the user query as input and predict top-K BRM recommendations\n\nVariables (during recommendation, you will be asked 2–3 choices, the meaning of those choices are as following)\n\n- top-K — how many top items you want to get in recommendation\n- secondary items: this will determine how many similar items you would like to add in consideration, for each primary matching item\n- sorted by frequency: since multiple input queries might point to same output, therefore this option allows to take that frequence count of outputs in consideration and will move the more frequent items at the top.\n\n### **Code**\n\n[https://gist.github.com/sparsh-ai/4e5f06ba3c55192b33a276ee67dbd42c#file-text-recommendations-ipynb](https://gist.github.com/sparsh-ai/4e5f06ba3c55192b33a276ee67dbd42c#file-text-recommendations-ipynb)"
        },
        {
          "id": "/2021/10/01/fake-voice-detection",
          "metadata": {
            "permalink": "/blog/2021/10/01/fake-voice-detection",
            "source": "@site/blog/2021-10-01-fake-voice-detection.mdx",
            "title": "Fake Voice Detection",
            "description": "/img/content-blog-raw-blog-fake-voice-detection-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "audio",
                "permalink": "/blog/tags/audio"
              },
              {
                "label": "deepfake",
                "permalink": "/blog/tags/deepfake"
              }
            ],
            "readingTime": 2.88,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Fake Voice Detection",
              "authors": "sparsh",
              "tags": [
                "audio",
                "deepfake"
              ]
            },
            "prevItem": {
              "title": "Document Recommendation",
              "permalink": "/blog/2021/10/01/document-recommendation"
            },
            "nextItem": {
              "title": "Image Similarity System",
              "permalink": "/blog/2021/10/01/image-similarity-system"
            }
          },
          "content": "![/img/content-blog-raw-blog-fake-voice-detection-untitled.png](/img/content-blog-raw-blog-fake-voice-detection-untitled.png)\n\n# Introduction\n\nFake audio can be used for malicious purposes which affect directly or indirectly human life. The objective is to differentiate between fake and real voice. Python and deep learning has been used and implemented to achieve the objective. Audio files or video file are being used as an input of this work then model has been trained for uniquely identify features for voice creation and voice detection. Deep learning technique is used to find accuracy between real and fake.\n\nSpeaker recognition usually refers to both speaker identification and speaker verification. A speaker identification system identifies who the speaker is, while an automatic speaker verification (ASV) system decides if an identity claim is true or false.\nA general ASV system is robust to zero-effort impostors, they are vulnerable to more sophisticated attacks. Such vulnerability represents one of the security concerns of ASV systems. Spoofing involves an adversary (attacker) who masquerades as the target speaker to gain the access to a system. Such spoofing attacks can happen to various biometric traits, such as fingerprints, iris, face, and voice patterns. We are focusing only on the voice-based spoofing and anti-spoofing techniques for ASV system. The spoofed speech samples can be obtained through speech synthesis, voice conversion, or replay of recorded speech. **Imagine the following scenario…**\nYour phone rings, you pick up. It’s your spouse asking you for details about your savings account — they don’t have the account information on hand, but want to deposit money there this afternoon. Later, you realize a bunch of money has went missing! After investigating, you find out that the person masquerading as them on the other line was a voice 100% generated with AI. You’ve just been scammed, and on top of that, can’t believe the voice you thought belonged to your spouse was actually a fake.\n\nTo discern between real and fake audio, the detector uses visual representations of audio clips called spectrograms, which are also used to train speech synthesis models.\nGoogle’s 2019 [AVSSpoof dataset](https://www.blog.google/outreach-initiatives/google-news-initiative/advancing-research-fake-audio-detection/) contains over 25,000 clips of audio, featuring both real and fake clips of a variety of male and female speakers.**Temporal Convolution Model**\n\n# Modeling Approach\n\nFirst, raw audio is preprocessed and converted into a mel-frequency spectrogram — this is the input for the model. The model performs convolutions over the time dimension of the spectrogram, then uses masked pooling to prevent overfitting. Finally, the output is passed into a dense layer and a sigmoid activation function, which ultimately outputs a predicted probability between 0 (fake) and 1 (real).\nThe baseline model achieved 99%, 95%, and 85% accuracy on the train, validation, and test sets respectively. The differing performance is caused by differences between the three datasets. While all three datasets feature distinct and different speakers, the test set uses a different set of fake audio generating algorithms that were not present in the train or validation set.\n\n# Proposed Framework\n\n# Process Flow\n\n- Voice detection\n    - Temporal Convolution model\n        - Install packages\n        - Download pretrained models\n        - Initialize the model\n        - Load data\n        - Detect DeepFakes\n    - GMM-UBG model\n        - Install packages\n        - Train the model\n        - Load data\n        - Detect DeepFakes\n    - Convolutional VAE model\n        - Install packages\n        - Train the model\n        - Load data\n        - Detect DeepFakes\n    - Voice Similarity\n        - Install packages\n        - Load data\n        - Voice similarity match\n        - Embedding visualization\n\n# Models Algorithms\n\n1. Temporal Convolution\n2. ResNet\n3. GMM\n4. Light CNN\n5. Fusion\n6. SincNet\n7. ASSERT\n8. HOSA\n9. CVAE"
        },
        {
          "id": "/2021/10/01/image-similarity-system",
          "metadata": {
            "permalink": "/blog/2021/10/01/image-similarity-system",
            "source": "@site/blog/2021-10-01-image-similarity-system.mdx",
            "title": "Image Similarity System",
            "description": "/img/content-blog-raw-blog-image-similarity-system-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "aws beanstalk",
                "permalink": "/blog/tags/aws-beanstalk"
              },
              {
                "label": "flask",
                "permalink": "/blog/tags/flask"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 3.045,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Image Similarity System",
              "authors": "sparsh",
              "tags": [
                "aws beanstalk",
                "flask",
                "similarity",
                "vision"
              ]
            },
            "prevItem": {
              "title": "Fake Voice Detection",
              "permalink": "/blog/2021/10/01/fake-voice-detection"
            },
            "nextItem": {
              "title": "Insurance Personalization",
              "permalink": "/blog/2021/10/01/insurance-personalization"
            }
          },
          "content": "![/img/content-blog-raw-blog-image-similarity-system-untitled.png](/img/content-blog-raw-blog-image-similarity-system-untitled.png)\n\n# Choice of variables\n\n### Image Encoder\n\nWe can select any pre-trained image classification model. These models are commonly known as encoders because their job is to encode an image into a feature vector. I analyzed four encoders named 1) MobileNet, 2) EfficientNet, 3) ResNet and 4) [BiT](https://tfhub.dev/google/bit/m-r152x4/1). After basic research, I decided to select BiT model because of its performance and state-of-the-art nature. I selected the BiT-M-50x3 variant of model which is of size 748 MB. More details about this architecture can be found on the official page [here](https://tfhub.dev/google/bit/m-r50x3/1). \n\n### Vector Similarity System\n\nImages are represented in a fixed-length feature vector format. For the given input vector, we need to find the TopK most similar vectors, keeping the memory efficiency and real-time retrival objective in mind. I explored the most popular techniques and listed down five of them: Annoy, Cosine distance, L1 distance, Locally Sensitive Hashing (LSH) and Image Deep Ranking. I selected Annoy because of its fast and efficient nature. More details about Annoy can be found on the official page [here](https://github.com/spotify/annoy).\n\n### Dataset\n\nI listed down 3 datasets from Kaggle that were best fitting the criteria of this use case: 1) [Fashion Product Images (Small)](https://www.kaggle.com/bhaskar2443053/fashion-small?), 2) [Food-11 image dataset](https://www.kaggle.com/trolukovich/food11-image-dataset?) and 3) [Caltech 256 Image Dataset](https://www.kaggle.com/jessicali9530/caltech256?). I selected Fashion dataset and Foods dataset.\n\n# Literature review\n\n- Determining Image similarity with Quasi-Euclidean Metric [arxiv](https://arxiv.org/abs/2006.14644v1)\n- CatSIM: A Categorical Image Similarity Metric [arxiv](https://arxiv.org/abs/2004.09073v1)\n- Central Similarity Quantization for Efficient Image and Video Retrieval [arxiv](https://arxiv.org/abs/1908.00347v5)\n- Improved Deep Hashing with Soft Pairwise Similarity for Multi-label Image Retrieval [arxiv](https://arxiv.org/abs/1803.02987v3)\n- Model-based Behavioral Cloning with Future Image Similarity Learning [arxiv](https://arxiv.org/abs/1910.03157v1)\n- Why do These Match? Explaining the Behavior of Image Similarity Models [arxiv](https://arxiv.org/abs/1905.10797v1)\n- Learning Non-Metric Visual Similarity for Image Retrieval [arxiv](https://arxiv.org/abs/1709.01353v2)\n\n# Process Flow\n\n### Step 1: Data Acquisition\n\nDownload the raw image dataset into a directory. Categorize these images into their respective category directories. Make sure that images are of the same type, JPEG recommended. We will also process the metadata and store it in a serialized file, CSV recommended. \n\n### Step 2: Encoder Fine-tuning\n\nDownload the pre-trained image model and add two additional layers on top of that: the first layer is a feature vector layer and the second layer is the classification layer. We will only train these 2 layers on our data and after training, we will select the feature vector layer as the output of our fine-tuned encoder. After fine-tuning the model, we will save the feature extractor for later use.\n\n![Fig: a screenshot of encoder fine-tuning process](/img/content-blog-raw-blog-image-similarity-system-untitled-1.png)\n\nFig: a screenshot of encoder fine-tuning process\n\n### Step 3: Image Vectorization\n\nNow, we will use the encoder (prepared in step 2) to encode the images (prepared in step 1). We will save feature vector of each image as an array in a directory. After processing, we will save these embeddings for later use.\n\n### Step 4: Metadata and Indexing\n\nWe will assign a unique id to each image and create dictionaries to locate information of this image: 1) Image id to Image name dictionary, 2) Image id to image feature vector dictionary, and 3) (optional) Image id to metadata product id dictionary. We will also create an image id to image feature vector indexing. Then we will save these dictionaries and index object for later use.\n\n### Step 5: API Call\n\nWe will receive an image from user, encode it with our image encoder, find TopK similar vectors using Indexing object, and retrieve the image (and metadata) using dictionaries. We send these images (and metadata) back to the user.\n\n# Deployment\n\nThe API was deployed on AWS cloud infrastructure using AWS Elastic Beanstalk service.\n\n![/img/content-blog-raw-blog-image-similarity-system-untitled-2.png](/img/content-blog-raw-blog-image-similarity-system-untitled-2.png)"
        },
        {
          "id": "/2021/10/01/insurance-personalization",
          "metadata": {
            "permalink": "/blog/2021/10/01/insurance-personalization",
            "source": "@site/blog/2021-10-01-insurance-personalization.mdx",
            "title": "Insurance Personalization",
            "description": "Author: Alexsoft",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "insurance",
                "permalink": "/blog/tags/insurance"
              },
              {
                "label": "personalization",
                "permalink": "/blog/tags/personalization"
              }
            ],
            "readingTime": 9.355,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Insurance Personalization",
              "authors": "sparsh",
              "tags": [
                "insurance",
                "personalization"
              ]
            },
            "prevItem": {
              "title": "Image Similarity System",
              "permalink": "/blog/2021/10/01/image-similarity-system"
            },
            "nextItem": {
              "title": "Name & Address Parsing",
              "permalink": "/blog/2021/10/01/name-&-address-parsing"
            }
          },
          "content": "Author: [Alexsoft](https://www.altexsoft.com/blog/personalized-insurance/)\n\nIn a hyper-connected world, where advanced analytics and smart devices constantly re-assess and monitor risks, the traditional once-a-year insurance policy looks increasingly irrelevant and static. Insurance will become a breathing and living thing that shrinks and scales with time to accommodate the changing risks in the clients’ daily lives. As technology continues to expand, real-time data from connected devices and predictive analysis from AIs and machine learning will enhance personalized insurance to benefit the client and insurer.\n\nTo satisfy the expectations of clients, insurers may need to go beyond the personalization of marketing communication and start personalizing product bundles for individuals.\n\n## What is personalized insurance?\n\n**Personalized insurance** is the process of reaching insurance customers with targeted pricing, offers, and messages at the right time. Personalization spans across various types of insurance services, from health to property insurance.\n\nSome insurers are already defining themselves as trusted advisors aiding people in navigating, anticipating, and eliminating risks rather than just paying the compensation when things go wrong.\n\nFor example, these companies use customer data from wearable and smart devices to monitor the user’s lifestyle. If the user’s data indicate the emergence of a serious medical condition, they can send the customer content designed to change their detrimental lifestyle or recommend immediate treatment. When the customer stays fit, healthy and does not carry out risky activities, their insurance cost will be decreased.\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled.png](/img/content-blog-raw-blog-insurance-personalization-untitled.png)\n\nInsurers can provide personalization to customers at different levels:\n\n- **Personalized product bundles.** The insurer offers a wide range of products such as health, car, life, and property insurance. So, clients can choose the specific products they want and group them in a bundle.\n- **Personalized communications.** Insurers use data collected from smart devices to notify customers about harmful activities and lifestyles. They also send recommendations on lifestyle changes. Some insurers take a step further to provide clients with incentives for a healthy lifestyle.\n- **Personalized insurance quote.** Customers are able to adjust the price of their insurance premiums by turning off the ones they don’t need at any time. Some insurers enable automatic quote adjustments depending on customer’s behavior (e.g., driving habits) or lifestyle choices (e.g., exercising).\n\n### Why is it important?\n\nCollecting and analyzing user data is vital in personalizing products based on individual behavior and preferences. In addition, insurers should use this data to enhance external relationships with their customers and guide their internal processes. This will eventually lead to delightful customer experiences and efficient operations.\n\nPersonalized insurance is important for many reasons:\n\n**Customers expect personalized treatment.** Every customer wants to feel special, and the personalization of your services and products will do just that. It will make them stay loyal to you. Moreover, customers are open for personalization. According to the [Accenture study](https://www.accenture.com/_acnmedia/PDF-95/Accenture-2019-Global-Financial-Services-Consumer-Study.pdf#zoom=50), 95 percent of new customers are ready to share their data in exchange for personalized insurance services. And about 58 percent of conservative users would be willing to do so.\n\n**Driving more effective sales and increasing revenue.** Personalization benefits your sales and income in two ways. First, lots of people are ready to share their data with you in exchange for incentives and reduced premiums. Secondly, having access to clients’ data gives you the ability to target people who are already interested in your product, thereby increasing sales and revenue at a lower cost. You will be able to reach your customers at the right time and with the product they need.\n\n**Streamlining operations and working with customers more accurately.** Having an insight into customer preferences and behavior is crucial if you want to provide personalized services. Data obtained from social media activity, fitness trackers, GPS, and other tech can help you serve customers better.\n\n## Success stories\n\n### Lemonade\n\nUse of AI and chatbots to personalize communications. \n\nLemonade is a US insurance company that uses Maya – an AI-powered bot, to collect and analyze customer data. Maya acts as a virtual assistant that gets information, provides quotes, and handles payments. It also has the ability to provide customized answers to user’s questions and even help them make changes to existing policies. Lemonade uses Natural Action Synthesis and Natural Language Processing to ensure that Maya gets smarter the more it chats. This is possible because their machine learning model is retrained almost daily.\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled-1.png](/img/content-blog-raw-blog-insurance-personalization-untitled-1.png)\n\nOn top of that, the company uses big data analytics to quantify losses and predict risks by placing the client into a risk group and quoting a relevant premium. Customers are grouped according to their risk behaviors. The groups are created using algorithms that collect extensive customer data, such as health conditions.\n\n### Cover\n\n**[Cover](https://cover.com/)** is a US-based insurance metasearch company that notifies its clients of price drops for their premiums. Their technology works by scanning the market, looking for discounted and lowered prices of insurance premiums for their clients. Cover blends automation, mobile technology, and expert advice to provide customers with high-quality insurance protection at the best prices.\n\nCover compares with policy data and prices from over 30 different insurers. From the start, the customers need to provide answers to some questions, which will be used to match the client with a policy that suits their needs.\n\n### Oscar\n\n**[Oscar](https://www.hioscar.com/)** is a health insurer that provides its clients with a concierge team of medical professionals who give health advice and help them know if they see the best specialist for their specific health condition. They also help with finding the best doctors that accept Oscar insurance and manage and treat chronic conditions. Also, they set aside a separate concierge team in cases of emergencies that helps with the patient’s discharge and follow-up care.\n\nOscar’s mobile app acts as an intermediary between the user and the health system. The platform facilitates the customer’s interaction with their healthcare professionals. Clients can receive their lab reports, medical records, physician recommendations, and virtual care from the app. Oscar has also improved its high-touch services, including telemedicine and an “Ask your concierge” feature that connects users with a health insurance advice team.\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled-2.png](/img/content-blog-raw-blog-insurance-personalization-untitled-2.png)\n\n### Alllstate\n\nAllstate is an auto insurance company that offers personalized car insurance to its customers using telematics programs called Drivewise and Milewise. Drivewise is offered through a mobile app that monitors the customers driving behavior and provides feedback after each drive. Customers also receive incentives for safe driving. From the app interface, clients can check their rewards and driving behavior for the last 100 trips. The customer’s premium is then calculated based on factors like speeding, abrupt braking, and time of the trip. One of the nice things about Drivewise is that even those who do not have an Allstate care insurance policy can participate in this program. Their Milewise program, as the name suggests, lets customers pay insurance based on the miles covered. So, the app monitors the distance covered by the car, and low-mileage drivers can save on insurance.\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled-3.png](/img/content-blog-raw-blog-insurance-personalization-untitled-3.png)\n\n## How to approach personalization?\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled-4.png](/img/content-blog-raw-blog-insurance-personalization-untitled-4.png)\n\nBefore fully investing in personalization, you need to carefully plan your approach. This will ensure you have all the pieces for success, and it will help you follow through with your plan.\n\n### Explore existing data\n\nHaving customer data is the minimum requirement to provide personalized services. First, you need to envision the type of personalization you want to offer. Then, make sure you have data collection channels that provide you with relevant data needed for your tasks. For instance, some of your documents may contain the required information, and you have to digitize, structure those, or extract specific details for that. So, you should audit your current information and data collection mechanisms to estimate whether you’ll need any additional effort to gather this data. For instance, you may want to use [intelligent document processing](https://www.altexsoft.com/blog/intelligent-document-processing/).\n\n### Engage data scientists to make the proof of concept and carry out A/B tests\n\nYour vision on personalization may not work for every business model. Or your data quality may be low to reach project feasibility. We’ve talked about that while explaining how to approach [ROI calculations with machine learning projects](https://www.altexsoft.com/blog/business/how-to-estimate-roi-and-costs-for-machine-learning-and-data-science-projects/). So, you need to present the data you have to a data science team to run several experiments and build prototypes. Once they are ready, you can roll out your new algorithms for a subset of customers to run A/B tests. Their results may show that the conventional approaches work better for you or help iterate on your assumptions.\n\n### Invest in data infrastructure\n\nIf the A/B tests show that personalization will work for your business model, that is where automation comes into play. You can start investing in data infrastructure and [analytical pipelines](https://www.altexsoft.com/blog/data-pipeline-components-and-types/) to automate data collection and analysis mechanisms.\n\nYou’ll need a [data engineering team](https://www.altexsoft.com/blog/datascience/what-is-data-engineering-explaining-data-pipeline-data-warehouse-and-data-engineer-role/) for that. These specialists set up connections with data sources, such as mobile, IoT, and telematics devices, enable automatic data preparation, configure storages, and integrate your infrastructure with business intelligence software that helps explore and visualize data.\n\n### Continuously learn your customers’ preferences and needs\n\nThe data you collect is only as good as the insights gained from it. That is why it is vital to have a [comprehensive analytic solution](https://www.altexsoft.com/blog/business/complete-guide-to-business-intelligence-and-analytics-strategy-steps-processes-and-tools/). A high-quality analytic software will transform the data into your most valuable asset. This data will be used to improve product development, make more accurate decisions, and provide personalized services to your customers.\n\n### Iterate on your infrastructure and algorithms\n\nPersonalization isn’t a one-time project. Whether you apply machine learning or build personalization based on rule-based systems, you still have to revisit your technology, continuously gather new data, and adapt your workflows.\n\n### Ensure a personalized cross-channel experience\n\nSince the data collected from IoT devices and other tech is vital for personalization, it is important to make the customer experience seamless across different communication channels. Therefore, the customer should always be provided with the same level of personalization regardless of the touchpoint.\n\n## Challenges\n\n**Personalization is financially intensive.** The ability of insurers to personalize insurance differs only marginally between marketing communications and products. Most of them, especially startups, do not have the funds to implement advanced technologies like machine learning needed for personalized insurance. However, insurers do not need to start with all the levels of personalization. They can often start by customizing their customer service, gathering data and insights, and then gradually developing towards more complex systems.\n\n**Complex process involving multiple parties.** Also, it is difficult to balance personalization with financial targets, especially when establishing a price for risk. In-depth personalization of insurance must use data analytics from different sources to ensure that personalized offers reflect the client’s needs as well as the profitability and risks implications for the company.\n\n**Customer data is heavily regulated.** Customer data from different sources are subject to industry regulations and privacy concerns. It is often a difficult task to obtain approval from regulators to use this data. Also, customers are becoming more aware of how companies are using their data and approve strict regulations. That is why laws such as General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) have been passed, which gives customers more control over their data. Insurers can address this barrier by explaining to people how their systems work and how personal data is used. Read more on [explainable machine learning](https://www.altexsoft.com/blog/interpretability-machine-learning/) in our dedicated article. Besides being open, insurers can provide clients with incentives and other services for free in exchange for access to personal data."
        },
        {
          "id": "/2021/10/01/name-&-address-parsing",
          "metadata": {
            "permalink": "/blog/2021/10/01/name-&-address-parsing",
            "source": "@site/blog/2021-10-01-name-&-address-parsing.mdx",
            "title": "Name & Address Parsing",
            "description": "/img/content-blog-raw-blog-name-&-address-parsing-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "app",
                "permalink": "/blog/tags/app"
              },
              {
                "label": "flask",
                "permalink": "/blog/tags/flask"
              },
              {
                "label": "ner",
                "permalink": "/blog/tags/ner"
              },
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              }
            ],
            "readingTime": 3.8,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Name & Address Parsing",
              "authors": "sparsh",
              "tags": [
                "app",
                "flask",
                "ner",
                "nlp"
              ]
            },
            "prevItem": {
              "title": "Insurance Personalization",
              "permalink": "/blog/2021/10/01/insurance-personalization"
            },
            "nextItem": {
              "title": "Object Detection Hands-on Exercises",
              "permalink": "/blog/2021/10/01/object-detection-hands-on-exercises"
            }
          },
          "content": "![/img/content-blog-raw-blog-name-&-address-parsing-untitled.png](/img/content-blog-raw-blog-name-&-address-parsing-untitled.png)\n\n# Introduction\n\nCreate an API that can parse and classify names and addresses given a string. We tried [probablepeople](https://github.com/datamade/probablepeople) and [usaddress](https://github.com/datamade/usaddress). These work well separately but need the functionality of these packages combined, and better accuracy than what probablepeople provides.\nFor the API, I'd like to mimic [this](https://parserator.datamade.us/api-docs/) with some minor modifications.\nA few examples: \n\n- \"KING JOHN A 5643 ROUTH CREEK PKWY #1314 RICHARDSON TEXAS 750820146 UNITED STATES OF AMERICA\" would return type: person; first_name: JOHN; last_name: KING; middle: A; street_address: 5643 ROUTH CREEK PKWY #1314; city: RICHARDSON; state: TEXAS; zip: 75082-0146; country: UNITED STATES OF AMERICA.\n- \"THRM NGUYEN LIVING TRUST 2720 SUMMERTREE CARROLLTON HOUSTON TEXAS 750062646 UNITED STATES OF AMERICA\" would return type: entity; name: THRM NGUYEN LIVING TRUST; street_address: 2720 SUMMERTREE CARROLLTON; state: TEXAS; city: HOUSTON; zip: 75006-2646; country: UNITED STATES OF AMERICA.\n\n# Modeling Approach\n\n### List of Entities\n\nList of Entities A - Person, Household, Corporation\n\nList of Entities B - Person First name, Person Middle name, Person Last name, Street address, City, State, Pincode, Country, Company name\n\n### Endpoint Configuration\n\n**OOR Endpoint**\n\nInput Instance: ANDERSON, EARLINE 1423 NEW YORK AVE FORT WORTH, TX 76104 7522\n\n```\nOutput Tags:-\n<Type> - Person/Household/Corporation\n<GivenName>, <MiddleName>, <Surname> - if Type Person/Household\n<Name> - Full Name - if Type Person \n<Name> - Household - if Type Household\n<Name> - Corporation - If Type Corporation\n<Address> - Full Address\n<StreetAddress>, <City>, <State>, <Zipcode>, <Country>\n~~NameConfidence, AddrConfidence~~\n```\n\n**Name Endpoint**\n\nInput Instance: ANDERSON, EARLINE\n\n```\nOutput Tags:-\n\n- <Type> - Person/Household/Corporation\n- <GivenName>, <MiddleName>, <Surname> - if Type Person/Household\n- <Name> - Full Name - if Type Person\n- <Name> - Household - if Type Household\n- <Name> - Corporation - If Type Corporation\n- ~~NameConfidence~~\n```\n\n**Address Endpoint**\n\nInput Instance: 1423 NEW YORK AVE FORT WORTH, TX 76104 7522\n\n```\nOutput Tags:-\n\n- <Address> - Full Address\n- <StreetAddress>, <City>, <State>, <Zipcode>, <Country>\n- ~~AddrConfidence~~\n```\n\n### Process Flow\n\n- Pytorch Flair NER model\n- Pre trained word embeddings\n- Additional parsing models on top of name tags\n- Tagging of 1000+ records to create training data\n- Deployment as REST api with 3 endpoints - name parse, address parse and whole string parse\n\n# Framework\n\n![/img/content-blog-raw-blog-name-&-address-parsing-untitled-1.png](/img/content-blog-raw-blog-name-&-address-parsing-untitled-1.png)\n\n![/img/content-blog-raw-blog-name-&-address-parsing-untitled-2.png](/img/content-blog-raw-blog-name-&-address-parsing-untitled-2.png)\n\n# Tagging process\n\nI used Doccano ([https://github.com/doccano/doccano](https://github.com/doccano/doccano)) for labeling the dataset. This tool is open-source and free to use. I deployed it with a one-click Heroku service (fig 1). After launching the app, log in with the provided credentials, and create a project (fig 2). Create the labels and upload the dataset (fig 3). Start the annotation process (fig 4). Now after enough annotations (you do not need complete all annotations in one go), go back to projects > edit section and export the data (fig 5). Bring the exported JSON file in python and run the model training code. The whole model will automatically get trained on the new annotations. To make the training faster, you can use Nvidia GPU support.\n\n![fig 1: screenshot taken from Doccano's github page](/img/content-blog-raw-blog-name-&-address-parsing-untitled-3.png)\n\nfig 1: screenshot taken from Doccano's github page\n\n![fig 2: Doccano's deployed app homepage](/img/content-blog-raw-blog-name-&-address-parsing-untitled-4.png)\n\nfig 2: Doccano's deployed app homepage\n\n![fig 3: create the labels. I defined these labels for my project](/img/content-blog-raw-blog-name-&-address-parsing-untitled-5.png)\n\nfig 3: create the labels. I defined these labels for my project\n\n![fig 5: export the annotations](/img/content-blog-raw-blog-name-&-address-parsing-untitled-6.png)\n\nfig 5: export the annotations\n\n# Model\n\nI first tried the Spacy NER blank model but it was not giving high-quality results. So I moved to the PyTorch Flair NER model. This model was a way faster (5 min training because of GPU compatibility comparing to 1-hour Spacy training time) and also much more accurate. F1 results for all tags were near perfect (score of 1).  This score will increase further with more labeled data. This model is production-ready.\n\n# Inference\n\nFor OOR, I directly used the model's output for core tagging and created the aggregated tags like recipient (aggregation of name tags) and address (aggregation of address tags like city and state) using simple conditional concatenation. For only Name and only Address inference, I added the dummy address in name text and dummy name in address text. This way, I passed the text in same model and later on filtered the required tags as output. \n\n### API\n\nI used Flask REST framework in Python to build the API with 3 endpoints. This API is production-ready.\n\n# Results and Discussion\n\n- 0.99 F1 score on 6 out of 8 tags & 0.95+ F1 score on other 2 tags\n- API inference time of less than 1 second on single CPU"
        },
        {
          "id": "/2021/10/01/object-detection-hands-on-exercises",
          "metadata": {
            "permalink": "/blog/2021/10/01/object-detection-hands-on-exercises",
            "source": "@site/blog/2021-10-01-object-detection-hands-on-exercises.mdx",
            "title": "Object Detection Hands-on Exercises",
            "description": "We are going to discuss the following 4 use cases:",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "object detection",
                "permalink": "/blog/tags/object-detection"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 3.165,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Object Detection Hands-on Exercises",
              "authors": "sparsh",
              "tags": [
                "object detection",
                "vision"
              ]
            },
            "prevItem": {
              "title": "Name & Address Parsing",
              "permalink": "/blog/2021/10/01/name-&-address-parsing"
            },
            "nextItem": {
              "title": "Object detection with OpenCV",
              "permalink": "/blog/2021/10/01/object-detection-with-opencv"
            }
          },
          "content": "We are going to discuss the following 4 use cases:\n\n1. Detect faces, eyes, pedestrians, cars, and number plates using OpenCV haar cascade classifiers\n2. Streamlit app for MobileNet SSD Caffe Pre-trained model\n3. Streamlit app for various object detection models and use cases\n4. Detect COCO-80 class objects in videos using TFHub MobileNet SSD model\n\n### Use Case 1 -  **Object detection with OpenCV**\n\n**Face detection** - We will use the frontal face Haar cascade classifier model to detect faces in the given image. The following function first passes the given image into the classifier model to detect a list of face bounding boxes and then runs a loop to draw a red rectangle box around each detected face in the image:\n\n```python\ndef detect_faces(fix_img):\n    face_rects = face_classifier.detectMultiScale(fix_img)\n    for (x, y, w, h) in face_rects:\n        cv2.rectangle(fix_img,\n                     (x,y),\n                     (x+w, y+h),\n                     (255,0,0),\n                     10)\n    return fix_img\n```\n\n**Eyes detection** - The process is almost similar to the face detection process. Instead of frontal face Haar cascade, we will use the eye detection Haar cascade model.\n\n![Input image](/img/content-blog-raw-blog-object-detection-with-opencv-untitled.png)\n\nInput image\n\n![detected faces and eyes in the image](/img/content-blog-raw-blog-object-detection-with-opencv-untitled-1.png)\n\ndetected faces and eyes in the image\n\n**Pedestrian detection** - We will use the full-body Haar cascade classifier model for pedestrian detection. We will apply this model to a video this time. The following function will run the model on each frame of the video to detect the pedestrians:\n\n```python\n# While Loop\nwhile cap.isOpened():\n    # Read the capture\n\t\tret, frame = cap.read()\n    # Pass the Frame to the Classifier\n\t\tbodies = body_classifier.detectMultiScale(frame, 1.2, 3)\n    # if Statement\n\t\tif ret == True:\n        # Bound Boxes to Identified Bodies\n\t\t\t\tfor (x,y,w,h) in bodies:\n            cv2.rectangle(frame,\n                         (x,y),\n                         (x+w, y+h),\n                         (25,125,225),\n                         5)\n            cv2.imshow('Pedestrians', frame) \n        # Exit with Esc button\n\t\t\t\tif cv2.waitKey(1) == 27:\n            break  \n    # else Statement\n\t\telse:\n        break\n    \n# Release the Capture & Destroy All Windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n**Car detection** - The process is almost similar to the pedestrian detection process. Again, we will use this model on a video. Instead of people Haar cascade, we will use the car cascade model.\n\n**Car number plate detection** - The process is almost similar to the face and eye detection process. We will use the car number plate cascade model.\n\n*You can find the code [here](https://github.com/sparsh-ai/0D7ACA15) on Github.*\n\n### Use Case 2 - MobileNet SSD Caffe Pre-trained model\n\n*You can play with the live app [here](https://share.streamlit.io/sparsh-ai/streamlit-5a407279/app.py). Souce code is available* [here](https://github.com/sparsh-ai/streamlit-489fbbb7) *on Github.*\n\n### Use Case 3 - YOLO Object Detection App\n\n*You can play with the live app* [*here](https://share.streamlit.io/sparsh-ai/streamlit-489fbbb7/app.py). Source code is available [here](https://github.com/sparsh-ai/streamlit-5a407279/tree/master) on Github.*\n\nThis app can detect COCO 80-classes using three different models - Caffe MobileNet SSD, Yolo3-tiny, and Yolo3. It can also detect faces using two different models - SSD Res10 and OpenCV face detector.  Yolo3-tiny can also detect fires.\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png)\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png)\n\n### Use Case 4 - TFHub MobileNet SSD on Videos\n\nIn this section, we will use the MobileNet SSD object detection model from TFHub. We will apply it to videos. We can load the model using the following command:\n\n```python\nmodule_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\ndetector = hub.load(module_handle).signatures['default']\n```\n\nAfter loading the model, we will capture frames using OpenCV video capture method, and pass each frame through the detection model:\n\n```python\ncap = cv2.VideoCapture('/content/Spectre_opening_highest_for_a_James_Bond_film_in_India.mp4')\nfor i in range(1,total_frames,200):\n    cap.set(cv2.CAP_PROP_POS_FRAMES,i)\n    ret,frame = cap.read()\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    run_detector(detector,frame)\n```\n\nHere are some detected objects in frames: \n\n![/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled.png](/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled.png)\n\n![/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled-1.png](/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled-1.png)\n\n![/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled-2.png](/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled-2.png)\n\n*You can find the code [here](https://gist.github.com/sparsh-ai/32ff6fe8c073f6be5d893029e4dc2960) on Github.*\n\n---\n\n*Congrats! In the next post of this series, we will cover 5 exciting use cases - 1) detectron 2 object detection fine-tuning on custom class, 2) Tensorflow Object detection API inference, fine-tuning, and few-shot learning, 3) Inference with 6 pre-trained models, 4) Mask R-CNN object detection app, and 5) Logo detection app deployment as a Rest API using AWS elastic Beanstalk.*"
        },
        {
          "id": "/2021/10/01/object-detection-with-opencv",
          "metadata": {
            "permalink": "/blog/2021/10/01/object-detection-with-opencv",
            "source": "@site/blog/2021-10-01-object-detection-with-opencv.mdx",
            "title": "Object detection with OpenCV",
            "description": "Face detection",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "object detection",
                "permalink": "/blog/tags/object-detection"
              },
              {
                "label": "opencv",
                "permalink": "/blog/tags/opencv"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 1.565,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Object detection with OpenCV",
              "authors": "sparsh",
              "tags": [
                "object detection",
                "opencv",
                "vision"
              ]
            },
            "prevItem": {
              "title": "Object Detection Hands-on Exercises",
              "permalink": "/blog/2021/10/01/object-detection-hands-on-exercises"
            },
            "nextItem": {
              "title": "Object detection with YOLO3",
              "permalink": "/blog/2021/10/01/object-detection-with-yolo3"
            }
          },
          "content": "## **Face detection**\n\nWe will use the frontal face Haar cascade classifier model to detect faces in the given image. The following function first passes the given image into the classifier model to detect a list of face bounding boxes and then runs a loop to draw a red rectangle box around each detected face in the image:\n\n```python\ndef detect_faces(fix_img):\n    face_rects = face_classifier.detectMultiScale(fix_img)\n    for (x, y, w, h) in face_rects:\n        cv2.rectangle(fix_img,\n                     (x,y),\n                     (x+w, y+h),\n                     (255,0,0),\n                     10)\n    return fix_img\n```\n\n## **Eyes detection**\n\nThe process is almost similar to the face detection process. Instead of frontal face Haar cascade, we will use the eye detection Haar cascade model.\n\n![Input image](/img/content-blog-raw-blog-object-detection-with-opencv-untitled.png)\n\nInput image\n\n![detected faces and eyes in the image](/img/content-blog-raw-blog-object-detection-with-opencv-untitled-1.png)\n\ndetected faces and eyes in the image\n\n## **Pedestrian detection**\n\nWe will use the full-body Haar cascade classifier model for pedestrian detection. We will apply this model to a video this time. The following function will run the model on each frame of the video to detect the pedestrians:\n\n```python\n# While Loop\nwhile cap.isOpened():\n    # Read the capture\n\t\tret, frame = cap.read()\n    # Pass the Frame to the Classifier\n\t\tbodies = body_classifier.detectMultiScale(frame, 1.2, 3)\n    # if Statement\n\t\tif ret == True:\n        # Bound Boxes to Identified Bodies\n\t\t\t\tfor (x,y,w,h) in bodies:\n            cv2.rectangle(frame,\n                         (x,y),\n                         (x+w, y+h),\n                         (25,125,225),\n                         5)\n            cv2.imshow('Pedestrians', frame) \n        # Exit with Esc button\n\t\t\t\tif cv2.waitKey(1) == 27:\n            break  \n    # else Statement\n\t\telse:\n        break\n    \n# Release the Capture & Destroy All Windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n## **Car detection**\n\nThe process is almost similar to the pedestrian detection process. Again, we will use this model on a video. Instead of people Haar cascade, we will use the car cascade model.\n\n## **Car number plate detection**\n\nThe process is almost similar to the face and eye detection process. We will use the car number plate cascade model.\n\n*You can find the code [here](https://github.com/sparsh-ai/0D7ACA15) on Github.*"
        },
        {
          "id": "/2021/10/01/object-detection-with-yolo3",
          "metadata": {
            "permalink": "/blog/2021/10/01/object-detection-with-yolo3",
            "source": "@site/blog/2021-10-01-object-detection-with-yolo3.mdx",
            "title": "Object detection with YOLO3",
            "description": "Live app",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "app",
                "permalink": "/blog/tags/app"
              },
              {
                "label": "streamlit",
                "permalink": "/blog/tags/streamlit"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 1.975,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Object detection with YOLO3",
              "authors": "sparsh",
              "tags": [
                "app",
                "streamlit",
                "vision"
              ]
            },
            "prevItem": {
              "title": "Object detection with OpenCV",
              "permalink": "/blog/2021/10/01/object-detection-with-opencv"
            },
            "nextItem": {
              "title": "OCR experiments",
              "permalink": "/blog/2021/10/01/ocr-experiments"
            }
          },
          "content": "## Live app\n\nThis app can detect COCO 80-classes using three different models - Caffe MobileNet SSD, Yolo3-tiny, and Yolo3. It can also detect faces using two different models - SSD Res10 and OpenCV face detector.  Yolo3-tiny can also detect fires.\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png)\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png)\n\n## Code\n\n```python\nimport streamlit as st\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport os\n\nfrom tempfile import NamedTemporaryFile\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\ntemp_file = NamedTemporaryFile(delete=False)\n\nDEFAULT_CONFIDENCE_THRESHOLD = 0.5\nDEMO_IMAGE = \"test_images/demo.jpg\"\nMODEL = \"model/MobileNetSSD_deploy.caffemodel\"\nPROTOTXT = \"model/MobileNetSSD_deploy.prototxt.txt\"\n\nCLASSES = [\n    \"background\",\n    \"aeroplane\",\n    \"bicycle\",\n    \"bird\",\n    \"boat\",\n    \"bottle\",\n    \"bus\",\n    \"car\",\n    \"cat\",\n    \"chair\",\n    \"cow\",\n    \"diningtable\",\n    \"dog\",\n    \"horse\",\n    \"motorbike\",\n    \"person\",\n    \"pottedplant\",\n    \"sheep\",\n    \"sofa\",\n    \"train\",\n    \"tvmonitor\",\n]\nCOLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n\n@st.cache\ndef process_image(image):\n    blob = cv2.dnn.blobFromImage(\n        cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5\n    )\n    net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n    net.setInput(blob)\n    detections = net.forward()\n    return detections\n\n@st.cache\ndef annotate_image(\n    image, detections, confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD\n):\n    # loop over the detections\n    (h, w) = image.shape[:2]\n    labels = []\n    for i in np.arange(0, detections.shape[2]):\n        confidence = detections[0, 0, i, 2]\n\n        if confidence > confidence_threshold:\n            # extract the index of the class label from the `detections`,\n            # then compute the (x, y)-coordinates of the bounding box for\n            # the object\n            idx = int(detections[0, 0, i, 1])\n            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n            (startX, startY, endX, endY) = box.astype(\"int\")\n\n            # display the prediction\n            label = f\"{CLASSES[idx]}: {round(confidence * 100, 2)}%\"\n            labels.append(label)\n            cv2.rectangle(image, (startX, startY), (endX, endY), COLORS[idx], 2)\n            y = startY - 15 if startY - 15 > 15 else startY + 15\n            cv2.putText(\n                image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2\n            )\n    return image, labels\n\ndef main():\n  selected_box = st.sidebar.selectbox(\n    'Choose one of the following',\n    ('Welcome', 'Object Detection')\n    )\n    \n  if selected_box == 'Welcome':\n      welcome()\n  if selected_box == 'Object Detection':\n      object_detection() \n\ndef welcome():\n  st.title('Object Detection using Streamlit')\n  st.subheader('A simple app for object detection')\n  st.image('test_images/demo.jpg',use_column_width=True)\n\ndef object_detection():\n  \n  st.title(\"Object detection with MobileNet SSD\")\n\n  confidence_threshold = st.sidebar.slider(\n    \"Confidence threshold\", 0.0, 1.0, DEFAULT_CONFIDENCE_THRESHOLD, 0.05)\n\n  st.sidebar.multiselect(\"Select object classes to include\",\n  options=CLASSES,\n  default=CLASSES\n  )\n\n  img_file_buffer = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n\n  if img_file_buffer is not None:\n      temp_file.write(img_file_buffer.getvalue())\n      image = load_img(temp_file.name)\n      image = img_to_array(image)\n      image = image/255.0\n\n  else:\n      demo_image = DEMO_IMAGE\n      image = np.array(Image.open(demo_image))\n\n  detections = process_image(image)\n  image, labels = annotate_image(image, detections, confidence_threshold)\n\n  st.image(\n      image, caption=f\"Processed image\", use_column_width=True,\n  )\n\n  st.write(labels)\n\nmain()\n```\n\n*You can play with the live app* [*here](https://share.streamlit.io/sparsh-ai/streamlit-489fbbb7/app.py). Source code is available [here](https://github.com/sparsh-ai/streamlit-5a407279/tree/master) on Github.*"
        },
        {
          "id": "/2021/10/01/ocr-experiments",
          "metadata": {
            "permalink": "/blog/2021/10/01/ocr-experiments",
            "source": "@site/blog/2021-10-01-ocr-experiments.mdx",
            "title": "OCR experiments",
            "description": "/img/content-blog-raw-blog-ocr-experiments-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "ocr",
                "permalink": "/blog/tags/ocr"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 1.155,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "OCR experiments",
              "authors": "sparsh",
              "tags": [
                "ocr",
                "vision"
              ]
            },
            "prevItem": {
              "title": "Object detection with YOLO3",
              "permalink": "/blog/2021/10/01/object-detection-with-yolo3"
            },
            "nextItem": {
              "title": "PDF to Wordcloud via Mail",
              "permalink": "/blog/2021/10/01/pdf-to-wordcloud-via-mail"
            }
          },
          "content": "![/img/content-blog-raw-blog-ocr-experiments-untitled.png](/img/content-blog-raw-blog-ocr-experiments-untitled.png)\n\n## 1. Tesseract\n\nTesseract is an open-source text recognition engine that is available under the Apache 2.0 license and its development has been sponsored by Google since 2006.\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/2d1f533048a3655de625298c3dd32d47)\n\n## 2. EasyOCR\n\nReady-to-use OCR with 70+ languages supported including Chinese, Japanese, Korean and Thai. EasyOCR is built with Python and Pytorch deep learning library, having a GPU could speed up the whole process of detection. The detection part is using the CRAFT algorithm and the Recognition model is CRNN. It is composed of 3 main components, feature extraction (we are currently using Resnet), sequence labelling (LSTM) and decoding (CTC). EasyOCR doesn’t have much software dependencies, it can directly be used with its API.\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/12359606ee4127513c66fc3b4ff18e5b)\n\n## 3. KerasOCR\n\nThis is a slightly polished and packaged version of the Keras CRNN implementation and the published CRAFT text detection model. It provides a high-level API for training a text detection and OCR pipeline and out-of-the-box OCR models, and an end-to-end training pipeline to build new OCR models.\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/2fcb764619baf5f56cf7122b1b2c527c)\n\n## 4. ArabicOCR\n\nIt is an OCR system for the Arabic language that converts images of typed text to machine-encoded text. It currently supports only letters (29 letters).  ArabicOCR aims to solve a simpler problem of OCR with images that contain only Arabic characters (check the dataset link below to see a sample of the images).\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/26df76b78f8cd2018a068b284b7cfe56)"
        },
        {
          "id": "/2021/10/01/pdf-to-wordcloud-via-mail",
          "metadata": {
            "permalink": "/blog/2021/10/01/pdf-to-wordcloud-via-mail",
            "source": "@site/blog/2021-10-01-pdf-to-wordcloud-via-mail.mdx",
            "title": "PDF to Wordcloud via Mail",
            "description": "/img/content-blog-raw-blog-pdf-to-wordcloud-via-mail-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [],
            "readingTime": 1.015,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "PDF to Wordcloud via Mail",
              "authors": "sparsh"
            },
            "prevItem": {
              "title": "OCR experiments",
              "permalink": "/blog/2021/10/01/ocr-experiments"
            },
            "nextItem": {
              "title": "Personalized Unexpectedness in  Recommender Systems",
              "permalink": "/blog/2021/10/01/personalized-unexpectedness-in-recommender-systems"
            }
          },
          "content": "![/img/content-blog-raw-blog-pdf-to-wordcloud-via-mail-untitled.png](/img/content-blog-raw-blog-pdf-to-wordcloud-via-mail-untitled.png)\n\n## Objective\n\nIntegrating PDF, Text, Wordcloud and Email functionalities in Python\n\n## Process Flow\n\n- Step 1 - I use PyPDF2 library to read PDF text in Python\n- Step 2 - Import the supporting libraries\n- Step 3 - Count No. of Pages for this pdf and extract text for each page using loop\n- Step 4 - Build Text corpus by simply attaching text of next page to all the previous ones\n- Step 5 - Creating word frequency dataframe by first splitting text into words and counting the frequency of each word\n- Step 6.1 - Pre-process text i.e. removing stopwords (using nltk library), grouping common words.\n- Step 6.2 - used regex to extract alphabets only, lower all chracters, and sorting as per decreasing order of frequency.\n- Step 7 - Creating Wordcloud using matplotlib and wordcloud libraries\n- Step 8 - Importing required libraries like smtplib, MIME, win32 for sending the mail\n- Step 9 - Create outlook mail object with supporting data like filepath attachment, recepient address, mail body etc.\n- Step 10 - Sending the mail with required wordcloud image file attached and checking if mail is received or not!\n\n## Code\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/f1de48fd4fac199bcc95e1d136fbdfd0)"
        },
        {
          "id": "/2021/10/01/personalized-unexpectedness-in-recommender-systems",
          "metadata": {
            "permalink": "/blog/2021/10/01/personalized-unexpectedness-in-recommender-systems",
            "source": "@site/blog/2021-10-01-personalized-unexpectedness-in-recommender-systems.mdx",
            "title": "Personalized Unexpectedness in  Recommender Systems",
            "description": "Classical recommender systems typically provides familier items, which not only bores customer after some time, but create a critical bias problem also, generally known as filter bubble or echo chamber problem.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "personalization",
                "permalink": "/blog/tags/personalization"
              }
            ],
            "readingTime": 2.96,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Personalized Unexpectedness in  Recommender Systems",
              "authors": "sparsh",
              "tags": [
                "personalization"
              ]
            },
            "prevItem": {
              "title": "PDF to Wordcloud via Mail",
              "permalink": "/blog/2021/10/01/pdf-to-wordcloud-via-mail"
            },
            "nextItem": {
              "title": "Predicting Electronics Resale Price",
              "permalink": "/blog/2021/10/01/predicting-electronics-resale-price"
            }
          },
          "content": "Classical recommender systems typically provides familier items, which not only bores customer after some time, but create a critical bias problem also, generally known as *filter bubble* or *echo chamber problem*. \n\nTo address this issue, instead of recommending best matching product all the time, we intentionally recommend a random product. For example, if a user subscribed to Netflix one month ago and watching action movies all the time. If we recommend another action movie, there is a high probability that user will click but keeping in mind the long-term user satisfaction and to address the filter bubble bias, we would recommend a comedy movie. Surprisingly, this strategy works!!\n\nThe most common metric is ***diversity*** factor but diversity only measures dispersion among recommended items. The better alternative is ***unexpectedness*** factor. It measures deviations of recommended items from user expectations and thus captures the concept of user surprise and allows recommender systems to break from the filter bubble. The goal is to provide novel, surprising and satisfying recommendations. \n\nIncluding session-based information into the design of an unexpected recommender system is beneficial. For example, it is more reasonable to recommend the next episode of a TV series to the user who has just finished the first episode, instead of recommending new types of videos to that person. On the other hand, if the user has been binge-watching the same TV series in one night, it is better to recommend something different to him or her.\n\n### Model\n\n![/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled.png](/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled.png)\n\n*Overview of the proposed PURS model. The base model estimates the click-through rate of certain user-item pairs, while the unexpected model captures the unexpectedness of the new recommendation as well as user perception towards unexpectedness.*\n\n### Offline Experiment Results\n\n![/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled-1.png](/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled-1.png)\n\n### Online A/B Test Results\n\nAuthors conducted the online A/B test at Alibaba-Youku, a major video recommendation platform from 2019-11 to 2019-12. During the testing period, they compared the proposed PURS model with the latest production model in the company. They measured the performance using standard business metrics: **VV** (Video View, average video viewed by each user), **TS** (Time Spent, average time that each user spends on the platform), **ID** (Impression Depth, average impression through one session) and **CTR** (Click-Through-Rate, the percentage of user clicking on the recommended video). They also measure the novelty of the recommended videos using the unexpectedness and coverage measures.\n\n![Represents statistical significance at the 0.95 level.](/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled-2.png)\n\nRepresents statistical significance at the 0.95 level.\n\n### Code Walkthrough\n\n> Note: PURS is *implemented in Tensorflow 1.x*\n\n**Unexpected attention ([model.py](https://github.com/lpworld/PURS/blob/master/model.py))**\n\n```python\ndef unexp_attention(self, querys, keys, keys_id):\n        \"\"\"\n        Same Attention as in the DIN model\n        queries:     [Batchsize, 1, embedding_size]\n        keys:        [Batchsize, max_seq_len, embedding_size]  max_seq_len is the number of keys(e.g. number of clicked creativeid for each sample)\n        keys_id:     [Batchsize, max_seq_len]\n        \"\"\"\n        querys = tf.expand_dims(querys, 1)\n        keys_length = tf.shape(keys)[1] # padded_dim\n        embedding_size = querys.get_shape().as_list()[-1]\n        keys = tf.reshape(keys, shape=[-1, keys_length, embedding_size])\n        querys = tf.reshape(tf.tile(querys, [1, keys_length, 1]), shape=[-1, keys_length, embedding_size])\n\n        net = tf.concat([keys, keys - querys, querys, keys*querys], axis=-1)\n        for units in [32,16]:\n            net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n        att_wgt = tf.layers.dense(net, units=1, activation=tf.sigmoid)        # shape(batch_size, max_seq_len, 1)\n        outputs = tf.reshape(att_wgt, shape=[-1, 1, keys_length], name=\"weight\")  #shape(batch_size, 1, max_seq_len)\n        scores = outputs\n        scores = scores / (embedding_size ** 0.5)       # scale\n        scores = tf.nn.softmax(scores)\n        outputs = tf.matmul(scores, keys)    #(batch_size, 1, embedding_size)\n        outputs = tf.reduce_sum(outputs, 1, name=\"unexp_embedding\")   #(batch_size, embedding_size)\n        return outputs\n```\n\n**Unexpected metric calculation ([train.py](https://github.com/lpworld/PURS/blob/master/train.py))**\n\n```python\ndef unexpectedness(sess, model, test_set):\n    unexp_list = []\n    for _, uij in DataInput(test_set, batch_size):\n        score, label, user, item, unexp = model.test(sess, uij)\n        for index in range(len(score)):\n            unexp_list.append(unexp[index])\n    return np.mean(unexp_list)\n```\n\n### References\n\n1. [https://arxiv.org/pdf/2106.02771v1.pdf](https://arxiv.org/pdf/2106.02771v1.pdf)\n2. [https://github.com/lpworld/PURS](https://github.com/lpworld/PURS)"
        },
        {
          "id": "/2021/10/01/predicting-electronics-resale-price",
          "metadata": {
            "permalink": "/blog/2021/10/01/predicting-electronics-resale-price",
            "source": "@site/blog/2021-10-01-predicting-electronics-resale-price.mdx",
            "title": "Predicting Electronics Resale Price",
            "description": "/img/content-blog-raw-blog-predicting-electronics-resale-price-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "regression",
                "permalink": "/blog/tags/regression"
              }
            ],
            "readingTime": 1.875,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Predicting Electronics Resale Price",
              "authors": "sparsh",
              "tags": [
                "regression"
              ]
            },
            "prevItem": {
              "title": "Personalized Unexpectedness in  Recommender Systems",
              "permalink": "/blog/2021/10/01/personalized-unexpectedness-in-recommender-systems"
            },
            "nextItem": {
              "title": "Real-time news personalization with Flink",
              "permalink": "/blog/2021/10/01/real-time-news-personalization-with-flink"
            }
          },
          "content": "![/img/content-blog-raw-blog-predicting-electronics-resale-price-untitled.png](/img/content-blog-raw-blog-predicting-electronics-resale-price-untitled.png)\n\n# Objective\n\nPredict the resale price based on brand, part id and purchase quantity\n\n# Milestones\n\n- Data analysis and discovery - What is the acceptable variance the model needs to meet in terms of similar part number and quantity?\n- Model research and validation - Does the model meet the variance requirement? (Variance of the model should meet or be below the variance of the sales history)\n- Model deployment - Traffic will increase 10 fold. So, model needs to be containerized or dockerized\n- Training - Model needs to be trainable on new sales data. Methodology to accept or reject the variance of the newly trained model documented.\n\n# Deliverables\n\n1. Data Analysis and Discovery (identify target variance for pricing model in terms of similar part numbers and quantities). Analysis should be done on the 12 following quantity ranges: 1-4, 5-9, 10-24, 25-49, 50-99, 100-249, 250-499, 500-999, 1000-2499, 2500-4999, 5000-9999, 10000+.\n\n2. ModelA Training (Resale Value Estimation [$] (Brand+PartNo.+Quantity)\n\n3. ModelA Validation (variance analysis and comparison with sales history variance in terms of similar part numbers and quantities)\n\n4. ModelA Containerization\n\n5. ModelA re-training based on new sales data\n\n6. ScriptA to calculate variance for new sales data (feedback for training results)\n\n7. Documentation for re-training\n\n8. ModelA deployment and API\n\n# Modeling Approach\n\n### Framework\n\n- Fully connected regression neural network\n- NLP feature extraction from part id\n- Batch generator to feed large data in batches\n- Hyperparameter tuning to find the best model fit\n\n### List of Variables\n\n- 2 years of sales history\n- PRC\n- PARTNO\n- ORDER_NUMBER\n- ORIG_ORDER_QTY\n- UNIT_COST\n- UNIT_REASLE\n- UOM (UNIT OF MEASUREMENT)\n\n# Bucket of Ideas\n\n1. Increase n-gram range; e.g. in part_id ABC-123-23, these are 4-grams: ABC-, BC-1, C-12, -123, 123-, 23-2, 3-23; Idea is to see if increasing this range further will increase the model's performance\n2. Employ Char-level LSTM to capture sequence information; e.g. in same part_id ABC-123-23, currently we are not maintaining sequence of grams, we don't know if 3-23 is coming at first or last; here, the idea is to see if lstm model can be employed to capture this sequence information to improve model's performance\n3. New Loss function - including cost based loss"
        },
        {
          "id": "/2021/10/01/real-time-news-personalization-with-flink",
          "metadata": {
            "permalink": "/blog/2021/10/01/real-time-news-personalization-with-flink",
            "source": "@site/blog/2021-10-01-real-time-news-personalization-with-flink.mdx",
            "title": "Real-time news personalization with Flink",
            "description": "Overview",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "personalization",
                "permalink": "/blog/tags/personalization"
              },
              {
                "label": "realtime",
                "permalink": "/blog/tags/realtime"
              }
            ],
            "readingTime": 9.82,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Real-time news personalization with Flink",
              "authors": "sparsh",
              "tags": [
                "personalization",
                "realtime"
              ]
            },
            "prevItem": {
              "title": "Predicting Electronics Resale Price",
              "permalink": "/blog/2021/10/01/predicting-electronics-resale-price"
            },
            "nextItem": {
              "title": "Semantic Similarity",
              "permalink": "/blog/2021/10/01/semantic-similarity"
            }
          },
          "content": "## Overview\n\nNews recommendation system has a high degree of real-time because there will be a large number of news and hot spots at any time. Incremental updating, online learning, local updating and even reinforcement learning can make the recommender system quickly respond to the user‘s new behavior, and the premise of these updating strategies is that the sample itself has enough real-time information. In news recommendation system, the typical training sample is the user’s click behavior data.\n\n### Why is the real-time nature of the recommendation system important?\n\nIntuitively, when users use personalized news applications, users expect to find articles that match their interests faster; when using short video services, they expect to \"flash\" content that they are interested in faster; when doing online shopping, I also hope to find the products that I like, faster. All recommendations highlight the word \"fast\", which is an intuitive manifestation of the \"real-time\" role of the recommendation system.\n\nFrom a professional point of view, the real-time performance of the recommendation system is also crucial, which is mainly reflected in the following two aspects:\n\n1. **The faster the update speed of the recommendation system is, the more it can reflect the user's recent user habits, and the more time-sensitive it can make recommendations to the user.**\n2. **The faster the recommendation system is updated, the easier it is for the model to find the latest popular data patterns, and the more it can make the model react to find the latest fashion trends.**\n\n### The real-time nature of the \"feature\" of the recommendation system\n\nSuppose a user has watched a 10-minute \"badminton teaching\" video in its entirety. Then there is no doubt that the user is interested in the subject of \"badminton\". The system hopes to continue to recommend \"badminton\" related videos when the user turns the page next time. However, due to the lack of real-time features of the system, the user’s viewing history cannot be fed back to the recommendation system in real time. As a result, the recommendation system learned that the user had watched the video \"Badminton Teaching\". It was already half an hour later. Has left the app. This is an example of recommendation failure caused by poor real-time performance of the recommendation system.\n\nIt is true that the next time the user opens the application, the recommendation system can use the last user behavior history to recommend \"badminton\" related videos, but the recommendation system undoubtedly loses what is most likely to increase user viscosity and increase user retention. opportunity.\n\n### The real-time nature of the \"model\" of the recommender system\n\nNo matter how strong the real-time feature is, the scope of influence is limited to the current user. Compared with the real-time nature of \"features\", the real-time nature of the recommendation system model is often considered from a more global perspective . The real-time nature of the feature attempts to describe a person with more accurate features, so that the recommendation system can give a recommendation result that is more in line with the person. The real-time nature of the model hopes to capture new data patterns at the global level faster and discover new trends and relevance.\n\nTake, for example, a large number of promotional activities on Double Eleven on an e-commerce website. The real-time nature of the feature will quickly discover the products that the user may be interested in based on the user's recent behavior, but will never find the latest preferences of similar users, the latest correlation information between the products, and the trend information of new activities.\n\nTo discover such global data changes, the model needs to be updated faster. The most important factor affecting the real-time performance of the model is the training method of the model.\n\n1. **Full update -** The most common way of model training is full update. The model will use all training samples in a certain period of time for retraining, and then replace the \"outdated\" model with the new trained model. However, the full update requires a large amount of training samples, so the training time required is longer; and the full update is often performed on offline big data platforms, such as spark+tensorflow, so the data delay is also longer, which leads to the full update It is the worst \"real-time\" model update method. In fact, for a model that has been trained, it is enough to learn only the newly added incremental samples, which is called incremental update.\n2. **Incremental update (Incremental Learning)** - Incremental update only feeds newly added samples to the model for incremental learning . Technically, deep learning models often use stochastic gradient descent (SGD) and its variants for learning. The model's learning of incremental samples is equivalent to continuing to input incremental samples for gradient descent on the basis of the original samples. Therefore, based on the deep learning model, it is not difficult to change from full update to incremental update. But everything in engineering is a tradeoff, there is never a perfect solution, and incremental updates are no exception. Since only incremental samples are used for learning, the model also converges to the best point of the new sample after multiple epochs, and it is difficult to converge to the global best point of all the original samples + incremental samples. Therefore, in the actual recommendation system, the incremental update and the global update are often combined . After several rounds of incremental update, the global update is performed in a time window with a small business volume, and the model is corrected after the incremental update process. Accumulated errors in. Make trade-offs and trade-offs between \"real-time performance\" and \"global optimization\".\n3. **Online learning** - \"Online learning\" is a further improvement of \"incremental update\", \"incremental update\" is to perform incremental update when a batch of new samples is obtained, and online learning is to update the model in real time every time a new sample is obtained. Online learning can also be implemented technically through SGD. But if you use the general SGD method, online learning will cause a very serious problem, that is, the sparsity of the model is very poor, opening too many \"fragmented\" unimportant features. We pay attention to the \"sparseness\" of the model in a sense that is also an engineering consideration. For example, in a model with an input vector of several million dimensions, if the sparsity of the model is good, the effect of the model can be maintained without affecting the model. , Only make the corresponding weight of the input vector of a very small part of the dimension non-zero, that is to say, when the model is online, the volume of the model is very small, which is undoubtedly beneficial to the entire model serving process. Both the memory space required to store the model and the speed of online inference will benefit from the sparsity of the model. If the SGD method is used to update the model, it is easier to generate a large number of features with small weights than the batch method, which increases the difficulty of model deployment and update. So in order to take into account the training effect and model sparsity in the online learning process, there are a lot of related researches. The most famous ones include Microsoft's RDA, Google's FOBOS and the most famous FTRL, etc.\n4. **Partial model update** - Another improvement direction to improve the real-time performance of the model is to perform a partial update of the model. The general idea is to reduce the update frequency of the part with low training efficiency and increase the update frequency of the part with high training efficiency . This approach is representative of the GBDT+LR model of Facebook.\n\n![/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled.png](/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled.png)\n\n## Data pipeline of a typical news recommendation system\n\nWhen a user is exposed with a list of news articles, a page view events are sent to the backend server and when that user clicks on the news of interest, the action events are also sent to the backend server. After receiving these 2 event streams (page view and clicks), the backend server will send these user behaviour events to the message queue. And message queue finally stores these messages into the distributed file system, such as HDFS.\n\nFor model training, we need a training sample. The most common sampling technique is negative sampling. In this, we generate 'n' negative samples for each positive event that we receive. Users will only generate behavior for some exposed news samples, which are positive samples, and the remaining exposure samples without behavior are negative samples. After generating positive and negative samples, the model can be trained.\n\nThe recommendation system with low real-time requirements can use batch processing technology (APACHE spark is a typical tool) to generate samples, as shown in the left figure. Set a timing task, and read the user behavior log and exposure log in the time window from HDFS every other period of time, such as one hour, to perform join operation, generate training samples, and then write the training samples back to HDFS, Then start the training update of the model.\n\n![/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled-1.png](/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled-1.png)\n\n### Problems\n\nOne obvious problem with batch processing is **latency**. The typical cycle of running batch tasks regularly is one hour, which means that there is a delay of at least one hour from sample generation to model training. Sometimes, if the batch platform is overloaded and the tasks need to be queued, the delay will be greater.\n\nAnother problem is the **boundary** problem. If page view (PV) data is generated at the end of the log time window selected by the batch task, the corresponding action data may fall into the next time window of the batch task, resulting in join failure and false negative samples.\n\nA related problem to this is the time synchronization problem. When a news item is exposed to the user, the user may click immediately after the PV data stream is generated, or the user may act after a few minutes, more than ten minutes, or even several hours. This means that after the PV data stream arrives, it needs to wait for a period of time to join with the action data stream. If the waiting time is too long, some samples (positive samples) that should have user behavior will be wrongly marked as negative samples because the user behavior has no time to return. Too long waiting time will damage and increase the system delay. Offline analysis of the delay distribution between the actual action data stream and PV data stream is a very typical exponential distribution.\n\n![/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled-2.png](/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled-2.png)\n\n## Apache Flink to the rescue\n\n### How Apache Flink solves the latency problem?\n\nIn order to enhance the real-time performance, we use Apache Flink framework to rewrite the sample generation logic with stream processing technology. As shown in the right figure above, after the user exposure and behavior logs generated by online services are written into the message queue, instead of waiting for them to drop to HDFS, we directly consume these message flows with Flink. At the same time, Flink reads the necessary feature information from the redis cache and generates the sample message stream directly. The sample message flow is written back to the Kafka queue, and downstream tensorflow can directly consume the message flow for model training.\n\n### How Apache Flink solved the boundary and synchronization problem?\n\nAs per the exponential distribution (analyzed on a private dataset of a news recommender app), most of the user behavior has reflow within a few minutes. And if few minutes is an acceptable delay, a simple solution is to set a time window with a compromise size. Flink provides window join to implement this logic.\n\n## References\n\n1. [https://developpaper.com/flink-streaming-processing-and-real-time-sample-generation-in-recommender-system/](https://developpaper.com/flink-streaming-processing-and-real-time-sample-generation-in-recommender-system/)\n2. [https://zhuanlan.zhihu.com/p/74813776](https://zhuanlan.zhihu.com/p/74813776)\n3. [https://zhuanlan.zhihu.com/p/75597761](https://zhuanlan.zhihu.com/p/75597761)"
        },
        {
          "id": "/2021/10/01/semantic-similarity",
          "metadata": {
            "permalink": "/blog/2021/10/01/semantic-similarity",
            "source": "@site/blog/2021-10-01-semantic-similarity.mdx",
            "title": "Semantic Similarity",
            "description": "/img/content-blog-raw-blog-semantic-similarity-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              }
            ],
            "readingTime": 1.67,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Semantic Similarity",
              "authors": "sparsh",
              "tags": [
                "nlp",
                "similarity"
              ]
            },
            "prevItem": {
              "title": "Real-time news personalization with Flink",
              "permalink": "/blog/2021/10/01/real-time-news-personalization-with-flink"
            },
            "nextItem": {
              "title": "Short-video Background Music Recommender",
              "permalink": "/blog/2021/10/01/short-video-background-music-recommender"
            }
          },
          "content": "![/img/content-blog-raw-blog-semantic-similarity-untitled.png](/img/content-blog-raw-blog-semantic-similarity-untitled.png)\n\n# Introduction\n\nDeliverable - Two paragraph-level distance outputs for L and Q, each has 35 columns. \n\nFor each paragraph, we need to calculate the L1 distance of consecutive sentences in this paragraph, and then generate the mean and standard deviation of all these distances for this paragraph. For example, say the paragraph 1 starts from sentence1 and ends with sentence 5. First, calculate the L1 distances for L1(1,2), L1(2,3), L1(3,4) and L1(4,5) and then calculate the mean and standard deviation of the 4 distances. In the end we got two measures for this paragraph: L1_m and L1_std. Similarly, we need to calculate the mean and standard deviation using L2 distance, plus a simple mean and deviation of the distances. We use 6 different embeddings: all dimensions of BERT embeddings, 100,200 and 300 dimensions of PCA Bert embeddings (PCA is a dimension reduction technique \n\nIn the end, we will have 35 columns for each paragraph : Paragraph ID +#sentences in the paragraph +(cosine_m, cosine_std,cossimillarity_m, cosimmilarity_std, L1_m, L1_std, L2_m, L2_std ) – by- ( all, 100, 200, 300)= 3+8*4. \n\nNote: for paragraph that only has 1 sentence, the std measures are empty.\n\n# Modeling Approach\n\n### Process Flow for Use Case 1\n\n1. Splitting paragraphs into sentences using 1) NLTK Sentence Tokenizer, 2) Spacy Sentence Tokenizer and, on two additional symbols `:` and `...`\n2. Text Preprocessing: Lowercasing, Removing Non-alphanumeric characters, Removing Null records, Removing sentence records (rows) having less than 3 words.\n3. TF-IDF vectorization\n4. LSA over document-term matrix\n5. Cosine distance calculation of adjacent sentences (rows)\n\n### Process Flow for Use Case 2\n\n- Split paragraphs into sentences\n- Text cleaning\n- BERT Sentence Encoding\n- BERT PCA 100\n- BERT PCA 200\n- BERT PCA 300\n- Calculate distance between consecutive sentences in the paragraph\n- Distances: L1, L2 and Cosine and Cosine similarity\n- Statistics: Mean, SD\n\n# Experimental Setup\n\n1. #IncrementalPCA\n2. GPU to speed up\n3. Data chunking\n4. Calculate BERT for a chunk and store in disk"
        },
        {
          "id": "/2021/10/01/short-video-background-music-recommender",
          "metadata": {
            "permalink": "/blog/2021/10/01/short-video-background-music-recommender",
            "source": "@site/blog/2021-10-01-short-video-background-music-recommender.mdx",
            "title": "Short-video Background Music Recommender",
            "description": "Matching micro-videos with suitable background music can help uploaders better convey their contents and emotions, and increase the click-through rate of their uploaded videos. However, manually selecting the background music becomes a painstaking task due to the voluminous and ever-growing pool of candidate music. Therefore, automatically recommending background music to videos becomes an important task.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "recsys",
                "permalink": "/blog/tags/recsys"
              }
            ],
            "readingTime": 2.17,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Short-video Background Music Recommender",
              "authors": "sparsh",
              "tags": [
                "recsys"
              ]
            },
            "prevItem": {
              "title": "Semantic Similarity",
              "permalink": "/blog/2021/10/01/semantic-similarity"
            },
            "nextItem": {
              "title": "The progression of analytics in enterprises",
              "permalink": "/blog/2021/10/01/the-progression-of-analytics-in-enterprises"
            }
          },
          "content": "Matching micro-videos with suitable background music can help uploaders better convey their contents and emotions, and increase the click-through rate of their uploaded videos. However, manually selecting the background music becomes a painstaking task due to the voluminous and ever-growing pool of candidate music. Therefore, automatically recommending background music to videos becomes an important task.\n\nIn [this](https://arxiv.org/pdf/2107.07268.pdf) paper, Zhu et. al. shared their approach to solve this task. They first collected ~3,000 background music from popular TikTok videos and also ~150,000 video clips that used some kind of background music. They named this dataset `TT-150K`.\n\n![An exemplar subset of videos and their matched background music in the established TT-150k dataset](/img/content-blog-raw-blog-short-video-background-music-recommender-untitled.png)\n\nAn exemplar subset of videos and their matched background music in the established TT-150k dataset\n\nAfter building the dataset, they worked on modeling and proposed the following architecture:\n\n![Proposed CMVAE (Cross-modal Variational Auto-encoder) framework](/img/content-blog-raw-blog-short-video-background-music-recommender-untitled-1.png)\n\nProposed CMVAE (Cross-modal Variational Auto-encoder) framework\n\nThe goal is to represent videos (`users` in recsys terminology) and music (`items`) in a shared latent space. To achieve this, CMVAE use pre-trained models to extract features from unstructured data - `vggish` model for audio2vec, `resnet` for video2vec and `bert-multilingual` for text2vec.  Text and video vectors are then fused using product-of-expert approach. \n\nIt uses the reconstruction power of variational autoencoders to 1) reconstruct video from music latent vector and, 2) reconstruct music from video latent vector. In layman terms, we are training a neural network that will try to guess the video activity just by listening background music, and also try to guess the background music just by seeing the video activities. \n\nThe joint training objective is $\\mathcal{L}_{(z_m,z_v)} = \\beta \\cdot\\mathcal{L}_{cross\\_recon} - \\mathcal{L}_{KL} + \\gamma \\cdot \\mathcal{L}_{matching}$, where $\\beta$ and $\\gamma$ control the weight of the cross reconstruction loss and the matching loss, respectively.\n\nAfter training the model, they compared the model's performance with existing baselines and the results are as follows:\n\n![/img/content-blog-raw-blog-short-video-background-music-recommender-untitled-2.png](/img/content-blog-raw-blog-short-video-background-music-recommender-untitled-2.png)\n\n**Conclusion**: I don't make short videos myself but can easily imagine the difficulty in finding the right background music. If I have to do this task manually, I will try out 5-6 videos and select one that I like. But here, I will be assuming that my audience would also like this music. Moreover, feedback is not actionable because it will create kind of an implicit sub-conscious effect (because when I see a video, I mostly judge it at overall level and rarely notice that background music is the problem). So, this kind of recommender system will definitely help me in selecting a better background music. Excited to see this feature soon in TikTok, Youtube Shorts and other similar services."
        },
        {
          "id": "/2021/10/01/the-progression-of-analytics-in-enterprises",
          "metadata": {
            "permalink": "/blog/2021/10/01/the-progression-of-analytics-in-enterprises",
            "source": "@site/blog/2021-10-01-the-progression-of-analytics-in-enterprises.mdx",
            "title": "The progression of analytics in enterprises",
            "description": "An organization’s analytics strategy is how its people, processes, tools, and data work together to collect, store, and analyze data. Processes refers to how analytics are produced, consumed, and maintained. A more modern approach to analytics is intended to support greater business agility at scale. This requires faster data preparation from a wider variety of sources, rapid prototyping and analytics model building, and cross-team collaboration processes. Tools, or technologies, are the raw programs and applications used to prepare for and perform analyses, such as the provisioning, flow, and automation of tasks and resources. As an analytics strategy matures, the technologies used to implement it tend to move from monolithic structures to composable microservices. The last element is data. A modern analytics architecture supports a growing volume and variety of data sources, which may include data from data warehouses and data lakes—streaming data, relational databases, graph databases, unstructured or semi-structured data, text data, and images.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "insight",
                "permalink": "/blog/tags/insight"
              }
            ],
            "readingTime": 12.09,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "The progression of analytics in enterprises",
              "authors": "sparsh",
              "tags": [
                "insight"
              ]
            },
            "prevItem": {
              "title": "Short-video Background Music Recommender",
              "permalink": "/blog/2021/10/01/short-video-background-music-recommender"
            },
            "nextItem": {
              "title": "Tools for building recommender systems",
              "permalink": "/blog/2021/10/01/tools-for-building-recommender-systems"
            }
          },
          "content": "An organization’s analytics strategy is how its *people, processes, tools, and data* work together to collect, store, and analyze data. *Processes* refers to *how* analytics are produced, consumed, and maintained. A more modern approach to analytics is intended to support greater business agility at scale. This requires faster data preparation from a wider variety of sources, rapid prototyping and analytics model building, and cross-team collaboration processes. *Tools*, or technologies, are the raw programs and applications used to prepare for and perform analyses, such as the provisioning, flow, and automation of tasks and resources. As an analytics strategy matures, the technologies used to implement it tend to move from monolithic structures to composable microservices. The last element is *data.* A modern analytics architecture supports a growing volume and variety of data sources, which may include data from data warehouses and data lakes—streaming data, relational databases, graph databases, unstructured or semi-structured data, text data, and images.\n\n### Analytics Past, Present, and Future\n\n|  | Past | Present | Future |\n| --- | --- | --- | --- |\n|  | This refers to an era of analytics starting in the 1990s and running through the mid-2000s. During this phase, organizations were able to consolidate mostly transactional data into a unified system, often a data warehouse, which limited end users’ ability to interact directly with the data due to technical and governance requirements. | Starting in the late 2000s, organizations were forced to rethink how they used analytics, in no small part due to the explosion of data during this time. This was the era of “Big Data” and its infamous “ V’s”: volume, velocity, and variety.4 As organizations shifted their approach during this period, they unlocked diagnostic analytics, or the capability to answer “Why did it happen?” | The Future of Analytics Is Converged. Converged analytics unifies advances in AI, streaming data, and related technologies into a seamless analytics experience for all users. This arrangement unlocks prescriptive analytics across an organization, allowing anyone to make data-driven decisions that answer important questions. |\n| People | IT professionals were needed to kick off any data-based work by extracting data from a centralized, difficult-to-use source. This process could take multiple days, and the number of query requests could easy exceed the IT team’s ability to fulfill those requests—and the opportune time for new insights.If some change was needed to data collection or storage methods, it could easily take IT months to perform. The data analysis and modeling work could take nearly as long. Rank-and-file domain experts did have some access to data, through so-called self-service business intelligence (BI) features. However, due to the same speed and accessibility issues that technical professionals faced, it was often difficult for domain experts like line of business leaders to truly lead with data for decision making. | It’s no coincidence that around the same time as Big Data emerged, so did the role of the data scientist. Compared with earlier roles like researcher or statistician, the data scientist blends quantitative and domain expertise with a greater degree of computational thinking. These skills became necessary both to handle the greater variety and volume of data sources and to update and deploy data and analytics models without the assistance of IT professionals.Whereas IT in the past sought to meticulously catalog and structure data to enter into a data warehouse, they no longer needed to always clean the data before collecting it; these analytics teams could focus on ease of use and speed to governed access.With these new workflows and organization structures in place, domain leaders are better able to lead with data: both via self-service BI tools and from frequent collaboration with data analysts, data scientists, and other data specialists. | Statisticians and IT served information to business users at the inception of a wider analytics adoption; further into maturity, data analysts and scientists built systems where business users could self-serve insights. In a converged architecture, not only is the business user at the center, but their decision making is augmented by automation. Given this arrangement, there is more collaboration, more automation, and greater scale for data-driven insights as a result of the convergence of teams and workstreams. Teams can work cross-functionally and in parallel across different domains iterating the system to their needs with the raw time and human resources needed to create and maintain analytics products such as dashboards and models. |\n| Processes | IT professionals spent long periods of time gathering requirements for analytics projects before they could build or deploy solutions. The team meticulously catalogued sources of data used across the organization, from financial or point-of-sale systems to frequently used external datasets. As part of the warehousing process, it was decided which of these data sources to store and how to store them.Once deployed, data passed into the warehouse through an extract-transform-load process (ETL), where the data was copied from these various sources, cleaned and reshaped into the defined structure of the data warehouse, then inserted into production. In other words, data went through rigorous cleaning and preprocessing before use.To reach this data, users needed to write time-consuming ad hoc queries. Alternatively, particular data segments or summaries that were frequently requested by business users could be delivered via scheduled automation to reports, dashboards, and scorecards. | As opposed to earlier analytics strategies, IT professionals now seek to collect data as is from any possible source of value. This data can be in a variety of formats, so few predefined rules or relationships are established for ingestion. Depending on the data size, data is processed in batch over discrete time periods, or in streams and events near real time. Because data cleaning is the last step, this process is sometimes referred to as extract-load-transform (ELT), as opposed to the ETL of earlier architectures. For data scientists and other technical professionals, faster access to more and more dynamic data better enables the rapid development of training sets of data for machine learning models. The ELT process allows for the construction of machine learning models, where computers are able to improve performance as more data is passed to them.As more data is collected and put into production, the importance of a data governance process typically grows, describing who has authority over data and how that data should be used. Similar approaches are necessary to audit how models are put into production and how they work. | While perhaps using different means, the ends of older analytics approaches were the same: insights, whether historic or in support of future decisions, using governed data and processes. In the methods for doing so, however, infrastructure tended to bloat, either from fragile data storage jobs or increasingly complex data pipelines.Given the volume, velocity, and variety of data needed for prescriptive analytics, such monolithic, centralized approaches are less than optimal. Using the tools discussed in the next section, a converged architecture offers a more nimble approach for providing the right insights at the right time to users of all technical levels.Such democratization relies on quick deployment and adjustment of data products; optimizing production, for example, requires bringing more machine learning models to production faster and at scale. The practice of ModelOps is used to institute and govern such rapid production. These processes have become a necessity in rapidly changing business conditions; for example, as the COVID-19 pandemic made structural changes to the economy, many models lost their predictive edge in the face of fundamentally different data. |\n| Tools | Data warehouses implemented some new technologies relative to the traditional relational database model. Importantly, the data warehouse separated data into fact tables, where measurements were stored, and dimension tables, which contained descriptive attributes. Business users interacted with the data via reporting software to view static data summaries. These tended to rely on overnight batch jobs to update.In a more sophisticated architecture, analysts could take advantage of online analytical processing (OLAP) cubes. Usually relying on a star schema, OLAP let users query the data across dimensions during interactive sessions. For example, they could “slice and dice” or “roll up and drill down” on the data.By this point, end users had some autonomy in how they looked at and acted upon the data. Automated processes to inform business activities through data were also put into place, such as alerts when inventory or sales dropped below some threshold. Basic what-if analyses also helped business users evaluate decisions and plan for the future.That said, given the limited sources of data from the data warehouse, there were limited ways to customize and work with the data. While reporting and basic analytics were automated, end users operated largely without the assistance of models developed by statisticians. Although business intelligence and operations research seek to create value from data, too often these complementary tools were siloed. | In 2011, James Dixon, then chief technology officer of Pentaho, coined the term data lake as the architecture needed to support the next level of analytics maturity. Dixon argued that because of the inherently rigid structures of data warehouses, getting value from the increasing volume and variety of data associated with Big Data was difficult. A data lake, “a repository of data stored in its natural/raw format,” was a better approach. In particular, this arrangement wasn’t suited to operate or capitalize on the expanding volume and variety of Big Data.The data lake is often powered by cloud computing for the benefits of reliability, redundancy, and scalability. Dominant cloud service providers include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP). Open source technologies like Hadoop and Spark are used to process and store massive datasets using parallel computing and distributed storage. Because this data is often unstructured, it may be stored in graph, document, or other non-relational databases.With the increasing volume and velocity of data, and the use of data lakes along with data warehouses to enable data-driven decisions, businesses needed better ways to scale and share business intelligence. One such path was through interactive, immersive exploration and visualization of the data, as pioneered with Spotfire. Other paths were through visual reports and dashboards, as used by not just Spotfire, but by Jaspersoft, Power BI, WebFOCUS, and many others. As BI tools matured, self-service capabilities and automation for end users also matured. | If maintaining legacy analytics is like raising a thoroughbred, then developing converged analytics is like cultivating a school of goldfish. That is, the backend provisioning is no longer served by monolithic systems but rather by composable groups of microservices. This arrangement supports elastic and scalable analytics; composability makes it easier to adapt to changes driven in part by a growing volume and variety of data sources. In previous analytics approaches, the distinction between backward-facing BI and prediction-focused data science was clear. Under convergence, analytics at the edge is possible—automating analytic computations so they can be performed on non-centralized data generated by sensors, switches, and similar. With converged analytics, individuals no longer need to wait for data science teams to provide ad hoc deeper insights. They have all the data-driven insights at their fingertips, assisted by AI to quickly explore and make decisions. This isn’t just the case for back-office analysts: frontline workers can, for example, adjust how they interact with a customer given data retrieved about that customer at the time of that interaction. |\n| Data | During this period, data tended to be transactional, or related to sales and purchases. Take a point-of-sales (POS) system, for example. Each time a sale is made, information about what was sold, possibly to whom, is recorded in the POS system. Those records can be compiled into tables and ultimately processed into a data warehouse.Under this process, data is gathered from prespecified sources at prespecified times, such as a nightly POS extract. Not all data made its way to the data warehouse, especially in the earlier days of analytics—either because it was judged unimportant, or because it was not prioritized. | Contemporary analytics expands the variety of data available and used: both structured tables and unstructured sources like natural language and images are available. On account of stream processing, refreshes of this data are available in minutes or even less. In particular, the data lake can accommodate real-time events such as IoT sensor readings, GPS signals, and online transactions as they happen. | A primary feature of converged analytics is the blending of historical and real-time data. According to a study by Seagate and International Data Corporation (IDC), 30% of all data will be real time by 2025. In particular, IoT sensor readings, GPS signals, and online transactions as they happen are available for immediate analysis and modeling. |\n| Agility | The relatively rigid nature of the data warehouse made changes to the collection and dissemination of data difficult. Subsequently, business agility was limited. Business users could get historic data about the business through static reports (descriptive analytics). Through OLAP cubes, they could possibly even dig into the data to parse out cause and effect (diagnostic analytics). But without more immediate access to broader data, it was difficult to advance to predictive analytics, or the ability to ask: “What is going to happen?” | This next phase in the evolution of analytics gets data-driven insights into the hands of end users quickly, with technology allowing them to interact with it on a deeper level. Data scientists are able to build machine learning systems that improve with more data. Using drag-and-drop tools, business users can process and analyze data without technical assistance. With cloud, automation, and streaming technologies, organizations have been better able to adapt to and plan for changing circumstances. That said, machine learning works only so long in production before the algorithm struggles to account for changes to the business and needs intervention. While data scientists undertake these predictive challenges, BI professionals and domain experts tend to operate solely in analyzing current or past data. The next generation of analytics architecture will further reflect organizational needs for greater collaboration among data scientists, BI and analytics teams, and business users and consumers of analytics insights. | Earlier analytics tended to isolate skills and processes: technical versus highly technical roles, data collection versus deployment versus modeling, and so forth. Converged analytics promotes close collaboration between teams to rapidly model, deploy, and act on data. As data operations become decentralized, teams and individuals can rapidly mine and act on the analytics.In particular, the marriage of real-time data with machine learning and AI-infused BI allows any user to magnify their own domain knowledge with data-driven insights. These features square precisely with the definition of business agility as “innovation via collaboration to be able to anticipate challenges and opportunities before they occur.” With the support of converged analytics, any professional can detect and act on both challenges and opportunities at the moment of impact, rather than months later. |\n\n---\n\n©️2021, RecoHut."
        },
        {
          "id": "/2021/10/01/tools-for-building-recommender-systems",
          "metadata": {
            "permalink": "/blog/2021/10/01/tools-for-building-recommender-systems",
            "source": "@site/blog/2021-10-01-tools-for-building-recommender-systems.mdx",
            "title": "Tools for building recommender systems",
            "description": "/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "recsys",
                "permalink": "/blog/tags/recsys"
              },
              {
                "label": "tool",
                "permalink": "/blog/tags/tool"
              }
            ],
            "readingTime": 11.025,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Tools for building recommender systems",
              "authors": "sparsh",
              "tags": [
                "recsys",
                "tool"
              ]
            },
            "prevItem": {
              "title": "The progression of analytics in enterprises",
              "permalink": "/blog/2021/10/01/the-progression-of-analytics-in-enterprises"
            },
            "nextItem": {
              "title": "Vehicle Suggestions",
              "permalink": "/blog/2021/10/01/vehicle-suggestions"
            }
          },
          "content": "![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled.png)\n\n## Recombee - Recommendation as a service API\n\nRecombee is a Recommender as a Service with easy integration and Admin UI. It can be used in many domains, for example in media (VoD, news …), e-commerce, job boards, aggregators or classifieds. Basically, it can be used in any domain with a catalog of **items** that can be interacted by **users**. The users can interact with the items in many ways: for example view them, rate them, bookmark them, purchase them, etc. Both items and users can have various properties (metadata) that are also used by the recommendation models.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-1.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-1.png)\n\n[Here](https://docs.recombee.com/tutorial.html) is the official tutorial series to get started. \n\n## Amazon Personalize - Self-service Platform to build and serve recommenders\n\nAmazon Personalize is a fully managed machine learning service that goes beyond rigid static rule based recommendation systems and trains, tunes, and deploys custom ML models to deliver highly customized recommendations to customers across industries such as retail and media and entertainment.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-2.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-2.png)\n\nIt covers 6 use-cases:\n\n![Popular Use-cases](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-3.png)\n\nPopular Use-cases\n\nFollowing are the hands-on tutorials:\n\n1. [Data Science on AWS Workshop - Personalize Recommendations**p**](https://github.com/data-science-on-aws/workshop/tree/937f6e4fed53fcc6c22bfac42c2c18a687317995/oreilly_book/02_usecases/personalize_recommendations)\n2. [https://aws.amazon.com/blogs/machine-learning/creating-a-recommendation-engine-using-amazon-personalize/](https://aws.amazon.com/blogs/machine-learning/creating-a-recommendation-engine-using-amazon-personalize/)\n3. [https://aws.amazon.com/blogs/machine-learning/omnichannel-personalization-with-amazon-personalize/](https://aws.amazon.com/blogs/machine-learning/omnichannel-personalization-with-amazon-personalize/)\n4. [https://aws.amazon.com/blogs/machine-learning/using-a-b-testing-to-measure-the-efficacy-of-recommendations-generated-by-amazon-personalize/](https://aws.amazon.com/blogs/machine-learning/using-a-b-testing-to-measure-the-efficacy-of-recommendations-generated-by-amazon-personalize/)\n\nAlso checkout these resources:\n\n1. [https://www.youtube.com/playlist?list=PLN7ADELDRRhiQB9QkFiZolioeJZb3wqPE](https://www.youtube.com/playlist?list=PLN7ADELDRRhiQB9QkFiZolioeJZb3wqPE)\n\n## Azure Personalizer - An API based service with Reinforcement learning capability\n\nAzure Personalizer is a cloud-based API service that helps developers create rich, personalized experiences for each user of your app. It learns from customer's real-time behavior, and uses reinforcement learning to select the best item (action) based on collective behavior and reward scores across all users. Actions are the content items, such as news articles, specific movies, or products. It takes a list of items (e.g. list of drop-down choices) and their context (e.g. Report Name, User Name, Time Zone) as input and returns the ranked list of items for the given context. While doing that, it also allows feedback submission regarding the relevance and efficiency of the ranking results returned by the service. The feedback (reward score) can be automatically calculated and submitted to the service based on the given personalization use case.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-4.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-4.png)\n\nYou can use the Personalizer service to determine what product to suggest to shoppers or to figure out the optimal position for an advertisement. After the content is shown to the user, your application monitors the user's reaction and reports a reward score back to the Personalizer service. This ensures continuous improvement of the machine learning model, and Personalizer's ability to select the best content item based on the contextual information it receives. \n\nFollowing are some of the interesting use cases of Azure Personalizer:\n\n1. Blog Recommender [[Video tutorial](https://youtu.be/fsn7hTOKXsY?list=PLN7ADELDRRhhHRu1tS3gmdeUfeQkG82k_&t=1145), [GitHub](https://github.com/georgiakalyva/azure-personalizer-service)]\n2. Food Personalizer [[Video tutorial](https://youtu.be/A-8OfoWySHQ?list=PLN7ADELDRRhhHRu1tS3gmdeUfeQkG82k_&t=1758), [Slideshare](https://www.slideshare.net/SetuChokshi/introduction-to-reinforcement-learning-with-azure-personalizer-233272693), [Code Blog](https://pipinstall.me/introduction_to_azure_personalizer/)]\n3. Coffee Personalizer [[GitHub](https://github.com/Azure-Samples/cognitive-services-personalizer-samples/tree/master/samples/azurenotebook), [Video tutorial](https://youtu.be/vkbIhX7xhcE?list=PLN7ADELDRRhhHRu1tS3gmdeUfeQkG82k_)]\n4. News Recommendation\n5. Movie Recommendation\n6. Product Recommendation\n7. **Intent clarification & disambiguation**: help your users have a better experience when their intent is not clear by providing an option that is personalized.\n8. **Default suggestions** for menus & options: have the bot suggest the most likely item in a personalized way as a first step, instead of presenting an impersonal menu or list of alternatives.\n9. **Bot traits & tone**: for bots that can vary tone, verbosity, and writing style, consider varying these traits.\n10. **Notification & alert content**: decide what text to use for alerts in order to engage users more.\n11. **Notification & alert timing**: have personalized learning of when to send notifications to users to engage them more.\n12. Dropdown Options - Different users of an application with manager privileges would see a list of reports that they can run. Before Personalizer was implemented, the list of dozens of reports was displayed in alphabetical order, requiring most of the managers to scroll through the lengthy list to find the report they needed. This created a poor user experience for daily users of the reporting system, making for a good use case for Personalizer. The tooling learned from the user behavior and began to rank frequently run reports on the top of the dropdown list. Frequently run reports would be different for different users, and would change over time for each manager as they get assigned to different projects. This is exactly the situation where Personalizer’s reward score-based learning models come into play.\n13. Projects in Timesheet - Every employee in the company logs a daily timesheet listing all of the projects the user is assigned to. It also lists other projects, such as overhead. Depending upon the employee project allocations, his or her timesheet table could have few to a couple of dozen active projects listed. Even though the employee is assigned to several projects, particularly at lead and manager levels, they don’t log time in more than 2 to 3 projects for a few weeks to months.\n    1. Reward Score Calculation\n\n## Google Recommendation - Recommender Service from Google\n\n![https://cloudx-bricks-prod-bucket.storage.googleapis.com/6a0d4afb1778e55d54cb7d66382a4b25f8748a50a93f3c3403d2a835aa166f3d.svg](https://cloudx-bricks-prod-bucket.storage.googleapis.com/6a0d4afb1778e55d54cb7d66382a4b25f8748a50a93f3c3403d2a835aa166f3d.svg)\n\n## [Abacus.ai](http://abacus.ai) - Self-service Platform at cheaper price\n\nIt uses multi-objective, real-time recommendations models and provides 4 use-cases for fasttrack train-&-deploy process - Personalized recommendations, personalized search, related items and real-time feed recommendations.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-5.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-5.png)\n\nHere is the hands-on video tutorial:\n\n[https://youtu.be/7hTKL73f2yA](https://youtu.be/7hTKL73f2yA)\n\n## Nvidia Merlin - Toolkit with GPU capabilities\n\nMerlin empowers data scientists, machine learning engineers, and researchers to build high-performing recommenders at scale. Merlin includes tools that democratize building deep learning recommenders by addressing common ETL, training, and inference challenges. Each stage of the Merlin pipeline is optimized to support hundreds of terabytes of data, all accessible through easy-to-use APIs. With Merlin, better predictions than traditional methods and increased click-through rates are within reach.\n\n![End-to-end recommender system architecture. FE: feature engineering; PP: preprocessing; ETL: extract-transform-load.](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-6.png)\n\nEnd-to-end recommender system architecture. FE: feature engineering; PP: preprocessing; ETL: extract-transform-load.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-7.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-7.png)\n\n## TFRS - Open-source Recommender library built on top of Tensorflow\n\nBuilt with TensorFlow 2.x, TFRS makes it possible to:\n\n- Build and evaluate flexible **[candidate nomination models](https://research.google/pubs/pub48840/)**;\n- Freely incorporate item, user, and context **[information](https://tensorflow.org/recommenders/examples/featurization)** into recommendation models;\n- Train **[multi-task models](https://tensorflow.org/recommenders/examples/multitask)** that jointly optimize multiple recommendation objectives;\n- Efficiently serve the resulting models using **[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)**.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-8.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-8.png)\n\nFollowing is a series of official tutorial notebooks:-\n\n[TensorFlow Recommenders: Quickstart](https://www.tensorflow.org/recommenders/examples/quickstart)\n\n## Elliot - An end-to-end framework good for recommender system experiments\n\n[Elliot](https://elliot.readthedocs.io/en/latest/) is a comprehensive recommendation framework that aims to run and reproduce an entire experimental pipeline by processing a simple configuration file. The framework loads, filters, and splits the data considering a vast set of strategies (13 splitting methods and 8 filtering approaches, from temporal training-test splitting to nested K-folds Cross-Validation). Elliot optimizes hyperparameters (51 strategies) for several recommendation algorithms (50), selects the best models, compares them with the baselines providing intra-model statistics, computes metrics (36) spanning from accuracy to beyond-accuracy, bias, and fairness, and conducts statistical analysis (Wilcoxon and Paired t-test). The aim is to provide the researchers with a tool to ease (and make them reproducible) all the experimental evaluation phases, from data reading to results collection.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-9.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-9.png)\n\n## RecBole - Another framework good for recommender system model experiments\n\nRecBole is developed based on Python and PyTorch for reproducing and developing recommendation algorithms in a unified, comprehensive and efficient framework for research purpose. It can be installed from pip, Conda and source, and easy to use. It includes 65 recommendation algorithms, covering four major categories: General Recommendation, Sequential Recommendation, Context-aware Recommendation, and Knowledge-based Recommendation, which can support the basic research in recommender systems.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-10.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-10.png)\n\nFeatures:\n\n- **General and extensible data structure**We deign general and extensible data structures to unify the formatting and usage of various recommendation datasets.\n- **Comprehensive benchmark models and datasets**We implement 65 commonly used recommendation algorithms, and provide the formatted copies of 28 recommendation datasets.\n- **Efficient GPU-accelerated execution**We design many tailored strategies in the GPU environment to enhance the efficiency of our library.\n- **Extensive and standard evaluation protocols**We support a series of commonly used evaluation protocols or settings for testing and comparing recommendation algorithms.\n\n## Microsoft Recommenders - A powerful set of tools for building high-quality recommender system at low-cost *(highly recommended)*\n\nThe Microsoft Recommenders repository is an open source collection of python utilities and Jupyter notebooks to help accelerate the process of designing, evaluating, and deploying recommender systems. The repository was initially formed by data scientists at Microsoft to consolidate common tools and best practices developed from working on recommender systems in various industry settings. The goal of the tools and notebooks is to show examples of how to effectively build, compare, and then deploy the best recommender solution for a given scenario. Contributions from the community have brought in new algorithm implementations and code examples covering multiple aspects of working with recommendation algorithms.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-11.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-11.png)\n\n## Surprise - An open-source library with easy api and powerful models\n\n[Surprise](http://surpriselib.com/) is a Python [scikit](https://www.scipy.org/scikits.html) for building and analyzing recommender systems that deal with explicit rating data.\n\n[Surprise](http://surpriselib.com/) **was designed with the following purposes in mind**:\n\n- Give users perfect control over their experiments. To this end, a strong emphasis is laid on [documentation](http://surprise.readthedocs.io/en/stable/index.html), which we have tried to make as clear and precise as possible by pointing out every detail of the algorithms.\n- Alleviate the pain of [Dataset handling](http://surprise.readthedocs.io/en/stable/getting_started.html#load-a-custom-dataset). Users can use both *built-in* datasets ([Movielens](http://grouplens.org/datasets/movielens/), [Jester](http://eigentaste.berkeley.edu/dataset/)), and their own *custom* datasets.\n- Provide various ready-to-use [prediction algorithms](http://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html) such as [baseline algorithms](http://surprise.readthedocs.io/en/stable/basic_algorithms.html), [neighborhood methods](http://surprise.readthedocs.io/en/stable/knn_inspired.html), matrix factorization-based ( [SVD](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD), [PMF](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#unbiased-note), [SVD++](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp), [NMF](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF)), and [many others](http://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html). Also, various [similarity measures](http://surprise.readthedocs.io/en/stable/similarities.html) (cosine, MSD, pearson…) are built-in.\n- Make it easy to implement [new algorithm ideas](http://surprise.readthedocs.io/en/stable/building_custom_algo.html).\n- Provide tools to [evaluate](http://surprise.readthedocs.io/en/stable/model_selection.html), [analyse](http://nbviewer.jupyter.org/github/NicolasHug/Surprise/tree/master/examples/notebooks/KNNBasic_analysis.ipynb/) and [compare](http://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/Compare.ipynb) the algorithms’ performance. Cross-validation procedures can be run very easily using powerful CV iterators (inspired by [scikit-learn](http://scikit-learn.org/) excellent tools), as well as [exhaustive search over a set of parameters](http://surprise.readthedocs.io/en/stable/getting_started.html#tune-algorithm-parameters-with-gridsearchcv).\n\n## Spotlight - Another open-source library\n\nSpotlight uses PyTorch to build both deep and shallow recommender models. By providing both a slew of building blocks for loss functions (various pointwise and pairwise ranking losses), representations (shallow factorization representations, deep sequence models), and utilities for fetching (or generating) recommendation datasets, it aims to be a tool for rapid exploration and prototyping of new recommender models.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-12.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-12.png)\n\n[Here](https://github.com/maciejkula/spotlight/tree/master/examples) is a series of hands-on tutorials to get started.\n\n## Vowpal Wabbit - library with reinforcement learning features\n\nVowpal Wabbit is an open source machine learning library, extensively used by industry, and is the first public terascale learning system. It provides fast, scalable machine learning and has unique capabilities such as learning to search, active learning, contextual memory, and extreme multiclass learning. It has a focus on reinforcement learning and provides production ready implementations of Contextual Bandit algorithms. It was developed originally at Yahoo! Research, and currently at Microsoft Research. Vowpal Wabbit sees significant innovation as a research to production vehicle for Microsoft Research.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-13.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-13.png)\n\nFor most applications, collaborative filtering yields satisfactory results for item recommendations; there are however several issues that arise that might make it difficult to scale up a recommender system.\n\n- The number of features can grow quite large, and given the usual sparsity of consumption datasets, collaborative filtering needs every single feature and datapoint available.\n- For new data points, the whole model has to be re-trained\n\nVowpal Wabbit’s matrix factorization capabilities can be used to build a recommender that is similar in spirit to collaborative filtering but that avoids the pitfalls that we mentioned before.\n\nFollowing are the three introductory hands-on tutorials on building recommender systems with vowpal wabbit:\n\n1. [Vowpal Wabbit Deep Dive - A Content-based Recommender System using Microsoft Recommender Library](https://github.com/microsoft/recommenders/blob/main/examples/02_model_content_based_filtering/vowpal_wabbit_deep_dive.ipynb)\n2. [Simulating Content Personalization with Contextual Bandits](https://vowpalwabbit.org/tutorials/cb_simulation.html)\n3. [Vowpal Wabbit, The Magic Recommender System!](https://samuel-guedj.medium.com/vowpal-wabbit-the-magic-58b7f1d8e39c)\n\n## DLRM - An open-source scalable model from Facebook's AI team, build on top of PyTorch\n\nDLRM advances on other models by combining principles from both collaborative filtering and predictive analytics-based approaches, which enables it to work efficiently with production-scale data and provide state-of-art results.\n\nIn the DLRM model, categorical features are processed using embeddings, while continuous features are processed with a bottom multilayer perceptron (MLP). Then, second-order interactions of different features are computed explicitly. Finally, the results are processed with a top MLP and fed into a sigmoid function in order to give a probability of a click.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-14.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-14.png)\n\nFollowing are the hands-on tutorials:\n\n1. [https://nbviewer.jupyter.org/github/gotorehanahmad/Recommendation-Systems/blob/master/dlrm/dlrm_main.ipynb](https://nbviewer.jupyter.org/github/gotorehanahmad/Recommendation-Systems/blob/master/dlrm/dlrm_main.ipynb)\n2. [Training Facebook's DLRM on the digix dataset](https://nbviewer.jupyter.org/github/mabeckers/dlrm/blob/new_dataset/Train_DLRM_Digix.ipynb)\n\n## References\n\n1. [https://elliot.readthedocs.io/en/latest/](https://elliot.readthedocs.io/en/latest/)\n2. [https://vowpalwabbit.org/index.html](https://vowpalwabbit.org/index.html)\n3. [https://abacus.ai/user_eng](https://abacus.ai/user_eng)\n4. [https://azure.microsoft.com/en-in/services/cognitive-services/personalizer/](https://azure.microsoft.com/en-in/services/cognitive-services/personalizer/)\n5. [https://aws.amazon.com/personalize/](https://aws.amazon.com/personalize/)\n6. [https://github.com/facebookresearch/dlrm](https://github.com/facebookresearch/dlrm)\n7. [https://www.tensorflow.org/recommenders](https://www.tensorflow.org/recommenders)\n8. [https://magento.com/products/product-recommendations](https://magento.com/products/product-recommendations)\n9. [https://cloud.google.com/recommendations](https://cloud.google.com/recommendations)\n10. [https://www.recombee.com/](https://www.recombee.com/)\n11. [https://recbole.io/](https://recbole.io/)\n12. [https://github.com/microsoft/recommenders](https://github.com/microsoft/recommenders)\n13. [http://surpriselib.com/](http://surpriselib.com/)\n14. [https://github.com/maciejkula/spotlight](https://github.com/maciejkula/spotlight)\n15. https://vowpalwabbit.org/tutorials/contextual_bandits.html\n16. https://github.com/VowpalWabbit/vowpal_wabbit/wiki\n17. https://vowpalwabbit.org/tutorials/cb_simulation.html\n18. https://vowpalwabbit.org/rlos/2021/projects.html\n19. https://vowpalwabbit.org/rlos/2020/projects.html\n20. https://getstream.io/blog/recommendations-activity-streams-vowpal-wabbit/\n21. https://samuel-guedj.medium.com/vowpal-wabbit-the-magic-58b7f1d8e39c\n22. https://vowpalwabbit.org/neurips2019/\n23. https://github.com/VowpalWabbit/neurips2019\n24. https://getstream.io/blog/introduction-contextual-bandits/\n25. https://www.youtube.com/watch?v=CeOcNK1xSSA&t=72s\n26. https://vowpalwabbit.org/blog/rlos-fest-2021.html\n27. https://github.com/VowpalWabbit/workshop\n28. https://github.com/VowpalWabbit/workshop/tree/master/aiNextCon2019\n29. [Blog post by Nasir Mirza. Azure Cognitive Services Personalizer: Part One. Oct, 2019.](https://www.ais.com/azure-cognitive-services-personalizer-part-one/)\n30. [Blog post by Nasir Mirza. Azure Cognitive Services Personalizer: Part Two. Oct, 2019.](https://www.ais.com/azure-cognitive-services-personalizer-part-two/)\n31. [Blog post by Nasir Mirza. Azure Cognitive Services Personalizer: Part Three. Dec, 2019.](https://www.ais.com/azure-cognitive-services-personalizer-part-three/)\n32. [Microsoft Azure Personalizer Official Documentation. Oct, 2020.](https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/what-is-personalizer)\n33. [Personalizer demo.](https://personalizationdemo.azurewebsites.net/)\n34. [Official Page.](https://azure.microsoft.com/en-in/services/cognitive-services/personalizer/#faqs)\n35. [Blog Post by Jake Wong. Get hands on with the Azure Personalizer API. Aug, 2019.](https://www.linkedin.com/pulse/get-hands-azure-personalizer-api-jake-wang/)\n36. [Medium Post.](https://enefitit.medium.com/we-tested-azure-personalizer-heres-what-you-can-expect-8c5ec074a28e)\n37. [Blog Post.](https://www.valoremreply.com/post/azure-personalizer/)\n38. [Git Repo.](https://github.com/Azure-Samples/cognitive-services-personalizer-samples)\n39. [https://youtu.be/7hTKL73f2yA](https://youtu.be/7hTKL73f2yA)\n40. [Deep-Learning Based Recommendation Systems — Learning AI](https://abacus.ai/blog/2020/03/31/deep-learning-based-recommendation-systems/#:~:text=Deep%2DLearning%20Based%20Recommendation%20Systems%20%E2%80%94%20Learning%20AI,-By%20Abacus.AI&text=Deep%20Learning%20(DL)%20has%20had,of%20Recommender%20Systems%20(RS).)\n41. [Evaluating Deep Learning Models with Abacus.AI – Recommendation Systems](https://abacus.ai/blog/2020/12/11/evaluating-deep-learning-models-recommender-systems/)\n42. https://aws.amazon.com/blogs/machine-learning/pioneering-personalized-user-experiences-at-stockx-with-amazon-personalize/\n43. https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-personalize/\n44. https://d1.awsstatic.com/events/reinvent/2019/REPEAT_1_Build_a_content-recommendation_engine_with_Amazon_Personalize_AIM304-R1.pdf\n45. https://aws.amazon.com/blogs/aws/amazon-personalize-real-time-personalization-and-recommendation-for-everyone/\n46. https://d1.awsstatic.com/events/reinvent/2019/REPEAT_1_Accelerate_experimentation_with_personalization_models_AIM424-R1.pdf\n47. https://d1.awsstatic.com/events/reinvent/2019/REPEAT_1_Personalized_user_engagement_with_machine_learning_AIM346-R1.pdf\n48. https://github.com/aws-samples/amazon-personalize-samples\n49. https://github.com/aws-samples/amazon-personalize-automated-retraining\n50. https://github.com/aws-samples/amazon-personalize-ingestion-pipeline\n51. https://github.com/aws-samples/amazon-personalize-monitor\n52. https://github.com/aws-samples/amazon-personalize-data-conversion-pipeline\n53. https://github.com/james-jory/segment-personalize-workshop\n54. https://github.com/aws-samples/amazon-personalize-samples/tree/master/next_steps/workshops/POC_in_a_box\n55. https://github.com/Imagination-Media/aws-personalize-magento2\n56. https://github.com/awslabs/amazon-personalize-optimizer-using-amazon-pinpoint-events\n57. https://github.com/aws-samples/amazon-personalize-with-aws-glue-sample-dataset\n58. https://github.com/awsdocs/amazon-personalize-developer-guide\n59. https://github.com/chrisking/NetflixPersonalize\n60. https://github.com/aws-samples/retail-demo-store\n61. https://github.com/aws-samples/personalize-data-science-sdk-workflow\n62. https://github.com/apac-ml-tfc/personalize-poc\n63. https://github.com/dalacan/personalize-batch-recommendations\n64. https://github.com/harunobukameda/Amazon-Personalize-Handson\n65. https://www.sagemakerworkshop.com/personalize/\n66. https://github.com/lmorri/vodpocinabox\n67. https://github.com/awslabs/unicornflix\n68. https://www.youtube.com/watch?v=r9J3UZmddC4&t=966s\n69. https://www.youtube.com/watch?v=kTufCK76Yus&t=1436s\n70. https://www.youtube.com/watch?v=hY_XzglTkak&t=66s\n71. [https://business.adobe.com/lv/summit/2020/adobe-sensei-powers-magento-product-recommendations.html](https://business.adobe.com/lv/summit/2020/adobe-sensei-powers-magento-product-recommendations.html)\n72. https://magento.com/products/product-recommendations\n73. https://docs.magento.com/user-guide/marketing/product-recommendations.html\n74. https://vod.webqem.com/detail/videos/magento-commerce/video/6195503645001/magento-commerce---product-recommendations?autoStart=true&page=1\n75. https://blog.adobe.com/en/publish/2020/11/23/new-ai-capabilities-for-magento-commerce-improve-retail.html#gs.yw6mtq\n76. https://developers.google.com/recommender/docs/reference/rest\n77. https://www.youtube.com/watch?v=nY5U0uQZRyU&t=6s"
        },
        {
          "id": "/2021/10/01/vehicle-suggestions",
          "metadata": {
            "permalink": "/blog/2021/10/01/vehicle-suggestions",
            "source": "@site/blog/2021-10-01-vehicle-suggestions.mdx",
            "title": "Vehicle Suggestions",
            "description": "/img/content-blog-raw-blog-vehicle-suggestions-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 13.86,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Vehicle Suggestions",
              "authors": "sparsh",
              "tags": [
                "nlp",
                "similarity",
                "vision"
              ]
            },
            "prevItem": {
              "title": "Tools for building recommender systems",
              "permalink": "/blog/2021/10/01/tools-for-building-recommender-systems"
            },
            "nextItem": {
              "title": "Web Scraping using Scrapy, BS4, and Selenium",
              "permalink": "/blog/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium"
            }
          },
          "content": "![/img/content-blog-raw-blog-vehicle-suggestions-untitled.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled.png)\n\n# Introduction\n\nThe customer owns a franchise store for selling Tesla Automobiles. The objective is to predict user preferences using social media data.\n\nTask 1 - Suggest the best vehicle for the given description\n\nTask 2 - Suggest the best vehicle for the given social media id of the user\n\n## Customer queries\n\n```json\n// car or truck or no mention of vehicle type means Cyber Truck\n// SUV mention means Model X\nconst one = \"I'm looking for a fast suv that I can go camping without worrying about recharging\".;\nconst two = \"cheap red car that is able to go long distances\";\nconst three = \"i am looking for a daily driver that i can charge everyday, do not need any extras\";\nconst four = \"i like to go offroading a lot on my jeep and i want to do the same with the truck\";\nconst five = \"i want the most basic suv possible\";\nconst six = \"I want all of the addons\";\n// mentions of large family or many people means model x\nconst seven = \"I have a big family and want to be able to take them around town and run errands without worrying about charging\";\n```\n\n- Expected output\n    \n    ```json\n    const oneJson = {\n    vehicle: 'Model X',\n    trim : 'adventure',\n    exteriorColor: 'whiteExterior',\n    wheels: \"22Performance\",\n    tonneau: \"powerTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"extendedRange\",\n    software: \"\",\n    }\n    \n    const twoJSON = {\n    vehicle: 'Cyber Truck',\n    trim : 'base',\n    exteriorColor: 'whiteExterior',\n    wheels: \"21AllSeason\",\n    tonneau: \"powerTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"extendedRange\",\n    software: \"\",\n    }\n    \n    const threeJSON = {\n    vehicle: 'Cyber Truck',\n    trim : 'base',\n    exteriorColor: 'whiteExterior',\n    wheels: \"21AllSeason\",\n    tonneau: \"powerTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"standardRange\",\n    software: \"\",\n    }\n    \n    const fourJSON = {\n    vehicle: 'Cyber Truck',\n    trim : 'adventure',\n    exteriorColor: 'whiteExterior',\n    wheels: \"20AllTerrain\",\n    tonneau: \"powerTonneau\",\n    packages: \"offroadPackage,matchingSpareTire\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"extendedRange\",\n    software: \"\",\n    }\n    \n    const fiveJSON = {\n    vehicle: 'Model X',\n    trim : 'base',\n    exteriorColor: 'whiteExterior',\n    wheels: \"20AllTerrain\",\n    tonneau: \"manualTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"standardRange\",\n    software: \"\",\n    }\n    \n    const sixJSON = {\n    vehicle: 'Cyber Truck',\n    trim : 'adventure',\n    exteriorColor: 'whiteExterior',\n    wheels: \"20AllTerrain\",\n    tonneau: \"powerTonneau\",\n    packages: \"offroadPackage,matchingSpareTire\",\n    interiorAddons: \"wirelessCharger\",\n    interiorColor: \"blackInterior\",\n    range: \"extendedRange\",\n    software: \"selfDrivingPackage\",\n    }\n    \n    const sevenJSON = {\n    vehicle: 'Model X',\n    trim : 'base',\n    exteriorColor: 'whiteExterior',\n    wheels: \"21AllSeason\",\n    tonneau: \"powerTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"mediumRange\",\n    software: \"\",\n    }\n    ```\n    \n- Vehicle model configurations\n    \n    ```json\n    const configuration = {\n    meta: {\n    configurationId: '???',\n    storeId: 'US_SALES',\n    country: 'US',\n    version: '1.0',\n    effectiveDate: '???',\n    currency: 'USD',\n    locale: 'en-US',\n    availableLocales: ['en-US'],\n    },\n    \n    defaults: {\n    basePrice: 50000,\n    deposit: 1000,\n    initialSelection: [\n    'adventure',\n    'whiteExterior',\n    '21AllSeason',\n    'powerTonneau',\n    'blackInterior',\n    'mediumRange',\n    ],\n    },\n    \n    groups: {\n    trim: {\n    name: { 'en-US': 'Choose trim' },\n    multiselect: false,\n    required: true,\n    options: ['base', 'adventure'],\n    },\n    exteriorColor: {\n    name: { 'en-US': 'Choose paint' },\n    multiselect: false,\n    required: true,\n    options: [\n    'whiteExterior',\n    'blueExterior',\n    'silverExterior',\n    'greyExterior',\n    'blackExterior',\n    'redExterior',\n    'greenExterior',\n    ],\n    },\n    wheels: {\n    name: { 'en-US': 'Choose wheels' },\n    multiselect: false,\n    required: true,\n    options: ['21AllSeason', '20AllTerrain', '22Performance'],\n    },\n    tonneau: {\n    name: { 'en-US': 'Choose tonneau cover' },\n    multiselect: false,\n    required: true,\n    options: ['manualTonneau', 'powerTonneau'],\n    },\n    packages: {\n    name: { 'en-US': 'Choose upgrades' },\n    multiselect: true,\n    required: false,\n    options: ['offroadPackage', 'matchingSpareTire'],\n    },\n    interiorColor: {\n    name: { 'en-US': 'Choose interior' },\n    multiselect: false,\n    required: true,\n    options: ['greyInterior', 'blackInterior', 'greenInterior'],\n    },\n    interiorAddons: {\n    name: { 'en-US': 'Choose upgrade' },\n    multiselect: true,\n    required: false,\n    options: ['wirelessCharger'],\n    },\n    range: {\n    name: { 'en-US': 'Choose range' },\n    multiselect: false,\n    required: true,\n    options: ['standardRange', 'mediumRange', 'extendedRange'],\n    },\n    software: {\n    name: { 'en-US': 'Choose upgrade' },\n    multiselect: true,\n    required: false,\n    options: ['selfDrivingPackage'],\n    },\n    specs: {\n    name: { 'en-US': 'Specs overview *' },\n    attrs: {\n    description: {\n    'en-US':\n    \"* Options, specs and pricing may change as we approach production. We'll contact you to review any updates to your preferred build.\",\n    },\n    },\n    multiselect: false,\n    required: false,\n    options: ['acceleration', 'power', 'towing', 'range'],\n    },\n    },\n    \n    options: {\n    base: {\n    name: { 'en-US': 'Base' },\n    attrs: {\n    description: { 'en-US': 'Production begins 2022' },\n    },\n    visual: true,\n    price: 0,\n    },\n    adventure: {\n    name: { 'en-US': 'Adventure' },\n    attrs: {\n    description: { 'en-US': 'Production begins 2021' },\n    },\n    visual: true,\n    price: 10000,\n    },\n    \n    standardRange: {\n    name: { 'en-US': 'Standard' },\n    attrs: {\n    description: { 'en-US': '230+ miles' },\n    },\n    price: 0,\n    },\n    mediumRange: {\n    name: { 'en-US': 'Medium' },\n    attrs: {\n    description: { 'en-US': '300+ miles' },\n    },\n    price: 3000,\n    },\n    extendedRange: {\n    name: { 'en-US': 'Extended' },\n    attrs: {\n    description: { 'en-US': '400+ miles' },\n    },\n    price: 8000,\n    },\n    \n    greenExterior: {\n    name: { 'en-US': 'Adirondack Green' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/green.svg',\n    },\n    visual: true,\n    price: 2000,\n    },\n    blueExterior: {\n    name: { 'en-US': 'Trestles Blue' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/blue.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    whiteExterior: {\n    name: { 'en-US': 'Arctic White' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/white.svg',\n    },\n    visual: true,\n    price: 0,\n    },\n    silverExterior: {\n    name: { 'en-US': 'Silver Gracier' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/silver.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    blackExterior: {\n    name: { 'en-US': 'Cosmic Black' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/black.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    redExterior: {\n    name: { 'en-US': 'Red Rocks' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/red.svg',\n    },\n    visual: true,\n    price: 2000,\n    },\n    greyExterior: {\n    name: { 'en-US': 'Antracite Grey' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/grey.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    \n    '21AllSeason': {\n    name: { 'en-US': '21\" Cast Wheel - All Season' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/wheels/twentyone.svg',\n    },\n    visual: true,\n    price: 0,\n    },\n    '20AllTerrain': {\n    name: { 'en-US': '20\" Forged Wheel - All Terrain' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/wheels/twenty.svg',\n    },\n    visual: true,\n    price: 0,\n    },\n    '22Performance': {\n    name: { 'en-US': '22\" Cast Wheel - Performance' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/wheels/twentytwo.svg',\n    },\n    visual: true,\n    price: 2000,\n    },\n    \n    manualTonneau: {\n    name: { 'en-US': 'Manual' },\n    attrs: {\n    description: { 'en-US': 'Description here' },\n    },\n    price: 0,\n    },\n    powerTonneau: {\n    name: { 'en-US': 'Powered' },\n    attrs: {\n    description: { 'en-US': 'Description here' },\n    },\n    price: 0,\n    },\n    \n    blackInterior: {\n    name: { 'en-US': 'Black' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/interiorcolors/black.svg',\n    },\n    visual: true,\n    price: 0,\n    },\n    greyInterior: {\n    name: { 'en-US': 'Grey' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/interiorcolors/grey.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    greenInterior: {\n    name: { 'en-US': 'Green' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/interiorcolors/green.svg',\n    },\n    visual: true,\n    price: 2000,\n    },\n    \n    offroadPackage: {\n    name: { 'en-US': 'Off-Road' },\n    attrs: {\n    description: { 'en-US': '' },\n    imageUrl: '/public/images/configurationOptions/packages/offroad.png',\n    },\n    visual: true,\n    price: 5000,\n    },\n    matchingSpareTire: {\n    name: { 'en-US': 'Matching Spare Tire' },\n    attrs: {\n    description: { 'en-US': 'Full sized tire' },\n    imageUrl: '/public/images/configurationOptions/packages/spare.png',\n    },\n    price: 500,\n    },\n    \n    wirelessCharger: {\n    name: { 'en-US': 'Wireless charger' },\n    attrs: {\n    description: { 'en-US': '' },\n    imageUrl: '/public/images/configurationOptions/packages/wireless.png',\n    },\n    price: 100,\n    },\n    selfDrivingPackage: {\n    name: { 'en-US': 'Autonomy' },\n    attrs: {\n    description: { 'en-US': '' },\n    imageUrl: '/public/images/configurationOptions/packages/autonomy.png',\n    },\n    price: 7000,\n    },\n    \n    acceleration: {\n    name: { 'en-US': '0 - 60 mph' },\n    attrs: {\n    units: { 'en-US': 'sec' },\n    decimals: 1,\n    },\n    value: 3.4,\n    },\n    power: {\n    name: { 'en-US': 'Horsepower' },\n    attrs: {\n    units: { 'en-US': 'hp' },\n    },\n    value: 750,\n    },\n    towing: {\n    name: { 'en-US': 'Towing' },\n    attrs: {\n    units: { 'en-US': 'lbs' },\n    },\n    value: 10000,\n    },\n    range: {\n    name: { 'en-US': 'Range' },\n    attrs: {\n    units: { 'en-US': 'mi' },\n    },\n    value: 400,\n    },\n    }\n    };\n    ```\n    \n\n## Public datasets\n\n- Instagram: 16539 images from 972 Instagram influencers ([link](https://github.com/gvsi/instagram-like-predictor))\n- TechCrunchPosts: ([link](https://www.kaggle.com/thibalbo/techcrunch-posts-compilation))\n- Tweets: ([link](https://data.world/data-society/twitter-user-data))\n\nPrimary (available for academic use only, need university affiliation for access)\n\n- [A Dataset and Benchmarks for Multimedia Social Analysis](https://arxiv.org/abs/2006.08335)\n\nSecondary (low quality data, not sure if can be used at all)\n\n- [Hacker News Posts](https://www.kaggle.com/hacker-news/hacker-news-posts)\n- [TechCrunch Posts Compilation](https://www.kaggle.com/thibalbo/techcrunch-posts-compilation)\n- Instagram image data [HowTo](https://towardsdatascience.com/predict-the-number-of-likes-on-instagram-a7ec5c020203)\n- Flikr Large with likes and comments\n- [The Images of Groups Dataset](http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html)\n- [http://www.multimediaeval.org/datasets/](http://www.multimediaeval.org/datasets/)\n- [The InstaCities1M Dataset](https://gombru.github.io/2018/08/01/InstaCities1M/)\n- [Multimodal Meme Classification: Identifying Offensive Content in Image and Text](https://www.insight-centre.org/sites/default/files/publications/memes_classification_lrec_1.pdf)\n- [Understanding Police Social Media Usage Through Posts and Tweets](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NRPHLC)\n- Topic clusters text\n    - Model X\n        - I like model X\n        - I want to buy model X\n        - Model X is my favorite car\n        - Tesla Modelx is my dream\n        - modelx tesla love\n    - Cyber Truck\n        - I like Cyber Truck\n        - I want to buy Cyber Truck\n        - Cyber Truck is my favorite car\n        - Tesla Cyber Truck is my dream\n        - CyberTruck tesla love\n    - Adventure\n        - I like adventure\n        - sports i play\n        - i went on trip\n        - I travels a lot\n        - car adventure\n        \n    - Exterior Color White\n        - I like white color\n        - White is my fav\n        - white car love\n        - I like white exterior\n    - Exterior Color Black\n        - I like Black color\n        - Black is my fav\n        - Black car love\n        - I like Black exterior\n    - Exterior Color Blue\n        - I like Blue color\n        - Blue is my fav\n        - Blue car love\n        - I like Blue exterior\n    - Exterior Color Green\n        - I like Green color\n        - Green is my fav\n        - Green car love\n        - I like Green exterior\n    - Exterior Color Red\n        - I like Red color\n        - Red is my fav\n        - Red car love\n        - I like Red exterior\n    - Exterior Color Grey\n        - I like Grey color\n        - Grey is my fav\n        - Grey car love\n        - I like Grey exterior\n    - Exterior Color Silver\n        - I like Silver color\n        - Silver is my fav\n        - Silver car love\n        - I like Silver exterior\n    - Self driving\n        - I like self driving technology\n        - selfDrivingPackage\n        - selfDrivingtech love\n        - self drive is my fav\n        - self driving car is amazing\n- Celebs\n    \n    ![/img/content-blog-raw-blog-vehicle-suggestions-untitled-1.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-1.png)\n    \n\n## Logical Reasoning\n\n- If I implicitly rate pictures of blue car, that means I might prefer a blue car.\n- If I like posts of self-driving, that means I might prefer a self-driving option.\n\n# Scope\n\n### Scope 1\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-2.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-2.png)\n\n### Scope 2\n\nmedia content categories: text and images\n\nplatforms: facebook, twitter and instagram\n\nimplicit rating categories: like, comment, share\n\ncolumns: userid, timestamp, platform, type, content, rating\n\n# Model Framework\n\n### Model framework 1\n\n1. Convert user's natural language query into vector using Universal Sentence Embedding model\n2. Create a product specs binary matrix based on different categories\n3. Find TopK similar query vectors using cosine distance\n4. For each TopK vector, Find TopM product specs using interaction table weights\n5. For each TopM specification, find TopN similar specs using binary matrix\n6. Show all the qualified product specifications\n\n### Model framework 2\n\n1. Seed data: 10 users with ground-truth persona, media content and implicit ratings\n2. Inflated data: 10 users with media content and implicit ratings\n3. media content → Implicit rating (A)\n4. media content → feature vector (B) + (A) → weighted pooling → similar users (C)\n5. media content → QA model → slot filling → global pooling → item associations (D)\n6. (C) → content-based filtering → item recommendations → (D) → top-k recommendations\n\n**User selection**\n\n- People who are connected to social media community of electric vehicles\n- Seed users are those who already have an electric vehicle\n- Inflated users are those who doesn't own an EV but inclined to purchase\n- Users having presense on all three sites or at least 2\n- List of common users\n    \n    [https://www.facebook.com/gossman](https://www.facebook.com/gossman)\n    \n    [https://www.facebook.com/ryanm06](https://www.facebook.com/ryanm06)\n    \n    [https://www.facebook.com/chad.turner.7146](https://www.facebook.com/chad.turner.7146)\n    \n    [https://www.facebook.com/cjacobs05](https://www.facebook.com/cjacobs05)\n    \n    [https://www.facebook.com/MafiaAllen](https://www.facebook.com/MafiaAllen)\n    \n    [https://www.facebook.com/rahul.mii.33](https://www.facebook.com/rahul.mii.33)\n    \n    [https://www.facebook.com/francisco.chavira.547](https://www.facebook.com/francisco.chavira.547)\n    \n    [https://www.facebook.com/JayTheillest74](https://www.facebook.com/JayTheillest74)\n    \n    [https://www.facebook.com/michael.creighton20](https://www.facebook.com/michael.creighton20)\n    \n    [https://www.facebook.com/darryl.grigggardening](https://www.facebook.com/darryl.grigggardening)\n    \n    [https://www.facebook.com/4X4Aus/](https://www.facebook.com/4X4Aus/)\n    \n    [https://www.instagram.com/minnyrc/](https://www.instagram.com/minnyrc/)\n    \n    [https://www.instagram.com/warnerbu7lt/](https://www.instagram.com/warnerbu7lt/)\n    \n- List of celebs\n    1. [https://en.wikipedia.org/wiki/List_of_most-followed_Instagram_accounts](https://en.wikipedia.org/wiki/List_of_most-followed_Instagram_accounts)\n    2. [https://en.wikipedia.org/wiki/List_of_most-followed_Twitter_accounts](https://en.wikipedia.org/wiki/List_of_most-followed_Twitter_accounts)\n    3. [https://en.wikipedia.org/wiki/List_of_most-followed_Facebook_pages](https://en.wikipedia.org/wiki/List_of_most-followed_Facebook_pages)\n    \n    ['Jennifer Lopez', 'Virat Kohli', 'Ariana Grande', 'Dwayne Johnson', 'Kylie Jenner', 'Lionel Messi', 'LeBron James', 'Beyoncé', 'Justin Bieber', 'Akshay Kumar', 'Demi Lovato', 'Kendall Jenner', 'Nicki Minaj', 'Khloé Kardashian', 'Kim Kardashian', 'Gigi Hadid', 'Ellen DeGeneres', 'Deepika Padukone', 'Rihanna', 'Shakira', 'Cardi B', 'Eminem', 'Drake', 'Chris Brown', 'Maluma', 'Vin Diesel', 'Ronaldinho', 'Kevin Hart', 'Emma Watson', 'Shawn Mendes', 'Neymar', 'Justin Timberlake', 'Katy Perry', 'Donald Trump', 'Lady Gaga', 'Amitabh Bachchan', 'Selena Gomez', 'Lil Wayne', 'Elon Musk', 'Britney Spears', 'Jimmy Fallon', 'Bill Gates', 'Ariana Grande', 'Miley Cyrus', 'Oprah Winfrey', 'Cristiano Ronaldo', 'Salman Khan', 'Shah Rukh Khan', 'Niall Horan']\n    \n\n### Model framework 3\n\nUser-User Similarity (clustering)\n\n- User → Media content → Embedding → Average pooling\n- Cosine Similarity of user's social vector with other user's social vector\n\nUser-Item Similarity (reranking)\n\n- **User → Implicit Rating on media content M → M's correlation with item features**\n- Item features: familySize\n- Cosine Similarity of user's social vector with item's feature vector\n\nUser-User Similarity (clustering)\n\n- User → Media content → Embedding → Average pooling\n- Cosine Similarity of user's social vector with other user's social vector\n\nUser-Item Similarity (reranking)\n\n- **User → Implicit Rating on media content M → M's correlation with item features**\n- Item features: familySize\n- Cosine Similarity of user's social vector with item's feature vector\n\n### Model framework 4\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-3.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-3.png)\n\nText → Prepare → Vectorize → Average → Similar Users\n\nImage → Prepare → Vectorize → Average → Similar Users\n\nText → Prepare → QA → Slot filling\n\nImage → Prepare → VQA → Slot filling\n\nImage → Similar Image from users → Detailed enquiry\n\n### Model framework 5\n\n1. Topic Clusters Text\n2. Topic Clusters Image\n3. Fetch raw text and images\n4. Combine, Clean and Store text in text dataframe\n5. Vectorize Texts\n6. Cosine similarities of texts with topic clusters\n7. Vectorize Images\n8. Cosine similarities of images with topic clusters\n\n# Experimental Setup\n\n- Experiment 1\n    \n    ```python\n    import numpy as np\n    import pandas as pd\n    import tensorflow_hub as hub\n    from itertools import product\n    from sklearn.preprocessing import OneHotEncoder\n    from sklearn.metrics.pairwise import cosine_similarity\n    \n    vehicle = ['modelX', 'cyberTruck']\n    trim = ['adventure', 'base']\n    exteriorColor = ['whiteExterior', 'blueExterior', 'silverExterior', 'greyExterior', 'blackExterior', 'redExterior', 'greenExterior']\n    wheels = ['20AllTerrain', '21AllSeason', '22Performance']\n    tonneau = ['powerTonneau', 'manualTonneau']\n    interiorColor = ['blackInterior', 'greyInterior', 'greenInterior']\n    range = ['standardRange', 'mediumRange', 'extendedRange']\n    packages = ['offroadPackage', 'matchingSpareTire', 'offroadPackage,matchingSpareTire', 'None']\n    interiorAddons = ['wirelessCharger', 'None']\n    software = ['selfDrivingPackage', 'None']\n    \n    specs_cols = ['vehicle', 'trim', 'exteriorColor', 'wheels', 'tonneau', 'interiorColor', 'range', 'packages', 'interiorAddons', 'software']\n    specs = pd.DataFrame(list(product(vehicle, trim, exteriorColor, wheels, tonneau, interiorColor, range, packages, interiorAddons, software)),\n                         columns=specs_cols)\n    \n    enc = OneHotEncoder(handle_unknown='error', sparse=False)\n    specs = pd.DataFrame(enc.fit_transform(specs))\n    \n    specs_ids = specs.index.tolist()\n    \n    query_list = [\"I'm looking for a fast suv that I can go camping without worrying about recharging\",\n                  \"cheap red car that is able to go long distances\",\n                  \"i am looking for a daily driver that i can charge everyday, do not need any extras\",\n                  \"i like to go offroading a lot on my jeep and i want to do the same with the truck\",\n                  \"i want the most basic suv possible\",\n                  \"I want all of the addons\", \n                  \"I have a big family and want to be able to take them around town and run errands without worrying about charging\"]\n    \n    queries = pd.DataFrame(query_list, columns=['query'])\n    query_ids = queries.index.tolist()\n    \n    const_oneJSON = {\n    'vehicle': 'modelX',\n    'trim' : 'adventure',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"22Performance\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"extendedRange\",\n    'software': \"None\",\n    }\n    \n    const_twoJSON = {\n    'vehicle': 'cyberTruck',\n    'trim' : 'base',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"21AllSeason\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"extendedRange\",\n    'software': \"None\",\n    }\n    \n    const_threeJSON = {\n    'vehicle': 'cyberTruck',\n    'trim' : 'base',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"21AllSeason\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"standardRange\",\n    'software': \"None\",\n    }\n    \n    const_fourJSON = {\n    'vehicle': 'cyberTruck',\n    'trim' : 'adventure',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"20AllTerrain\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"offroadPackage,matchingSpareTire\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"extendedRange\",\n    'software': \"None\",\n    }\n    \n    const_fiveJSON = {\n    'vehicle': 'modelX',\n    'trim' : 'base',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"20AllTerrain\",\n    'tonneau': \"manualTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"standardRange\",\n    'software': \"None\",\n    }\n    \n    const_sixJSON = {\n    'vehicle': 'cyberTruck',\n    'trim' : 'adventure',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"20AllTerrain\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"offroadPackage,matchingSpareTire\",\n    'interiorAddons': \"wirelessCharger\",\n    'interiorColor': \"blackInterior\",\n    'range': \"extendedRange\",\n    'software': \"selfDrivingPackage\",\n    }\n    \n    const_sevenJSON = {\n    'vehicle': 'modelX',\n    'trim' : 'base',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"21AllSeason\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"mediumRange\",\n    'software': \"None\",\n    }\n    \n    historical_data = pd.DataFrame([const_oneJSON, const_twoJSON, const_threeJSON, const_fourJSON, const_fiveJSON, const_sixJSON, const_sevenJSON])\n    \n    input_vec = enc.transform([specs_frame.append(historical_data.iloc[0], sort=False).iloc[-1]])\n    idx = np.argsort(-cosine_similarity(input_vec, specs.values))[0,:][:1]\n    rslt = enc.inverse_transform([specs.iloc[idx]])\n    \n    interactions = pd.DataFrame(columns=['query_id','specs_id'])\n    interactions['query_id'] = queries.index.tolist()\n    input_vecs = enc.transform(specs_frame.append(historical_data, sort=False).iloc[-len(historical_data):])\n    interactions['specs_id'] = np.argsort(-cosine_similarity(input_vecs, specs.values))[:,0]\n    \n    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n    embed_model = hub.load(module_url)\n    def embed(input):\n      return embed_model(input)\n    query_vecs = embed(queries['query'].tolist()).numpy()\n    \n    _query = input('Please enter query: ') or 'i want the most basic suv possible'\n    _query_vec = embed([_query]).numpy()\n    _match_qid = np.argsort(-cosine_similarity(_query_vec, query_vecs))[0,:][:1]\n    _match_sid = interactions.loc[interactions['query_id']==_match_qid[0], 'specs_id'].values[0]\n    input_vec = enc.transform([specs_frame.append(historical_data.iloc[0], sort=False).iloc[-1]])\n    idx = np.argsort(-cosine_similarity([specs.iloc[_match_sid].values], specs.values))[0,:][:5]\n    results = []\n    for x in idx:\n      results.append(enc.inverse_transform([specs.iloc[x]]))\n    _temp = np.array(results).reshape(5,-1)\n    _temp = pd.DataFrame(_temp, columns=specs_frame.columns)\n    print(_temp)\n    ```\n    \n\n## Experiment 2\n\nCeleb Scraping\n\n### Facebook Scraping\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-4.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-4.png)\n\n### Twitter Scraping\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-5.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-5.png)\n\n### Dataframe\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-6.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-6.png)\n\n### Insta Image Grid\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-7.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-7.png)\n\n### User Text NER\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-8.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-8.png)\n\n## Experiment 3\n\nTopic model\n\n### Topic scores\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-9.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-9.png)\n\n### JSON rules\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-10.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-10.png)\n\n# Results and Discussion\n\n- API with 3 input fields - Facebook username, Twitter handle & Instagram username\n- The system will automatically scrap the user's publicly available text and images from these 3 social media platforms and provide a list of recommendations from most to least preferred product"
        },
        {
          "id": "/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
          "metadata": {
            "permalink": "/blog/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
            "source": "@site/blog/2021-10-01-web-scraping-using-scrapy-bs4-and-selenium.mdx",
            "title": "Web Scraping using Scrapy, BS4, and Selenium",
            "description": "1. Handling single request & response by extracting a city’s weather from a weather site using Scrapy",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "scraping",
                "permalink": "/blog/tags/scraping"
              }
            ],
            "readingTime": 3.78,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Web Scraping using Scrapy, BS4, and Selenium",
              "authors": "sparsh",
              "tags": [
                "scraping"
              ]
            },
            "prevItem": {
              "title": "Vehicle Suggestions",
              "permalink": "/blog/2021/10/01/vehicle-suggestions"
            },
            "nextItem": {
              "title": "Web Scraping with Gazpacho",
              "permalink": "/blog/2021/10/01/web-scraping-with-gazpacho"
            }
          },
          "content": "1. Handling single request & response by extracting a city’s weather from a weather site using Scrapy\n2. Handling multiple request & response by extracting book details from a dummy online book store using Scrapy\n3. Scrape the cover images of all the books from the website [books.toscrape.com](http://books.toscrape.com/) using Scrapy\n4. Logging into Facebook using Selenium\n5. Extract PM2.5 data from [openaq.org](http://openaq.org) using Selenium\n6. Extract PM2.5 data from [openaq.org](http://openaq.org) using Selenium Scrapy\n\n:::note Scrapy vs. Selenium\n\nSelenium is an automation tool for testing web applications. It uses a webdriver as an interface to control webpages through programming languages. So, this gives Selenium the capability to handle dynamic webpages effectively. Selenium is capable of extracting data on its own. It is true, but it has its caveats. Selenium cannot handle large data, but Scrapy can handle large data with ease. Also, Selenium is much slower when compared to Scrapy. So, the smart choice would be to use Selenium with Scrapy to scrape dynamic webpages containing large data, consuming less time. Combining Selenium with Scrapy is a simpler process. All that needs to be done is let Selenium render the webpage and once it is done, pass the webpage’s source to create a Scrapy Selector object. And from here on, Scrapy can crawl the page with ease and effectively extract a large amount of data.\n\n:::\n\n```python\n# SKELETON FOR COMBINING SELENIUM WITH SCRAPY\nfrom scrapy import Selector\n# Other Selenium and Scrapy imports\n...\ndriver = webdriver.Chrome()\n# Selenium tasks and actions to render the webpage with required content\nselenium_response_text = driver.page_source\nnew_selector = Selector(text=selenium_response_text)\n# Scrapy tasks to extract data from Selector\n```\n\n## Project tree\n\n```html\n.\n├── airQuality\n│   ├── countries_list.json\n│   ├── get_countries.py\n│   ├── get_pm_data.py\n│   ├── get_urls.py\n│   ├── openaq_data.json\n│   ├── openaq_scraper.py\n│   ├── README.md\n│   └── urls.json\n├── airQualityScrapy\n│   ├── LICENSE\n│   ├── openaq\n│   │   ├── countries_list.json\n│   │   ├── openaq\n│   │   │   ├── __init__.py\n│   │   │   ├── items.py\n│   │   │   ├── middlewares.py\n│   │   │   ├── pipelines.py\n│   │   │   ├── settings.py\n│   │   │   └── spiders\n│   │   ├── output.json\n│   │   ├── README.md\n│   │   ├── scrapy.cfg\n│   │   └── urls.json\n│   ├── performance_comparison\n│   │   ├── performance_comparison\n│   │   │   ├── __init__.py\n│   │   │   ├── items.py\n│   │   │   ├── middlewares.py\n│   │   │   ├── pipelines.py\n│   │   │   ├── settings.py\n│   │   │   └── spiders\n│   │   ├── README.md\n│   │   ├── scrapy.cfg\n│   │   ├── scrapy_output.json\n│   │   └── selenium_scraper\n│   │       ├── bts_scraper.py\n│   │       ├── selenium_output.json\n│   │       └── urls.json\n│   └── README.md\n├── books\n│   ├── books\n│   │   ├── __init__.py\n│   │   ├── items.py\n│   │   ├── middlewares.py\n│   │   ├── pipelines.py\n│   │   ├── settings.py\n│   │   └── spiders\n│   │       ├── book_spider.py\n│   │       ├── crawl_spider.py\n│   │       └── __init__.py\n│   ├── crawl_spider_output.json\n│   ├── README.md\n│   └── scrapy.cfg\n├── booksCoverImage\n│   ├── booksCoverImage\n│   │   ├── __init__.py\n│   │   ├── items.py\n│   │   ├── middlewares.py\n│   │   ├── pipelines.py\n│   │   ├── settings.py\n│   │   └── spiders\n│   │       ├── image_crawl_spider.py\n│   │       └── __init__.py\n│   ├── output.json\n│   ├── path\n│   │   └── to\n│   │       └── store\n│   ├── README.md\n│   └── scrapy.cfg\n├── etc\n│   └── Selenium\n│       ├── chromedriver.exe\n│       ├── chromedriver_v87.exe\n│       └── install.sh\n├── facebook\n│   └── login.py\n├── gazpacho1\n│   ├── data\n│   │   ├── media.html\n│   │   ├── ocr.html\n│   │   ├── page.html\n│   │   ├── static\n│   │   │   └── stheno.mp4\n│   │   └── table.html\n│   ├── media\n│   │   ├── euryale.png\n│   │   ├── medusa.mp3\n│   │   ├── medusa.png\n│   │   ├── stheno.mp4\n│   │   └── test.png\n│   ├── scrap_login.py\n│   ├── scrap_media.py\n│   ├── scrap_ocr.py\n│   ├── scrap_page.py\n│   └── scrap_table.py\n├── houzzdotcom\n│   ├── houzzdotcom\n│   │   ├── __init__.py\n│   │   ├── items.py\n│   │   ├── middlewares.py\n│   │   ├── pipelines.py\n│   │   ├── settings.py\n│   │   └── spiders\n│   │       ├── crawl_spider.py\n│   │       └── __init__.py\n│   └── scrapy.cfg\n├── media\n│   └── test.png\n├── README.md\n├── scrapyPractice\n│   ├── scrapy.cfg\n│   └── scrapyPractice\n│       ├── __init__.py\n│       ├── items.py\n│       ├── middlewares.py\n│       ├── pipelines.py\n│       ├── settings.py\n│       └── spiders\n│           └── __init__.py\n└── weather\n    ├── output.json\n    ├── README.md\n    ├── scrapy.cfg\n    └── weather\n        ├── __init__.py\n        ├── items.py\n        ├── middlewares.py\n        ├── pipelines.py\n        ├── settings.py\n        └── spiders\n            ├── __init__.py\n            └── weather_spider.py\n\n35 directories, 98 files\n```\n\n![For code, drop me a message on mail or LinkedIn.](/img/content-blog-raw-blog-web-scraping-using-scrapy-bs4-and-selenium-untitled.png)\n\nFor code, drop me a message on mail or LinkedIn."
        },
        {
          "id": "/2021/10/01/web-scraping-with-gazpacho",
          "metadata": {
            "permalink": "/blog/2021/10/01/web-scraping-with-gazpacho",
            "source": "@site/blog/2021-10-01-web-scraping-with-gazpacho.mdx",
            "title": "Web Scraping with Gazpacho",
            "description": "Using gazpacho to Download and Parse the Contents of a Website. Scrape the names of the three \"Gorgons\".",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "scraping",
                "permalink": "/blog/tags/scraping"
              }
            ],
            "readingTime": 0.52,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Web Scraping with Gazpacho",
              "authors": "sparsh",
              "tags": [
                "scraping"
              ]
            },
            "prevItem": {
              "title": "Web Scraping using Scrapy, BS4, and Selenium",
              "permalink": "/blog/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium"
            },
            "nextItem": {
              "title": "Wellness tracker chatbot",
              "permalink": "/blog/2021/10/01/wellness-tracker-chatbot"
            }
          },
          "content": "### Using gazpacho to Download and Parse the Contents of a Website. Scrape the names of the three \"Gorgons\".\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled.png)\n\n### Using gazpacho and pandas to Retrieve the Contents of an HTML Table. Scrape the creature and habitat columns.\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-1.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-1.png)\n\n### Using gazpacho and Selenium to Retrieve the Contents of a Password-Protected Web Page. Scrape the quote text behind the login form.\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-2.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-2.png)\n\n### Using gazpacho and pytesseract to Parse the Contents of “Non-Text” Text Data. Extract the embedded text.\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-3.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-3.png)\n\n### Using gazpacho and urllib to Retrieve and Download Images, Videos, and Audio Clippings. To download the Image, Audio and Video data.\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-4.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-4.png)"
        },
        {
          "id": "/2021/10/01/wellness-tracker-chatbot",
          "metadata": {
            "permalink": "/blog/2021/10/01/wellness-tracker-chatbot",
            "source": "@site/blog/2021-10-01-wellness-tracker-chatbot.mdx",
            "title": "Wellness tracker chatbot",
            "description": "/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "chatbot",
                "permalink": "/blog/tags/chatbot"
              },
              {
                "label": "healthcare",
                "permalink": "/blog/tags/healthcare"
              },
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              }
            ],
            "readingTime": 0.455,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Wellness tracker chatbot",
              "authors": "sparsh",
              "tags": [
                "chatbot",
                "healthcare",
                "nlp"
              ]
            },
            "prevItem": {
              "title": "Web Scraping with Gazpacho",
              "permalink": "/blog/2021/10/01/web-scraping-with-gazpacho"
            },
            "nextItem": {
              "title": "What is Livestream Ecommerce",
              "permalink": "/blog/2021/10/01/what-is-livestream-ecommerce"
            }
          },
          "content": "![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled.png)\n\n## Problem Statement\n\nA bot that logs daily wellness data to a spreadsheet (using the Airtable API), to help the user keep track of their health goals. Connect the assistant to a messaging channel—Twilio—so users can talk to the assistant via text message and Whatsapp.\n\n---\n\n## Proposed Solution\n\n- RASA chatbot with Forms and Custom actions\n- Connect with Airtable API to log records in table database\n- Connect with Whatsapp for user interaction\n\n---\n\n## Modeling\n\n![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-1.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-1.png)\n\n![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-2.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-2.png)\n\n![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-3.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-3.png)\n\n![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-4.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-4.png)\n\n---\n\n## Delivery\n\n[https://github.com/sparsh-ai/chatbots/tree/master/wellnessTracker](https://github.com/sparsh-ai/chatbots/tree/master/wellnessTracker)\n\n---\n\n## Reference\n\n[https://www.udemy.com/course/rasa-for-beginners/learn/lecture/20746878#overview](https://www.udemy.com/course/rasa-for-beginners/learn/lecture/20746878#overview)"
        },
        {
          "id": "/2021/10/01/what-is-livestream-ecommerce",
          "metadata": {
            "permalink": "/blog/2021/10/01/what-is-livestream-ecommerce",
            "source": "@site/blog/2021-10-01-what-is-livestream-ecommerce.mdx",
            "title": "What is Livestream Ecommerce",
            "description": "/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "personalization",
                "permalink": "/blog/tags/personalization"
              },
              {
                "label": "trend",
                "permalink": "/blog/tags/trend"
              }
            ],
            "readingTime": 3.385,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "What is Livestream Ecommerce",
              "authors": "sparsh",
              "tags": [
                "personalization",
                "trend"
              ]
            },
            "prevItem": {
              "title": "Wellness tracker chatbot",
              "permalink": "/blog/2021/10/01/wellness-tracker-chatbot"
            },
            "nextItem": {
              "title": "Object detection with YOLO3",
              "permalink": "/blog/2021/01/23/object-detection-with-yolo3"
            }
          },
          "content": "![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled.png)\n\nRecent years witness the prosperity of online live streaming. With the development of mobile phones, cameras, and high-speed internet, more and more users are able to broadcast their experiences in live streams on various social platforms, such as Facebook Live and YouTube Live. There are a variety of live streaming applications, including knowledge share, video-gaming, and outdoor traveling.\n\nOne of the most important scenarios is live streaming commerce, a new form of online shopping becomes more and more popular, which combines live streaming with E-Commerce activity. The streamers introduce products and interact with their audiences, and hence greatly improve the performance of selling products.\n\n![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-1.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-1.png)\n\n> Livestream ecommerce is a business model in which retailers, influencers, or celebrities sell products and services via online video streaming where the presenter demonstrates and discusses the offering and answers audience questions in real-time.\n> \n\n![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-2.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-2.png)\n\n### Examples\n\n[https://media.nngroup.com/media/editor/2021/02/16/tiktok_livestream_compressed.mp4](https://media.nngroup.com/media/editor/2021/02/16/tiktok_livestream_compressed.mp4)\n\n*During a livestream event hosted by Walmart on TikTok, users watched an influencer presenting various products such as a pair of jeans. Those interested in the jeans could tap the product listing shown at the bottom of the screen. They could also browse the list of products promoted during the livestream and purchase them without leaving the TikTok app. Viewers’ real-time comments appeared along the left-hand side of the livestream feed.*\n\n### Advantages\n\n- Livestreams allow users to see products in detail and get their questions answered in real time\n- During livestream sessions, the hosts can show product details in close-up (left), give instructions of use for products like essential oils and cosmetic face masks (middle), or even show how a particular product, like the tea they’re selling, is made (right)\n    \n    ![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-3.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-3.png)\n    \n- Greatly shorten the decision-making time of consumers and provoke the sales volume\n- The expert streamers introduce and promote the products in a live streaming manner, which makes the shopping process more interesting and convincing\n- Rich and real-time interactions between streamers and their audiences, which makes live streaming a new medium and a powerful marketing tool for E-Commerce\n- Viewers not only can watch the showing for product’s looks and functions, but also can ask the streamers to show different or individual perspectives of the products in real-time\n\n### Market\n\nLivestream ecommerce has been surging dramatically in China. According to Forbes, this industry is estimated to earn $60 billion annually. In 2019, about 37 percent of the online shoppers in China (265 million people) made livestream purchases. On Taobao’s 2020 annual Single-Day Global Shopping Festival (November 11th), livestreams accounted for $6 billion in sales (twice the amount from the prior year).\n\nAmazon has also launched its live platform, where influencers promote items and chat with potential customers. And Facebook and Instagram are exploring the integration between ecommerce and social media. For instance, the new Shop feature on Instagram allows users to browse products and place orders directly within Instagram — a form of social commerce.\n\nThe total GMV driven by live streaming achieved $6 Billion USD. Some quantitative research results show that adopting live streaming in sales can achieve a 21.8% increase in online sales volume.\n\n![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-4.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-4.png)\n\n### The Anatomy of a Livestream Session\n\n![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-5.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-5.png)\n\nA typical livestream session has the following basic components:\n\n1. **The video stream,** where the host shows the products, talks about them, and answers questions from the audience. In the Amazon Live case, the stream occupies the most of the screen space.\n2. **The list of products being promoted**, with the product currently being shown highlighted. This list appears at the bottom of the Amazon video stream.\n3. **A chat area,** where viewers can type questions and comments to interact with the host and other viewers. The chat area is at the right of the live stream on Amazon Live.\n4. **A reaction button, that users** can use to send reactions, displayed as animated emojis. The reaction button shows up as a little star icon at the bottom right of the video stream on Amazon.\n\n### References\n\n1. [Features of Livestream ecommerce: What We Can Learn from China](https://www.nngroup.com/articles/livestream-ecommerce-china/)\n2. [Top Live Streaming E-Commerce Startups](https://tracxn.com/d/trending-themes/Startups-in-Live-Streaming-E-Commerce)"
        },
        {
          "id": "/2021/01/23/object-detection-with-yolo3",
          "metadata": {
            "permalink": "/blog/2021/01/23/object-detection-with-yolo3",
            "source": "@site/blog/2021-01-23-object-detection-with-yolo3.mdx",
            "title": "Object detection with YOLO3",
            "description": "Live app",
            "date": "2021-01-23T00:00:00.000Z",
            "formattedDate": "January 23, 2021",
            "tags": [
              {
                "label": "app",
                "permalink": "/blog/tags/app"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              },
              {
                "label": "streamlit",
                "permalink": "/blog/tags/streamlit"
              }
            ],
            "readingTime": 1.975,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "Object detection with YOLO3",
              "authors": [
                "sparsh"
              ],
              "tags": [
                "app",
                "vision",
                "streamlit"
              ]
            },
            "prevItem": {
              "title": "What is Livestream Ecommerce",
              "permalink": "/blog/2021/10/01/what-is-livestream-ecommerce"
            },
            "nextItem": {
              "title": "MobileNet SSD Caffe Pre-trained model",
              "permalink": "/blog/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
            }
          },
          "content": "## Live app\n\nThis app can detect COCO 80-classes using three different models - Caffe MobileNet SSD, Yolo3-tiny, and Yolo3. It can also detect faces using two different models - SSD Res10 and OpenCV face detector.  Yolo3-tiny can also detect fires.\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png)\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png)\n\n## Code\n\n```python\nimport streamlit as st\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport os\n\nfrom tempfile import NamedTemporaryFile\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\ntemp_file = NamedTemporaryFile(delete=False)\n\nDEFAULT_CONFIDENCE_THRESHOLD = 0.5\nDEMO_IMAGE = \"test_images/demo.jpg\"\nMODEL = \"model/MobileNetSSD_deploy.caffemodel\"\nPROTOTXT = \"model/MobileNetSSD_deploy.prototxt.txt\"\n\nCLASSES = [\n    \"background\",\n    \"aeroplane\",\n    \"bicycle\",\n    \"bird\",\n    \"boat\",\n    \"bottle\",\n    \"bus\",\n    \"car\",\n    \"cat\",\n    \"chair\",\n    \"cow\",\n    \"diningtable\",\n    \"dog\",\n    \"horse\",\n    \"motorbike\",\n    \"person\",\n    \"pottedplant\",\n    \"sheep\",\n    \"sofa\",\n    \"train\",\n    \"tvmonitor\",\n]\nCOLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n\n@st.cache\ndef process_image(image):\n    blob = cv2.dnn.blobFromImage(\n        cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5\n    )\n    net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n    net.setInput(blob)\n    detections = net.forward()\n    return detections\n\n@st.cache\ndef annotate_image(\n    image, detections, confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD\n):\n    # loop over the detections\n    (h, w) = image.shape[:2]\n    labels = []\n    for i in np.arange(0, detections.shape[2]):\n        confidence = detections[0, 0, i, 2]\n\n        if confidence > confidence_threshold:\n            # extract the index of the class label from the `detections`,\n            # then compute the (x, y)-coordinates of the bounding box for\n            # the object\n            idx = int(detections[0, 0, i, 1])\n            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n            (startX, startY, endX, endY) = box.astype(\"int\")\n\n            # display the prediction\n            label = f\"{CLASSES[idx]}: {round(confidence * 100, 2)}%\"\n            labels.append(label)\n            cv2.rectangle(image, (startX, startY), (endX, endY), COLORS[idx], 2)\n            y = startY - 15 if startY - 15 > 15 else startY + 15\n            cv2.putText(\n                image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2\n            )\n    return image, labels\n\ndef main():\n  selected_box = st.sidebar.selectbox(\n    'Choose one of the following',\n    ('Welcome', 'Object Detection')\n    )\n    \n  if selected_box == 'Welcome':\n      welcome()\n  if selected_box == 'Object Detection':\n      object_detection() \n\ndef welcome():\n  st.title('Object Detection using Streamlit')\n  st.subheader('A simple app for object detection')\n  st.image('test_images/demo.jpg',use_column_width=True)\n\ndef object_detection():\n  \n  st.title(\"Object detection with MobileNet SSD\")\n\n  confidence_threshold = st.sidebar.slider(\n    \"Confidence threshold\", 0.0, 1.0, DEFAULT_CONFIDENCE_THRESHOLD, 0.05)\n\n  st.sidebar.multiselect(\"Select object classes to include\",\n  options=CLASSES,\n  default=CLASSES\n  )\n\n  img_file_buffer = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n\n  if img_file_buffer is not None:\n      temp_file.write(img_file_buffer.getvalue())\n      image = load_img(temp_file.name)\n      image = img_to_array(image)\n      image = image/255.0\n\n  else:\n      demo_image = DEMO_IMAGE\n      image = np.array(Image.open(demo_image))\n\n  detections = process_image(image)\n  image, labels = annotate_image(image, detections, confidence_threshold)\n\n  st.image(\n      image, caption=f\"Processed image\", use_column_width=True,\n  )\n\n  st.write(labels)\n\nmain()\n```\n\n*You can play with the live app* [*here](https://share.streamlit.io/sparsh-ai/streamlit-489fbbb7/app.py). Source code is available [here](https://github.com/sparsh-ai/streamlit-5a407279/tree/master) on Github.*"
        },
        {
          "id": "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model",
          "metadata": {
            "permalink": "/blog/2020/01/19/mobilenet-ssd-caffe-pre-trained-model",
            "source": "@site/blog/2020-01-19-mobilenet-ssd-caffe-pre-trained-model.mdx",
            "title": "MobileNet SSD Caffe Pre-trained model",
            "description": "You can play with the live app here. Souce code is available here on Github.",
            "date": "2020-01-19T00:00:00.000Z",
            "formattedDate": "January 19, 2020",
            "tags": [
              {
                "label": "app",
                "permalink": "/blog/tags/app"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              },
              {
                "label": "streamlit",
                "permalink": "/blog/tags/streamlit"
              }
            ],
            "readingTime": 0.74,
            "hasTruncateMarker": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Data Scientist & Engineer",
                "url": "https://github.com/sparsh-ai",
                "email": "sprsag@gmail.com",
                "imageURL": "https://github.com/sparsh-ai.png",
                "key": "sparsh"
              }
            ],
            "frontMatter": {
              "title": "MobileNet SSD Caffe Pre-trained model",
              "authors": [
                "sparsh"
              ],
              "tags": [
                "app",
                "vision",
                "streamlit"
              ]
            },
            "prevItem": {
              "title": "Object detection with YOLO3",
              "permalink": "/blog/2021/01/23/object-detection-with-yolo3"
            }
          },
          "content": "*You can play with the live app [here](https://share.streamlit.io/sparsh-ai/streamlit-5a407279/app.py). Souce code is available* [here](https://github.com/sparsh-ai/streamlit-489fbbb7) *on Github.*\n\n## Live app\n\n![/img/content-blog-raw-mobilenet-ssd-caffe-pre-trained-model-untitled.png](/img/content-blog-raw-mobilenet-ssd-caffe-pre-trained-model-untitled.png)\n\n## Code\n\n```python\n#------------------------------------------------------#\n# Import libraries\n#------------------------------------------------------#\n\nimport datetime\nimport urllib\nimport time\nimport cv2 as cv\nimport streamlit as st\n\nfrom plugins import Motion_Detection\nfrom utils import GUI, AppManager, DataManager\n\n#------------------------------------------------------#\n#------------------------------------------------------#\n\ndef imageWebApp(guiParam):\n    \"\"\"\n    \"\"\"\n    # Load the image according to the selected option\n    conf = DataManager(guiParam)\n    image = conf.load_image_or_video()\n    \n    # GUI\n    switchProcessing = st.button('* Start Processing *')\n\n    # Apply the selected plugin on the image\n    bboxed_frame, output = AppManager(guiParam).process(image, True)\n\n    # Display results\n    st.image(bboxed_frame, channels=\"BGR\",  use_column_width=True)\n\ndef main():\n    \"\"\"\n    \"\"\"\n    # Get the parameter entered by the user from the GUI\n    guiParam = GUI().getGuiParameters()\n\n    # Check if the application if it is Empty\n    if guiParam['appType'] == 'Image Applications':\n        if guiParam[\"selectedApp\"] is not 'Empty':\n            imageWebApp(guiParam)\n\n    else:\n        raise st.ScriptRunner.StopException\n\n#------------------------------------------------------#\n#------------------------------------------------------#\n\nif __name__ == \"__main__\":\n    main()\n```"
        }
      ],
      "blogListPaginated": [
        {
          "items": [
            "/2022/12/24/ab-mab-tests",
            "/2022/12/13/sql-to-snowflake-schema-conversion",
            "/2022/12/12/the-complete-python-course-2022",
            "/2022/11/16/opening-material",
            "/2021/10/01/clinical-decision-making",
            "/2021/10/01/detectron-2",
            "/2021/10/01/distributed-training-of-recommender-systems",
            "/2021/10/01/document-recommendation",
            "/2021/10/01/fake-voice-detection",
            "/2021/10/01/image-similarity-system"
          ],
          "metadata": {
            "permalink": "/blog",
            "page": 1,
            "postsPerPage": 10,
            "totalPages": 4,
            "totalCount": 31,
            "nextPage": "/blog/page/2",
            "blogDescription": "Blog",
            "blogTitle": "Blog"
          }
        },
        {
          "items": [
            "/2021/10/01/insurance-personalization",
            "/2021/10/01/name-&-address-parsing",
            "/2021/10/01/object-detection-hands-on-exercises",
            "/2021/10/01/object-detection-with-opencv",
            "/2021/10/01/object-detection-with-yolo3",
            "/2021/10/01/ocr-experiments",
            "/2021/10/01/pdf-to-wordcloud-via-mail",
            "/2021/10/01/personalized-unexpectedness-in-recommender-systems",
            "/2021/10/01/predicting-electronics-resale-price",
            "/2021/10/01/real-time-news-personalization-with-flink"
          ],
          "metadata": {
            "permalink": "/blog/page/2",
            "page": 2,
            "postsPerPage": 10,
            "totalPages": 4,
            "totalCount": 31,
            "previousPage": "/blog",
            "nextPage": "/blog/page/3",
            "blogDescription": "Blog",
            "blogTitle": "Blog"
          }
        },
        {
          "items": [
            "/2021/10/01/semantic-similarity",
            "/2021/10/01/short-video-background-music-recommender",
            "/2021/10/01/the-progression-of-analytics-in-enterprises",
            "/2021/10/01/tools-for-building-recommender-systems",
            "/2021/10/01/vehicle-suggestions",
            "/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
            "/2021/10/01/web-scraping-with-gazpacho",
            "/2021/10/01/wellness-tracker-chatbot",
            "/2021/10/01/what-is-livestream-ecommerce",
            "/2021/01/23/object-detection-with-yolo3"
          ],
          "metadata": {
            "permalink": "/blog/page/3",
            "page": 3,
            "postsPerPage": 10,
            "totalPages": 4,
            "totalCount": 31,
            "previousPage": "/blog/page/2",
            "nextPage": "/blog/page/4",
            "blogDescription": "Blog",
            "blogTitle": "Blog"
          }
        },
        {
          "items": [
            "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
          ],
          "metadata": {
            "permalink": "/blog/page/4",
            "page": 4,
            "postsPerPage": 10,
            "totalPages": 4,
            "totalCount": 31,
            "previousPage": "/blog/page/3",
            "blogDescription": "Blog",
            "blogTitle": "Blog"
          }
        }
      ],
      "blogTags": {
        "/blog/tags/mab": {
          "label": "mab",
          "items": [
            "/2022/12/24/ab-mab-tests"
          ],
          "permalink": "/blog/tags/mab",
          "pages": [
            {
              "items": [
                "/2022/12/24/ab-mab-tests"
              ],
              "metadata": {
                "permalink": "/blog/tags/mab",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/ab": {
          "label": "ab",
          "items": [
            "/2022/12/24/ab-mab-tests"
          ],
          "permalink": "/blog/tags/ab",
          "pages": [
            {
              "items": [
                "/2022/12/24/ab-mab-tests"
              ],
              "metadata": {
                "permalink": "/blog/tags/ab",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/snowflake": {
          "label": "snowflake",
          "items": [
            "/2022/12/13/sql-to-snowflake-schema-conversion"
          ],
          "permalink": "/blog/tags/snowflake",
          "pages": [
            {
              "items": [
                "/2022/12/13/sql-to-snowflake-schema-conversion"
              ],
              "metadata": {
                "permalink": "/blog/tags/snowflake",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/python": {
          "label": "python",
          "items": [
            "/2022/12/12/the-complete-python-course-2022"
          ],
          "permalink": "/blog/tags/python",
          "pages": [
            {
              "items": [
                "/2022/12/12/the-complete-python-course-2022"
              ],
              "metadata": {
                "permalink": "/blog/tags/python",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/course": {
          "label": "course",
          "items": [
            "/2022/12/12/the-complete-python-course-2022"
          ],
          "permalink": "/blog/tags/course",
          "pages": [
            {
              "items": [
                "/2022/12/12/the-complete-python-course-2022"
              ],
              "metadata": {
                "permalink": "/blog/tags/course",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/packtpublishing": {
          "label": "packtpublishing",
          "items": [
            "/2022/12/12/the-complete-python-course-2022"
          ],
          "permalink": "/blog/tags/packtpublishing",
          "pages": [
            {
              "items": [
                "/2022/12/12/the-complete-python-course-2022"
              ],
              "metadata": {
                "permalink": "/blog/tags/packtpublishing",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/docusaurus": {
          "label": "docusaurus",
          "items": [
            "/2022/11/16/opening-material"
          ],
          "permalink": "/blog/tags/docusaurus",
          "pages": [
            {
              "items": [
                "/2022/11/16/opening-material"
              ],
              "metadata": {
                "permalink": "/blog/tags/docusaurus",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/recohut": {
          "label": "recohut",
          "items": [
            "/2022/11/16/opening-material"
          ],
          "permalink": "/blog/tags/recohut",
          "pages": [
            {
              "items": [
                "/2022/11/16/opening-material"
              ],
              "metadata": {
                "permalink": "/blog/tags/recohut",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/dataengineering": {
          "label": "dataengineering",
          "items": [
            "/2022/11/16/opening-material"
          ],
          "permalink": "/blog/tags/dataengineering",
          "pages": [
            {
              "items": [
                "/2022/11/16/opening-material"
              ],
              "metadata": {
                "permalink": "/blog/tags/dataengineering",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/classification": {
          "label": "classification",
          "items": [
            "/2021/10/01/clinical-decision-making"
          ],
          "permalink": "/blog/tags/classification",
          "pages": [
            {
              "items": [
                "/2021/10/01/clinical-decision-making"
              ],
              "metadata": {
                "permalink": "/blog/tags/classification",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/healthcare": {
          "label": "healthcare",
          "items": [
            "/2021/10/01/clinical-decision-making",
            "/2021/10/01/wellness-tracker-chatbot"
          ],
          "permalink": "/blog/tags/healthcare",
          "pages": [
            {
              "items": [
                "/2021/10/01/clinical-decision-making",
                "/2021/10/01/wellness-tracker-chatbot"
              ],
              "metadata": {
                "permalink": "/blog/tags/healthcare",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 2,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/tool": {
          "label": "tool",
          "items": [
            "/2021/10/01/detectron-2",
            "/2021/10/01/tools-for-building-recommender-systems"
          ],
          "permalink": "/blog/tags/tool",
          "pages": [
            {
              "items": [
                "/2021/10/01/detectron-2",
                "/2021/10/01/tools-for-building-recommender-systems"
              ],
              "metadata": {
                "permalink": "/blog/tags/tool",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 2,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/vision": {
          "label": "vision",
          "items": [
            "/2021/10/01/detectron-2",
            "/2021/10/01/image-similarity-system",
            "/2021/10/01/object-detection-hands-on-exercises",
            "/2021/10/01/object-detection-with-opencv",
            "/2021/10/01/object-detection-with-yolo3",
            "/2021/10/01/ocr-experiments",
            "/2021/10/01/vehicle-suggestions",
            "/2021/01/23/object-detection-with-yolo3",
            "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
          ],
          "permalink": "/blog/tags/vision",
          "pages": [
            {
              "items": [
                "/2021/10/01/detectron-2",
                "/2021/10/01/image-similarity-system",
                "/2021/10/01/object-detection-hands-on-exercises",
                "/2021/10/01/object-detection-with-opencv",
                "/2021/10/01/object-detection-with-yolo3",
                "/2021/10/01/ocr-experiments",
                "/2021/10/01/vehicle-suggestions",
                "/2021/01/23/object-detection-with-yolo3",
                "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
              ],
              "metadata": {
                "permalink": "/blog/tags/vision",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 9,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/distributed": {
          "label": "distributed",
          "items": [
            "/2021/10/01/distributed-training-of-recommender-systems"
          ],
          "permalink": "/blog/tags/distributed",
          "pages": [
            {
              "items": [
                "/2021/10/01/distributed-training-of-recommender-systems"
              ],
              "metadata": {
                "permalink": "/blog/tags/distributed",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/recsys": {
          "label": "recsys",
          "items": [
            "/2021/10/01/distributed-training-of-recommender-systems",
            "/2021/10/01/short-video-background-music-recommender",
            "/2021/10/01/tools-for-building-recommender-systems"
          ],
          "permalink": "/blog/tags/recsys",
          "pages": [
            {
              "items": [
                "/2021/10/01/distributed-training-of-recommender-systems",
                "/2021/10/01/short-video-background-music-recommender",
                "/2021/10/01/tools-for-building-recommender-systems"
              ],
              "metadata": {
                "permalink": "/blog/tags/recsys",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 3,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/nlp": {
          "label": "nlp",
          "items": [
            "/2021/10/01/document-recommendation",
            "/2021/10/01/name-&-address-parsing",
            "/2021/10/01/semantic-similarity",
            "/2021/10/01/vehicle-suggestions",
            "/2021/10/01/wellness-tracker-chatbot"
          ],
          "permalink": "/blog/tags/nlp",
          "pages": [
            {
              "items": [
                "/2021/10/01/document-recommendation",
                "/2021/10/01/name-&-address-parsing",
                "/2021/10/01/semantic-similarity",
                "/2021/10/01/vehicle-suggestions",
                "/2021/10/01/wellness-tracker-chatbot"
              ],
              "metadata": {
                "permalink": "/blog/tags/nlp",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 5,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/similarity": {
          "label": "similarity",
          "items": [
            "/2021/10/01/document-recommendation",
            "/2021/10/01/image-similarity-system",
            "/2021/10/01/semantic-similarity",
            "/2021/10/01/vehicle-suggestions"
          ],
          "permalink": "/blog/tags/similarity",
          "pages": [
            {
              "items": [
                "/2021/10/01/document-recommendation",
                "/2021/10/01/image-similarity-system",
                "/2021/10/01/semantic-similarity",
                "/2021/10/01/vehicle-suggestions"
              ],
              "metadata": {
                "permalink": "/blog/tags/similarity",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 4,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/audio": {
          "label": "audio",
          "items": [
            "/2021/10/01/fake-voice-detection"
          ],
          "permalink": "/blog/tags/audio",
          "pages": [
            {
              "items": [
                "/2021/10/01/fake-voice-detection"
              ],
              "metadata": {
                "permalink": "/blog/tags/audio",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/deepfake": {
          "label": "deepfake",
          "items": [
            "/2021/10/01/fake-voice-detection"
          ],
          "permalink": "/blog/tags/deepfake",
          "pages": [
            {
              "items": [
                "/2021/10/01/fake-voice-detection"
              ],
              "metadata": {
                "permalink": "/blog/tags/deepfake",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/aws-beanstalk": {
          "label": "aws beanstalk",
          "items": [
            "/2021/10/01/image-similarity-system"
          ],
          "permalink": "/blog/tags/aws-beanstalk",
          "pages": [
            {
              "items": [
                "/2021/10/01/image-similarity-system"
              ],
              "metadata": {
                "permalink": "/blog/tags/aws-beanstalk",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/flask": {
          "label": "flask",
          "items": [
            "/2021/10/01/image-similarity-system",
            "/2021/10/01/name-&-address-parsing"
          ],
          "permalink": "/blog/tags/flask",
          "pages": [
            {
              "items": [
                "/2021/10/01/image-similarity-system",
                "/2021/10/01/name-&-address-parsing"
              ],
              "metadata": {
                "permalink": "/blog/tags/flask",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 2,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/insurance": {
          "label": "insurance",
          "items": [
            "/2021/10/01/insurance-personalization"
          ],
          "permalink": "/blog/tags/insurance",
          "pages": [
            {
              "items": [
                "/2021/10/01/insurance-personalization"
              ],
              "metadata": {
                "permalink": "/blog/tags/insurance",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/personalization": {
          "label": "personalization",
          "items": [
            "/2021/10/01/insurance-personalization",
            "/2021/10/01/personalized-unexpectedness-in-recommender-systems",
            "/2021/10/01/real-time-news-personalization-with-flink",
            "/2021/10/01/what-is-livestream-ecommerce"
          ],
          "permalink": "/blog/tags/personalization",
          "pages": [
            {
              "items": [
                "/2021/10/01/insurance-personalization",
                "/2021/10/01/personalized-unexpectedness-in-recommender-systems",
                "/2021/10/01/real-time-news-personalization-with-flink",
                "/2021/10/01/what-is-livestream-ecommerce"
              ],
              "metadata": {
                "permalink": "/blog/tags/personalization",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 4,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/app": {
          "label": "app",
          "items": [
            "/2021/10/01/name-&-address-parsing",
            "/2021/10/01/object-detection-with-yolo3",
            "/2021/01/23/object-detection-with-yolo3",
            "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
          ],
          "permalink": "/blog/tags/app",
          "pages": [
            {
              "items": [
                "/2021/10/01/name-&-address-parsing",
                "/2021/10/01/object-detection-with-yolo3",
                "/2021/01/23/object-detection-with-yolo3",
                "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
              ],
              "metadata": {
                "permalink": "/blog/tags/app",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 4,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/ner": {
          "label": "ner",
          "items": [
            "/2021/10/01/name-&-address-parsing"
          ],
          "permalink": "/blog/tags/ner",
          "pages": [
            {
              "items": [
                "/2021/10/01/name-&-address-parsing"
              ],
              "metadata": {
                "permalink": "/blog/tags/ner",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/object-detection": {
          "label": "object detection",
          "items": [
            "/2021/10/01/object-detection-hands-on-exercises",
            "/2021/10/01/object-detection-with-opencv"
          ],
          "permalink": "/blog/tags/object-detection",
          "pages": [
            {
              "items": [
                "/2021/10/01/object-detection-hands-on-exercises",
                "/2021/10/01/object-detection-with-opencv"
              ],
              "metadata": {
                "permalink": "/blog/tags/object-detection",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 2,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/opencv": {
          "label": "opencv",
          "items": [
            "/2021/10/01/object-detection-with-opencv"
          ],
          "permalink": "/blog/tags/opencv",
          "pages": [
            {
              "items": [
                "/2021/10/01/object-detection-with-opencv"
              ],
              "metadata": {
                "permalink": "/blog/tags/opencv",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/streamlit": {
          "label": "streamlit",
          "items": [
            "/2021/10/01/object-detection-with-yolo3",
            "/2021/01/23/object-detection-with-yolo3",
            "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
          ],
          "permalink": "/blog/tags/streamlit",
          "pages": [
            {
              "items": [
                "/2021/10/01/object-detection-with-yolo3",
                "/2021/01/23/object-detection-with-yolo3",
                "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
              ],
              "metadata": {
                "permalink": "/blog/tags/streamlit",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 3,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/ocr": {
          "label": "ocr",
          "items": [
            "/2021/10/01/ocr-experiments"
          ],
          "permalink": "/blog/tags/ocr",
          "pages": [
            {
              "items": [
                "/2021/10/01/ocr-experiments"
              ],
              "metadata": {
                "permalink": "/blog/tags/ocr",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/regression": {
          "label": "regression",
          "items": [
            "/2021/10/01/predicting-electronics-resale-price"
          ],
          "permalink": "/blog/tags/regression",
          "pages": [
            {
              "items": [
                "/2021/10/01/predicting-electronics-resale-price"
              ],
              "metadata": {
                "permalink": "/blog/tags/regression",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/realtime": {
          "label": "realtime",
          "items": [
            "/2021/10/01/real-time-news-personalization-with-flink"
          ],
          "permalink": "/blog/tags/realtime",
          "pages": [
            {
              "items": [
                "/2021/10/01/real-time-news-personalization-with-flink"
              ],
              "metadata": {
                "permalink": "/blog/tags/realtime",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/insight": {
          "label": "insight",
          "items": [
            "/2021/10/01/the-progression-of-analytics-in-enterprises"
          ],
          "permalink": "/blog/tags/insight",
          "pages": [
            {
              "items": [
                "/2021/10/01/the-progression-of-analytics-in-enterprises"
              ],
              "metadata": {
                "permalink": "/blog/tags/insight",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/scraping": {
          "label": "scraping",
          "items": [
            "/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
            "/2021/10/01/web-scraping-with-gazpacho"
          ],
          "permalink": "/blog/tags/scraping",
          "pages": [
            {
              "items": [
                "/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
                "/2021/10/01/web-scraping-with-gazpacho"
              ],
              "metadata": {
                "permalink": "/blog/tags/scraping",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 2,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/chatbot": {
          "label": "chatbot",
          "items": [
            "/2021/10/01/wellness-tracker-chatbot"
          ],
          "permalink": "/blog/tags/chatbot",
          "pages": [
            {
              "items": [
                "/2021/10/01/wellness-tracker-chatbot"
              ],
              "metadata": {
                "permalink": "/blog/tags/chatbot",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        },
        "/blog/tags/trend": {
          "label": "trend",
          "items": [
            "/2021/10/01/what-is-livestream-ecommerce"
          ],
          "permalink": "/blog/tags/trend",
          "pages": [
            {
              "items": [
                "/2021/10/01/what-is-livestream-ecommerce"
              ],
              "metadata": {
                "permalink": "/blog/tags/trend",
                "page": 1,
                "postsPerPage": 10,
                "totalPages": 1,
                "totalCount": 1,
                "blogDescription": "Blog",
                "blogTitle": "Blog"
              }
            }
          ]
        }
      },
      "blogTagsListPath": "/blog/tags"
    }
  },
  "docusaurus-plugin-content-pages": {
    "default": [
      {
        "type": "jsx",
        "permalink": "/",
        "source": "@site/src/pages/index.js"
      },
      {
        "type": "mdx",
        "permalink": "/markdown-page",
        "source": "@site/src/pages/markdown-page.md",
        "title": "Markdown page example",
        "description": "You don't need React to write simple standalone pages.",
        "frontMatter": {
          "title": "Markdown page example"
        }
      }
    ]
  },
  "docusaurus-plugin-debug": {},
  "docusaurus-plugin-google-gtag": {},
  "docusaurus-theme-classic": {},
  "@easyops-cn/docusaurus-search-local": {},
  "docusaurus-theme-github-codeblock": {},
  "docusaurus-theme-mermaid": {},
  "docusaurus-bootstrap-plugin": {},
  "docusaurus-mdx-fallback-plugin": {}
}